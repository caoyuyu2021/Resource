{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b9aa0d",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**时间序列预测前沿算法汇总Ⅱ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a49cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T03:21:48.263008Z",
     "start_time": "2024-05-08T03:21:41.912686Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-20T10:24:02.776085Z",
     "iopub.status.busy": "2024-04-20T10:24:02.775092Z",
     "iopub.status.idle": "2024-04-20T10:24:07.246771Z",
     "shell.execute_reply": "2024-04-20T10:24:07.245935Z",
     "shell.execute_reply.started": "2024-04-20T10:24:02.776085Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.fft as fft\n",
    "import os\n",
    "from tqdm import tqdm # 打印进度条\n",
    "import math\n",
    "from einops import rearrange, repeat, reduce\n",
    "from scipy.fftpack import next_fast_len\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "from functools import partial, wraps\n",
    "from sympy import Poly, legendre, Symbol, chebyshevt\n",
    "from scipy.special import eval_legendre\n",
    "from scipy import signal\n",
    "from torch.nn.modules.linear import Linear\n",
    "from operator import mul\n",
    "from typing import List\n",
    "from pandas.tseries import offsets\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "import joblib\n",
    "# 两种绘图接口\n",
    "import plotly_express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f85599",
   "metadata": {},
   "source": [
    "# 基于Crossformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2df08a",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c3731",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aff33a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:07:25.801132Z",
     "start_time": "2024-04-14T13:07:25.780850Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:35:53.666342Z",
     "iopub.status.busy": "2024-04-19T11:35:53.663341Z",
     "iopub.status.idle": "2024-04-19T11:35:53.701421Z",
     "shell.execute_reply": "2024-04-19T11:35:53.699742Z",
     "shell.execute_reply.started": "2024-04-19T11:35:53.666342Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6fa305a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:07:26.866013Z",
     "start_time": "2024-04-14T13:07:26.722686Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:35:54.379675Z",
     "iopub.status.busy": "2024-04-19T11:35:54.378636Z",
     "iopub.status.idle": "2024-04-19T11:35:54.481398Z",
     "shell.execute_reply": "2024-04-19T11:35:54.480436Z",
     "shell.execute_reply.started": "2024-04-19T11:35:54.379675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d4b202-992f-4370-bde2-f939d173e5ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T11:35:55.135355Z",
     "iopub.status.busy": "2024-04-19T11:35:55.134658Z",
     "iopub.status.idle": "2024-04-19T11:35:55.172388Z",
     "shell.execute_reply": "2024-04-19T11:35:55.171386Z",
     "shell.execute_reply.started": "2024-04-19T11:35:55.135355Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "960ea005",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:07:33.017950Z",
     "start_time": "2024-04-14T13:07:32.975597Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:35:56.085273Z",
     "iopub.status.busy": "2024-04-19T11:35:56.083310Z",
     "iopub.status.idle": "2024-04-19T11:35:56.119273Z",
     "shell.execute_reply": "2024-04-19T11:35:56.117297Z",
     "shell.execute_reply.started": "2024-04-19T11:35:56.085273Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "893c75d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:07:34.013901Z",
     "start_time": "2024-04-14T13:07:33.922063Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:35:57.567497Z",
     "iopub.status.busy": "2024-04-19T11:35:57.564066Z",
     "iopub.status.idle": "2024-04-19T11:35:57.661546Z",
     "shell.execute_reply": "2024-04-19T11:35:57.660582Z",
     "shell.execute_reply.started": "2024-04-19T11:35:57.567497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/Crossformer'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fecd39e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:07:35.137838Z",
     "start_time": "2024-04-14T13:07:35.117710Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:36:08.262927Z",
     "iopub.status.busy": "2024-04-19T11:36:08.261924Z",
     "iopub.status.idle": "2024-04-19T11:36:08.283552Z",
     "shell.execute_reply": "2024-04-19T11:36:08.282555Z",
     "shell.execute_reply.started": "2024-04-19T11:36:08.262927Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a52dd2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:07:37.115398Z",
     "start_time": "2024-04-14T13:07:36.247176Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:36:16.923191Z",
     "iopub.status.busy": "2024-04-19T11:36:16.922191Z",
     "iopub.status.idle": "2024-04-19T11:36:18.216140Z",
     "shell.execute_reply": "2024-04-19T11:36:18.215226Z",
     "shell.execute_reply.started": "2024-04-19T11:36:16.922191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 0,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391071f0",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c56b6f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:09:59.790415Z",
     "start_time": "2024-04-14T13:09:59.719045Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:36:22.158576Z",
     "iopub.status.busy": "2024-04-19T11:36:22.157981Z",
     "iopub.status.idle": "2024-04-19T11:36:22.242412Z",
     "shell.execute_reply": "2024-04-19T11:36:22.241448Z",
     "shell.execute_reply.started": "2024-04-19T11:36:22.158576Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "    \n",
    "    \n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, patch_len, stride, padding, dropout):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "        # Patching\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch_layer = nn.ReplicationPad1d((0, padding))\n",
    "\n",
    "        # Backbone, Input encoding: projection of feature vectors onto a d-dim vector space\n",
    "        self.value_embedding = nn.Linear(patch_len, d_model, bias=False)\n",
    "\n",
    "        # Positional embedding\n",
    "        self.position_embedding = PositionalEmbedding(d_model)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # do patching\n",
    "        n_vars = x.shape[1]\n",
    "        x = self.padding_patch_layer(x)\n",
    "        x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
    "        x = torch.reshape(x, (x.shape[0] * x.shape[1], x.shape[2], x.shape[3]))\n",
    "        # Input encoding\n",
    "        x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        return self.dropout(x), n_vars\n",
    "    \n",
    "    \n",
    "class TwoStageAttentionLayer(nn.Module):\n",
    "    '''\n",
    "    The Two Stage Attention (TSA) Layer\n",
    "    input/output shape: [batch_size, Data_dim(D), Seg_num(L), d_model]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, seg_num, factor, d_model, n_heads, output_attention, d_ff=None, dropout=0.1):\n",
    "        super(TwoStageAttentionLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.time_attention = AttentionLayer(FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                                           output_attention=output_attention), d_model, n_heads)\n",
    "        self.dim_sender = AttentionLayer(FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                                       output_attention=output_attention), d_model, n_heads)\n",
    "        self.dim_receiver = AttentionLayer(FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                                         output_attention=output_attention), d_model, n_heads)\n",
    "        self.router = nn.Parameter(torch.randn(seg_num, factor, d_model))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.norm4 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.MLP1 = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_ff, d_model))\n",
    "        self.MLP2 = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_ff, d_model))\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # Cross Time Stage: Directly apply MSA to each dimension\n",
    "        batch = x.shape[0]\n",
    "        time_in = rearrange(x, 'b ts_d seg_num d_model -> (b ts_d) seg_num d_model')\n",
    "        time_enc, attn = self.time_attention(\n",
    "            time_in, time_in, time_in, attn_mask=None, tau=None, delta=None\n",
    "        )\n",
    "        dim_in = time_in + self.dropout(time_enc)\n",
    "        dim_in = self.norm1(dim_in)\n",
    "        dim_in = dim_in + self.dropout(self.MLP1(dim_in))\n",
    "        dim_in = self.norm2(dim_in)\n",
    "\n",
    "        # Cross Dimension Stage: use a small set of learnable vectors to aggregate and distribute messages to build the D-to-D connection\n",
    "        dim_send = rearrange(dim_in, '(b ts_d) seg_num d_model -> (b seg_num) ts_d d_model', b=batch)\n",
    "        batch_router = repeat(self.router, 'seg_num factor d_model -> (repeat seg_num) factor d_model', repeat=batch)\n",
    "        dim_buffer, attn = self.dim_sender(batch_router, dim_send, dim_send, attn_mask=None, tau=None, delta=None)\n",
    "        dim_receive, attn = self.dim_receiver(dim_send, dim_buffer, dim_buffer, attn_mask=None, tau=None, delta=None)\n",
    "        dim_enc = dim_send + self.dropout(dim_receive)\n",
    "        dim_enc = self.norm3(dim_enc)\n",
    "        dim_enc = dim_enc + self.dropout(self.MLP2(dim_enc))\n",
    "        dim_enc = self.norm4(dim_enc)\n",
    "\n",
    "        final_out = rearrange(dim_enc, '(b seg_num) ts_d d_model -> b ts_d seg_num d_model', b=batch)\n",
    "\n",
    "        return final_out\n",
    "\n",
    "    \n",
    "class SegMerging(nn.Module):\n",
    "    def __init__(self, d_model, win_size, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.win_size = win_size\n",
    "        self.linear_trans = nn.Linear(win_size * d_model, d_model)\n",
    "        self.norm = norm_layer(win_size * d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, ts_d, seg_num, d_model = x.shape\n",
    "        pad_num = seg_num % self.win_size\n",
    "        if pad_num != 0:\n",
    "            pad_num = self.win_size - pad_num\n",
    "            x = torch.cat((x, x[:, :, -pad_num:, :]), dim=-2)\n",
    "\n",
    "        seg_to_merge = []\n",
    "        for i in range(self.win_size):\n",
    "            seg_to_merge.append(x[:, :, i::self.win_size, :])\n",
    "        x = torch.cat(seg_to_merge, -1)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.linear_trans(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class scale_block(nn.Module):\n",
    "    def __init__(self, win_size, d_model, n_heads, d_ff, depth, dropout, output_attention, \n",
    "                 seg_num=10, factor=10):\n",
    "        super(scale_block, self).__init__()\n",
    "\n",
    "        if win_size > 1:\n",
    "            self.merge_layer = SegMerging(d_model, win_size, nn.LayerNorm)\n",
    "        else:\n",
    "            self.merge_layer = None\n",
    "\n",
    "        self.encode_layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.encode_layers.append(TwoStageAttentionLayer(seg_num, factor, d_model, n_heads, output_attention, \n",
    "                                                             d_ff, dropout))\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        _, ts_dim, _, _ = x.shape\n",
    "\n",
    "        if self.merge_layer is not None:\n",
    "            x = self.merge_layer(x)\n",
    "\n",
    "        for layer in self.encode_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x, None\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encode_blocks = nn.ModuleList(attn_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encode_x = []\n",
    "        encode_x.append(x)\n",
    "\n",
    "        for block in self.encode_blocks:\n",
    "            x, attns = block(x)\n",
    "            encode_x.append(x)\n",
    "\n",
    "        return encode_x, None\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, seg_len, d_model, d_ff=None, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.MLP1 = nn.Sequential(nn.Linear(d_model, d_model),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_model, d_model))\n",
    "        self.linear_pred = nn.Linear(d_model, seg_len)\n",
    "\n",
    "    def forward(self, x, cross):\n",
    "        batch = x.shape[0]\n",
    "        x = self.self_attention(x)\n",
    "        x = rearrange(x, 'b ts_d out_seg_num d_model -> (b ts_d) out_seg_num d_model')\n",
    "\n",
    "        cross = rearrange(cross, 'b ts_d in_seg_num d_model -> (b ts_d) in_seg_num d_model')\n",
    "        tmp, attn = self.cross_attention(x, cross, cross, None, None, None,)\n",
    "        x = x + self.dropout(tmp)\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.MLP1(y)\n",
    "        dec_output = self.norm2(x + y)\n",
    "\n",
    "        dec_output = rearrange(dec_output, '(b ts_d) seg_dec_num d_model -> b ts_d seg_dec_num d_model', b=batch)\n",
    "        layer_predict = self.linear_pred(dec_output)\n",
    "        layer_predict = rearrange(layer_predict, 'b out_d seg_num seg_len -> b (out_d seg_num) seg_len')\n",
    "\n",
    "        return dec_output, layer_predict\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decode_layers = nn.ModuleList(layers)\n",
    "\n",
    "\n",
    "    def forward(self, x, cross):\n",
    "        final_predict = None\n",
    "        i = 0\n",
    "\n",
    "        ts_d = x.shape[1]\n",
    "        for layer in self.decode_layers:\n",
    "            cross_enc = cross[i]\n",
    "            x, layer_predict = layer(x, cross_enc)\n",
    "            if final_predict is None:\n",
    "                final_predict = layer_predict\n",
    "            else:\n",
    "                final_predict = final_predict + layer_predict\n",
    "            i += 1\n",
    "\n",
    "        final_predict = rearrange(final_predict, 'b (out_d seg_num) seg_len -> b (seg_num seg_len) out_d', out_d=ts_d)\n",
    "\n",
    "        return final_predict\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "    \n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "        \n",
    "        \n",
    "class FlattenHead(nn.Module):\n",
    "    def __init__(self, n_vars, nf, target_window, head_dropout=0):\n",
    "        super().__init__()\n",
    "        self.n_vars = n_vars\n",
    "        self.flatten = nn.Flatten(start_dim=-2)\n",
    "        self.linear = nn.Linear(nf, target_window)\n",
    "        self.dropout = nn.Dropout(head_dropout)\n",
    "\n",
    "    def forward(self, x):  # x: [bs x nvars x d_model x patch_num]\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "# Crossformer模型\n",
    "class Crossformer(nn.Module):\n",
    "    def __init__(self, enc_in, seq_len, pred_len, label_len, e_layers, d_layers, d_model, \n",
    "                 output_attention, n_heads, d_ff, dropout, factor):\n",
    "        super(Crossformer, self).__init__()\n",
    "        self.enc_in = enc_in\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.seg_len = 12\n",
    "        self.win_size = 2\n",
    "\n",
    "        # The padding operation to handle invisible sgemnet length\n",
    "        self.pad_in_len = math.ceil(1.0 * seq_len / self.seg_len) * self.seg_len\n",
    "        self.pad_out_len = math.ceil(1.0 * pred_len / self.seg_len) * self.seg_len\n",
    "        self.in_seg_num = self.pad_in_len // self.seg_len\n",
    "        self.out_seg_num = math.ceil(self.in_seg_num / (self.win_size ** (e_layers - 1)))\n",
    "        self.head_nf = d_model * self.out_seg_num\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_value_embedding = PatchEmbedding(d_model, self.seg_len, self.seg_len, self.pad_in_len - seq_len, 0)\n",
    "        self.enc_pos_embedding = nn.Parameter(\n",
    "            torch.randn(1, enc_in, self.in_seg_num, d_model))\n",
    "        self.pre_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                scale_block(1 if l is 0 else self.win_size, d_model, n_heads, d_ff, 1, dropout, output_attention, \n",
    "                            self.in_seg_num if l is 0 else math.ceil(self.in_seg_num / self.win_size ** l), factor\n",
    "                            ) for l in range(e_layers)\n",
    "            ]\n",
    "        )\n",
    "        # Decoder\n",
    "        self.dec_pos_embedding = nn.Parameter(\n",
    "            torch.randn(1, enc_in, (self.pad_out_len // self.seg_len), d_model))\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    TwoStageAttentionLayer((self.pad_out_len // self.seg_len), factor, d_model, n_heads, output_attention,\n",
    "                                           d_ff, dropout),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout, output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    self.seg_len,\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    # activation=configs.activation,\n",
    "                )\n",
    "                for l in range(d_layers + 1)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # embedding\n",
    "        x_enc, n_vars = self.enc_value_embedding(x_enc.permute(0, 2, 1))\n",
    "        x_enc = rearrange(x_enc, '(b d) seg_num d_model -> b d seg_num d_model', d = n_vars)\n",
    "        x_enc += self.enc_pos_embedding\n",
    "        x_enc = self.pre_norm(x_enc)\n",
    "        enc_out, attns = self.encoder(x_enc)\n",
    "\n",
    "        dec_in = repeat(self.dec_pos_embedding, 'b ts_d l d -> (repeat b) ts_d l d', repeat=x_enc.shape[0])\n",
    "        dec_out = self.decoder(dec_in, enc_out)\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f0c58",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f44a61ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:10:01.927297Z",
     "start_time": "2024-04-14T13:10:01.882785Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:36:33.180482Z",
     "iopub.status.busy": "2024-04-19T11:36:33.180482Z",
     "iopub.status.idle": "2024-04-19T11:36:33.227248Z",
     "shell.execute_reply": "2024-04-19T11:36:33.226246Z",
     "shell.execute_reply.started": "2024-04-19T11:36:33.180482Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0092e7e1-cccd-40f9-bfbd-5eea2a982ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T11:37:23.394157Z",
     "iopub.status.busy": "2024-04-19T11:37:23.394157Z",
     "iopub.status.idle": "2024-04-19T11:46:19.097818Z",
     "shell.execute_reply": "2024-04-19T11:46:19.096931Z",
     "shell.execute_reply.started": "2024-04-19T11:37:23.394157Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:29<09:12, 29.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0220, Validation Loss: 0.0039\n",
      "Validation loss decreased (inf --> 0.003853).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:54<08:07, 27.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0046, Validation Loss: 0.0029\n",
      "Validation loss decreased (0.003853 --> 0.002911).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [01:21<07:35, 26.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0034, Validation Loss: 0.0020\n",
      "Validation loss decreased (0.002911 --> 0.001994).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [01:47<07:07, 26.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0028, Validation Loss: 0.0032\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [02:14<06:39, 26.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0022, Validation Loss: 0.0014\n",
      "Validation loss decreased (0.001994 --> 0.001436).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [02:40<06:11, 26.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0020, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.001436 --> 0.001091).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [03:07<05:44, 26.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0018, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.001091 --> 0.001084).  Saving model ...\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [03:32<05:15, 26.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0016, Validation Loss: 0.0008\n",
      "Validation loss decreased (0.001084 --> 0.000832).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                             | 9/20 [03:59<04:49, 26.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0015, Validation Loss: 0.0009\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 10/20 [04:26<04:24, 26.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0013, Validation Loss: 0.0007\n",
      "Validation loss decreased (0.000832 --> 0.000730).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████                                     | 11/20 [04:52<03:58, 26.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0013, Validation Loss: 0.0008\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [05:20<03:34, 26.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0012, Validation Loss: 0.0008\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [05:45<03:05, 26.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0011, Validation Loss: 0.0007\n",
      "Validation loss decreased (0.000730 --> 0.000661).  Saving model ...\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [06:12<02:39, 26.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0011, Validation Loss: 0.0008\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [06:40<02:14, 26.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0010, Validation Loss: 0.0006\n",
      "Validation loss decreased (0.000661 --> 0.000638).  Saving model ...\n",
      "Updating learning rate to 0.00014644660940672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [07:07<01:48, 27.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0010, Validation Loss: 0.0006\n",
      "Validation loss decreased (0.000638 --> 0.000611).  Saving model ...\n",
      "Updating learning rate to 9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [07:34<01:20, 26.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0010, Validation Loss: 0.0006\n",
      "Validation loss decreased (0.000611 --> 0.000605).  Saving model ...\n",
      "Updating learning rate to 5.449673790581611e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [08:01<00:53, 26.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0009, Validation Loss: 0.0006\n",
      "Validation loss decreased (0.000605 --> 0.000593).  Saving model ...\n",
      "Updating learning rate to 2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [08:27<00:26, 26.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0009, Validation Loss: 0.0006\n",
      "Validation loss decreased (0.000593 --> 0.000587).  Saving model ...\n",
      "Updating learning rate to 6.15582970243117e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [08:54<00:00, 26.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0009, Validation Loss: 0.0006\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Crossformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/Crossformer\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'label_len': 0,\n",
    "        'output_attention': False,\n",
    "        'd_model': 32,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 32,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'factor': 3\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795bcea",
   "metadata": {},
   "source": [
    "# 基于ETSformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b3b4c",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f458f952",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea9a8c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:17:14.770003Z",
     "start_time": "2024-04-14T13:17:14.751557Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:46:46.555698Z",
     "iopub.status.busy": "2024-04-19T11:46:46.554686Z",
     "iopub.status.idle": "2024-04-19T11:46:46.575366Z",
     "shell.execute_reply": "2024-04-19T11:46:46.574399Z",
     "shell.execute_reply.started": "2024-04-19T11:46:46.555698Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2b06190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:17:15.580590Z",
     "start_time": "2024-04-14T13:17:15.513934Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:46:47.242676Z",
     "iopub.status.busy": "2024-04-19T11:46:47.241656Z",
     "iopub.status.idle": "2024-04-19T11:46:47.343622Z",
     "shell.execute_reply": "2024-04-19T11:46:47.342619Z",
     "shell.execute_reply.started": "2024-04-19T11:46:47.242676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d134ab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:17:16.764466Z",
     "start_time": "2024-04-14T13:17:16.723570Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:46:48.123232Z",
     "iopub.status.busy": "2024-04-19T11:46:48.122231Z",
     "iopub.status.idle": "2024-04-19T11:46:48.170218Z",
     "shell.execute_reply": "2024-04-19T11:46:48.168259Z",
     "shell.execute_reply.started": "2024-04-19T11:46:48.123232Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d722833-05d9-4e0c-ad31-b320159e1b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T11:46:48.879231Z",
     "iopub.status.busy": "2024-04-19T11:46:48.877278Z",
     "iopub.status.idle": "2024-04-19T11:46:48.921582Z",
     "shell.execute_reply": "2024-04-19T11:46:48.920667Z",
     "shell.execute_reply.started": "2024-04-19T11:46:48.879231Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5e38278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:17:17.829968Z",
     "start_time": "2024-04-14T13:17:17.755630Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:46:50.609927Z",
     "iopub.status.busy": "2024-04-19T11:46:50.608933Z",
     "iopub.status.idle": "2024-04-19T11:46:50.690280Z",
     "shell.execute_reply": "2024-04-19T11:46:50.688934Z",
     "shell.execute_reply.started": "2024-04-19T11:46:50.609927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/ETSformer'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8620e43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:17:19.221166Z",
     "start_time": "2024-04-14T13:17:19.200105Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:46:52.446376Z",
     "iopub.status.busy": "2024-04-19T11:46:52.444398Z",
     "iopub.status.idle": "2024-04-19T11:46:52.476550Z",
     "shell.execute_reply": "2024-04-19T11:46:52.475489Z",
     "shell.execute_reply.started": "2024-04-19T11:46:52.445333Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd9450fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:17:20.854727Z",
     "start_time": "2024-04-14T13:17:20.005614Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:46:53.773251Z",
     "iopub.status.busy": "2024-04-19T11:46:53.771249Z",
     "iopub.status.idle": "2024-04-19T11:46:54.970954Z",
     "shell.execute_reply": "2024-04-19T11:46:54.969954Z",
     "shell.execute_reply.started": "2024-04-19T11:46:53.773251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 0,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51480be9",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86260892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:03.743409Z",
     "start_time": "2024-04-14T13:20:03.647178Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:46:56.338069Z",
     "iopub.status.busy": "2024-04-19T11:46:56.335514Z",
     "iopub.status.idle": "2024-04-19T11:46:56.454117Z",
     "shell.execute_reply": "2024-04-19T11:46:56.453117Z",
     "shell.execute_reply.started": "2024-04-19T11:46:56.337532Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        second_size = 2\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.second_size = Embed(second_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        second_x = self.second_size(x[:, :, 5])\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x + second_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# 编码器和解码器\n",
    "class Transform:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def transform(self, x):\n",
    "        return self.jitter(self.shift(self.scale(x)))\n",
    "\n",
    "    def jitter(self, x):\n",
    "        return x + (torch.randn(x.shape).to(x.device) * self.sigma)\n",
    "\n",
    "    def scale(self, x):\n",
    "        return x * (torch.randn(x.size(-1)).to(x.device) * self.sigma + 1)\n",
    "\n",
    "    def shift(self, x):\n",
    "        return x + (torch.randn(x.size(-1)).to(x.device) * self.sigma)\n",
    "\n",
    "\n",
    "def conv1d_fft(f, g, dim=-1):\n",
    "    N = f.size(dim)\n",
    "    M = g.size(dim)\n",
    "\n",
    "    fast_len = next_fast_len(N + M - 1)\n",
    "\n",
    "    F_f = fft.rfft(f, fast_len, dim=dim)\n",
    "    F_g = fft.rfft(g, fast_len, dim=dim)\n",
    "\n",
    "    F_fg = F_f * F_g.conj()\n",
    "    out = fft.irfft(F_fg, fast_len, dim=dim)\n",
    "    out = out.roll((-1,), dims=(dim,))\n",
    "    idx = torch.as_tensor(range(fast_len - N, fast_len)).to(out.device)\n",
    "    out = out.index_select(dim, idx)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class ExponentialSmoothing(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, nhead, dropout=0.1, aux=False):\n",
    "        super().__init__()\n",
    "        self._smoothing_weight = nn.Parameter(torch.randn(nhead, 1))\n",
    "        self.v0 = nn.Parameter(torch.randn(1, 1, nhead, dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if aux:\n",
    "            self.aux_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, values, aux_values=None):\n",
    "        b, t, h, d = values.shape\n",
    "\n",
    "        init_weight, weight = self.get_exponential_weight(t)\n",
    "        output = conv1d_fft(self.dropout(values), weight, dim=1)\n",
    "        output = init_weight * self.v0 + output\n",
    "\n",
    "        if aux_values is not None:\n",
    "            aux_weight = weight / (1 - self.weight) * self.weight\n",
    "            aux_output = conv1d_fft(self.aux_dropout(aux_values), aux_weight)\n",
    "            output = output + aux_output\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_exponential_weight(self, T):\n",
    "        # Generate array [0, 1, ..., T-1]\n",
    "        powers = torch.arange(T, dtype=torch.float, device=self.weight.device)\n",
    "\n",
    "        # (1 - \\alpha) * \\alpha^t, for all t = T-1, T-2, ..., 0]\n",
    "        weight = (1 - self.weight) * (self.weight ** torch.flip(powers, dims=(0,)))\n",
    "\n",
    "        # \\alpha^t for all t = 1, 2, ..., T\n",
    "        init_weight = self.weight ** (powers + 1)\n",
    "\n",
    "        return rearrange(init_weight, 'h t -> 1 t h 1'), \\\n",
    "               rearrange(weight, 'h t -> 1 t h 1')\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return torch.sigmoid(self._smoothing_weight)\n",
    "\n",
    "\n",
    "class Feedforward(nn.Module):\n",
    "    def __init__(self, d_model, dim_feedforward, dropout=0.1, activation='sigmoid'):\n",
    "        # Implementation of Feedforward model\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward, bias=False)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model, bias=False)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = getattr(F, activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear2(self.dropout1(self.activation(self.linear1(x))))\n",
    "        return self.dropout2(x)\n",
    "\n",
    "\n",
    "class GrowthLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, d_head=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head or (d_model // nhead)\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "\n",
    "        self.z0 = nn.Parameter(torch.randn(self.nhead, self.d_head))\n",
    "        self.in_proj = nn.Linear(self.d_model, self.d_head * self.nhead)\n",
    "        self.es = ExponentialSmoothing(self.d_head, self.nhead, dropout=dropout)\n",
    "        self.out_proj = nn.Linear(self.d_head * self.nhead, self.d_model)\n",
    "\n",
    "        assert self.d_head * self.nhead == self.d_model, \"d_model must be divisible by nhead\"\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        :param inputs: shape: (batch, seq_len, dim)\n",
    "        :return: shape: (batch, seq_len, dim)\n",
    "        \"\"\"\n",
    "        b, t, d = inputs.shape\n",
    "        values = self.in_proj(inputs).view(b, t, self.nhead, -1)\n",
    "        values = torch.cat([repeat(self.z0, 'h d -> b 1 h d', b=b), values], dim=1)\n",
    "        values = values[:, 1:] - values[:, :-1]\n",
    "        out = self.es(values)\n",
    "        out = torch.cat([repeat(self.es.v0, '1 1 h d -> b 1 h d', b=b), out], dim=1)\n",
    "        out = rearrange(out, 'b t h d -> b t (h d)')\n",
    "        return self.out_proj(out)\n",
    "\n",
    "\n",
    "class FourierLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, pred_len, k=None, low_freq=1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pred_len = pred_len\n",
    "        self.k = k\n",
    "        self.low_freq = low_freq\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: (b, t, d)\"\"\"\n",
    "        b, t, d = x.shape\n",
    "        x_freq = fft.rfft(x, dim=1)\n",
    "\n",
    "        if t % 2 == 0:\n",
    "            x_freq = x_freq[:, self.low_freq:-1]\n",
    "            f = fft.rfftfreq(t)[self.low_freq:-1]\n",
    "        else:\n",
    "            x_freq = x_freq[:, self.low_freq:]\n",
    "            f = fft.rfftfreq(t)[self.low_freq:]\n",
    "\n",
    "        x_freq, index_tuple = self.topk_freq(x_freq)\n",
    "        f = repeat(f, 'f -> b f d', b=x_freq.size(0), d=x_freq.size(2)).to(x_freq.device)\n",
    "        f = rearrange(f[index_tuple], 'b f d -> b f () d').to(x_freq.device)\n",
    "\n",
    "        return self.extrapolate(x_freq, f, t)\n",
    "\n",
    "    def extrapolate(self, x_freq, f, t):\n",
    "        x_freq = torch.cat([x_freq, x_freq.conj()], dim=1)\n",
    "        f = torch.cat([f, -f], dim=1)\n",
    "        t_val = rearrange(torch.arange(t + self.pred_len, dtype=torch.float),\n",
    "                          't -> () () t ()').to(x_freq.device)\n",
    "\n",
    "        amp = rearrange(x_freq.abs() / t, 'b f d -> b f () d')\n",
    "        phase = rearrange(x_freq.angle(), 'b f d -> b f () d')\n",
    "\n",
    "        x_time = amp * torch.cos(2 * math.pi * f * t_val + phase)\n",
    "\n",
    "        return reduce(x_time, 'b f t d -> b t d', 'sum')\n",
    "\n",
    "    def topk_freq(self, x_freq):\n",
    "        values, indices = torch.topk(x_freq.abs(), self.k, dim=1, largest=True, sorted=True)\n",
    "        mesh_a, mesh_b = torch.meshgrid(torch.arange(x_freq.size(0)), torch.arange(x_freq.size(2)))\n",
    "        index_tuple = (mesh_a.unsqueeze(1), indices, mesh_b.unsqueeze(1))\n",
    "        x_freq = x_freq[index_tuple]\n",
    "\n",
    "        return x_freq, index_tuple\n",
    "\n",
    "\n",
    "class LevelLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, c_out, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.c_out = c_out\n",
    "\n",
    "        self.es = ExponentialSmoothing(1, self.c_out, dropout=dropout, aux=True)\n",
    "        self.growth_pred = nn.Linear(self.d_model, self.c_out)\n",
    "        self.season_pred = nn.Linear(self.d_model, self.c_out)\n",
    "\n",
    "    def forward(self, level, growth, season):\n",
    "        b, t, _ = level.shape\n",
    "        growth = self.growth_pred(growth).view(b, t, self.c_out, 1)\n",
    "        season = self.season_pred(season).view(b, t, self.c_out, 1)\n",
    "        growth = growth.view(b, t, self.c_out, 1)\n",
    "        season = season.view(b, t, self.c_out, 1)\n",
    "        level = level.view(b, t, self.c_out, 1)\n",
    "        out = self.es(level - season, aux_values=growth)\n",
    "        out = rearrange(out, 'b t h d -> b t (h d)')\n",
    "        return out\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, c_out, seq_len, pred_len, k, dim_feedforward=None, dropout=0.1,\n",
    "                 activation='sigmoid', layer_norm_eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.c_out = c_out\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        dim_feedforward = dim_feedforward or 4 * d_model\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.growth_layer = GrowthLayer(d_model, nhead, dropout=dropout)\n",
    "        self.seasonal_layer = FourierLayer(d_model, pred_len, k=k)\n",
    "        self.level_layer = LevelLayer(d_model, c_out, dropout=dropout)\n",
    "\n",
    "        # Implementation of Feedforward model\n",
    "        self.ff = Feedforward(d_model, dim_feedforward, dropout=dropout, activation=activation)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, res, level, attn_mask=None):\n",
    "        season = self._season_block(res)\n",
    "        res = res - season[:, :-self.pred_len]\n",
    "        growth = self._growth_block(res)\n",
    "        res = self.norm1(res - growth[:, 1:])\n",
    "        res = self.norm2(res + self.ff(res))\n",
    "\n",
    "        level = self.level_layer(level, growth[:, :-1], season[:, :-self.pred_len])\n",
    "        return res, level, growth, season\n",
    "\n",
    "    def _growth_block(self, x):\n",
    "        x = self.growth_layer(x)\n",
    "        return self.dropout1(x)\n",
    "\n",
    "    def _season_block(self, x):\n",
    "        x = self.seasonal_layer(x)\n",
    "        return self.dropout2(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, res, level, attn_mask=None):\n",
    "        growths = []\n",
    "        seasons = []\n",
    "        for layer in self.layers:\n",
    "            res, level, growth, season = layer(res, level, attn_mask=None)\n",
    "            growths.append(growth)\n",
    "            seasons.append(season)\n",
    "\n",
    "        return level, growths, seasons\n",
    "\n",
    "\n",
    "class DampingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, pred_len, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.nhead = nhead\n",
    "        self._damping_factor = nn.Parameter(torch.randn(1, nhead))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = repeat(x, 'b 1 d -> b t d', t=self.pred_len)\n",
    "        b, t, d = x.shape\n",
    "\n",
    "        powers = torch.arange(self.pred_len).to(self._damping_factor.device) + 1\n",
    "        powers = powers.view(self.pred_len, 1)\n",
    "        damping_factors = self.damping_factor ** powers\n",
    "        damping_factors = damping_factors.cumsum(dim=0)\n",
    "        x = x.view(b, t, self.nhead, -1)\n",
    "        x = self.dropout(x) * damping_factors.unsqueeze(-1)\n",
    "        return x.view(b, t, d)\n",
    "\n",
    "    @property\n",
    "    def damping_factor(self):\n",
    "        return torch.sigmoid(self._damping_factor)\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, c_out, pred_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.c_out = c_out\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        self.growth_damping = DampingLayer(pred_len, nhead, dropout=dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, growth, season):\n",
    "        growth_horizon = self.growth_damping(growth[:, -1:])\n",
    "        growth_horizon = self.dropout1(growth_horizon)\n",
    "\n",
    "        seasonal_horizon = season[:, -self.pred_len:]\n",
    "        return growth_horizon, seasonal_horizon\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.d_model = layers[0].d_model\n",
    "        self.c_out = layers[0].c_out\n",
    "        self.pred_len = layers[0].pred_len\n",
    "        self.nhead = layers[0].nhead\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.pred = nn.Linear(self.d_model, self.c_out)\n",
    "\n",
    "    def forward(self, growths, seasons):\n",
    "        growth_repr = []\n",
    "        season_repr = []\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            growth_horizon, season_horizon = layer(growths[idx], seasons[idx])\n",
    "            growth_repr.append(growth_horizon)\n",
    "            season_repr.append(season_horizon)\n",
    "        growth_repr = sum(growth_repr)\n",
    "        season_repr = sum(season_repr)\n",
    "        return self.pred(growth_repr), self.pred(season_repr)\n",
    "\n",
    "    \n",
    "# ETSformer模型\n",
    "class ETSformer(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, label_len, e_layers, d_layers, enc_in, d_model, \n",
    "                 dropout, n_heads, top_k, d_ff, c_out, embed, freq):\n",
    "        super(ETSformer, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        assert e_layers == d_layers, \"Encoder and decoder layers must be equal\"\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    d_model, n_heads, enc_in, seq_len, pred_len, top_k,\n",
    "                    dim_feedforward=d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                ) for _ in range(e_layers)\n",
    "            ]\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    d_model, n_heads, c_out, pred_len,\n",
    "                    dropout=dropout,\n",
    "                ) for _ in range(d_layers)\n",
    "            ],\n",
    "        )\n",
    "        self.transform = Transform(sigma=0.2)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        with torch.no_grad():\n",
    "            if self.training:\n",
    "                x_enc = self.transform.transform(x_enc)\n",
    "        res = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        level, growths, seasons = self.encoder(res, x_enc, attn_mask=None)\n",
    "\n",
    "        growth, season = self.decoder(growths, seasons)\n",
    "        dec_out = level[:, -1:] + growth + season\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e272698",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "829705a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:06.029678Z",
     "start_time": "2024-04-14T13:20:05.986678Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:46:58.142122Z",
     "iopub.status.busy": "2024-04-19T11:46:58.140482Z",
     "iopub.status.idle": "2024-04-19T11:46:58.220101Z",
     "shell.execute_reply": "2024-04-19T11:46:58.219101Z",
     "shell.execute_reply.started": "2024-04-19T11:46:58.142122Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de64bf6b-070b-417d-a8c2-c8f7b1c60466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T11:47:00.764493Z",
     "iopub.status.busy": "2024-04-19T11:47:00.762489Z",
     "iopub.status.idle": "2024-04-19T11:48:59.675414Z",
     "shell.execute_reply": "2024-04-19T11:48:59.674446Z",
     "shell.execute_reply.started": "2024-04-19T11:47:00.763492Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:16<05:08, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0704, Validation Loss: 0.0131\n",
      "Validation loss decreased (inf --> 0.013053).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:30<04:36, 15.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0339, Validation Loss: 0.0154\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:45<04:11, 14.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0319, Validation Loss: 0.0102\n",
      "Validation loss decreased (0.013053 --> 0.010162).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [00:59<03:53, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0306, Validation Loss: 0.0099\n",
      "Validation loss decreased (0.010162 --> 0.009856).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [01:14<03:42, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0307, Validation Loss: 0.0093\n",
      "Validation loss decreased (0.009856 --> 0.009307).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [01:28<03:25, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0294, Validation Loss: 0.0097\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [01:43<03:09, 14.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0289, Validation Loss: 0.0108\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [01:58<03:39, 16.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0283, Validation Loss: 0.0114\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": ETSformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/ETSformer\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 6,\n",
    "        \"label_len\": 0,\n",
    "        'pred_len': 3,\n",
    "        'top_k': 2,\n",
    "        'd_model': 128,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'embed': 'fixed',\n",
    "        'freq': 'h',\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e78031",
   "metadata": {},
   "source": [
    "# 基于FEDformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59e8f4",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd9834",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3077c42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:46.135368Z",
     "start_time": "2024-04-14T13:20:46.118925Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:49:19.471273Z",
     "iopub.status.busy": "2024-04-19T11:49:19.471273Z",
     "iopub.status.idle": "2024-04-19T11:49:19.491652Z",
     "shell.execute_reply": "2024-04-19T11:49:19.490094Z",
     "shell.execute_reply.started": "2024-04-19T11:49:19.471273Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19668802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:47.031487Z",
     "start_time": "2024-04-14T13:20:46.953764Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:49:20.330748Z",
     "iopub.status.busy": "2024-04-19T11:49:20.329752Z",
     "iopub.status.idle": "2024-04-19T11:49:20.431898Z",
     "shell.execute_reply": "2024-04-19T11:49:20.430732Z",
     "shell.execute_reply.started": "2024-04-19T11:49:20.330748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2aba21a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:48.821900Z",
     "start_time": "2024-04-14T13:20:48.791069Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:49:21.442400Z",
     "iopub.status.busy": "2024-04-19T11:49:21.442400Z",
     "iopub.status.idle": "2024-04-19T11:49:21.476712Z",
     "shell.execute_reply": "2024-04-19T11:49:21.475711Z",
     "shell.execute_reply.started": "2024-04-19T11:49:21.442400Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50338e42-bbbb-4eb2-afeb-90be6f29482f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T11:49:22.548487Z",
     "iopub.status.busy": "2024-04-19T11:49:22.547535Z",
     "iopub.status.idle": "2024-04-19T11:49:22.584340Z",
     "shell.execute_reply": "2024-04-19T11:49:22.583326Z",
     "shell.execute_reply.started": "2024-04-19T11:49:22.548487Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2f92385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:50.781521Z",
     "start_time": "2024-04-14T13:20:50.717651Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:49:24.245352Z",
     "iopub.status.busy": "2024-04-19T11:49:24.243318Z",
     "iopub.status.idle": "2024-04-19T11:49:24.336434Z",
     "shell.execute_reply": "2024-04-19T11:49:24.335564Z",
     "shell.execute_reply.started": "2024-04-19T11:49:24.245352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/FEDformer'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08234d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:52.858303Z",
     "start_time": "2024-04-14T13:20:52.841204Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:49:25.128240Z",
     "iopub.status.busy": "2024-04-19T11:49:25.127234Z",
     "iopub.status.idle": "2024-04-19T11:49:25.149824Z",
     "shell.execute_reply": "2024-04-19T11:49:25.147818Z",
     "shell.execute_reply.started": "2024-04-19T11:49:25.128240Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e299e35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:55.182210Z",
     "start_time": "2024-04-14T13:20:54.210340Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:49:26.404268Z",
     "iopub.status.busy": "2024-04-19T11:49:26.401267Z",
     "iopub.status.idle": "2024-04-19T11:49:27.730549Z",
     "shell.execute_reply": "2024-04-19T11:49:27.729550Z",
     "shell.execute_reply.started": "2024-04-19T11:49:26.404268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 3,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920fcf1e",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "404f30a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:20:59.043287Z",
     "start_time": "2024-04-14T13:20:58.592404Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:49:29.168209Z",
     "iopub.status.busy": "2024-04-19T11:49:29.167209Z",
     "iopub.status.idle": "2024-04-19T11:49:29.637371Z",
     "shell.execute_reply": "2024-04-19T11:49:29.635508Z",
     "shell.execute_reply.started": "2024-04-19T11:49:29.168209Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        second_size = 2\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.second_size = Embed(second_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        second_x = self.second_size(x[:, :, 5])\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x + second_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# AutoCorrelationLayer类\n",
    "class AutoCorrelation(nn.Module):\n",
    "    \"\"\"\n",
    "    AutoCorrelation Mechanism with the following two phases:\n",
    "    (1) period-based dependencies discovery\n",
    "    (2) time delay aggregation\n",
    "    This block can replace the self-attention family mechanism seamlessly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_flag=True, factor=1, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(AutoCorrelation, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def time_delay_agg_training(self, values, corr):\n",
    "        \"\"\"\n",
    "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
    "        This is for the training phase.\n",
    "        \"\"\"\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
    "        index = torch.topk(torch.mean(mean_value, dim=0), top_k, dim=-1)[1]\n",
    "        weights = torch.stack([mean_value[:, index[i]] for i in range(top_k)], dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            pattern = torch.roll(tmp_values, -int(index[i]), -1)\n",
    "            delays_agg = delays_agg + pattern * \\\n",
    "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
    "        return delays_agg\n",
    "\n",
    "    def time_delay_agg_inference(self, values, corr):\n",
    "        \"\"\"\n",
    "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
    "        This is for the inference phase.\n",
    "        \"\"\"\n",
    "        batch = values.shape[0]\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # index init\n",
    "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0).repeat(batch, head, channel, 1).cuda()\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
    "        weights, delay = torch.topk(mean_value, top_k, dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values.repeat(1, 1, 1, 2)\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            tmp_delay = init_index + delay[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length)\n",
    "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
    "            delays_agg = delays_agg + pattern * \\\n",
    "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
    "        return delays_agg\n",
    "\n",
    "    def time_delay_agg_full(self, values, corr):\n",
    "        \"\"\"\n",
    "        Standard version of Autocorrelation\n",
    "        \"\"\"\n",
    "        batch = values.shape[0]\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # index init\n",
    "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0).repeat(batch, head, channel, 1).cuda()\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        weights, delay = torch.topk(corr, top_k, dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values.repeat(1, 1, 1, 2)\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            tmp_delay = init_index + delay[..., i].unsqueeze(-1)\n",
    "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
    "            delays_agg = delays_agg + pattern * (tmp_corr[..., i].unsqueeze(-1))\n",
    "        return delays_agg\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        if L > S:\n",
    "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
    "            values = torch.cat([values, zeros], dim=1)\n",
    "            keys = torch.cat([keys, zeros], dim=1)\n",
    "        else:\n",
    "            values = values[:, :L, :, :]\n",
    "            keys = keys[:, :L, :, :]\n",
    "\n",
    "        # period-based dependencies\n",
    "        q_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "        k_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "        res = q_fft * torch.conj(k_fft)\n",
    "        corr = torch.fft.irfft(res, dim=-1)\n",
    "\n",
    "        # time delay agg\n",
    "        if self.training:\n",
    "            V = self.time_delay_agg_training(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
    "        else:\n",
    "            V = self.time_delay_agg_inference(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), corr.permute(0, 3, 1, 2))\n",
    "        else:\n",
    "            return (V.contiguous(), None)\n",
    "\n",
    "\n",
    "class AutoCorrelationLayer(nn.Module):\n",
    "    def __init__(self, correlation, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AutoCorrelationLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_correlation = correlation\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_correlation(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "# 傅里叶层\n",
    "def get_frequency_modes(seq_len, modes=64, mode_select_method='random'):\n",
    "    \"\"\"\n",
    "    get modes on frequency domain:\n",
    "    'random' means sampling randomly;\n",
    "    'else' means sampling the lowest modes;\n",
    "    \"\"\"\n",
    "    modes = min(modes, seq_len // 2)\n",
    "    if mode_select_method == 'random':\n",
    "        index = list(range(0, seq_len // 2))\n",
    "        np.random.shuffle(index)\n",
    "        index = index[:modes]\n",
    "    else:\n",
    "        index = list(range(0, modes))\n",
    "    index.sort()\n",
    "    return index\n",
    "\n",
    "\n",
    "# ########## fourier layer #############\n",
    "class FourierBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, seq_len, modes=0, mode_select_method='random'):\n",
    "        super(FourierBlock, self).__init__()\n",
    "        print('fourier enhanced block used!')\n",
    "        \"\"\"\n",
    "        1D Fourier block. It performs representation learning on frequency domain, \n",
    "        it does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "        # get modes on frequency domain\n",
    "        self.index = get_frequency_modes(seq_len, modes=modes, mode_select_method=mode_select_method)\n",
    "        print('modes={}, index={}'.format(modes, self.index))\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(\n",
    "            self.scale * torch.rand(8, in_channels // 8, out_channels // 8, len(self.index), dtype=torch.float))\n",
    "        self.weights2 = nn.Parameter(\n",
    "            self.scale * torch.rand(8, in_channels // 8, out_channels // 8, len(self.index), dtype=torch.float))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul1d(self, order, x, weights):\n",
    "        x_flag = True\n",
    "        w_flag = True\n",
    "        if not torch.is_complex(x):\n",
    "            x_flag = False\n",
    "            x = torch.complex(x, torch.zeros_like(x).to(x.device))\n",
    "        if not torch.is_complex(weights):\n",
    "            w_flag = False\n",
    "            weights = torch.complex(weights, torch.zeros_like(weights).to(weights.device))\n",
    "        if x_flag or w_flag:\n",
    "            return torch.complex(torch.einsum(order, x.real, weights.real) - torch.einsum(order, x.imag, weights.imag),\n",
    "                                 torch.einsum(order, x.real, weights.imag) + torch.einsum(order, x.imag, weights.real))\n",
    "        else:\n",
    "            return torch.einsum(order, x.real, weights.real)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # size = [B, L, H, E]\n",
    "        B, L, H, E = q.shape\n",
    "        x = q.permute(0, 2, 3, 1)\n",
    "        # Compute Fourier coefficients\n",
    "        x_ft = torch.fft.rfft(x, dim=-1)\n",
    "        # Perform Fourier neural operations\n",
    "        out_ft = torch.zeros(B, H, E, L // 2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        for wi, i in enumerate(self.index):\n",
    "            if i >= x_ft.shape[3] or wi >= out_ft.shape[3]:\n",
    "                continue\n",
    "            out_ft[:, :, :, wi] = self.compl_mul1d(\"bhi,hio->bho\", x_ft[:, :, :, i],\n",
    "                                                   torch.complex(self.weights1, self.weights2)[:, :, :, wi])\n",
    "        # Return to time domain\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return (x, None)\n",
    "\n",
    "\n",
    "# ########## Fourier Cross Former ####################\n",
    "class FourierCrossAttention(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, seq_len_q, seq_len_kv, modes=64, mode_select_method='random',\n",
    "                 activation='tanh', policy=0, num_heads=8):\n",
    "        super(FourierCrossAttention, self).__init__()\n",
    "        print('fourier enhanced cross attention used!')\n",
    "        \"\"\"\n",
    "        1D Fourier Cross Attention layer. It does FFT, linear transform, attention mechanism and Inverse FFT.    \n",
    "        \"\"\"\n",
    "        self.activation = activation\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        # get modes for queries and keys (& values) on frequency domain\n",
    "        self.index_q = get_frequency_modes(seq_len_q, modes=modes, mode_select_method=mode_select_method)\n",
    "        self.index_kv = get_frequency_modes(seq_len_kv, modes=modes, mode_select_method=mode_select_method)\n",
    "\n",
    "        print('modes_q={}, index_q={}'.format(len(self.index_q), self.index_q))\n",
    "        print('modes_kv={}, index_kv={}'.format(len(self.index_kv), self.index_kv))\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(\n",
    "            self.scale * torch.rand(num_heads, in_channels // num_heads, out_channels // num_heads, len(self.index_q), dtype=torch.float))\n",
    "        self.weights2 = nn.Parameter(\n",
    "            self.scale * torch.rand(num_heads, in_channels // num_heads, out_channels // num_heads, len(self.index_q), dtype=torch.float))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul1d(self, order, x, weights):\n",
    "        x_flag = True\n",
    "        w_flag = True\n",
    "        if not torch.is_complex(x):\n",
    "            x_flag = False\n",
    "            x = torch.complex(x, torch.zeros_like(x).to(x.device))\n",
    "        if not torch.is_complex(weights):\n",
    "            w_flag = False\n",
    "            weights = torch.complex(weights, torch.zeros_like(weights).to(weights.device))\n",
    "        if x_flag or w_flag:\n",
    "            return torch.complex(torch.einsum(order, x.real, weights.real) - torch.einsum(order, x.imag, weights.imag),\n",
    "                                 torch.einsum(order, x.real, weights.imag) + torch.einsum(order, x.imag, weights.real))\n",
    "        else:\n",
    "            return torch.einsum(order, x.real, weights.real)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # size = [B, L, H, E]\n",
    "        B, L, H, E = q.shape\n",
    "        xq = q.permute(0, 2, 3, 1)  # size = [B, H, E, L]\n",
    "        xk = k.permute(0, 2, 3, 1)\n",
    "        xv = v.permute(0, 2, 3, 1)\n",
    "\n",
    "        # Compute Fourier coefficients\n",
    "        xq_ft_ = torch.zeros(B, H, E, len(self.index_q), device=xq.device, dtype=torch.cfloat)\n",
    "        xq_ft = torch.fft.rfft(xq, dim=-1)\n",
    "        for i, j in enumerate(self.index_q):\n",
    "            if j >= xq_ft.shape[3]:\n",
    "                continue\n",
    "            xq_ft_[:, :, :, i] = xq_ft[:, :, :, j]\n",
    "        xk_ft_ = torch.zeros(B, H, E, len(self.index_kv), device=xq.device, dtype=torch.cfloat)\n",
    "        xk_ft = torch.fft.rfft(xk, dim=-1)\n",
    "        for i, j in enumerate(self.index_kv):\n",
    "            if j >= xk_ft.shape[3]:\n",
    "                continue\n",
    "            xk_ft_[:, :, :, i] = xk_ft[:, :, :, j]\n",
    "\n",
    "        # perform attention mechanism on frequency domain\n",
    "        xqk_ft = (self.compl_mul1d(\"bhex,bhey->bhxy\", xq_ft_, xk_ft_))\n",
    "        if self.activation == 'tanh':\n",
    "            xqk_ft = torch.complex(xqk_ft.real.tanh(), xqk_ft.imag.tanh())\n",
    "        elif self.activation == 'softmax':\n",
    "            xqk_ft = torch.softmax(abs(xqk_ft), dim=-1)\n",
    "            xqk_ft = torch.complex(xqk_ft, torch.zeros_like(xqk_ft))\n",
    "        else:\n",
    "            raise Exception('{} actiation function is not implemented'.format(self.activation))\n",
    "        xqkv_ft = self.compl_mul1d(\"bhxy,bhey->bhex\", xqk_ft, xk_ft_)\n",
    "        xqkvw = self.compl_mul1d(\"bhex,heox->bhox\", xqkv_ft, torch.complex(self.weights1, self.weights2))\n",
    "        out_ft = torch.zeros(B, H, E, L // 2 + 1, device=xq.device, dtype=torch.cfloat)\n",
    "        for i, j in enumerate(self.index_q):\n",
    "            if i >= xqkvw.shape[3] or j >= out_ft.shape[3]:\n",
    "                continue\n",
    "            out_ft[:, :, :, j] = xqkvw[:, :, :, i]\n",
    "        # Return to time domain\n",
    "        out = torch.fft.irfft(out_ft / self.in_channels / self.out_channels, n=xq.size(-1))\n",
    "        return (out, None)\n",
    "    \n",
    "\n",
    "# MultiWaveletCorrelation类\n",
    "def legendreDer(k, x):\n",
    "    def _legendre(k, x):\n",
    "        return (2 * k + 1) * eval_legendre(k, x)\n",
    "\n",
    "    out = 0\n",
    "    for i in np.arange(k - 1, -1, -2):\n",
    "        out += _legendre(i, x)\n",
    "    return out\n",
    "\n",
    "\n",
    "def phi_(phi_c, x, lb=0, ub=1):\n",
    "    mask = np.logical_or(x < lb, x > ub) * 1.0\n",
    "    return np.polynomial.polynomial.Polynomial(phi_c)(x) * (1 - mask)\n",
    "\n",
    "\n",
    "def get_phi_psi(k, base):\n",
    "    x = Symbol('x')\n",
    "    phi_coeff = np.zeros((k, k))\n",
    "    phi_2x_coeff = np.zeros((k, k))\n",
    "    if base == 'legendre':\n",
    "        for ki in range(k):\n",
    "            coeff_ = Poly(legendre(ki, 2 * x - 1), x).all_coeffs()\n",
    "            phi_coeff[ki, :ki + 1] = np.flip(np.sqrt(2 * ki + 1) * np.array(coeff_).astype(np.float64))\n",
    "            coeff_ = Poly(legendre(ki, 4 * x - 1), x).all_coeffs()\n",
    "            phi_2x_coeff[ki, :ki + 1] = np.flip(np.sqrt(2) * np.sqrt(2 * ki + 1) * np.array(coeff_).astype(np.float64))\n",
    "\n",
    "        psi1_coeff = np.zeros((k, k))\n",
    "        psi2_coeff = np.zeros((k, k))\n",
    "        for ki in range(k):\n",
    "            psi1_coeff[ki, :] = phi_2x_coeff[ki, :]\n",
    "            for i in range(k):\n",
    "                a = phi_2x_coeff[ki, :ki + 1]\n",
    "                b = phi_coeff[i, :i + 1]\n",
    "                prod_ = np.convolve(a, b)\n",
    "                prod_[np.abs(prod_) < 1e-8] = 0\n",
    "                proj_ = (prod_ * 1 / (np.arange(len(prod_)) + 1) * np.power(0.5, 1 + np.arange(len(prod_)))).sum()\n",
    "                psi1_coeff[ki, :] -= proj_ * phi_coeff[i, :]\n",
    "                psi2_coeff[ki, :] -= proj_ * phi_coeff[i, :]\n",
    "            for j in range(ki):\n",
    "                a = phi_2x_coeff[ki, :ki + 1]\n",
    "                b = psi1_coeff[j, :]\n",
    "                prod_ = np.convolve(a, b)\n",
    "                prod_[np.abs(prod_) < 1e-8] = 0\n",
    "                proj_ = (prod_ * 1 / (np.arange(len(prod_)) + 1) * np.power(0.5, 1 + np.arange(len(prod_)))).sum()\n",
    "                psi1_coeff[ki, :] -= proj_ * psi1_coeff[j, :]\n",
    "                psi2_coeff[ki, :] -= proj_ * psi2_coeff[j, :]\n",
    "\n",
    "            a = psi1_coeff[ki, :]\n",
    "            prod_ = np.convolve(a, a)\n",
    "            prod_[np.abs(prod_) < 1e-8] = 0\n",
    "            norm1 = (prod_ * 1 / (np.arange(len(prod_)) + 1) * np.power(0.5, 1 + np.arange(len(prod_)))).sum()\n",
    "\n",
    "            a = psi2_coeff[ki, :]\n",
    "            prod_ = np.convolve(a, a)\n",
    "            prod_[np.abs(prod_) < 1e-8] = 0\n",
    "            norm2 = (prod_ * 1 / (np.arange(len(prod_)) + 1) * (1 - np.power(0.5, 1 + np.arange(len(prod_))))).sum()\n",
    "            norm_ = np.sqrt(norm1 + norm2)\n",
    "            psi1_coeff[ki, :] /= norm_\n",
    "            psi2_coeff[ki, :] /= norm_\n",
    "            psi1_coeff[np.abs(psi1_coeff) < 1e-8] = 0\n",
    "            psi2_coeff[np.abs(psi2_coeff) < 1e-8] = 0\n",
    "\n",
    "        phi = [np.poly1d(np.flip(phi_coeff[i, :])) for i in range(k)]\n",
    "        psi1 = [np.poly1d(np.flip(psi1_coeff[i, :])) for i in range(k)]\n",
    "        psi2 = [np.poly1d(np.flip(psi2_coeff[i, :])) for i in range(k)]\n",
    "\n",
    "    elif base == 'chebyshev':\n",
    "        for ki in range(k):\n",
    "            if ki == 0:\n",
    "                phi_coeff[ki, :ki + 1] = np.sqrt(2 / np.pi)\n",
    "                phi_2x_coeff[ki, :ki + 1] = np.sqrt(2 / np.pi) * np.sqrt(2)\n",
    "            else:\n",
    "                coeff_ = Poly(chebyshevt(ki, 2 * x - 1), x).all_coeffs()\n",
    "                phi_coeff[ki, :ki + 1] = np.flip(2 / np.sqrt(np.pi) * np.array(coeff_).astype(np.float64))\n",
    "                coeff_ = Poly(chebyshevt(ki, 4 * x - 1), x).all_coeffs()\n",
    "                phi_2x_coeff[ki, :ki + 1] = np.flip(\n",
    "                    np.sqrt(2) * 2 / np.sqrt(np.pi) * np.array(coeff_).astype(np.float64))\n",
    "\n",
    "        phi = [partial(phi_, phi_coeff[i, :]) for i in range(k)]\n",
    "\n",
    "        x = Symbol('x')\n",
    "        kUse = 2 * k\n",
    "        roots = Poly(chebyshevt(kUse, 2 * x - 1)).all_roots()\n",
    "        x_m = np.array([rt.evalf(20) for rt in roots]).astype(np.float64)\n",
    "        # x_m[x_m==0.5] = 0.5 + 1e-8 # add small noise to avoid the case of 0.5 belonging to both phi(2x) and phi(2x-1)\n",
    "        # not needed for our purpose here, we use even k always to avoid\n",
    "        wm = np.pi / kUse / 2\n",
    "\n",
    "        psi1_coeff = np.zeros((k, k))\n",
    "        psi2_coeff = np.zeros((k, k))\n",
    "\n",
    "        psi1 = [[] for _ in range(k)]\n",
    "        psi2 = [[] for _ in range(k)]\n",
    "\n",
    "        for ki in range(k):\n",
    "            psi1_coeff[ki, :] = phi_2x_coeff[ki, :]\n",
    "            for i in range(k):\n",
    "                proj_ = (wm * phi[i](x_m) * np.sqrt(2) * phi[ki](2 * x_m)).sum()\n",
    "                psi1_coeff[ki, :] -= proj_ * phi_coeff[i, :]\n",
    "                psi2_coeff[ki, :] -= proj_ * phi_coeff[i, :]\n",
    "\n",
    "            for j in range(ki):\n",
    "                proj_ = (wm * psi1[j](x_m) * np.sqrt(2) * phi[ki](2 * x_m)).sum()\n",
    "                psi1_coeff[ki, :] -= proj_ * psi1_coeff[j, :]\n",
    "                psi2_coeff[ki, :] -= proj_ * psi2_coeff[j, :]\n",
    "\n",
    "            psi1[ki] = partial(phi_, psi1_coeff[ki, :], lb=0, ub=0.5)\n",
    "            psi2[ki] = partial(phi_, psi2_coeff[ki, :], lb=0.5, ub=1)\n",
    "\n",
    "            norm1 = (wm * psi1[ki](x_m) * psi1[ki](x_m)).sum()\n",
    "            norm2 = (wm * psi2[ki](x_m) * psi2[ki](x_m)).sum()\n",
    "\n",
    "            norm_ = np.sqrt(norm1 + norm2)\n",
    "            psi1_coeff[ki, :] /= norm_\n",
    "            psi2_coeff[ki, :] /= norm_\n",
    "            psi1_coeff[np.abs(psi1_coeff) < 1e-8] = 0\n",
    "            psi2_coeff[np.abs(psi2_coeff) < 1e-8] = 0\n",
    "\n",
    "            psi1[ki] = partial(phi_, psi1_coeff[ki, :], lb=0, ub=0.5 + 1e-16)\n",
    "            psi2[ki] = partial(phi_, psi2_coeff[ki, :], lb=0.5 + 1e-16, ub=1)\n",
    "\n",
    "    return phi, psi1, psi2\n",
    "\n",
    "\n",
    "def get_filter(base, k):\n",
    "    def psi(psi1, psi2, i, inp):\n",
    "        mask = (inp <= 0.5) * 1.0\n",
    "        return psi1[i](inp) * mask + psi2[i](inp) * (1 - mask)\n",
    "\n",
    "    if base not in ['legendre', 'chebyshev']:\n",
    "        raise Exception('Base not supported')\n",
    "\n",
    "    x = Symbol('x')\n",
    "    H0 = np.zeros((k, k))\n",
    "    H1 = np.zeros((k, k))\n",
    "    G0 = np.zeros((k, k))\n",
    "    G1 = np.zeros((k, k))\n",
    "    PHI0 = np.zeros((k, k))\n",
    "    PHI1 = np.zeros((k, k))\n",
    "    phi, psi1, psi2 = get_phi_psi(k, base)\n",
    "    if base == 'legendre':\n",
    "        roots = Poly(legendre(k, 2 * x - 1)).all_roots()\n",
    "        x_m = np.array([rt.evalf(20) for rt in roots]).astype(np.float64)\n",
    "        wm = 1 / k / legendreDer(k, 2 * x_m - 1) / eval_legendre(k - 1, 2 * x_m - 1)\n",
    "\n",
    "        for ki in range(k):\n",
    "            for kpi in range(k):\n",
    "                H0[ki, kpi] = 1 / np.sqrt(2) * (wm * phi[ki](x_m / 2) * phi[kpi](x_m)).sum()\n",
    "                G0[ki, kpi] = 1 / np.sqrt(2) * (wm * psi(psi1, psi2, ki, x_m / 2) * phi[kpi](x_m)).sum()\n",
    "                H1[ki, kpi] = 1 / np.sqrt(2) * (wm * phi[ki]((x_m + 1) / 2) * phi[kpi](x_m)).sum()\n",
    "                G1[ki, kpi] = 1 / np.sqrt(2) * (wm * psi(psi1, psi2, ki, (x_m + 1) / 2) * phi[kpi](x_m)).sum()\n",
    "\n",
    "        PHI0 = np.eye(k)\n",
    "        PHI1 = np.eye(k)\n",
    "\n",
    "    elif base == 'chebyshev':\n",
    "        x = Symbol('x')\n",
    "        kUse = 2 * k\n",
    "        roots = Poly(chebyshevt(kUse, 2 * x - 1)).all_roots()\n",
    "        x_m = np.array([rt.evalf(20) for rt in roots]).astype(np.float64)\n",
    "        # x_m[x_m==0.5] = 0.5 + 1e-8 # add small noise to avoid the case of 0.5 belonging to both phi(2x) and phi(2x-1)\n",
    "        # not needed for our purpose here, we use even k always to avoid\n",
    "        wm = np.pi / kUse / 2\n",
    "\n",
    "        for ki in range(k):\n",
    "            for kpi in range(k):\n",
    "                H0[ki, kpi] = 1 / np.sqrt(2) * (wm * phi[ki](x_m / 2) * phi[kpi](x_m)).sum()\n",
    "                G0[ki, kpi] = 1 / np.sqrt(2) * (wm * psi(psi1, psi2, ki, x_m / 2) * phi[kpi](x_m)).sum()\n",
    "                H1[ki, kpi] = 1 / np.sqrt(2) * (wm * phi[ki]((x_m + 1) / 2) * phi[kpi](x_m)).sum()\n",
    "                G1[ki, kpi] = 1 / np.sqrt(2) * (wm * psi(psi1, psi2, ki, (x_m + 1) / 2) * phi[kpi](x_m)).sum()\n",
    "\n",
    "                PHI0[ki, kpi] = (wm * phi[ki](2 * x_m) * phi[kpi](2 * x_m)).sum() * 2\n",
    "                PHI1[ki, kpi] = (wm * phi[ki](2 * x_m - 1) * phi[kpi](2 * x_m - 1)).sum() * 2\n",
    "\n",
    "        PHI0[np.abs(PHI0) < 1e-8] = 0\n",
    "        PHI1[np.abs(PHI1) < 1e-8] = 0\n",
    "\n",
    "    H0[np.abs(H0) < 1e-8] = 0\n",
    "    H1[np.abs(H1) < 1e-8] = 0\n",
    "    G0[np.abs(G0) < 1e-8] = 0\n",
    "    G1[np.abs(G1) < 1e-8] = 0\n",
    "\n",
    "    return H0, H1, G0, G1, PHI0, PHI1\n",
    "\n",
    "\n",
    "class MultiWaveletTransform(nn.Module):\n",
    "    \"\"\"\n",
    "    1D multiwavelet block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ich=1, k=8, alpha=16, c=128,\n",
    "                 nCZ=1, L=0, base='legendre', attention_dropout=0.1):\n",
    "        super(MultiWaveletTransform, self).__init__()\n",
    "        print('base', base)\n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.L = L\n",
    "        self.nCZ = nCZ\n",
    "        self.Lk0 = nn.Linear(ich, c * k)\n",
    "        self.Lk1 = nn.Linear(c * k, ich)\n",
    "        self.ich = ich\n",
    "        self.MWT_CZ = nn.ModuleList(MWT_CZ1d(k, alpha, L, c, base) for i in range(nCZ))\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        if L > S:\n",
    "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
    "            values = torch.cat([values, zeros], dim=1)\n",
    "            keys = torch.cat([keys, zeros], dim=1)\n",
    "        else:\n",
    "            values = values[:, :L, :, :]\n",
    "            keys = keys[:, :L, :, :]\n",
    "        values = values.view(B, L, -1)\n",
    "\n",
    "        V = self.Lk0(values).view(B, L, self.c, -1)\n",
    "        for i in range(self.nCZ):\n",
    "            V = self.MWT_CZ[i](V)\n",
    "            if i < self.nCZ - 1:\n",
    "                V = F.relu(V)\n",
    "\n",
    "        V = self.Lk1(V.view(B, L, -1))\n",
    "        V = V.view(B, L, -1, D)\n",
    "        return (V.contiguous(), None)\n",
    "\n",
    "\n",
    "class MultiWaveletCross(nn.Module):\n",
    "    \"\"\"\n",
    "    1D Multiwavelet Cross Attention layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, seq_len_q, seq_len_kv, modes, c=64,\n",
    "                 k=8, ich=512,\n",
    "                 L=0,\n",
    "                 base='legendre',\n",
    "                 mode_select_method='random',\n",
    "                 initializer=None, activation='tanh',\n",
    "                 **kwargs):\n",
    "        super(MultiWaveletCross, self).__init__()\n",
    "        print('base', base)\n",
    "\n",
    "        self.c = c\n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0 @ PHI0\n",
    "        G0r = G0 @ PHI0\n",
    "        H1r = H1 @ PHI1\n",
    "        G1r = G1 @ PHI1\n",
    "\n",
    "        H0r[np.abs(H0r) < 1e-8] = 0\n",
    "        H1r[np.abs(H1r) < 1e-8] = 0\n",
    "        G0r[np.abs(G0r) < 1e-8] = 0\n",
    "        G1r[np.abs(G1r) < 1e-8] = 0\n",
    "        self.max_item = 3\n",
    "\n",
    "        self.attn1 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.attn2 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.attn3 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.attn4 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.T0 = nn.Linear(k, k)\n",
    "        self.register_buffer('ec_s', torch.Tensor(\n",
    "            np.concatenate((H0.T, H1.T), axis=0)))\n",
    "        self.register_buffer('ec_d', torch.Tensor(\n",
    "            np.concatenate((G0.T, G1.T), axis=0)))\n",
    "\n",
    "        self.register_buffer('rc_e', torch.Tensor(\n",
    "            np.concatenate((H0r, G0r), axis=0)))\n",
    "        self.register_buffer('rc_o', torch.Tensor(\n",
    "            np.concatenate((H1r, G1r), axis=0)))\n",
    "\n",
    "        self.Lk = nn.Linear(ich, c * k)\n",
    "        self.Lq = nn.Linear(ich, c * k)\n",
    "        self.Lv = nn.Linear(ich, c * k)\n",
    "        self.out = nn.Linear(c * k, ich)\n",
    "        self.modes1 = modes\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        B, N, H, E = q.shape  # (B, N, H, E) torch.Size([3, 768, 8, 2])\n",
    "        _, S, _, _ = k.shape  # (B, S, H, E) torch.Size([3, 96, 8, 2])\n",
    "\n",
    "        q = q.view(q.shape[0], q.shape[1], -1)\n",
    "        k = k.view(k.shape[0], k.shape[1], -1)\n",
    "        v = v.view(v.shape[0], v.shape[1], -1)\n",
    "        q = self.Lq(q)\n",
    "        q = q.view(q.shape[0], q.shape[1], self.c, self.k)\n",
    "        k = self.Lk(k)\n",
    "        k = k.view(k.shape[0], k.shape[1], self.c, self.k)\n",
    "        v = self.Lv(v)\n",
    "        v = v.view(v.shape[0], v.shape[1], self.c, self.k)\n",
    "\n",
    "        if N > S:\n",
    "            zeros = torch.zeros_like(q[:, :(N - S), :]).float()\n",
    "            v = torch.cat([v, zeros], dim=1)\n",
    "            k = torch.cat([k, zeros], dim=1)\n",
    "        else:\n",
    "            v = v[:, :N, :, :]\n",
    "            k = k[:, :N, :, :]\n",
    "\n",
    "        ns = math.floor(np.log2(N))\n",
    "        nl = pow(2, math.ceil(np.log2(N)))\n",
    "        extra_q = q[:, 0:nl - N, :, :]\n",
    "        extra_k = k[:, 0:nl - N, :, :]\n",
    "        extra_v = v[:, 0:nl - N, :, :]\n",
    "        q = torch.cat([q, extra_q], 1)\n",
    "        k = torch.cat([k, extra_k], 1)\n",
    "        v = torch.cat([v, extra_v], 1)\n",
    "\n",
    "        Ud_q = torch.jit.annotate(List[Tuple[Tensor]], [])\n",
    "        Ud_k = torch.jit.annotate(List[Tuple[Tensor]], [])\n",
    "        Ud_v = torch.jit.annotate(List[Tuple[Tensor]], [])\n",
    "\n",
    "        Us_q = torch.jit.annotate(List[Tensor], [])\n",
    "        Us_k = torch.jit.annotate(List[Tensor], [])\n",
    "        Us_v = torch.jit.annotate(List[Tensor], [])\n",
    "\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "\n",
    "        # decompose\n",
    "        for i in range(ns - self.L):\n",
    "            # print('q shape',q.shape)\n",
    "            d, q = self.wavelet_transform(q)\n",
    "            Ud_q += [tuple([d, q])]\n",
    "            Us_q += [d]\n",
    "        for i in range(ns - self.L):\n",
    "            d, k = self.wavelet_transform(k)\n",
    "            Ud_k += [tuple([d, k])]\n",
    "            Us_k += [d]\n",
    "        for i in range(ns - self.L):\n",
    "            d, v = self.wavelet_transform(v)\n",
    "            Ud_v += [tuple([d, v])]\n",
    "            Us_v += [d]\n",
    "        for i in range(ns - self.L):\n",
    "            dk, sk = Ud_k[i], Us_k[i]\n",
    "            dq, sq = Ud_q[i], Us_q[i]\n",
    "            dv, sv = Ud_v[i], Us_v[i]\n",
    "            Ud += [self.attn1(dq[0], dk[0], dv[0], mask)[0] + self.attn2(dq[1], dk[1], dv[1], mask)[0]]\n",
    "            Us += [self.attn3(sq, sk, sv, mask)[0]]\n",
    "        v = self.attn4(q, k, v, mask)[0]\n",
    "\n",
    "        # reconstruct\n",
    "        for i in range(ns - 1 - self.L, -1, -1):\n",
    "            v = v + Us[i]\n",
    "            v = torch.cat((v, Ud[i]), -1)\n",
    "            v = self.evenOdd(v)\n",
    "        v = self.out(v[:, :N, :, :].contiguous().view(B, N, -1))\n",
    "        return (v.contiguous(), None)\n",
    "\n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat([x[:, ::2, :, :],\n",
    "                        x[:, 1::2, :, :],\n",
    "                        ], -1)\n",
    "        d = torch.matmul(xa, self.ec_d)\n",
    "        s = torch.matmul(xa, self.ec_s)\n",
    "        return d, s\n",
    "\n",
    "    def evenOdd(self, x):\n",
    "        B, N, c, ich = x.shape  # (B, N, c, k)\n",
    "        assert ich == 2 * self.k\n",
    "        x_e = torch.matmul(x, self.rc_e)\n",
    "        x_o = torch.matmul(x, self.rc_o)\n",
    "\n",
    "        x = torch.zeros(B, N * 2, c, self.k,\n",
    "                        device=x.device)\n",
    "        x[..., ::2, :, :] = x_e\n",
    "        x[..., 1::2, :, :] = x_o\n",
    "        return x\n",
    "\n",
    "\n",
    "class FourierCrossAttentionW(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, seq_len_q, seq_len_kv, modes=16, activation='tanh',\n",
    "                 mode_select_method='random'):\n",
    "        super(FourierCrossAttentionW, self).__init__()\n",
    "        print('corss fourier correlation used!')\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes\n",
    "        self.activation = activation\n",
    "\n",
    "    def compl_mul1d(self, order, x, weights):\n",
    "        x_flag = True\n",
    "        w_flag = True\n",
    "        if not torch.is_complex(x):\n",
    "            x_flag = False\n",
    "            x = torch.complex(x, torch.zeros_like(x).to(x.device))\n",
    "        if not torch.is_complex(weights):\n",
    "            w_flag = False\n",
    "            weights = torch.complex(weights, torch.zeros_like(weights).to(weights.device))\n",
    "        if x_flag or w_flag:\n",
    "            return torch.complex(torch.einsum(order, x.real, weights.real) - torch.einsum(order, x.imag, weights.imag),\n",
    "                                 torch.einsum(order, x.real, weights.imag) + torch.einsum(order, x.imag, weights.real))\n",
    "        else:\n",
    "            return torch.einsum(order, x.real, weights.real)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        B, L, E, H = q.shape\n",
    "\n",
    "        xq = q.permute(0, 3, 2, 1)  # size = [B, H, E, L] torch.Size([3, 8, 64, 512])\n",
    "        xk = k.permute(0, 3, 2, 1)\n",
    "        xv = v.permute(0, 3, 2, 1)\n",
    "        self.index_q = list(range(0, min(int(L // 2), self.modes1)))\n",
    "        self.index_k_v = list(range(0, min(int(xv.shape[3] // 2), self.modes1)))\n",
    "\n",
    "        # Compute Fourier coefficients\n",
    "        xq_ft_ = torch.zeros(B, H, E, len(self.index_q), device=xq.device, dtype=torch.cfloat)\n",
    "        xq_ft = torch.fft.rfft(xq, dim=-1)\n",
    "        for i, j in enumerate(self.index_q):\n",
    "            xq_ft_[:, :, :, i] = xq_ft[:, :, :, j]\n",
    "\n",
    "        xk_ft_ = torch.zeros(B, H, E, len(self.index_k_v), device=xq.device, dtype=torch.cfloat)\n",
    "        xk_ft = torch.fft.rfft(xk, dim=-1)\n",
    "        for i, j in enumerate(self.index_k_v):\n",
    "            xk_ft_[:, :, :, i] = xk_ft[:, :, :, j]\n",
    "        xqk_ft = (self.compl_mul1d(\"bhex,bhey->bhxy\", xq_ft_, xk_ft_))\n",
    "        if self.activation == 'tanh':\n",
    "            xqk_ft = torch.complex(xqk_ft.real.tanh(), xqk_ft.imag.tanh())\n",
    "        elif self.activation == 'softmax':\n",
    "            xqk_ft = torch.softmax(abs(xqk_ft), dim=-1)\n",
    "            xqk_ft = torch.complex(xqk_ft, torch.zeros_like(xqk_ft))\n",
    "        else:\n",
    "            raise Exception('{} actiation function is not implemented'.format(self.activation))\n",
    "        xqkv_ft = self.compl_mul1d(\"bhxy,bhey->bhex\", xqk_ft, xk_ft_)\n",
    "\n",
    "        xqkvw = xqkv_ft\n",
    "        out_ft = torch.zeros(B, H, E, L // 2 + 1, device=xq.device, dtype=torch.cfloat)\n",
    "        for i, j in enumerate(self.index_q):\n",
    "            out_ft[:, :, :, j] = xqkvw[:, :, :, i]\n",
    "\n",
    "        out = torch.fft.irfft(out_ft / self.in_channels / self.out_channels, n=xq.size(-1)).permute(0, 3, 2, 1)\n",
    "        # size = [B, L, H, E]\n",
    "        return (out, None)\n",
    "\n",
    "\n",
    "class sparseKernelFT1d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k, alpha, c=1,\n",
    "                 nl=1,\n",
    "                 initializer=None,\n",
    "                 **kwargs):\n",
    "        super(sparseKernelFT1d, self).__init__()\n",
    "\n",
    "        self.modes1 = alpha\n",
    "        self.scale = (1 / (c * k * c * k))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(c * k, c * k, self.modes1, dtype=torch.float))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(c * k, c * k, self.modes1, dtype=torch.float))\n",
    "        self.weights1.requires_grad = True\n",
    "        self.weights2.requires_grad = True\n",
    "        self.k = k\n",
    "\n",
    "    def compl_mul1d(self, order, x, weights):\n",
    "        x_flag = True\n",
    "        w_flag = True\n",
    "        if not torch.is_complex(x):\n",
    "            x_flag = False\n",
    "            x = torch.complex(x, torch.zeros_like(x).to(x.device))\n",
    "        if not torch.is_complex(weights):\n",
    "            w_flag = False\n",
    "            weights = torch.complex(weights, torch.zeros_like(weights).to(weights.device))\n",
    "        if x_flag or w_flag:\n",
    "            return torch.complex(torch.einsum(order, x.real, weights.real) - torch.einsum(order, x.imag, weights.imag),\n",
    "                                 torch.einsum(order, x.real, weights.imag) + torch.einsum(order, x.imag, weights.real))\n",
    "        else:\n",
    "            return torch.einsum(order, x.real, weights.real)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, c, k = x.shape  # (B, N, c, k)\n",
    "\n",
    "        x = x.view(B, N, -1)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x_fft = torch.fft.rfft(x)\n",
    "        # Multiply relevant Fourier modes\n",
    "        l = min(self.modes1, N // 2 + 1)\n",
    "        out_ft = torch.zeros(B, c * k, N // 2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        out_ft[:, :, :l] = self.compl_mul1d(\"bix,iox->box\", x_fft[:, :, :l],\n",
    "                                            torch.complex(self.weights1, self.weights2)[:, :, :l])\n",
    "        x = torch.fft.irfft(out_ft, n=N)\n",
    "        x = x.permute(0, 2, 1).view(B, N, c, k)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ##\n",
    "class MWT_CZ1d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k=3, alpha=64,\n",
    "                 L=0, c=1,\n",
    "                 base='legendre',\n",
    "                 initializer=None,\n",
    "                 **kwargs):\n",
    "        super(MWT_CZ1d, self).__init__()\n",
    "\n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0 @ PHI0\n",
    "        G0r = G0 @ PHI0\n",
    "        H1r = H1 @ PHI1\n",
    "        G1r = G1 @ PHI1\n",
    "\n",
    "        H0r[np.abs(H0r) < 1e-8] = 0\n",
    "        H1r[np.abs(H1r) < 1e-8] = 0\n",
    "        G0r[np.abs(G0r) < 1e-8] = 0\n",
    "        G1r[np.abs(G1r) < 1e-8] = 0\n",
    "        self.max_item = 3\n",
    "\n",
    "        self.A = sparseKernelFT1d(k, alpha, c)\n",
    "        self.B = sparseKernelFT1d(k, alpha, c)\n",
    "        self.C = sparseKernelFT1d(k, alpha, c)\n",
    "\n",
    "        self.T0 = nn.Linear(k, k)\n",
    "\n",
    "        self.register_buffer('ec_s', torch.Tensor(\n",
    "            np.concatenate((H0.T, H1.T), axis=0)))\n",
    "        self.register_buffer('ec_d', torch.Tensor(\n",
    "            np.concatenate((G0.T, G1.T), axis=0)))\n",
    "\n",
    "        self.register_buffer('rc_e', torch.Tensor(\n",
    "            np.concatenate((H0r, G0r), axis=0)))\n",
    "        self.register_buffer('rc_o', torch.Tensor(\n",
    "            np.concatenate((H1r, G1r), axis=0)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, c, k = x.shape  # (B, N, k)\n",
    "        ns = math.floor(np.log2(N))\n",
    "        nl = pow(2, math.ceil(np.log2(N)))\n",
    "        extra_x = x[:, 0:nl - N, :, :]\n",
    "        x = torch.cat([x, extra_x], 1)\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "        for i in range(ns - self.L):\n",
    "            d, x = self.wavelet_transform(x)\n",
    "            Ud += [self.A(d) + self.B(x)]\n",
    "            Us += [self.C(d)]\n",
    "        x = self.T0(x)  # coarsest scale transform\n",
    "\n",
    "        #        reconstruct\n",
    "        for i in range(ns - 1 - self.L, -1, -1):\n",
    "            x = x + Us[i]\n",
    "            x = torch.cat((x, Ud[i]), -1)\n",
    "            x = self.evenOdd(x)\n",
    "        x = x[:, :N, :, :]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat([x[:, ::2, :, :],\n",
    "                        x[:, 1::2, :, :],\n",
    "                        ], -1)\n",
    "        d = torch.matmul(xa, self.ec_d)\n",
    "        s = torch.matmul(xa, self.ec_s)\n",
    "        return d, s\n",
    "\n",
    "    def evenOdd(self, x):\n",
    "\n",
    "        B, N, c, ich = x.shape  # (B, N, c, k)\n",
    "        assert ich == 2 * self.k\n",
    "        x_e = torch.matmul(x, self.rc_e)\n",
    "        x_o = torch.matmul(x, self.rc_o)\n",
    "\n",
    "        x = torch.zeros(B, N * 2, c, self.k,\n",
    "                        device=x.device)\n",
    "        x[..., ::2, :, :] = x_e\n",
    "        x[..., 1::2, :, :] = x_o\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "# Autoformer_EncDec类\n",
    "class my_Layernorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Special designed layernorm for the seasonal part\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super(my_Layernorm, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_hat = self.layernorm(x)\n",
    "        bias = torch.mean(x_hat, dim=1).unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        return x_hat - bias\n",
    "\n",
    "\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "\n",
    "class series_decomp_multi(nn.Module):\n",
    "    \"\"\"\n",
    "    Multiple Series decomposition block from FEDformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp_multi, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.series_decomp = [series_decomp(kernel) for kernel in kernel_size]\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = []\n",
    "        res = []\n",
    "        for func in self.series_decomp:\n",
    "            sea, moving_avg = func(x)\n",
    "            moving_mean.append(moving_avg)\n",
    "            res.append(sea)\n",
    "\n",
    "        sea = sum(res) / len(res)\n",
    "        moving_mean = sum(moving_mean) / len(moving_mean)\n",
    "        return sea, moving_mean\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder layer with the progressive decomposition architecture\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, attention, d_model, d_ff=None, moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
    "        self.decomp1 = series_decomp(moving_avg)\n",
    "        self.decomp2 = series_decomp(moving_avg)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "        x, _ = self.decomp1(x)\n",
    "        y = x\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        res, _ = self.decomp2(x + y)\n",
    "        return res, attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer decoder layer with the progressive decomposition architecture\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, self_attention, cross_attention, d_model, c_out, d_ff=None,\n",
    "                 moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
    "        self.decomp1 = series_decomp(moving_avg)\n",
    "        self.decomp2 = series_decomp(moving_avg)\n",
    "        self.decomp3 = series_decomp(moving_avg)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.projection = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=3, stride=1, padding=1,\n",
    "                                    padding_mode='circular', bias=False)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask\n",
    "        )[0])\n",
    "        x, trend1 = self.decomp1(x)\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask\n",
    "        )[0])\n",
    "        x, trend2 = self.decomp2(x)\n",
    "        y = x\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        x, trend3 = self.decomp3(x + y)\n",
    "\n",
    "        residual_trend = trend1 + trend2 + trend3\n",
    "        residual_trend = self.projection(residual_trend.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x, residual_trend\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, trend=None):\n",
    "        for layer in self.layers:\n",
    "            x, residual_trend = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
    "            trend = trend + residual_trend\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x, trend\n",
    "    \n",
    "    \n",
    "# FEDformer模块\n",
    "class FEDformer(nn.Module):\n",
    "    def __init__(self, seq_len, label_len, pred_len, moving_avg, enc_in, dec_in, d_model, dropout, n_heads, d_ff, \n",
    "                 e_layers, c_out, d_layers, embed, freq, version='fourier', mode_select='random', modes=32):\n",
    "        \"\"\"\n",
    "        version: str, for FEDformer, there are two versions to choose, options: [Fourier, Wavelets].\n",
    "        mode_select: str, for FEDformer, there are two mode selection method, options: [random, low].\n",
    "        modes: int, modes to be selected.\n",
    "        \"\"\"\n",
    "        super(FEDformer, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = pred_len\n",
    "        self.version = version\n",
    "        self.mode_select = mode_select\n",
    "        self.modes = modes\n",
    "\n",
    "        # Decomp\n",
    "        self.decomp = series_decomp(moving_avg)\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n",
    "\n",
    "        if self.version == 'Wavelets':\n",
    "            encoder_self_att = MultiWaveletTransform(ich=d_model, L=1, base='legendre')\n",
    "            decoder_self_att = MultiWaveletTransform(ich=d_model, L=1, base='legendre')\n",
    "            decoder_cross_att = MultiWaveletCross(in_channels=d_model,\n",
    "                                                  out_channels=d_model,\n",
    "                                                  seq_len_q=self.seq_len // 2 + self.pred_len,\n",
    "                                                  seq_len_kv=self.seq_len,\n",
    "                                                  modes=self.modes,\n",
    "                                                  ich=d_model,\n",
    "                                                  base='legendre',\n",
    "                                                  activation='tanh')\n",
    "        else:\n",
    "            encoder_self_att = FourierBlock(in_channels=d_model,\n",
    "                                            out_channels=d_model,\n",
    "                                            seq_len=self.seq_len,\n",
    "                                            modes=self.modes,\n",
    "                                            mode_select_method=self.mode_select)\n",
    "            decoder_self_att = FourierBlock(in_channels=d_model,\n",
    "                                            out_channels=d_model,\n",
    "                                            seq_len=self.seq_len // 2 + self.pred_len,\n",
    "                                            modes=self.modes,\n",
    "                                            mode_select_method=self.mode_select)\n",
    "            decoder_cross_att = FourierCrossAttention(in_channels=d_model,\n",
    "                                                      out_channels=d_model,\n",
    "                                                      seq_len_q=self.seq_len // 2 + self.pred_len,\n",
    "                                                      seq_len_kv=self.seq_len,\n",
    "                                                      modes=self.modes,\n",
    "                                                      mode_select_method=self.mode_select,\n",
    "                                                      num_heads=n_heads)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        encoder_self_att,  # instead of multi-head attention in transformer\n",
    "                        d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    moving_avg=moving_avg,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu'\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        decoder_self_att, d_model, n_heads),\n",
    "                    AutoCorrelationLayer(\n",
    "                        decoder_cross_att, d_model, n_heads),\n",
    "                    d_model,\n",
    "                    c_out,\n",
    "                    d_ff,\n",
    "                    moving_avg=moving_avg,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(d_model),\n",
    "            projection=nn.Linear(d_model, c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # decomp init\n",
    "        mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\n",
    "        seasonal_init, trend_init = self.decomp(x_enc)  # x - moving_avg, moving_avg\n",
    "        # decoder input\n",
    "        trend_init = torch.cat([trend_init[:, -self.label_len:, :], mean], dim=1)\n",
    "        seasonal_init = F.pad(seasonal_init[:, -self.label_len:, :], (0, 0, 0, self.pred_len))\n",
    "        # enc\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        dec_out = self.dec_embedding(seasonal_init, x_mark_dec)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "        # dec\n",
    "        seasonal_part, trend_part = self.decoder(dec_out, enc_out, x_mask=None, cross_mask=None, trend=trend_init)\n",
    "        # final\n",
    "        dec_out = trend_part + seasonal_part\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fe96f",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b184f28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:21:08.232878Z",
     "start_time": "2024-04-14T13:21:08.195758Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T11:49:31.948152Z",
     "iopub.status.busy": "2024-04-19T11:49:31.946151Z",
     "iopub.status.idle": "2024-04-19T11:49:32.046744Z",
     "shell.execute_reply": "2024-04-19T11:49:32.045604Z",
     "shell.execute_reply.started": "2024-04-19T11:49:31.948152Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ed07997-92d9-4778-bd67-867d0a34125c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T11:49:56.586269Z",
     "iopub.status.busy": "2024-04-19T11:49:56.585269Z",
     "iopub.status.idle": "2024-04-19T12:01:28.355624Z",
     "shell.execute_reply": "2024-04-19T12:01:28.354623Z",
     "shell.execute_reply.started": "2024-04-19T11:49:56.586269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourier enhanced block used!\n",
      "modes=32, index=[0, 1, 2]\n",
      "fourier enhanced block used!\n",
      "modes=32, index=[0, 1, 2]\n",
      "fourier enhanced cross attention used!\n",
      "modes_q=3, index_q=[0, 1, 2]\n",
      "modes_kv=3, index_kv=[0, 1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:34<10:54, 34.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0761, Validation Loss: 0.2741\n",
      "Validation loss decreased (inf --> 0.274142).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [01:09<10:21, 34.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0106, Validation Loss: 0.0347\n",
      "Validation loss decreased (0.274142 --> 0.034717).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [01:43<09:46, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0073, Validation Loss: 0.0165\n",
      "Validation loss decreased (0.034717 --> 0.016527).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [02:18<09:15, 34.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0064, Validation Loss: 0.0170\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [02:53<08:43, 34.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0060, Validation Loss: 0.0105\n",
      "Validation loss decreased (0.016527 --> 0.010492).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [03:28<08:06, 34.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0055, Validation Loss: 0.0103\n",
      "Validation loss decreased (0.010492 --> 0.010349).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [04:02<07:29, 34.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0048, Validation Loss: 0.0086\n",
      "Validation loss decreased (0.010349 --> 0.008553).  Saving model ...\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [04:37<06:54, 34.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0048, Validation Loss: 0.0060\n",
      "Validation loss decreased (0.008553 --> 0.006043).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                             | 9/20 [05:11<06:18, 34.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0042, Validation Loss: 0.0049\n",
      "Validation loss decreased (0.006043 --> 0.004935).  Saving model ...\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 10/20 [05:44<05:42, 34.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0039, Validation Loss: 0.0090\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████                                     | 11/20 [06:19<05:08, 34.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0035, Validation Loss: 0.0051\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [06:53<04:33, 34.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0034, Validation Loss: 0.0034\n",
      "Validation loss decreased (0.004935 --> 0.003387).  Saving model ...\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [07:28<04:00, 34.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0032, Validation Loss: 0.0042\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [08:02<03:26, 34.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0030, Validation Loss: 0.0031\n",
      "Validation loss decreased (0.003387 --> 0.003056).  Saving model ...\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [08:37<02:52, 34.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0029, Validation Loss: 0.0038\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00014644660940672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [09:13<02:19, 34.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0028, Validation Loss: 0.0033\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [09:47<01:43, 34.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0026, Validation Loss: 0.0028\n",
      "Validation loss decreased (0.003056 --> 0.002802).  Saving model ...\n",
      "Updating learning rate to 5.449673790581611e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [10:22<01:09, 34.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0026, Validation Loss: 0.0027\n",
      "Validation loss decreased (0.002802 --> 0.002694).  Saving model ...\n",
      "Updating learning rate to 2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [10:56<00:34, 34.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0025, Validation Loss: 0.0027\n",
      "Validation loss decreased (0.002694 --> 0.002653).  Saving model ...\n",
      "Updating learning rate to 6.15582970243117e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [11:31<00:00, 34.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0024, Validation Loss: 0.0026\n",
      "Validation loss decreased (0.002653 --> 0.002581).  Saving model ...\n",
      "Updating learning rate to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": FEDformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/FEDformer\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'dec_in': 2,\n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'label_len': 3,\n",
    "        'moving_avg': 3,\n",
    "        'd_model': 128,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'embed': 'fixed',\n",
    "        'freq': 'h',\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cefa5b",
   "metadata": {},
   "source": [
    "# 基于FiLM的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72af68",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c613a21c",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7e7047a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:22:30.484029Z",
     "start_time": "2024-04-14T13:22:30.472983Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:01:58.636418Z",
     "iopub.status.busy": "2024-04-19T12:01:58.634429Z",
     "iopub.status.idle": "2024-04-19T12:01:58.665041Z",
     "shell.execute_reply": "2024-04-19T12:01:58.664041Z",
     "shell.execute_reply.started": "2024-04-19T12:01:58.636418Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0502843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:22:31.772677Z",
     "start_time": "2024-04-14T13:22:31.693119Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:01:59.375433Z",
     "iopub.status.busy": "2024-04-19T12:01:59.374415Z",
     "iopub.status.idle": "2024-04-19T12:01:59.464168Z",
     "shell.execute_reply": "2024-04-19T12:01:59.463198Z",
     "shell.execute_reply.started": "2024-04-19T12:01:59.375433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5f03197",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:22:33.359465Z",
     "start_time": "2024-04-14T13:22:33.324053Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:02:00.232833Z",
     "iopub.status.busy": "2024-04-19T12:02:00.231793Z",
     "iopub.status.idle": "2024-04-19T12:02:00.264449Z",
     "shell.execute_reply": "2024-04-19T12:02:00.263406Z",
     "shell.execute_reply.started": "2024-04-19T12:02:00.232833Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70d8772d-aedb-4d8e-ba5b-f44d824f96a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:02:01.234972Z",
     "iopub.status.busy": "2024-04-19T12:02:01.233933Z",
     "iopub.status.idle": "2024-04-19T12:02:01.262598Z",
     "shell.execute_reply": "2024-04-19T12:02:01.261600Z",
     "shell.execute_reply.started": "2024-04-19T12:02:01.234972Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94510130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:22:34.445158Z",
     "start_time": "2024-04-14T13:22:34.371511Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:02:02.305439Z",
     "iopub.status.busy": "2024-04-19T12:02:02.305439Z",
     "iopub.status.idle": "2024-04-19T12:02:02.385437Z",
     "shell.execute_reply": "2024-04-19T12:02:02.384533Z",
     "shell.execute_reply.started": "2024-04-19T12:02:02.305439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/FiLM'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "437dbe70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:22:36.009075Z",
     "start_time": "2024-04-14T13:22:35.991478Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:02:03.779967Z",
     "iopub.status.busy": "2024-04-19T12:02:03.777873Z",
     "iopub.status.idle": "2024-04-19T12:02:03.808802Z",
     "shell.execute_reply": "2024-04-19T12:02:03.806804Z",
     "shell.execute_reply.started": "2024-04-19T12:02:03.779967Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60657bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:22:38.393111Z",
     "start_time": "2024-04-14T13:22:37.363411Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:02:05.544729Z",
     "iopub.status.busy": "2024-04-19T12:02:05.542731Z",
     "iopub.status.idle": "2024-04-19T12:02:06.866607Z",
     "shell.execute_reply": "2024-04-19T12:02:06.865958Z",
     "shell.execute_reply.started": "2024-04-19T12:02:05.543724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 3,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc791901",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcbd4b41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:22:41.066590Z",
     "start_time": "2024-04-14T13:22:41.026965Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:02:08.062429Z",
     "iopub.status.busy": "2024-04-19T12:02:08.061442Z",
     "iopub.status.idle": "2024-04-19T12:02:08.132397Z",
     "shell.execute_reply": "2024-04-19T12:02:08.131394Z",
     "shell.execute_reply.started": "2024-04-19T12:02:08.062429Z"
    }
   },
   "outputs": [],
   "source": [
    "def transition(N):\n",
    "    Q = np.arange(N, dtype=np.float64)\n",
    "    R = (2 * Q + 1)[:, None]  # / theta\n",
    "    j, i = np.meshgrid(Q, Q)\n",
    "    A = np.where(i < j, -1, (-1.) ** (i - j + 1)) * R\n",
    "    B = (-1.) ** Q[:, None] * R\n",
    "    return A, B\n",
    "\n",
    "\n",
    "class HiPPO_LegT(nn.Module):\n",
    "    def __init__(self, N, dt=1.0, discretization='bilinear'):\n",
    "        \"\"\"\n",
    "        N: the order of the HiPPO projection\n",
    "        dt: discretization step size - should be roughly inverse to the length of the sequence\n",
    "        \"\"\"\n",
    "        super(HiPPO_LegT, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.N = N\n",
    "        A, B = transition(N)\n",
    "        C = np.ones((1, N))\n",
    "        D = np.zeros((1,))\n",
    "        A, B, _, _, _ = signal.cont2discrete((A, B, C, D), dt=dt, method=discretization)\n",
    "\n",
    "        B = B.squeeze(-1)\n",
    "\n",
    "        self.register_buffer('A', torch.Tensor(A).to(self.device))\n",
    "        self.register_buffer('B', torch.Tensor(B).to(self.device))\n",
    "        vals = np.arange(0.0, 1.0, dt)\n",
    "        self.register_buffer('eval_matrix', torch.Tensor(eval_legendre(np.arange(N)[:, None], 1 - 2 * vals).T).to(self.device))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs : (length, ...)\n",
    "        output : (length, ..., N) where N is the order of the HiPPO projection\n",
    "        \"\"\"\n",
    "        c = torch.zeros(inputs.shape[:-1] + tuple([self.N])).to(self.device)\n",
    "        cs = []\n",
    "        for f in inputs.permute([-1, 0, 1]):\n",
    "            f = f.unsqueeze(-1)\n",
    "            new = f @ self.B.unsqueeze(0)\n",
    "            c = F.linear(c, self.A) + new\n",
    "            cs.append(c)\n",
    "        return torch.stack(cs, dim=0)\n",
    "\n",
    "    def reconstruct(self, c):\n",
    "        return (self.eval_matrix @ c.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "\n",
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, seq_len, ratio=0.5):\n",
    "        \"\"\"\n",
    "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
    "        \"\"\"\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.ratio = ratio\n",
    "        self.modes = min(32, seq_len // 2)\n",
    "        self.index = list(range(0, self.modes))\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights_real = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, len(self.index), dtype=torch.float))\n",
    "        self.weights_imag = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, len(self.index), dtype=torch.float))\n",
    "\n",
    "    def compl_mul1d(self, order, x, weights_real, weights_imag):\n",
    "        return torch.complex(torch.einsum(order, x.real, weights_real) - torch.einsum(order, x.imag, weights_imag),\n",
    "                                 torch.einsum(order, x.real, weights_imag) + torch.einsum(order, x.imag, weights_real))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H, E, N = x.shape\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "        out_ft = torch.zeros(B, H, self.out_channels, x.size(-1) // 2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        a = x_ft[:, :, :, :self.modes]\n",
    "        out_ft[:, :, :, :self.modes] = self.compl_mul1d(\"bjix,iox->bjox\", a, self.weights_real, self.weights_imag)\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x\n",
    "\n",
    "# FiLM模型\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, seq_len, label_len, pred_len, enc_in):\n",
    "        super(FiLM, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = seq_len if pred_len == 0 else pred_len\n",
    "\n",
    "        self.seq_len_all = self.seq_len + self.label_len\n",
    "\n",
    "        # b, s, f means b, f\n",
    "        self.affine_weight = nn.Parameter(torch.ones(1, 1, enc_in))\n",
    "        self.affine_bias = nn.Parameter(torch.zeros(1, 1, enc_in))\n",
    "\n",
    "        self.multiscale = [1, 2, 4]\n",
    "        self.window_size = [256]\n",
    "        ratio = 0.5\n",
    "        self.legts = nn.ModuleList(\n",
    "            [HiPPO_LegT(N=n, dt=1. / self.pred_len / i) for n in self.window_size for i in self.multiscale])\n",
    "        self.spec_conv_1 = nn.ModuleList([SpectralConv1d(in_channels=n, out_channels=n,\n",
    "                                                         seq_len=min(self.pred_len, self.seq_len),\n",
    "                                                         ratio=ratio) for n in\n",
    "                                          self.window_size for _ in range(len(self.multiscale))])\n",
    "        self.mlp = nn.Linear(len(self.multiscale) * len(self.window_size), 1)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # Normalization from Non-stationary Transformer\n",
    "        means = x_enc.mean(1, keepdim=True).detach()\n",
    "        x_enc = x_enc - means\n",
    "        stdev = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach()\n",
    "        x_enc /= stdev\n",
    "\n",
    "        x_enc = x_enc * self.affine_weight + self.affine_bias\n",
    "        x_decs = []\n",
    "        jump_dist = 0\n",
    "        for i in range(0, len(self.multiscale) * len(self.window_size)):\n",
    "            x_in_len = self.multiscale[i % len(self.multiscale)] * self.pred_len\n",
    "            x_in = x_enc[:, -x_in_len:]\n",
    "            legt = self.legts[i]\n",
    "            x_in_c = legt(x_in.transpose(1, 2)).permute([1, 2, 3, 0])[:, :, :, jump_dist:]\n",
    "            out1 = self.spec_conv_1[i](x_in_c)\n",
    "            if self.seq_len >= self.pred_len:\n",
    "                x_dec_c = out1.transpose(2, 3)[:, :, self.pred_len - 1 - jump_dist, :]\n",
    "            else:\n",
    "                x_dec_c = out1.transpose(2, 3)[:, :, -1, :]\n",
    "            x_dec = x_dec_c @ legt.eval_matrix[-self.pred_len:, :].T\n",
    "            x_decs.append(x_dec)\n",
    "        x_dec = torch.stack(x_decs, dim=-1)\n",
    "        x_dec = self.mlp(x_dec).squeeze(-1).permute(0, 2, 1)\n",
    "\n",
    "        # De-Normalization from Non-stationary Transformer\n",
    "        x_dec = x_dec - self.affine_bias\n",
    "        x_dec = x_dec / (self.affine_weight + 1e-10)\n",
    "        x_dec = x_dec * stdev\n",
    "        dec_out = x_dec + means\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8d572",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9274aa96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:22:48.448879Z",
     "start_time": "2024-04-14T13:22:48.407043Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:02:09.676703Z",
     "iopub.status.busy": "2024-04-19T12:02:09.675701Z",
     "iopub.status.idle": "2024-04-19T12:02:09.742902Z",
     "shell.execute_reply": "2024-04-19T12:02:09.741958Z",
     "shell.execute_reply.started": "2024-04-19T12:02:09.676703Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4694a9e5-750f-4e90-aa37-9a565de714f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:02:13.474478Z",
     "iopub.status.busy": "2024-04-19T12:02:13.473445Z",
     "iopub.status.idle": "2024-04-19T12:04:02.588617Z",
     "shell.execute_reply": "2024-04-19T12:04:02.587658Z",
     "shell.execute_reply.started": "2024-04-19T12:02:13.474478Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:15<04:54, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0055, Validation Loss: 0.0034\n",
      "Validation loss decreased (inf --> 0.003438).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:30<04:37, 15.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0030, Validation Loss: 0.0029\n",
      "Validation loss decreased (0.003438 --> 0.002891).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:46<04:22, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0028, Validation Loss: 0.0027\n",
      "Validation loss decreased (0.002891 --> 0.002749).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [01:01<04:08, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0027, Validation Loss: 0.0027\n",
      "Validation loss decreased (0.002749 --> 0.002715).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [01:18<03:55, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0027, Validation Loss: 0.0027\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [01:33<03:37, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0027, Validation Loss: 0.0027\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [01:48<04:13, 18.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0027, Validation Loss: 0.0027\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": FiLM,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/FiLM\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'label_len': 3,\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d8b27",
   "metadata": {},
   "source": [
    "# 基于Koopa的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf2ba6",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13a7b5",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "affd3f52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:23:16.055582Z",
     "start_time": "2024-04-14T13:23:16.044932Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:04:24.666065Z",
     "iopub.status.busy": "2024-04-19T12:04:24.664075Z",
     "iopub.status.idle": "2024-04-19T12:04:24.681177Z",
     "shell.execute_reply": "2024-04-19T12:04:24.680122Z",
     "shell.execute_reply.started": "2024-04-19T12:04:24.666065Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60b2b13f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:23:17.474971Z",
     "start_time": "2024-04-14T13:23:17.390728Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:04:25.406472Z",
     "iopub.status.busy": "2024-04-19T12:04:25.404473Z",
     "iopub.status.idle": "2024-04-19T12:04:25.525460Z",
     "shell.execute_reply": "2024-04-19T12:04:25.523457Z",
     "shell.execute_reply.started": "2024-04-19T12:04:25.406472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f7bb731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:23:19.334838Z",
     "start_time": "2024-04-14T13:23:19.292152Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:04:26.260742Z",
     "iopub.status.busy": "2024-04-19T12:04:26.259859Z",
     "iopub.status.idle": "2024-04-19T12:04:26.292765Z",
     "shell.execute_reply": "2024-04-19T12:04:26.291326Z",
     "shell.execute_reply.started": "2024-04-19T12:04:26.260742Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "64c79d56-5b85-477f-9e08-0b0030535e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:04:27.069029Z",
     "iopub.status.busy": "2024-04-19T12:04:27.068028Z",
     "iopub.status.idle": "2024-04-19T12:04:27.093293Z",
     "shell.execute_reply": "2024-04-19T12:04:27.091729Z",
     "shell.execute_reply.started": "2024-04-19T12:04:27.069029Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f686ff4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:23:21.118072Z",
     "start_time": "2024-04-14T13:23:21.049820Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:04:29.060523Z",
     "iopub.status.busy": "2024-04-19T12:04:29.059524Z",
     "iopub.status.idle": "2024-04-19T12:04:29.147668Z",
     "shell.execute_reply": "2024-04-19T12:04:29.146783Z",
     "shell.execute_reply.started": "2024-04-19T12:04:29.060523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/Koopa'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10123319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:23:23.105082Z",
     "start_time": "2024-04-14T13:23:23.092650Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:04:30.020615Z",
     "iopub.status.busy": "2024-04-19T12:04:30.019614Z",
     "iopub.status.idle": "2024-04-19T12:04:30.050749Z",
     "shell.execute_reply": "2024-04-19T12:04:30.048701Z",
     "shell.execute_reply.started": "2024-04-19T12:04:30.020615Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b725980e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:23:25.838113Z",
     "start_time": "2024-04-14T13:23:24.942023Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:04:31.233020Z",
     "iopub.status.busy": "2024-04-19T12:04:31.231020Z",
     "iopub.status.idle": "2024-04-19T12:04:32.361895Z",
     "shell.execute_reply": "2024-04-19T12:04:32.360970Z",
     "shell.execute_reply.started": "2024-04-19T12:04:31.233020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 0,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda04ab3",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a085a4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:24:20.331208Z",
     "start_time": "2024-04-14T13:24:20.267323Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:04:33.637517Z",
     "iopub.status.busy": "2024-04-19T12:04:33.636497Z",
     "iopub.status.idle": "2024-04-19T12:04:33.725437Z",
     "shell.execute_reply": "2024-04-19T12:04:33.724434Z",
     "shell.execute_reply.started": "2024-04-19T12:04:33.637517Z"
    }
   },
   "outputs": [],
   "source": [
    "class FourierFilter(nn.Module):\n",
    "    \"\"\"\n",
    "    Fourier Filter: to time-variant and time-invariant term\n",
    "    \"\"\"\n",
    "    def __init__(self, mask_spectrum):\n",
    "        super(FourierFilter, self).__init__()\n",
    "        self.mask_spectrum = mask_spectrum\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xf = torch.fft.rfft(x, dim=1)\n",
    "        mask = torch.ones_like(xf)\n",
    "        mask[:, self.mask_spectrum, :] = 0\n",
    "        x_var = torch.fft.irfft(xf*mask, dim=1)\n",
    "        x_inv = x - x_var\n",
    "        \n",
    "        return x_var, x_inv\n",
    "    \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    '''\n",
    "    Multilayer perceptron to encode/decode high dimension representation of sequential data\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 f_in, \n",
    "                 f_out, \n",
    "                 hidden_dim=128, \n",
    "                 hidden_layers=2, \n",
    "                 dropout=0.05,\n",
    "                 activation='tanh'): \n",
    "        super(MLP, self).__init__()\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.dropout = dropout\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        layers = [nn.Linear(self.f_in, self.hidden_dim), \n",
    "                  self.activation, nn.Dropout(self.dropout)]\n",
    "        for i in range(self.hidden_layers-2):\n",
    "            layers += [nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "                       self.activation, nn.Dropout(dropout)]\n",
    "        \n",
    "        layers += [nn.Linear(hidden_dim, f_out)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x:     B x S x f_in\n",
    "        # y:     B x S x f_out\n",
    "        y = self.layers(x)\n",
    "        return y\n",
    "    \n",
    "\n",
    "class KPLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Find koopman transition of linear system by DMD with one step approximation\n",
    "    \"\"\"\n",
    "    def __init__(self): \n",
    "        super(KPLayer, self).__init__()\n",
    "        \n",
    "        self.K = None # B E E\n",
    "\n",
    "    def one_step_forward(self, z, return_rec=False, return_K=False):\n",
    "        B, input_len, E = z.shape\n",
    "        assert input_len > 1, 'snapshots number should be larger than 1'\n",
    "        x, y = z[:, :-1], z[:, 1:]\n",
    "\n",
    "        # solve linear system\n",
    "        self.K = torch.linalg.lstsq(x, y).solution # B E E\n",
    "        if torch.isnan(self.K).any():\n",
    "            print('Encounter K with nan, replace K by identity matrix')\n",
    "            self.K = torch.eye(self.K.shape[1]).to(self.K.device).unsqueeze(0).repeat(B, 1, 1)\n",
    "\n",
    "        z_pred = torch.bmm(z[:, -1:], self.K)\n",
    "        if return_rec:\n",
    "            z_rec = torch.cat((z[:, :1], torch.bmm(x, self.K)), dim=1)\n",
    "            return z_rec, z_pred\n",
    "\n",
    "        return z_pred\n",
    "    \n",
    "    def forward(self, z, pred_len=1):\n",
    "        z_rec, z_pred= self.one_step_forward(z, return_rec=True)\n",
    "        z_preds = []\n",
    "        for i in range(pred_len):\n",
    "            z_pred = torch.bmm(z_pred, self.K)\n",
    "            z_preds.append(z_pred)\n",
    "        z_preds = torch.cat(z_preds, dim=1)\n",
    "        return z_rec, z_preds\n",
    "\n",
    "\n",
    "class KPLayerApprox(nn.Module):\n",
    "    \"\"\"\n",
    "    Find koopman transition of linear system by DMD with multistep K approximation\n",
    "    \"\"\"\n",
    "    def __init__(self): \n",
    "        super(KPLayerApprox, self).__init__()\n",
    "        \n",
    "        self.K = None # B E E\n",
    "        self.K_step = None # B E E\n",
    "\n",
    "    def forward(self, z, pred_len=1):\n",
    "        # z:       B L E, koopman invariance space representation\n",
    "        # z_rec:   B L E, reconstructed representation\n",
    "        # z_pred:  B S E, forecasting representation\n",
    "        B, input_len, E = z.shape\n",
    "        assert input_len > 1, 'snapshots number should be larger than 1'\n",
    "        x, y = z[:, :-1], z[:, 1:]\n",
    "\n",
    "        # solve linear system\n",
    "        self.K = torch.linalg.lstsq(x, y).solution # B E E\n",
    "\n",
    "        if torch.isnan(self.K).any():\n",
    "            print('Encounter K with nan, replace K by identity matrix')\n",
    "            self.K = torch.eye(self.K.shape[1]).to(self.K.device).unsqueeze(0).repeat(B, 1, 1)\n",
    "\n",
    "        z_rec = torch.cat((z[:, :1], torch.bmm(x, self.K)), dim=1) # B L E\n",
    "        \n",
    "        if pred_len <= input_len:\n",
    "            self.K_step = torch.linalg.matrix_power(self.K, pred_len)\n",
    "            if torch.isnan(self.K_step).any():\n",
    "                print('Encounter multistep K with nan, replace it by identity matrix')\n",
    "                self.K_step = torch.eye(self.K_step.shape[1]).to(self.K_step.device).unsqueeze(0).repeat(B, 1, 1)\n",
    "            z_pred = torch.bmm(z[:, -pred_len:, :], self.K_step)\n",
    "        else:\n",
    "            self.K_step = torch.linalg.matrix_power(self.K, input_len)\n",
    "            if torch.isnan(self.K_step).any():\n",
    "                print('Encounter multistep K with nan, replace it by identity matrix')\n",
    "                self.K_step = torch.eye(self.K_step.shape[1]).to(self.K_step.device).unsqueeze(0).repeat(B, 1, 1)\n",
    "            temp_z_pred, all_pred = z, []\n",
    "            for _ in range(math.ceil(pred_len / input_len)):\n",
    "                temp_z_pred = torch.bmm(temp_z_pred, self.K_step)\n",
    "                all_pred.append(temp_z_pred)\n",
    "            z_pred = torch.cat(all_pred, dim=1)[:, :pred_len, :]\n",
    "\n",
    "        return z_rec, z_pred\n",
    "    \n",
    "\n",
    "class TimeVarKP(nn.Module):\n",
    "    \"\"\"\n",
    "    Koopman Predictor with DMD (analysitical solution of Koopman operator)\n",
    "    Utilize local variations within individual sliding window to predict the future of time-variant term\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 enc_in=8,\n",
    "                 input_len=96,\n",
    "                 pred_len=96,\n",
    "                 seg_len=24,\n",
    "                 dynamic_dim=128,\n",
    "                 encoder=None,\n",
    "                 decoder=None,\n",
    "                 multistep=False,\n",
    "                ):\n",
    "        super(TimeVarKP, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in = enc_in\n",
    "        self.seg_len = seg_len\n",
    "        self.dynamic_dim = dynamic_dim\n",
    "        self.multistep = multistep\n",
    "        self.encoder, self.decoder = encoder, decoder            \n",
    "        self.freq = math.ceil(self.input_len / self.seg_len)  # segment number of input\n",
    "        self.step = math.ceil(self.pred_len / self.seg_len)   # segment number of output\n",
    "        self.padding_len = self.seg_len * self.freq - self.input_len\n",
    "        # Approximate mulitstep K by KPLayerApprox when pred_len is large\n",
    "        self.dynamics = KPLayerApprox() if self.multistep else KPLayer() \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: B L C\n",
    "        B, L, C = x.shape\n",
    "\n",
    "        res = torch.cat((x[:, L-self.padding_len:, :], x) ,dim=1)\n",
    "\n",
    "        res = res.chunk(self.freq, dim=1)     # F x B P C, P means seg_len\n",
    "        res = torch.stack(res, dim=1).reshape(B, self.freq, -1)   # B F PC\n",
    "\n",
    "        res = self.encoder(res) # B F H\n",
    "        x_rec, x_pred = self.dynamics(res, self.step) # B F H, B S H\n",
    "\n",
    "        x_rec = self.decoder(x_rec) # B F PC\n",
    "        x_rec = x_rec.reshape(B, self.freq, self.seg_len, self.enc_in)\n",
    "        x_rec = x_rec.reshape(B, -1, self.enc_in)[:, :self.input_len, :]  # B L C\n",
    "        \n",
    "        x_pred = self.decoder(x_pred)     # B S PC\n",
    "        x_pred = x_pred.reshape(B, self.step, self.seg_len, self.enc_in)\n",
    "        x_pred = x_pred.reshape(B, -1, self.enc_in)[:, :self.pred_len, :] # B S C\n",
    "\n",
    "        return x_rec, x_pred\n",
    "\n",
    "\n",
    "class TimeInvKP(nn.Module):\n",
    "    \"\"\"\n",
    "    Koopman Predictor with learnable Koopman operator\n",
    "    Utilize lookback and forecast window snapshots to predict the future of time-invariant term\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_len=96,\n",
    "                 pred_len=96,\n",
    "                 dynamic_dim=128,\n",
    "                 encoder=None,\n",
    "                 decoder=None):\n",
    "        super(TimeInvKP, self).__init__()\n",
    "        self.dynamic_dim = dynamic_dim\n",
    "        self.input_len = input_len\n",
    "        self.pred_len = pred_len\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        K_init = torch.randn(self.dynamic_dim, self.dynamic_dim)\n",
    "        U, _, V = torch.svd(K_init) # stable initialization\n",
    "        self.K = nn.Linear(self.dynamic_dim, self.dynamic_dim, bias=False)\n",
    "        self.K.weight.data = torch.mm(U, V.t())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: B L C\n",
    "        res = x.transpose(1, 2) # B C L\n",
    "        res = self.encoder(res) # B C H\n",
    "        res = self.K(res) # B C H\n",
    "        res = self.decoder(res) # B C S\n",
    "        res = res.transpose(1, 2) # B S C\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "# Koopa模型\n",
    "class Koopa(nn.Module):\n",
    "    def __init__(self, enc_in, seq_len, pred_len, label_len, train_loader, dynamic_dim=128, hidden_dim=64, \n",
    "                 hidden_layers=2, num_blocks=3, multistep=False):\n",
    "        \"\"\"\n",
    "        mask_spectrum: list, shared frequency spectrums\n",
    "        seg_len: int, segment length of time series\n",
    "        dynamic_dim: int, latent dimension of koopman embedding\n",
    "        hidden_dim: int, hidden dimension of en/decoder\n",
    "        hidden_layers: int, number of hidden layers of en/decoder\n",
    "        num_blocks: int, number of Koopa blocks\n",
    "        multistep: bool, whether to use approximation for multistep K\n",
    "        alpha: float, spectrum filter ratio\n",
    "        \"\"\"\n",
    "        super(Koopa, self).__init__()\n",
    "        self.enc_in = enc_in\n",
    "        self.input_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        self.seg_len = self.pred_len\n",
    "        self.num_blocks = num_blocks\n",
    "        self.dynamic_dim = dynamic_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.multistep = multistep\n",
    "        self.alpha = 0.2\n",
    "        self.mask_spectrum = self._get_mask_spectrum(train_loader)\n",
    "\n",
    "        self.disentanglement = FourierFilter(self.mask_spectrum)\n",
    "\n",
    "        # shared encoder/decoder to make koopman embedding consistent\n",
    "        self.time_inv_encoder = MLP(f_in=self.input_len, f_out=self.dynamic_dim, activation='relu',\n",
    "                    hidden_dim=self.hidden_dim, hidden_layers=self.hidden_layers)\n",
    "        self.time_inv_decoder = MLP(f_in=self.dynamic_dim, f_out=self.pred_len, activation='relu',\n",
    "                           hidden_dim=self.hidden_dim, hidden_layers=self.hidden_layers)\n",
    "        self.time_inv_kps = self.time_var_kps = nn.ModuleList([\n",
    "                                TimeInvKP(input_len=self.input_len,\n",
    "                                    pred_len=self.pred_len, \n",
    "                                    dynamic_dim=self.dynamic_dim,\n",
    "                                    encoder=self.time_inv_encoder, \n",
    "                                    decoder=self.time_inv_decoder)\n",
    "                                for _ in range(self.num_blocks)])\n",
    "\n",
    "        # shared encoder/decoder to make koopman embedding consistent\n",
    "        self.time_var_encoder = MLP(f_in=self.seg_len*self.enc_in, f_out=self.dynamic_dim, activation='tanh',\n",
    "                           hidden_dim=self.hidden_dim, hidden_layers=self.hidden_layers)\n",
    "        self.time_var_decoder = MLP(f_in=self.dynamic_dim, f_out=self.seg_len*self.enc_in, activation='tanh',\n",
    "                           hidden_dim=self.hidden_dim, hidden_layers=self.hidden_layers)\n",
    "        self.time_var_kps = nn.ModuleList([\n",
    "                    TimeVarKP(enc_in=enc_in,\n",
    "                        input_len=self.input_len,\n",
    "                        pred_len=self.pred_len,\n",
    "                        seg_len=self.seg_len,\n",
    "                        dynamic_dim=self.dynamic_dim,\n",
    "                        encoder=self.time_var_encoder,\n",
    "                        decoder=self.time_var_decoder,\n",
    "                        multistep=self.multistep)\n",
    "                    for _ in range(self.num_blocks)])\n",
    "\n",
    "    def _get_mask_spectrum(self, train_loader):\n",
    "        \"\"\"\n",
    "        get shared frequency spectrums\n",
    "        \"\"\"\n",
    "#         train_data, train_loader = data_provider(configs, 'train')\n",
    "        amps = 0.0\n",
    "        for data in train_loader:\n",
    "            lookback_window = data[0]\n",
    "            amps += abs(torch.fft.rfft(lookback_window, dim=1)).mean(dim=0).mean(dim=1)\n",
    "        mask_spectrum = amps.topk(int(amps.shape[0]*self.alpha)).indices\n",
    "        return mask_spectrum # as the spectrums of time-invariant component\n",
    "    \n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # Series Stationarization adopted from NSformer\n",
    "        mean_enc = x_enc.mean(1, keepdim=True).detach() # B x 1 x E\n",
    "        x_enc = x_enc - mean_enc\n",
    "        std_enc = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach()\n",
    "        x_enc = x_enc / std_enc\n",
    "\n",
    "        # Koopman Forecasting\n",
    "        residual, forecast = x_enc, None\n",
    "        for i in range(self.num_blocks):\n",
    "            time_var_input, time_inv_input = self.disentanglement(residual)\n",
    "            time_inv_output = self.time_inv_kps[i](time_inv_input)\n",
    "            time_var_backcast, time_var_output = self.time_var_kps[i](time_var_input)\n",
    "            residual = residual - time_var_backcast\n",
    "            if forecast is None:\n",
    "                forecast = (time_inv_output + time_var_output)\n",
    "            else:\n",
    "                forecast += (time_inv_output + time_var_output)\n",
    "\n",
    "        # Series Stationarization adopted from NSformer\n",
    "        dec_out = forecast * std_enc + mean_enc\n",
    "\n",
    "        output = dec_out[:, -self.pred_len:, :] # [B, L, D]\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bbdc4",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5952dbbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:24:22.807326Z",
     "start_time": "2024-04-14T13:24:22.765773Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:04:35.232844Z",
     "iopub.status.busy": "2024-04-19T12:04:35.230842Z",
     "iopub.status.idle": "2024-04-19T12:04:35.303353Z",
     "shell.execute_reply": "2024-04-19T12:04:35.302354Z",
     "shell.execute_reply.started": "2024-04-19T12:04:35.232844Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "adbfe759-94db-4c34-933d-b5c285053d02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:04:38.833859Z",
     "iopub.status.busy": "2024-04-19T12:04:38.831283Z",
     "iopub.status.idle": "2024-04-19T12:17:40.997643Z",
     "shell.execute_reply": "2024-04-19T12:17:40.996674Z",
     "shell.execute_reply.started": "2024-04-19T12:04:38.832856Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:37<11:46, 37.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0034, Validation Loss: 0.0024\n",
      "Validation loss decreased (inf --> 0.002411).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [01:14<11:06, 37.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0025, Validation Loss: 0.0018\n",
      "Validation loss decreased (0.002411 --> 0.001830).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [01:50<10:24, 36.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0023, Validation Loss: 0.0018\n",
      "Validation loss decreased (0.001830 --> 0.001790).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [02:26<09:43, 36.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0022, Validation Loss: 0.0017\n",
      "Validation loss decreased (0.001790 --> 0.001697).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [03:03<09:11, 36.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0022, Validation Loss: 0.0017\n",
      "Validation loss decreased (0.001697 --> 0.001652).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [03:41<08:37, 36.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0020, Validation Loss: 0.0016\n",
      "Validation loss decreased (0.001652 --> 0.001618).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [04:17<07:59, 36.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0020, Validation Loss: 0.0016\n",
      "Validation loss decreased (0.001618 --> 0.001615).  Saving model ...\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [04:54<07:20, 36.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0019, Validation Loss: 0.0018\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                             | 9/20 [05:32<06:48, 37.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0019, Validation Loss: 0.0015\n",
      "Validation loss decreased (0.001615 --> 0.001455).  Saving model ...\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 10/20 [06:09<06:11, 37.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0018, Validation Loss: 0.0014\n",
      "Validation loss decreased (0.001455 --> 0.001415).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████                                     | 11/20 [06:48<05:40, 37.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0018, Validation Loss: 0.0014\n",
      "Validation loss decreased (0.001415 --> 0.001364).  Saving model ...\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [07:28<05:06, 38.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0018, Validation Loss: 0.0014\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [08:04<04:24, 37.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0017, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.001364 --> 0.001323).  Saving model ...\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [08:41<03:44, 37.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0017, Validation Loss: 0.0014\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [09:28<03:21, 40.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0017, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.001323 --> 0.001303).  Saving model ...\n",
      "Updating learning rate to 0.00014644660940672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [10:06<02:38, 39.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0017, Validation Loss: 0.0013\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [10:54<02:06, 42.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0017, Validation Loss: 0.0013\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.449673790581611e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [11:36<01:24, 42.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0017, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.001303 --> 0.001296).  Saving model ...\n",
      "Updating learning rate to 2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [12:21<00:42, 42.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0017, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.001296 --> 0.001292).  Saving model ...\n",
      "Updating learning rate to 6.15582970243117e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [13:00<00:00, 39.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0016, Validation Loss: 0.0013\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Koopa,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/Koopa\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        \"label_len\": 0,\n",
    "        'train_loader': train_loader,\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd0701",
   "metadata": {},
   "source": [
    "# 基于LightTS的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b98b6",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773c5f3",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3774513a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:05.808373Z",
     "start_time": "2024-04-14T13:25:05.794653Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:17:51.309628Z",
     "iopub.status.busy": "2024-04-19T12:17:51.308629Z",
     "iopub.status.idle": "2024-04-19T12:17:51.336625Z",
     "shell.execute_reply": "2024-04-19T12:17:51.335629Z",
     "shell.execute_reply.started": "2024-04-19T12:17:51.309628Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01289bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:06.815598Z",
     "start_time": "2024-04-14T13:25:06.733431Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:17:52.178224Z",
     "iopub.status.busy": "2024-04-19T12:17:52.177646Z",
     "iopub.status.idle": "2024-04-19T12:17:52.255270Z",
     "shell.execute_reply": "2024-04-19T12:17:52.254262Z",
     "shell.execute_reply.started": "2024-04-19T12:17:52.178224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0cf04d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:08.099507Z",
     "start_time": "2024-04-14T13:25:08.065344Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:17:52.938208Z",
     "iopub.status.busy": "2024-04-19T12:17:52.937211Z",
     "iopub.status.idle": "2024-04-19T12:17:52.970748Z",
     "shell.execute_reply": "2024-04-19T12:17:52.969765Z",
     "shell.execute_reply.started": "2024-04-19T12:17:52.938208Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf74ef68-dc6c-44be-8133-235ccd0ee58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:17:53.697393Z",
     "iopub.status.busy": "2024-04-19T12:17:53.696439Z",
     "iopub.status.idle": "2024-04-19T12:17:53.734488Z",
     "shell.execute_reply": "2024-04-19T12:17:53.733030Z",
     "shell.execute_reply.started": "2024-04-19T12:17:53.697393Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "00c2f379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:09.198121Z",
     "start_time": "2024-04-14T13:25:09.127706Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:17:55.699408Z",
     "iopub.status.busy": "2024-04-19T12:17:55.698440Z",
     "iopub.status.idle": "2024-04-19T12:17:55.769440Z",
     "shell.execute_reply": "2024-04-19T12:17:55.768442Z",
     "shell.execute_reply.started": "2024-04-19T12:17:55.699408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/LightTS'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0482dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:10.556901Z",
     "start_time": "2024-04-14T13:25:10.536851Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:17:56.560363Z",
     "iopub.status.busy": "2024-04-19T12:17:56.559914Z",
     "iopub.status.idle": "2024-04-19T12:17:56.586391Z",
     "shell.execute_reply": "2024-04-19T12:17:56.585395Z",
     "shell.execute_reply.started": "2024-04-19T12:17:56.560363Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "892e7676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:12.647496Z",
     "start_time": "2024-04-14T13:25:11.786489Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:17:57.604856Z",
     "iopub.status.busy": "2024-04-19T12:17:57.603866Z",
     "iopub.status.idle": "2024-04-19T12:17:58.794651Z",
     "shell.execute_reply": "2024-04-19T12:17:58.793647Z",
     "shell.execute_reply.started": "2024-04-19T12:17:57.604856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 0,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0aa3e",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c194077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:15.135398Z",
     "start_time": "2024-04-14T13:25:15.107363Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:18:00.144711Z",
     "iopub.status.busy": "2024-04-19T12:18:00.143713Z",
     "iopub.status.idle": "2024-04-19T12:18:00.178702Z",
     "shell.execute_reply": "2024-04-19T12:18:00.177707Z",
     "shell.execute_reply.started": "2024-04-19T12:18:00.144711Z"
    }
   },
   "outputs": [],
   "source": [
    "class IEBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, output_dim, num_node):\n",
    "        super(IEBlock, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_node = num_node\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        self.spatial_proj = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hid_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hid_dim, self.hid_dim // 4)\n",
    "        )\n",
    "\n",
    "        self.channel_proj = nn.Linear(self.num_node, self.num_node)\n",
    "        torch.nn.init.eye_(self.channel_proj.weight)\n",
    "\n",
    "        self.output_proj = nn.Linear(self.hid_dim // 4, self.output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spatial_proj(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1) + self.channel_proj(x.permute(0, 2, 1))\n",
    "        x = self.output_proj(x.permute(0, 2, 1))\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# LightTS模型\n",
    "class LightTS(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, label_len, chunk_size, d_model, enc_in, dropout):\n",
    "        \"\"\"\n",
    "        chunk_size: int, reshape T into [num_chunks, chunk_size]\n",
    "        \"\"\"\n",
    "        super(LightTS, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        self.chunk_size = min(pred_len, seq_len, chunk_size)\n",
    "        assert (self.seq_len % self.chunk_size == 0)\n",
    "        self.num_chunks = self.seq_len // self.chunk_size\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.enc_in = enc_in\n",
    "        self.dropout = dropout\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        self.layer_1 = IEBlock(\n",
    "            input_dim=self.chunk_size,\n",
    "            hid_dim=self.d_model // 4,\n",
    "            output_dim=self.d_model // 4,\n",
    "            num_node=self.num_chunks\n",
    "        )\n",
    "\n",
    "        self.chunk_proj_1 = nn.Linear(self.num_chunks, 1)\n",
    "\n",
    "        self.layer_2 = IEBlock(\n",
    "            input_dim=self.chunk_size,\n",
    "            hid_dim=self.d_model // 4,\n",
    "            output_dim=self.d_model // 4,\n",
    "            num_node=self.num_chunks\n",
    "        )\n",
    "\n",
    "        self.chunk_proj_2 = nn.Linear(self.num_chunks, 1)\n",
    "\n",
    "        self.layer_3 = IEBlock(\n",
    "            input_dim=self.d_model // 2,\n",
    "            hid_dim=self.d_model // 2,\n",
    "            output_dim=self.pred_len,\n",
    "            num_node=self.enc_in\n",
    "        )\n",
    "\n",
    "        self.ar = nn.Linear(self.seq_len, self.pred_len)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        B, T, N = x.size()\n",
    "\n",
    "        highway = self.ar(x.permute(0, 2, 1))\n",
    "        highway = highway.permute(0, 2, 1)\n",
    "\n",
    "        # continuous sampling\n",
    "        x1 = x.reshape(B, self.num_chunks, self.chunk_size, N)\n",
    "        x1 = x1.permute(0, 3, 2, 1)\n",
    "        x1 = x1.reshape(-1, self.chunk_size, self.num_chunks)\n",
    "        x1 = self.layer_1(x1)\n",
    "        x1 = self.chunk_proj_1(x1).squeeze(dim=-1)\n",
    "\n",
    "        # interval sampling\n",
    "        x2 = x.reshape(B, self.chunk_size, self.num_chunks, N)\n",
    "        x2 = x2.permute(0, 3, 1, 2)\n",
    "        x2 = x2.reshape(-1, self.chunk_size, self.num_chunks)\n",
    "        x2 = self.layer_2(x2)\n",
    "        x2 = self.chunk_proj_2(x2).squeeze(dim=-1)\n",
    "\n",
    "        x3 = torch.cat([x1, x2], dim=-1)\n",
    "\n",
    "        x3 = x3.reshape(B, N, -1)\n",
    "        x3 = x3.permute(0, 2, 1)\n",
    "\n",
    "        out = self.layer_3(x3)\n",
    "\n",
    "        out = out + highway\n",
    "        return out\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        dec_out = self.encoder(x_enc)\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c4dda3",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2dcad24b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:21.848673Z",
     "start_time": "2024-04-14T13:25:21.806887Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:18:01.866879Z",
     "iopub.status.busy": "2024-04-19T12:18:01.864872Z",
     "iopub.status.idle": "2024-04-19T12:18:01.925005Z",
     "shell.execute_reply": "2024-04-19T12:18:01.924000Z",
     "shell.execute_reply.started": "2024-04-19T12:18:01.866879Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "757a6355-2fbf-4b48-a57f-0e4d7ccb54ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:18:05.662258Z",
     "iopub.status.busy": "2024-04-19T12:18:05.661535Z",
     "iopub.status.idle": "2024-04-19T12:18:59.010873Z",
     "shell.execute_reply": "2024-04-19T12:18:59.009870Z",
     "shell.execute_reply.started": "2024-04-19T12:18:05.662258Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:06<01:54,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0050, Validation Loss: 0.0017\n",
      "Validation loss decreased (inf --> 0.001739).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:11<01:45,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0021, Validation Loss: 0.0016\n",
      "Validation loss decreased (0.001739 --> 0.001551).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:17<01:38,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0019, Validation Loss: 0.0019\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [00:23<01:33,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0017, Validation Loss: 0.0014\n",
      "Validation loss decreased (0.001551 --> 0.001371).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [00:29<01:26,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0016, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.001371 --> 0.001309).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [00:35<01:22,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0016, Validation Loss: 0.0012\n",
      "Validation loss decreased (0.001309 --> 0.001243).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [00:40<01:16,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0015, Validation Loss: 0.0015\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [00:46<01:10,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0015, Validation Loss: 0.0014\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [00:52<01:19,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0014, Validation Loss: 0.0014\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": LightTS,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/LightTS\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        \"label_len\": 0,\n",
    "        'd_model': 512,\n",
    "        'chunk_size': 3,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cebc78",
   "metadata": {},
   "source": [
    "# 基于MICN的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4df734",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f233cf90",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "95abb636",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:51.988890Z",
     "start_time": "2024-04-14T13:25:51.976886Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:47:57.983095Z",
     "iopub.status.busy": "2024-04-19T12:47:57.983095Z",
     "iopub.status.idle": "2024-04-19T12:47:58.007130Z",
     "shell.execute_reply": "2024-04-19T12:47:58.006127Z",
     "shell.execute_reply.started": "2024-04-19T12:47:57.983095Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b037cc4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:53.099502Z",
     "start_time": "2024-04-14T13:25:53.027367Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:47:58.765657Z",
     "iopub.status.busy": "2024-04-19T12:47:58.764693Z",
     "iopub.status.idle": "2024-04-19T12:47:58.846694Z",
     "shell.execute_reply": "2024-04-19T12:47:58.845692Z",
     "shell.execute_reply.started": "2024-04-19T12:47:58.765657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bf2145bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:54.473736Z",
     "start_time": "2024-04-14T13:25:54.438760Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:47:59.752678Z",
     "iopub.status.busy": "2024-04-19T12:47:59.751550Z",
     "iopub.status.idle": "2024-04-19T12:47:59.784562Z",
     "shell.execute_reply": "2024-04-19T12:47:59.782641Z",
     "shell.execute_reply.started": "2024-04-19T12:47:59.752678Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "efd7ad5b-dd73-4816-8426-6fa4400c2f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:48:00.515486Z",
     "iopub.status.busy": "2024-04-19T12:48:00.514811Z",
     "iopub.status.idle": "2024-04-19T12:48:00.546488Z",
     "shell.execute_reply": "2024-04-19T12:48:00.545487Z",
     "shell.execute_reply.started": "2024-04-19T12:48:00.515486Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6a7671ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:55.608801Z",
     "start_time": "2024-04-14T13:25:55.539375Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:48:01.999664Z",
     "iopub.status.busy": "2024-04-19T12:48:01.997701Z",
     "iopub.status.idle": "2024-04-19T12:48:02.093832Z",
     "shell.execute_reply": "2024-04-19T12:48:02.092829Z",
     "shell.execute_reply.started": "2024-04-19T12:48:01.999664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/MICN'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9735e4c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:57.038268Z",
     "start_time": "2024-04-14T13:25:57.013552Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:48:04.555545Z",
     "iopub.status.busy": "2024-04-19T12:48:04.554548Z",
     "iopub.status.idle": "2024-04-19T12:48:04.579043Z",
     "shell.execute_reply": "2024-04-19T12:48:04.578042Z",
     "shell.execute_reply.started": "2024-04-19T12:48:04.555545Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b26f9013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:25:58.995467Z",
     "start_time": "2024-04-14T13:25:58.164627Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:48:11.279787Z",
     "iopub.status.busy": "2024-04-19T12:48:11.278789Z",
     "iopub.status.idle": "2024-04-19T12:48:12.669505Z",
     "shell.execute_reply": "2024-04-19T12:48:12.668504Z",
     "shell.execute_reply.started": "2024-04-19T12:48:11.279787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 3,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd312df",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c1da8a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:26:01.313037Z",
     "start_time": "2024-04-14T13:26:01.251127Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:52:48.950928Z",
     "iopub.status.busy": "2024-04-19T12:52:48.949926Z",
     "iopub.status.idle": "2024-04-19T12:52:49.037920Z",
     "shell.execute_reply": "2024-04-19T12:52:49.036958Z",
     "shell.execute_reply.started": "2024-04-19T12:52:48.950928Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        second_size = 2\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.second_size = Embed(second_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        second_x = self.second_size(x[:, :, 5])\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x + second_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# 编码器和解码器\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "\n",
    "class series_decomp_multi(nn.Module):\n",
    "    \"\"\"\n",
    "    Multiple Series decomposition block from FEDformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp_multi, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.series_decomp = [series_decomp(kernel) for kernel in kernel_size]\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = []\n",
    "        res = []\n",
    "        for func in self.series_decomp:\n",
    "            sea, moving_avg = func(x)\n",
    "            moving_mean.append(moving_avg)\n",
    "            res.append(sea)\n",
    "\n",
    "        sea = sum(res) / len(res)\n",
    "        moving_mean = sum(moving_mean) / len(moving_mean)\n",
    "        return sea, moving_mean\n",
    "    \n",
    "    \n",
    "class MIC(nn.Module):\n",
    "    \"\"\"\n",
    "    MIC layer to extract local and global features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_size=512, n_heads=8, dropout=0.05, decomp_kernel=[32], conv_kernel=[24],\n",
    "                 isometric_kernel=[18, 6]):\n",
    "        super(MIC, self).__init__()\n",
    "        self.conv_kernel = conv_kernel\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # isometric convolution\n",
    "        self.isometric_conv = nn.ModuleList([nn.Conv1d(in_channels=feature_size, out_channels=feature_size,\n",
    "                                                       kernel_size=i, padding=0, stride=1)\n",
    "                                             for i in isometric_kernel])\n",
    "\n",
    "        # downsampling convolution: padding=i//2, stride=i\n",
    "        self.conv = nn.ModuleList([nn.Conv1d(in_channels=feature_size, out_channels=feature_size,\n",
    "                                             kernel_size=i, padding=i // 2, stride=i)\n",
    "                                   for i in conv_kernel])\n",
    "\n",
    "        # upsampling convolution\n",
    "        self.conv_trans = nn.ModuleList([nn.ConvTranspose1d(in_channels=feature_size, out_channels=feature_size,\n",
    "                                                            kernel_size=i, padding=0, stride=i)\n",
    "                                         for i in conv_kernel])\n",
    "\n",
    "        self.decomp = nn.ModuleList([series_decomp(k) for k in decomp_kernel])\n",
    "        self.merge = torch.nn.Conv2d(in_channels=feature_size, out_channels=feature_size,\n",
    "                                     kernel_size=(len(self.conv_kernel), 1))\n",
    "\n",
    "        # feedforward network\n",
    "        self.conv1 = nn.Conv1d(in_channels=feature_size, out_channels=feature_size * 4, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=feature_size * 4, out_channels=feature_size, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(feature_size)\n",
    "        self.norm2 = nn.LayerNorm(feature_size)\n",
    "\n",
    "        self.norm = torch.nn.LayerNorm(feature_size)\n",
    "        self.act = torch.nn.Tanh()\n",
    "        self.drop = torch.nn.Dropout(0.05)\n",
    "\n",
    "    def conv_trans_conv(self, input, conv1d, conv1d_trans, isometric):\n",
    "        batch, seq_len, channel = input.shape\n",
    "        x = input.permute(0, 2, 1)\n",
    "\n",
    "        # downsampling convolution\n",
    "        x1 = self.drop(self.act(conv1d(x)))\n",
    "        x = x1\n",
    "\n",
    "        # isometric convolution\n",
    "        zeros = torch.zeros((x.shape[0], x.shape[1], x.shape[2] - 1), device=self.device)\n",
    "        x = torch.cat((zeros, x), dim=-1)\n",
    "        x = self.drop(self.act(isometric(x)))\n",
    "        x = self.norm((x + x1).permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        # upsampling convolution\n",
    "        x = self.drop(self.act(conv1d_trans(x)))\n",
    "        x = x[:, :, :seq_len]  # truncate\n",
    "\n",
    "        x = self.norm(x.permute(0, 2, 1) + input)\n",
    "        return x\n",
    "\n",
    "    def forward(self, src):\n",
    "        # multi-scale\n",
    "        multi = []\n",
    "        for i in range(len(self.conv_kernel)):\n",
    "            src_out, trend1 = self.decomp[i](src)\n",
    "            src_out = self.conv_trans_conv(src_out, self.conv[i], self.conv_trans[i], self.isometric_conv[i])\n",
    "            multi.append(src_out)\n",
    "\n",
    "            # merge\n",
    "        mg = torch.tensor([], device=self.device)\n",
    "        for i in range(len(self.conv_kernel)):\n",
    "            mg = torch.cat((mg, multi[i].unsqueeze(1)), dim=1)\n",
    "        mg = self.merge(mg.permute(0, 3, 1, 2)).squeeze(-2).permute(0, 2, 1)\n",
    "\n",
    "        y = self.norm1(mg)\n",
    "        y = self.conv2(self.conv1(y.transpose(-1, 1))).transpose(-1, 1)\n",
    "\n",
    "        return self.norm2(mg + y)\n",
    "\n",
    "\n",
    "class SeasonalPrediction(nn.Module):\n",
    "    def __init__(self, embedding_size=512, n_heads=8, dropout=0.05, d_layers=1, decomp_kernel=[32], c_out=1,\n",
    "                 conv_kernel=[2, 4], isometric_kernel=[18, 6]):\n",
    "        super(SeasonalPrediction, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.mic = nn.ModuleList([MIC(feature_size=embedding_size, n_heads=n_heads,\n",
    "                                      decomp_kernel=decomp_kernel, conv_kernel=conv_kernel,\n",
    "                                      isometric_kernel=isometric_kernel)\n",
    "                                  for i in range(d_layers)])\n",
    "\n",
    "        self.projection = nn.Linear(embedding_size, c_out)\n",
    "\n",
    "    def forward(self, dec):\n",
    "        for mic_layer in self.mic:\n",
    "            dec = mic_layer(dec)\n",
    "        return self.projection(dec)\n",
    "\n",
    "\n",
    "# MICN模型\n",
    "class MICN(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, label_len, enc_in, d_model, dropout, n_heads, d_layers, c_out, embed, freq, \n",
    "                 conv_kernel=[12, 16]):\n",
    "        \"\"\"\n",
    "        conv_kernel: downsampling and upsampling convolution kernel_size\n",
    "        \"\"\"\n",
    "        super(MICN, self).__init__()\n",
    "\n",
    "        decomp_kernel = []  # kernel of decomposition operation\n",
    "        isometric_kernel = []  # kernel of isometric convolution\n",
    "        for ii in conv_kernel:\n",
    "            if ii % 2 == 0:  # the kernel of decomposition operation must be odd\n",
    "                decomp_kernel.append(ii + 1)\n",
    "                isometric_kernel.append((seq_len + pred_len + ii) // ii)\n",
    "            else:\n",
    "                decomp_kernel.append(ii)\n",
    "                isometric_kernel.append((seq_len + pred_len + ii - 1) // ii)\n",
    "\n",
    "        self.pred_len = pred_len\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "\n",
    "        # Multiple Series decomposition block from FEDformer\n",
    "        self.decomp_multi = series_decomp_multi(decomp_kernel)\n",
    "\n",
    "        # embedding\n",
    "        self.dec_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "\n",
    "        self.conv_trans = SeasonalPrediction(embedding_size=d_model, n_heads=n_heads,\n",
    "                                             dropout=dropout, d_layers=d_layers, decomp_kernel=decomp_kernel,\n",
    "                                             c_out=c_out, conv_kernel=conv_kernel,\n",
    "                                             isometric_kernel=isometric_kernel)\n",
    "        # refer to DLinear\n",
    "        self.regression = nn.Linear(seq_len, pred_len)\n",
    "        self.regression.weight = nn.Parameter((1 / pred_len) * torch.ones([pred_len, seq_len]), requires_grad=True)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # Multi-scale Hybrid Decomposition\n",
    "        seasonal_init_enc, trend = self.decomp_multi(x_enc)\n",
    "        trend = self.regression(trend.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        # embedding\n",
    "        zeros = torch.zeros([x_dec.shape[0], self.pred_len, x_dec.shape[2]], device=x_dec.device)\n",
    "        seasonal_init_dec = torch.cat([seasonal_init_enc[:, -self.label_len:, :], zeros], dim=1)\n",
    "        dec_out = self.dec_embedding(seasonal_init_dec, x_mark_dec)\n",
    "        dec_out = self.conv_trans(dec_out)\n",
    "        dec_out = dec_out[:, -self.pred_len:, :] + trend[:, -self.pred_len:, :]\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658e3ff",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2dd094f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:27:13.997132Z",
     "start_time": "2024-04-14T13:27:13.955809Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:52:50.717492Z",
     "iopub.status.busy": "2024-04-19T12:52:50.716506Z",
     "iopub.status.idle": "2024-04-19T12:52:50.785090Z",
     "shell.execute_reply": "2024-04-19T12:52:50.784201Z",
     "shell.execute_reply.started": "2024-04-19T12:52:50.717492Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "707c9556-6510-4366-ab31-b271d62ea948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:52:51.741978Z",
     "iopub.status.busy": "2024-04-19T12:52:51.741134Z",
     "iopub.status.idle": "2024-04-19T12:57:28.194565Z",
     "shell.execute_reply": "2024-04-19T12:57:28.193643Z",
     "shell.execute_reply.started": "2024-04-19T12:52:51.741978Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:19<06:07, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0165, Validation Loss: 0.0047\n",
      "Validation loss decreased (inf --> 0.004726).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:38<05:47, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0027, Validation Loss: 0.0027\n",
      "Validation loss decreased (0.004726 --> 0.002742).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:57<05:28, 19.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0021, Validation Loss: 0.0022\n",
      "Validation loss decreased (0.002742 --> 0.002213).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [01:17<05:09, 19.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0017, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.002213 --> 0.001280).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [01:36<04:51, 19.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0016, Validation Loss: 0.0013\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [01:57<04:35, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0015, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.001280 --> 0.001058).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [02:31<05:19, 24.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0014, Validation Loss: 0.0012\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [02:53<04:45, 23.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0013, Validation Loss: 0.0009\n",
      "Validation loss decreased (0.001058 --> 0.000945).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                             | 9/20 [03:13<04:09, 22.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0013, Validation Loss: 0.0009\n",
      "Validation loss decreased (0.000945 --> 0.000926).  Saving model ...\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 10/20 [03:34<03:39, 21.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0012, Validation Loss: 0.0008\n",
      "Validation loss decreased (0.000926 --> 0.000752).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████                                     | 11/20 [03:54<03:13, 21.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0012, Validation Loss: 0.0008\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [04:15<02:49, 21.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0011, Validation Loss: 0.0008\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [04:35<03:03, 22.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0011, Validation Loss: 0.0008\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": MICN,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/MICN\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'label_len': 3,\n",
    "        'd_model': 128,\n",
    "        'n_heads': 8,\n",
    "        'dropout': 0.1,\n",
    "        'd_layers': 1,\n",
    "        'c_out': 2,\n",
    "        'embed': 'fixed',\n",
    "        'freq': 'h',\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaf496",
   "metadata": {},
   "source": [
    "# 基于Nonstationary_Transformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47cb66",
   "metadata": {},
   "source": [
    "非平稳时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1363432",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad9466",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "18fea494",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:27:42.605171Z",
     "start_time": "2024-04-14T13:27:42.577451Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:23:45.211182Z",
     "iopub.status.busy": "2024-04-19T12:23:45.211182Z",
     "iopub.status.idle": "2024-04-19T12:23:45.237054Z",
     "shell.execute_reply": "2024-04-19T12:23:45.236017Z",
     "shell.execute_reply.started": "2024-04-19T12:23:45.211182Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9ec9a5ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:27:43.559720Z",
     "start_time": "2024-04-14T13:27:43.479496Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:23:46.044760Z",
     "iopub.status.busy": "2024-04-19T12:23:46.043786Z",
     "iopub.status.idle": "2024-04-19T12:23:46.128137Z",
     "shell.execute_reply": "2024-04-19T12:23:46.127198Z",
     "shell.execute_reply.started": "2024-04-19T12:23:46.044760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "770724f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:27:44.781315Z",
     "start_time": "2024-04-14T13:27:44.742487Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:23:46.878480Z",
     "iopub.status.busy": "2024-04-19T12:23:46.877483Z",
     "iopub.status.idle": "2024-04-19T12:23:46.920416Z",
     "shell.execute_reply": "2024-04-19T12:23:46.918418Z",
     "shell.execute_reply.started": "2024-04-19T12:23:46.878480Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9950e536-39a4-4559-a2a6-c4ffdadd6278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:23:47.862151Z",
     "iopub.status.busy": "2024-04-19T12:23:47.861193Z",
     "iopub.status.idle": "2024-04-19T12:23:47.902176Z",
     "shell.execute_reply": "2024-04-19T12:23:47.901168Z",
     "shell.execute_reply.started": "2024-04-19T12:23:47.862151Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "88d19b82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:27:45.869772Z",
     "start_time": "2024-04-14T13:27:45.796832Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:23:49.606003Z",
     "iopub.status.busy": "2024-04-19T12:23:49.604016Z",
     "iopub.status.idle": "2024-04-19T12:23:49.684989Z",
     "shell.execute_reply": "2024-04-19T12:23:49.684098Z",
     "shell.execute_reply.started": "2024-04-19T12:23:49.606003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/Nonstationary_Transformer'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4f77dbfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:27:47.351781Z",
     "start_time": "2024-04-14T13:27:47.329621Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:23:50.402183Z",
     "iopub.status.busy": "2024-04-19T12:23:50.400233Z",
     "iopub.status.idle": "2024-04-19T12:23:50.435256Z",
     "shell.execute_reply": "2024-04-19T12:23:50.434257Z",
     "shell.execute_reply.started": "2024-04-19T12:23:50.402183Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "22a9a9d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:27:49.741551Z",
     "start_time": "2024-04-14T13:27:48.775651Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:23:55.568567Z",
     "iopub.status.busy": "2024-04-19T12:23:55.568567Z",
     "iopub.status.idle": "2024-04-19T12:23:56.860985Z",
     "shell.execute_reply": "2024-04-19T12:23:56.859982Z",
     "shell.execute_reply.started": "2024-04-19T12:23:55.568567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 3,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20496d35",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c17c68c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:27:52.320725Z",
     "start_time": "2024-04-14T13:27:52.245312Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:23:58.180092Z",
     "iopub.status.busy": "2024-04-19T12:23:58.177115Z",
     "iopub.status.idle": "2024-04-19T12:23:58.490050Z",
     "shell.execute_reply": "2024-04-19T12:23:58.485053Z",
     "shell.execute_reply.started": "2024-04-19T12:23:58.180092Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        second_size = 2\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.second_size = Embed(second_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        second_x = self.second_size(x[:, :, 5])\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x + second_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "# Transformer_EncDec类\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
    "                 dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask,\n",
    "            tau=tau, delta=None\n",
    "        )[0])\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )[0])\n",
    "\n",
    "        y = x = self.norm2(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm3(x + y)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask, tau=tau, delta=delta)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# 掩码层\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask    \n",
    "    \n",
    "    \n",
    "# 自注意力层\n",
    "class DSAttention(nn.Module):\n",
    "    '''De-stationary Attention'''\n",
    "\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(DSAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        tau = 1.0 if tau is None else tau.unsqueeze(\n",
    "            1).unsqueeze(1)  # B x 1 x 1 x 1\n",
    "        delta = 0.0 if delta is None else delta.unsqueeze(\n",
    "            1).unsqueeze(1)  # B x 1 x 1 x S\n",
    "\n",
    "        # De-stationary Attention, rescaling pre-softmax score with learned de-stationary factors\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys) * tau + delta\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "    \n",
    "    \n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "class Projector(nn.Module):\n",
    "    '''\n",
    "    MLP to learn the De-stationary factors\n",
    "    '''\n",
    "\n",
    "    def __init__(self, enc_in, seq_len, hidden_dims, hidden_layers, output_dim, kernel_size=3):\n",
    "        super(Projector, self).__init__()\n",
    "\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.series_conv = nn.Conv1d(in_channels=seq_len, out_channels=1, kernel_size=kernel_size, padding=padding,\n",
    "                                     padding_mode='circular', bias=False)\n",
    "\n",
    "        layers = [nn.Linear(2 * enc_in, hidden_dims[0]), nn.ReLU()]\n",
    "        for i in range(hidden_layers - 1):\n",
    "            layers += [nn.Linear(hidden_dims[i], hidden_dims[i + 1]), nn.ReLU()]\n",
    "\n",
    "        layers += [nn.Linear(hidden_dims[-1], output_dim, bias=False)]\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, stats):\n",
    "        # x:     B x S x E\n",
    "        # stats: B x 1 x E\n",
    "        # y:     B x O\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.series_conv(x)  # B x 1 x E\n",
    "        x = torch.cat([x, stats], dim=1)  # B x 2 x E\n",
    "        x = x.view(batch_size, -1)  # B x 2E\n",
    "        y = self.backbone(x)  # B x O\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "# Nonstationary_Transformer模型\n",
    "class Nonstationary_Transformer(nn.Module):\n",
    "    def __init__(self, pred_len, seq_len, label_len, output_attention, enc_in, d_model, \n",
    "                 dropout, factor, n_heads, d_ff, e_layers, d_layers, dec_in, c_out, p_hidden_dims, \n",
    "                p_hidden_layers, embed, freq):\n",
    "        super(Nonstationary_Transformer, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.output_attention = output_attention\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        DSAttention(False, factor, attention_dropout=dropout,\n",
    "                                    output_attention=output_attention), d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu'\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, dropout)\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        DSAttention(True, factor, attention_dropout=dropout,\n",
    "                                    output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    AttentionLayer(\n",
    "                        DSAttention(False, factor, attention_dropout=dropout,\n",
    "                                    output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model),\n",
    "            projection=nn.Linear(d_model, c_out, bias=True)\n",
    "        )\n",
    "\n",
    "        self.tau_learner = Projector(enc_in=enc_in, seq_len=seq_len, hidden_dims=p_hidden_dims,\n",
    "                                     hidden_layers=p_hidden_layers, output_dim=1)\n",
    "        self.delta_learner = Projector(enc_in=enc_in, seq_len=seq_len,\n",
    "                                       hidden_dims=p_hidden_dims, hidden_layers=p_hidden_layers,\n",
    "                                       output_dim=seq_len)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        x_raw = x_enc.clone().detach()\n",
    "\n",
    "        # Normalization\n",
    "        mean_enc = x_enc.mean(1, keepdim=True).detach()  # B x 1 x E\n",
    "        x_enc = x_enc - mean_enc\n",
    "        std_enc = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach()  # B x 1 x E\n",
    "        x_enc = x_enc / std_enc\n",
    "        # B x S x E, B x 1 x E -> B x 1, positive scalar\n",
    "        tau = self.tau_learner(x_raw, std_enc).exp()\n",
    "        # B x S x E, B x 1 x E -> B x S\n",
    "        delta = self.delta_learner(x_raw, mean_enc)\n",
    "\n",
    "        x_dec_new = torch.cat([x_enc[:, -self.label_len:, :], torch.zeros_like(x_dec[:, -self.pred_len:, :])],\n",
    "                              dim=1).to(x_enc.device).clone()\n",
    "\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None, tau=tau, delta=delta)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec_new, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out, x_mask=None, cross_mask=None, tau=tau, delta=delta)\n",
    "        dec_out = dec_out * std_enc + mean_enc\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f79d78",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7aa9f8b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:27:55.022609Z",
     "start_time": "2024-04-14T13:27:54.980567Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:23:59.728221Z",
     "iopub.status.busy": "2024-04-19T12:23:59.727242Z",
     "iopub.status.idle": "2024-04-19T12:23:59.792811Z",
     "shell.execute_reply": "2024-04-19T12:23:59.791922Z",
     "shell.execute_reply.started": "2024-04-19T12:23:59.728221Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b27c3f2d-7ec8-45c2-8d15-d214dd1f5fdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:24:08.332060Z",
     "iopub.status.busy": "2024-04-19T12:24:08.332060Z",
     "iopub.status.idle": "2024-04-19T12:28:12.579281Z",
     "shell.execute_reply": "2024-04-19T12:28:12.578504Z",
     "shell.execute_reply.started": "2024-04-19T12:24:08.332060Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:18<05:58, 18.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0030, Validation Loss: 0.0021\n",
      "Validation loss decreased (inf --> 0.002090).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:37<05:37, 18.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0018, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.002090 --> 0.001068).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:55<05:15, 18.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0015, Validation Loss: 0.0009\n",
      "Validation loss decreased (0.001068 --> 0.000926).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [01:14<04:54, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0012, Validation Loss: 0.0009\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [01:32<04:38, 18.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0012, Validation Loss: 0.0010\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [01:52<04:23, 18.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0011, Validation Loss: 0.0008\n",
      "Validation loss decreased (0.000926 --> 0.000755).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [02:11<04:05, 18.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0010, Validation Loss: 0.0007\n",
      "Validation loss decreased (0.000755 --> 0.000689).  Saving model ...\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [02:29<03:44, 18.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0010, Validation Loss: 0.0006\n",
      "Validation loss decreased (0.000689 --> 0.000570).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                             | 9/20 [02:48<03:25, 18.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0010, Validation Loss: 0.0006\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 10/20 [03:06<03:06, 18.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0009, Validation Loss: 0.0006\n",
      "Validation loss decreased (0.000570 --> 0.000553).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████                                     | 11/20 [03:25<02:48, 18.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0009, Validation Loss: 0.0006\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [03:44<02:29, 18.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0009, Validation Loss: 0.0006\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [04:03<02:42, 20.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0008, Validation Loss: 0.0006\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Nonstationary_Transformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/Nonstationary_Transformer\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'pred_len': 3, \n",
    "        'seq_len': 6,\n",
    "        'label_len': 3,\n",
    "        'd_model': 128,\n",
    "        'output_attention': False,\n",
    "        'enc_in': 2,\n",
    "        'dec_in': 2,\n",
    "        'dropout': 0.1,\n",
    "        'factor': 3, \n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'p_hidden_dims': [256, 256],\n",
    "        'p_hidden_layers': 1,\n",
    "        'embed': 'fixed',\n",
    "        'freq': 'h',\n",
    "        'c_out': 2,\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10d82f",
   "metadata": {},
   "source": [
    "# 基于Pyraformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d27401",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84b5940",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "accdf4bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:19.409670Z",
     "start_time": "2024-04-14T13:28:19.398538Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:28:29.189744Z",
     "iopub.status.busy": "2024-04-19T12:28:29.189744Z",
     "iopub.status.idle": "2024-04-19T12:28:29.210781Z",
     "shell.execute_reply": "2024-04-19T12:28:29.209784Z",
     "shell.execute_reply.started": "2024-04-19T12:28:29.189744Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ad782b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:20.546377Z",
     "start_time": "2024-04-14T13:28:20.461764Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:28:29.940718Z",
     "iopub.status.busy": "2024-04-19T12:28:29.940718Z",
     "iopub.status.idle": "2024-04-19T12:28:30.023566Z",
     "shell.execute_reply": "2024-04-19T12:28:30.022679Z",
     "shell.execute_reply.started": "2024-04-19T12:28:29.940718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0b154ca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:21.995447Z",
     "start_time": "2024-04-14T13:28:21.957599Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:28:30.722075Z",
     "iopub.status.busy": "2024-04-19T12:28:30.720077Z",
     "iopub.status.idle": "2024-04-19T12:28:30.755110Z",
     "shell.execute_reply": "2024-04-19T12:28:30.753223Z",
     "shell.execute_reply.started": "2024-04-19T12:28:30.721077Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c99701c-f6d3-4d0f-bbaa-a6def8076c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:28:31.439463Z",
     "iopub.status.busy": "2024-04-19T12:28:31.438464Z",
     "iopub.status.idle": "2024-04-19T12:28:31.473420Z",
     "shell.execute_reply": "2024-04-19T12:28:31.472451Z",
     "shell.execute_reply.started": "2024-04-19T12:28:31.439463Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d8c8a495",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:23.061731Z",
     "start_time": "2024-04-14T13:28:22.975184Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:28:32.836857Z",
     "iopub.status.busy": "2024-04-19T12:28:32.835315Z",
     "iopub.status.idle": "2024-04-19T12:28:32.955839Z",
     "shell.execute_reply": "2024-04-19T12:28:32.954878Z",
     "shell.execute_reply.started": "2024-04-19T12:28:32.836857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/Pyraformer'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c115f8e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:24.439808Z",
     "start_time": "2024-04-14T13:28:24.416743Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:28:33.617999Z",
     "iopub.status.busy": "2024-04-19T12:28:33.616966Z",
     "iopub.status.idle": "2024-04-19T12:28:33.638184Z",
     "shell.execute_reply": "2024-04-19T12:28:33.636636Z",
     "shell.execute_reply.started": "2024-04-19T12:28:33.617999Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "acee0507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:26.559551Z",
     "start_time": "2024-04-14T13:28:25.656320Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:28:34.845108Z",
     "iopub.status.busy": "2024-04-19T12:28:34.843055Z",
     "iopub.status.idle": "2024-04-19T12:28:36.421011Z",
     "shell.execute_reply": "2024-04-19T12:28:36.420288Z",
     "shell.execute_reply.started": "2024-04-19T12:28:34.845108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 0,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2885a8ec",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "796c6adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:29.663971Z",
     "start_time": "2024-04-14T13:28:29.577508Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:28:37.417413Z",
     "iopub.status.busy": "2024-04-19T12:28:37.416887Z",
     "iopub.status.idle": "2024-04-19T12:28:37.565407Z",
     "shell.execute_reply": "2024-04-19T12:28:37.564492Z",
     "shell.execute_reply.started": "2024-04-19T12:28:37.417413Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        second_size = 2\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.second_size = Embed(second_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        second_x = self.second_size(x[:, :, 5])\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x + second_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# 自注意力模块\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "    \n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "        \n",
    "        \n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "# Pyraformer_EncDec模块\n",
    "def get_mask(input_size, window_size, inner_size):\n",
    "    \"\"\"Get the attention mask of PAM-Naive\"\"\"\n",
    "    # Get the size of all layers\n",
    "    all_size = []\n",
    "    all_size.append(input_size)\n",
    "    for i in range(len(window_size)):\n",
    "        layer_size = math.floor(all_size[i] / window_size[i])\n",
    "        all_size.append(layer_size)\n",
    "\n",
    "    seq_length = sum(all_size)\n",
    "    mask = torch.zeros(seq_length, seq_length)\n",
    "\n",
    "    # get intra-scale mask\n",
    "    inner_window = inner_size // 2\n",
    "    for layer_idx in range(len(all_size)):\n",
    "        start = sum(all_size[:layer_idx])\n",
    "        for i in range(start, start + all_size[layer_idx]):\n",
    "            left_side = max(i - inner_window, start)\n",
    "            right_side = min(i + inner_window + 1, start + all_size[layer_idx])\n",
    "            mask[i, left_side:right_side] = 1\n",
    "\n",
    "    # get inter-scale mask\n",
    "    for layer_idx in range(1, len(all_size)):\n",
    "        start = sum(all_size[:layer_idx])\n",
    "        for i in range(start, start + all_size[layer_idx]):\n",
    "            left_side = (start - all_size[layer_idx - 1]) + \\\n",
    "                (i - start) * window_size[layer_idx - 1]\n",
    "            if i == (start + all_size[layer_idx] - 1):\n",
    "                right_side = start\n",
    "            else:\n",
    "                right_side = (\n",
    "                    start - all_size[layer_idx - 1]) + (i - start + 1) * window_size[layer_idx - 1]\n",
    "            mask[i, left_side:right_side] = 1\n",
    "            mask[left_side:right_side, i] = 1\n",
    "\n",
    "    mask = (1 - mask).bool()\n",
    "\n",
    "    return mask, all_size\n",
    "\n",
    "\n",
    "def refer_points(all_sizes, window_size):\n",
    "    \"\"\"Gather features from PAM's pyramid sequences\"\"\"\n",
    "    input_size = all_sizes[0]\n",
    "    indexes = torch.zeros(input_size, len(all_sizes))\n",
    "\n",
    "    for i in range(input_size):\n",
    "        indexes[i][0] = i\n",
    "        former_index = i\n",
    "        for j in range(1, len(all_sizes)):\n",
    "            start = sum(all_sizes[:j])\n",
    "            inner_layer_idx = former_index - (start - all_sizes[j - 1])\n",
    "            former_index = start + \\\n",
    "                min(inner_layer_idx // window_size[j - 1], all_sizes[j] - 1)\n",
    "            indexes[i][j] = former_index\n",
    "\n",
    "    indexes = indexes.unsqueeze(0).unsqueeze(3)\n",
    "\n",
    "    return indexes.long()\n",
    "\n",
    "\n",
    "class RegularMask():\n",
    "    def __init__(self, mask):\n",
    "        self._mask = mask.unsqueeze(1)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\" Compose with two layers \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_inner, n_head, dropout=0.1, normalize_before=True):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.slf_attn = AttentionLayer(\n",
    "            FullAttention(mask_flag=True, factor=0,\n",
    "                          attention_dropout=dropout, output_attention=False),\n",
    "            d_model, n_head)\n",
    "        self.pos_ffn = PositionwiseFeedForward(\n",
    "            d_model, d_inner, dropout=dropout, normalize_before=normalize_before)\n",
    "\n",
    "    def forward(self, enc_input, slf_attn_mask=None):\n",
    "        attn_mask = RegularMask(slf_attn_mask)\n",
    "        enc_output, _ = self.slf_attn(\n",
    "            enc_input, enc_input, enc_input, attn_mask=attn_mask)\n",
    "        enc_output = self.pos_ffn(enc_output)\n",
    "        return enc_output\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" A encoder model with self attention mechanism. \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, seq_len, d_ff, n_heads, dropout, e_layers, enc_in, \n",
    "                 window_size, inner_size, embed, freq):\n",
    "        super().__init__()\n",
    "\n",
    "        d_bottleneck = d_model//4\n",
    "\n",
    "        self.mask, self.all_size = get_mask(seq_len, window_size, inner_size)\n",
    "        self.indexes = refer_points(self.all_size, window_size)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, d_ff, n_heads, dropout=dropout,\n",
    "                         normalize_before=False) for _ in range(e_layers)\n",
    "        ])  # naive pyramid attention\n",
    "\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "        self.conv_layers = Bottleneck_Construct(d_model, window_size, d_bottleneck)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc=None):\n",
    "        seq_enc = self.enc_embedding(x_enc, x_mark_enc)\n",
    "\n",
    "        mask = self.mask.repeat(len(seq_enc), 1, 1).to(x_enc.device)\n",
    "        seq_enc = self.conv_layers(seq_enc)\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            seq_enc = self.layers[i](seq_enc, mask)\n",
    "\n",
    "        indexes = self.indexes.repeat(seq_enc.size(\n",
    "            0), 1, 1, seq_enc.size(2)).to(seq_enc.device)\n",
    "        indexes = indexes.view(seq_enc.size(0), -1, seq_enc.size(2))\n",
    "        all_enc = torch.gather(seq_enc, 1, indexes)\n",
    "        seq_enc = all_enc.view(seq_enc.size(0), self.all_size[0], -1)\n",
    "\n",
    "        return seq_enc\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, c_in, window_size):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.downConv = nn.Conv1d(in_channels=c_in,\n",
    "                                  out_channels=c_in,\n",
    "                                  kernel_size=window_size,\n",
    "                                  stride=window_size)\n",
    "        self.norm = nn.BatchNorm1d(c_in)\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downConv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bottleneck_Construct(nn.Module):\n",
    "    \"\"\"Bottleneck convolution CSCM\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, window_size, d_inner):\n",
    "        super(Bottleneck_Construct, self).__init__()\n",
    "        if not isinstance(window_size, list):\n",
    "            self.conv_layers = nn.ModuleList([\n",
    "                ConvLayer(d_inner, window_size),\n",
    "                ConvLayer(d_inner, window_size),\n",
    "                ConvLayer(d_inner, window_size)\n",
    "            ])\n",
    "        else:\n",
    "            self.conv_layers = []\n",
    "            for i in range(len(window_size)):\n",
    "                self.conv_layers.append(ConvLayer(d_inner, window_size[i]))\n",
    "            self.conv_layers = nn.ModuleList(self.conv_layers)\n",
    "        self.up = Linear(d_inner, d_model)\n",
    "        self.down = Linear(d_model, d_inner)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, enc_input):\n",
    "        temp_input = self.down(enc_input).permute(0, 2, 1)\n",
    "        all_inputs = []\n",
    "        for i in range(len(self.conv_layers)):\n",
    "            temp_input = self.conv_layers[i](temp_input)\n",
    "            all_inputs.append(temp_input)\n",
    "\n",
    "        all_inputs = torch.cat(all_inputs, dim=2).transpose(1, 2)\n",
    "        all_inputs = self.up(all_inputs)\n",
    "        all_inputs = torch.cat([enc_input, all_inputs], dim=1)\n",
    "\n",
    "        all_inputs = self.norm(all_inputs)\n",
    "        return all_inputs\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\" Two-layer position-wise feed-forward neural network. \"\"\"\n",
    "\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1, normalize_before=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.normalize_before = normalize_before\n",
    "\n",
    "        self.w_1 = nn.Linear(d_in, d_hid)\n",
    "        self.w_2 = nn.Linear(d_hid, d_in)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_in, eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.normalize_before:\n",
    "            x = self.layer_norm(x)\n",
    "\n",
    "        x = F.gelu(self.w_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.w_2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + residual\n",
    "\n",
    "        if not self.normalize_before:\n",
    "            x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# Pyraformer模型\n",
    "class Pyraformer(nn.Module):\n",
    "    \"\"\" \n",
    "    Pyraformer: Pyramidal attention to reduce complexity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, task_name, pred_len, label_len, d_model, seq_len, d_ff, n_heads, dropout, e_layers, enc_in, embed, freq,\n",
    "                 window_size=[4,4], inner_size=5):\n",
    "        \"\"\"\n",
    "        window_size: list, the downsample window size in pyramidal attention.\n",
    "        inner_size: int, the size of neighbour attention\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.task_name = task_name\n",
    "        self.pred_len = pred_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "        if self.task_name == 'short_term_forecast':\n",
    "            window_size = [2,2]\n",
    "        self.encoder = Encoder(d_model, seq_len, d_ff, n_heads, dropout, e_layers, enc_in, \n",
    "                 window_size, inner_size, embed, freq)\n",
    "\n",
    "        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n",
    "            self.projection = nn.Linear(\n",
    "                (len(window_size)+1)*self.d_model, self.pred_len * enc_in)\n",
    "\n",
    "    def long_forecast(self, x_enc, x_mark_enc):\n",
    "        enc_out = self.encoder(x_enc, x_mark_enc)[:, -1, :]\n",
    "        dec_out = self.projection(enc_out).view(\n",
    "            enc_out.size(0), self.pred_len, -1)\n",
    "        return dec_out\n",
    "    \n",
    "    def short_forecast(self, x_enc, x_mark_enc):\n",
    "        # Normalization\n",
    "        mean_enc = x_enc.mean(1, keepdim=True).detach()  # B x 1 x E\n",
    "        x_enc = x_enc - mean_enc\n",
    "        std_enc = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach()  # B x 1 x E\n",
    "        x_enc = x_enc / std_enc\n",
    "\n",
    "        enc_out = self.encoder(x_enc, x_mark_enc)[:, -1, :]\n",
    "        dec_out = self.projection(enc_out).view(\n",
    "            enc_out.size(0), self.pred_len, -1)\n",
    "        \n",
    "        dec_out = dec_out * std_enc + mean_enc\n",
    "        return dec_out\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        if self.task_name == 'long_term_forecast':\n",
    "            dec_out = self.long_forecast(x_enc, x_mark_enc)\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        if self.task_name == 'short_term_forecast':\n",
    "            dec_out = self.short_forecast(x_enc, x_mark_enc)\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9112cc97",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a944cfbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:32.195228Z",
     "start_time": "2024-04-14T13:28:32.154182Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:28:38.939758Z",
     "iopub.status.busy": "2024-04-19T12:28:38.938757Z",
     "iopub.status.idle": "2024-04-19T12:28:38.994753Z",
     "shell.execute_reply": "2024-04-19T12:28:38.993870Z",
     "shell.execute_reply.started": "2024-04-19T12:28:38.939758Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2664c779-c90d-4c61-a515-7c1ed9cdfafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:28:42.505708Z",
     "iopub.status.busy": "2024-04-19T12:28:42.504708Z",
     "iopub.status.idle": "2024-04-19T12:30:13.376725Z",
     "shell.execute_reply": "2024-04-19T12:30:13.374757Z",
     "shell.execute_reply.started": "2024-04-19T12:28:42.505708Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:10<03:13, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0025, Validation Loss: 0.0014\n",
      "Validation loss decreased (inf --> 0.001352).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:20<03:08, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0017, Validation Loss: 0.0012\n",
      "Validation loss decreased (0.001352 --> 0.001244).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:31<02:58, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0016, Validation Loss: 0.0012\n",
      "Validation loss decreased (0.001244 --> 0.001240).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [00:42<02:53, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0015, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.001240 --> 0.001137).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [00:54<02:47, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0015, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.001137 --> 0.001117).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [01:06<02:42, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0014, Validation Loss: 0.0012\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [01:18<02:31, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0014, Validation Loss: 0.0011\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [01:30<02:47, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0013, Validation Loss: 0.0012\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Pyraformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/Pyraformer\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'task_name': 'short_term_forecast',\n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        \"label_len\": 0,\n",
    "        'd_model': 128,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'embed': 'fixed',\n",
    "        'freq': 'h',\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afffa2f",
   "metadata": {},
   "source": [
    "# 基于Reformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14414277",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad49d3ef",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8271a52a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:57.475554Z",
     "start_time": "2024-04-14T13:28:57.454518Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:30:47.586031Z",
     "iopub.status.busy": "2024-04-19T12:30:47.584033Z",
     "iopub.status.idle": "2024-04-19T12:30:47.608027Z",
     "shell.execute_reply": "2024-04-19T12:30:47.607065Z",
     "shell.execute_reply.started": "2024-04-19T12:30:47.586031Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "599595a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:58.493325Z",
     "start_time": "2024-04-14T13:28:58.411911Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:30:48.418749Z",
     "iopub.status.busy": "2024-04-19T12:30:48.417436Z",
     "iopub.status.idle": "2024-04-19T12:30:48.517009Z",
     "shell.execute_reply": "2024-04-19T12:30:48.516460Z",
     "shell.execute_reply.started": "2024-04-19T12:30:48.418749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6c2db148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:28:59.768340Z",
     "start_time": "2024-04-14T13:28:59.728176Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:30:49.387340Z",
     "iopub.status.busy": "2024-04-19T12:30:49.386344Z",
     "iopub.status.idle": "2024-04-19T12:30:49.420842Z",
     "shell.execute_reply": "2024-04-19T12:30:49.419805Z",
     "shell.execute_reply.started": "2024-04-19T12:30:49.387340Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e6e7e58b-80fa-4d5e-bff1-4bfa1f0d67f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:30:50.161316Z",
     "iopub.status.busy": "2024-04-19T12:30:50.160312Z",
     "iopub.status.idle": "2024-04-19T12:30:50.199142Z",
     "shell.execute_reply": "2024-04-19T12:30:50.197753Z",
     "shell.execute_reply.started": "2024-04-19T12:30:50.161316Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ccb51c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:00.898961Z",
     "start_time": "2024-04-14T13:29:00.829917Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:31:23.048846Z",
     "iopub.status.busy": "2024-04-19T12:31:23.048846Z",
     "iopub.status.idle": "2024-04-19T12:31:23.127620Z",
     "shell.execute_reply": "2024-04-19T12:31:23.126623Z",
     "shell.execute_reply.started": "2024-04-19T12:31:23.048846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/Reformer'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f6d84a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:02.003708Z",
     "start_time": "2024-04-14T13:29:01.984850Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:31:23.979462Z",
     "iopub.status.busy": "2024-04-19T12:31:23.977462Z",
     "iopub.status.idle": "2024-04-19T12:31:24.000291Z",
     "shell.execute_reply": "2024-04-19T12:31:23.998785Z",
     "shell.execute_reply.started": "2024-04-19T12:31:23.979462Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8e773fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:03.993775Z",
     "start_time": "2024-04-14T13:29:03.065331Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:31:25.479990Z",
     "iopub.status.busy": "2024-04-19T12:31:25.479004Z",
     "iopub.status.idle": "2024-04-19T12:31:26.837447Z",
     "shell.execute_reply": "2024-04-19T12:31:26.836515Z",
     "shell.execute_reply.started": "2024-04-19T12:31:25.479990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 0,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f17fa",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d258926d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:06.458141Z",
     "start_time": "2024-04-14T13:29:06.282756Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:31:28.163923Z",
     "iopub.status.busy": "2024-04-19T12:31:28.162919Z",
     "iopub.status.idle": "2024-04-19T12:31:28.389553Z",
     "shell.execute_reply": "2024-04-19T12:31:28.387698Z",
     "shell.execute_reply.started": "2024-04-19T12:31:28.163923Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        second_size = 2\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.second_size = Embed(second_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        second_x = self.second_size(x[:, :, 5])\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x + second_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# Transformer_EncDec类\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "    \n",
    "    \n",
    "# 自编码类\n",
    "TOKEN_SELF_ATTN_VALUE = -5e4 # carefully set for half precision to work\n",
    "\n",
    "def max_neg_value(tensor):\n",
    "    return -torch.finfo(tensor.dtype).max\n",
    "\n",
    "\n",
    "def batched_index_select(values, indices):\n",
    "    last_dim = values.shape[-1]\n",
    "    return values.gather(1, indices[:, :, None].expand(-1, -1, last_dim))\n",
    "\n",
    "\n",
    "def sort_key_val(t1, t2, dim=-1):\n",
    "    values, indices = t1.sort(dim=dim)\n",
    "    t2 = t2.expand_as(t1)\n",
    "    return values, t2.gather(dim, indices)\n",
    "\n",
    "\n",
    "def process_inputs_chunk(fn, chunks=1, dim=0):\n",
    "    def inner_fn(*args, **kwargs):\n",
    "        keys, values, len_args = kwargs.keys(), kwargs.values(), len(args)\n",
    "        chunked_args = list(zip(*map(lambda x: x.chunk(chunks, dim=dim), list(args) + list(values))))\n",
    "        all_args = map(lambda x: (x[:len_args], dict(zip(keys, x[len_args:]))), chunked_args)\n",
    "        outputs = [fn(*c_args, **c_kwargs) for c_args, c_kwargs in all_args]\n",
    "        return tuple(map(lambda x: torch.cat(x, dim=dim), zip(*outputs)))\n",
    "    return inner_fn\n",
    "\n",
    "\n",
    "def split_at_index(dim, index, t):\n",
    "    pre_slices = (slice(None),) * dim\n",
    "    l = (*pre_slices, slice(None, index))\n",
    "    r = (*pre_slices, slice(index, None))\n",
    "    return t[l], t[r]\n",
    "\n",
    "\n",
    "def merge_dims(ind_from, ind_to, tensor):\n",
    "    shape = list(tensor.shape)\n",
    "    arr_slice = slice(ind_from, ind_to + 1)\n",
    "    shape[arr_slice] = [functools.reduce(mul, shape[arr_slice])]\n",
    "    return tensor.reshape(*shape)\n",
    "\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "\n",
    "def default(val, default_val):\n",
    "    return default_val if val is None else val\n",
    "\n",
    "\n",
    "def cache_method_decorator(cache_attr, cache_namespace, reexecute = False):\n",
    "    def inner_fn(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapper(self, *args, key_namespace=None, fetch=False, set_cache=True, **kwargs):\n",
    "            namespace_str = str(default(key_namespace, ''))\n",
    "            _cache = getattr(self, cache_attr)\n",
    "            _keyname = f'{cache_namespace}:{namespace_str}'\n",
    "\n",
    "            if fetch:\n",
    "                val = _cache[_keyname]\n",
    "                if reexecute:\n",
    "                    fn(self, *args, **kwargs)\n",
    "            else:\n",
    "                val = fn(self, *args, **kwargs)\n",
    "                if set_cache:\n",
    "                    setattr(self, cache_attr, {**_cache, **{_keyname: val}})\n",
    "            return val\n",
    "        return wrapper\n",
    "    return inner_fn\n",
    "\n",
    "class Always(nn.Module):\n",
    "    def __init__(self, val):\n",
    "        super().__init__()\n",
    "        self.val = val\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.val\n",
    "\n",
    "class MatrixMultiply(nn.Module):\n",
    "    def __init__(self, tensor, transpose = False, normalize = False):\n",
    "        super().__init__()\n",
    "        self.tensor = tensor\n",
    "        self.transpose = transpose\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, x):\n",
    "        tensor = self.tensor\n",
    "        if self.normalize:\n",
    "            tensor = F.normalize(tensor, dim=-1)\n",
    "        if self.transpose:\n",
    "            tensor = tensor.t()\n",
    "        return x @ tensor\n",
    "\n",
    "class ReZero(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.g = nn.Parameter(torch.zeros(1))\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) * self.g\n",
    "\n",
    "class ScaleNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.g = nn.Parameter(torch.ones(1))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = torch.norm(x, dim=-1, keepdim=True).clamp(min=self.eps)\n",
    "        return x / n * self.g\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, norm_class, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = norm_class(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x, **kwargs)\n",
    "\n",
    "class Chunk(nn.Module):\n",
    "    def __init__(self, chunks, fn, along_dim = -1):\n",
    "        super().__init__()\n",
    "        self.dim = along_dim\n",
    "        self.chunks = chunks\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        if self.chunks == 1:\n",
    "            return self.fn(x, **kwargs)\n",
    "        chunks = x.chunk(self.chunks, dim = self.dim)\n",
    "        return torch.cat([self.fn(c, **kwargs) for c in chunks], dim = self.dim)\n",
    "\n",
    "# LSH attention as described in https://openreview.net/pdf?id=rkgNKkHtvB\n",
    "# adapted from trax, stripped to what paper said needed to work\n",
    "# namely that buckets need to be at least 64 with 8 rounds of hashing\n",
    "# https://github.com/google/trax/blob/master/trax/layers/research/efficient_attention.py#L442\n",
    "\n",
    "class LSHAttention(nn.Module):\n",
    "    def __init__( self,\n",
    "                  dropout = 0.,\n",
    "                  bucket_size = 64,\n",
    "                  n_hashes = 8,\n",
    "                  causal = False,\n",
    "                  allow_duplicate_attention = True,\n",
    "                  attend_across_buckets = True,\n",
    "                  rehash_each_round = True,\n",
    "                  drop_for_hash_rate = 0.0,\n",
    "                  random_rotations_per_head = False,\n",
    "                  return_attn = False):\n",
    "        super().__init__()\n",
    "        if dropout >= 1.0:\n",
    "            raise ValueError('Dropout rates must be lower than 1.')\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dropout_for_hash = nn.Dropout(drop_for_hash_rate)\n",
    "\n",
    "        assert rehash_each_round or allow_duplicate_attention, (\n",
    "            'The setting {allow_duplicate_attention=False, rehash_each_round=False}'\n",
    "            ' is not implemented.')\n",
    "\n",
    "        self.causal = causal\n",
    "        self.bucket_size = bucket_size\n",
    "\n",
    "        self.n_hashes = n_hashes\n",
    "\n",
    "        self._allow_duplicate_attention = allow_duplicate_attention\n",
    "        self._attend_across_buckets = attend_across_buckets\n",
    "        self._rehash_each_round = rehash_each_round\n",
    "        self._random_rotations_per_head = random_rotations_per_head\n",
    "\n",
    "        # will expend extra computation to return attention matrix\n",
    "        self._return_attn = return_attn\n",
    "\n",
    "        # cache buckets for reversible network, reported by authors to make Reformer work at depth\n",
    "        self._cache = {}\n",
    "\n",
    "    @cache_method_decorator('_cache', 'buckets', reexecute=True)\n",
    "    def hash_vectors(self, n_buckets, vecs):\n",
    "        batch_size = vecs.shape[0]\n",
    "        device = vecs.device\n",
    "\n",
    "        # See https://arxiv.org/pdf/1509.02897.pdf\n",
    "        # We sample a different random rotation for each round of hashing to\n",
    "        # decrease the probability of hash misses.\n",
    "        assert n_buckets % 2 == 0\n",
    "\n",
    "        rot_size = n_buckets\n",
    "\n",
    "        rotations_shape = (\n",
    "            batch_size if self._random_rotations_per_head else 1,\n",
    "            vecs.shape[-1],\n",
    "            self.n_hashes if self._rehash_each_round else 1,\n",
    "            rot_size // 2)\n",
    "\n",
    "        random_rotations = torch.randn(rotations_shape, dtype=vecs.dtype, device=device).expand(batch_size, -1, -1, -1)\n",
    "\n",
    "        dropped_vecs = self.dropout_for_hash(vecs)\n",
    "        rotated_vecs = torch.einsum('btf,bfhi->bhti', dropped_vecs, random_rotations)\n",
    "\n",
    "        if self._rehash_each_round:\n",
    "            # rotated_vectors size [batch,n_hash,seq_len,buckets]\n",
    "            rotated_vecs = torch.cat([rotated_vecs, -rotated_vecs], dim=-1)\n",
    "            buckets = torch.argmax(rotated_vecs, dim=-1)\n",
    "        else:\n",
    "            rotated_vecs = torch.cat([rotated_vecs, -rotated_vecs], dim=-1)\n",
    "            # In this configuration, we map each item to the top self.n_hashes buckets\n",
    "            rotated_vecs = torch.squeeze(rotated_vecs, 1)\n",
    "            bucket_range = torch.arange(rotated_vecs.shape[-1], device=device)\n",
    "            bucket_range = torch.reshape(bucket_range, (1, -1))\n",
    "            bucket_range = bucket_range.expand_as(rotated_vecs)\n",
    "\n",
    "            _, buckets = sort_key_val(rotated_vecs, bucket_range, dim=-1)\n",
    "            # buckets size [batch size, seq_len, buckets]\n",
    "            buckets = buckets[... , -self.n_hashes:].transpose(1, 2)\n",
    "\n",
    "        # buckets is now (self.n_hashes, seq_len). Next we add offsets so that\n",
    "        # bucket numbers from different hashing rounds don't overlap.\n",
    "        offsets = torch.arange(self.n_hashes, device=device)\n",
    "        offsets = torch.reshape(offsets * n_buckets, (1, -1, 1))\n",
    "        buckets = torch.reshape(buckets + offsets, (batch_size, -1,))\n",
    "        return buckets\n",
    "\n",
    "    def forward(self, qk, v, query_len = None, input_mask = None, input_attn_mask = None, pos_emb = None, **kwargs):\n",
    "        batch_size, seqlen, dim, device = *qk.shape, qk.device\n",
    "\n",
    "        query_len = default(query_len, seqlen)\n",
    "        is_reverse = kwargs.pop('_reverse', False)\n",
    "        depth = kwargs.pop('_depth', None)\n",
    "\n",
    "        assert seqlen % (self.bucket_size * 2) == 0, f'Sequence length ({seqlen}) needs to be divisible by target bucket size  x 2 - {self.bucket_size * 2}'\n",
    "\n",
    "        n_buckets = seqlen // self.bucket_size\n",
    "        buckets = self.hash_vectors(n_buckets, qk, key_namespace=depth, fetch=is_reverse, set_cache=self.training)\n",
    "\n",
    "        # We use the same vector as both a query and a key.\n",
    "        assert int(buckets.shape[1]) == self.n_hashes * seqlen\n",
    "\n",
    "        total_hashes = self.n_hashes\n",
    "\n",
    "        ticker = torch.arange(total_hashes * seqlen, device=device).unsqueeze(0).expand_as(buckets)\n",
    "        buckets_and_t = seqlen * buckets + (ticker % seqlen)\n",
    "        buckets_and_t = buckets_and_t.detach()\n",
    "\n",
    "        # Hash-based sort (\"s\" at the start of variable names means \"sorted\")\n",
    "        sbuckets_and_t, sticker = sort_key_val(buckets_and_t, ticker, dim=-1)\n",
    "        _, undo_sort = sticker.sort(dim=-1)\n",
    "        del ticker\n",
    "\n",
    "        sbuckets_and_t = sbuckets_and_t.detach()\n",
    "        sticker = sticker.detach()\n",
    "        undo_sort = undo_sort.detach()\n",
    "\n",
    "        if exists(pos_emb):\n",
    "            qk = apply_rotary_pos_emb(qk, pos_emb)\n",
    "\n",
    "        st = (sticker % seqlen)\n",
    "        sqk = batched_index_select(qk, st)\n",
    "        sv = batched_index_select(v, st)\n",
    "\n",
    "        # Split off a \"bin\" axis so that attention only occurs within chunks.\n",
    "        chunk_size = total_hashes * n_buckets\n",
    "        bq_t = bkv_t = torch.reshape(st, (batch_size, chunk_size, -1))\n",
    "        bqk = torch.reshape(sqk, (batch_size, chunk_size, -1, dim))\n",
    "        bv = torch.reshape(sv, (batch_size, chunk_size, -1, dim))\n",
    "\n",
    "        # Hashing operates on unit-length vectors. Unnormalized query vectors are\n",
    "        # fine because they effectively provide a learnable temperature for the\n",
    "        # attention softmax, but normalizing keys is needed so that similarity for\n",
    "        # the purposes of attention correctly corresponds to hash locality.\n",
    "        bq = bqk\n",
    "        bk = F.normalize(bqk, p=2, dim=-1).type_as(bq)\n",
    "\n",
    "        # Allow each chunk to attend within itself, and also one chunk back. Chunk\n",
    "        # boundaries might occur in the middle of a sequence of items from the\n",
    "        # same bucket, so this increases the chances of attending to relevant items.\n",
    "        def look_one_back(x):\n",
    "            x_extra = torch.cat([x[:, -1:, ...], x[:, :-1, ...]], dim=1)\n",
    "            return torch.cat([x, x_extra], dim=2)\n",
    "\n",
    "        bk = look_one_back(bk)\n",
    "        bv = look_one_back(bv)\n",
    "        bkv_t = look_one_back(bkv_t)\n",
    "\n",
    "        # Dot-product attention.\n",
    "        dots = torch.einsum('bhie,bhje->bhij', bq, bk) * (dim ** -0.5)\n",
    "        masked_value = max_neg_value(dots)\n",
    "\n",
    "        # Mask for post qk attention logits of the input sequence\n",
    "        if input_attn_mask is not None:\n",
    "            input_attn_mask = F.pad(input_attn_mask, (0, seqlen - input_attn_mask.shape[-1], 0, seqlen - input_attn_mask.shape[-2]), value=True)\n",
    "            dot_attn_indices = ((bq_t * seqlen)[:, :, :, None] + bkv_t[:, :, None, :])\n",
    "            input_attn_mask = input_attn_mask.reshape(batch_size, -1)\n",
    "            dot_attn_indices = dot_attn_indices.reshape(batch_size, -1)\n",
    "            mask = input_attn_mask.gather(1, dot_attn_indices).reshape_as(dots)\n",
    "            dots.masked_fill_(~mask, masked_value)\n",
    "            del mask\n",
    "\n",
    "        # Input mask for padding in variable lengthed sequences\n",
    "        if input_mask is not None:\n",
    "            input_mask = F.pad(input_mask, (0, seqlen - input_mask.shape[1]), value=True)\n",
    "            mq = input_mask.gather(1, st).reshape((batch_size, chunk_size, -1))\n",
    "            mkv = look_one_back(mq)\n",
    "            mask = mq[:, :, :, None] * mkv[:, :, None, :]\n",
    "            dots.masked_fill_(~mask, masked_value)\n",
    "            del mask\n",
    "\n",
    "        # Causal masking\n",
    "        if self.causal:\n",
    "            mask = bq_t[:, :, :, None] < bkv_t[:, :, None, :]\n",
    "            if seqlen > query_len:\n",
    "                mask = mask & (bkv_t[:, :, None, :] < query_len)\n",
    "            dots.masked_fill_(mask, masked_value)\n",
    "            del mask\n",
    "\n",
    "        # Mask out attention to self except when no other targets are available.\n",
    "        self_mask = bq_t[:, :, :, None] == bkv_t[:, :, None, :]\n",
    "        dots.masked_fill_(self_mask, TOKEN_SELF_ATTN_VALUE)\n",
    "        del self_mask\n",
    "\n",
    "        # Mask out attention to other hash buckets.\n",
    "        if not self._attend_across_buckets:\n",
    "            bq_buckets = bkv_buckets = torch.reshape(sbuckets_and_t // seqlen, (batch_size, chunk_size, -1))\n",
    "            bkv_buckets = look_one_back(bkv_buckets)\n",
    "            bucket_mask = bq_buckets[:, :, :, None] != bkv_buckets[:, :, None, :]\n",
    "            dots.masked_fill_(bucket_mask, masked_value)\n",
    "            del bucket_mask\n",
    "\n",
    "        # Don't double-count query-key pairs across multiple rounds of hashing.\n",
    "        # There are two possible strategies here. (1) The default is to count how\n",
    "        # many times a query-key pair is repeated, and to lower its log-prob\n",
    "        # correspondingly at each repetition. (2) When hard_k is set, the code\n",
    "        # instead masks all but the first occurence of each query-key pair.\n",
    "        if not self._allow_duplicate_attention:\n",
    "            locs1 = undo_sort // bq_t.shape[-1]\n",
    "            locs2 = (locs1 + 1) % chunk_size\n",
    "            if not self._attend_across_buckets:\n",
    "                locs1 = buckets * chunk_size + locs1\n",
    "                locs2 = buckets * chunk_size + locs2\n",
    "            locs = torch.cat([\n",
    "                torch.reshape(locs1, (batch_size, total_hashes, seqlen)),\n",
    "                torch.reshape(locs2, (batch_size, total_hashes, seqlen)),\n",
    "            ], 1).permute((0, 2, 1))\n",
    "\n",
    "            slocs = batched_index_select(locs, st)\n",
    "            b_locs = torch.reshape(slocs, (batch_size, chunk_size, -1, 2 * total_hashes))\n",
    "\n",
    "            b_locs1 = b_locs[:, :, :, None, :total_hashes]\n",
    "\n",
    "            bq_locs = b_locs1.expand(b_locs.shape[:3] + (2, total_hashes))\n",
    "            bq_locs = torch.reshape(bq_locs, b_locs.shape)\n",
    "            bkv_locs = look_one_back(b_locs)\n",
    "\n",
    "            dup_counts = (bq_locs[:, :, :, None, :] == bkv_locs[:, :, None, :, :])\n",
    "            # for memory considerations, chunk summation of last dimension for counting duplicates\n",
    "            dup_counts = chunked_sum(dup_counts, chunks=(total_hashes * batch_size))\n",
    "            dup_counts = dup_counts.detach()\n",
    "            assert dup_counts.shape == dots.shape\n",
    "            dots = dots - torch.log(dup_counts + 1e-9)\n",
    "            del dup_counts\n",
    "\n",
    "        # Softmax.\n",
    "        dots_logsumexp = torch.logsumexp(dots, dim=-1, keepdim=True)\n",
    "        dots = torch.exp(dots - dots_logsumexp).type_as(dots)\n",
    "        dropped_dots = self.dropout(dots)\n",
    "\n",
    "        bo = torch.einsum('buij,buje->buie', dropped_dots, bv)\n",
    "        so = torch.reshape(bo, (batch_size, -1, dim))\n",
    "        slogits = torch.reshape(dots_logsumexp, (batch_size, -1,))\n",
    "\n",
    "        # unsort logits\n",
    "        o = batched_index_select(so, undo_sort)\n",
    "        logits = slogits.gather(1, undo_sort)\n",
    "\n",
    "        o = torch.reshape(o, (batch_size, total_hashes, seqlen, dim))\n",
    "        logits = torch.reshape(logits, (batch_size, total_hashes, seqlen, 1))\n",
    "\n",
    "        if query_len != seqlen:\n",
    "            query_slice = (slice(None), slice(None), slice(0, query_len))\n",
    "            o, logits = o[query_slice], logits[query_slice]\n",
    "\n",
    "        probs = torch.exp(logits - torch.logsumexp(logits, dim=1, keepdim=True))\n",
    "        out = torch.sum(o * probs, dim=1)\n",
    "\n",
    "        attn = torch.empty(0, device=device)\n",
    "\n",
    "        # return unsorted attention weights\n",
    "        if self._return_attn:\n",
    "            attn_unsort = ((bq_t * seqlen)[:, :, :, None] + bkv_t[:, :, None, :])\n",
    "            attn_unsort = attn_unsort.view(batch_size * total_hashes, -1).long()\n",
    "            unsorted_dots = torch.zeros(batch_size * total_hashes, seqlen * seqlen, device=device)\n",
    "            unsorted_dots.scatter_add_(1, attn_unsort, dots.view_as(attn_unsort))\n",
    "            del attn_unsort\n",
    "            unsorted_dots = unsorted_dots.reshape(batch_size, total_hashes, seqlen, seqlen)\n",
    "            attn = torch.sum(unsorted_dots[:, :, 0:query_len, :] * probs, dim=1)\n",
    "\n",
    "        # return output, attention matrix, and bucket distribution\n",
    "        return out, attn, buckets\n",
    "\n",
    "\n",
    "class FullQKAttention(nn.Module):\n",
    "    def __init__(self, causal = False, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.causal = causal\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, qk, v, query_len = None, input_mask = None, input_attn_mask = None, **kwargs):\n",
    "        b, seq_len, dim = qk.shape\n",
    "        query_len = default(query_len, seq_len)\n",
    "        t = query_len\n",
    "\n",
    "        q = qk[:, 0:query_len]\n",
    "        qk = F.normalize(qk, 2, dim=-1).type_as(q)\n",
    "\n",
    "        dot = torch.einsum('bie,bje->bij', q, qk) * (dim ** -0.5)\n",
    "\n",
    "        # qk attention requires tokens not attend to self\n",
    "        i = torch.arange(t)\n",
    "        dot[:, i, i] = TOKEN_SELF_ATTN_VALUE\n",
    "        masked_value = max_neg_value(dot)\n",
    "\n",
    "        # Input mask for padding in variable lengthed sequences\n",
    "        if input_mask is not None:\n",
    "            mask = input_mask[:, 0:query_len, None] * input_mask[:, None, :]\n",
    "            mask = F.pad(mask, (0, seq_len - mask.shape[-1]), value=True)\n",
    "            dot.masked_fill_(~mask, masked_value)\n",
    "\n",
    "        # Mask for post qk attention logits of the input sequence\n",
    "        if input_attn_mask is not None:\n",
    "            input_attn_mask = F.pad(input_attn_mask, (0, seq_len - input_attn_mask.shape[-1]), value=True)\n",
    "            dot.masked_fill_(~input_attn_mask, masked_value)\n",
    "\n",
    "        if self.causal:\n",
    "            i, j = torch.triu_indices(t, t, 1)\n",
    "            dot[:, i, j] = masked_value\n",
    "\n",
    "        dot = dot.softmax(dim=-1)\n",
    "        dot = self.dropout(dot)\n",
    "\n",
    "        out = torch.einsum('bij,bje->bie', dot, v)\n",
    "\n",
    "        return out, dot, torch.empty(0)\n",
    "\n",
    "    \n",
    "class LocalAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_size,\n",
    "        causal = False,\n",
    "        look_backward = 1,\n",
    "        look_forward = None,\n",
    "        dropout = 0.,\n",
    "        shared_qk = False,\n",
    "        rel_pos_emb_config = None,\n",
    "        dim = None,\n",
    "        autopad = False,\n",
    "        exact_windowsize = False,\n",
    "        scale = None,\n",
    "        use_rotary_pos_emb = True,\n",
    "        use_xpos = False,\n",
    "        xpos_scale_base = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        look_forward = default(look_forward, 0 if causal else 1)\n",
    "        assert not (causal and look_forward > 0), 'you cannot look forward if causal'\n",
    "\n",
    "        self.scale = scale\n",
    "\n",
    "        self.window_size = window_size\n",
    "        self.autopad = autopad\n",
    "        self.exact_windowsize = exact_windowsize\n",
    "\n",
    "        self.causal = causal\n",
    "\n",
    "        self.look_backward = look_backward\n",
    "        self.look_forward = look_forward\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.shared_qk = shared_qk\n",
    "\n",
    "        # relative positions\n",
    "\n",
    "        self.rel_pos = None\n",
    "        self.use_xpos = use_xpos\n",
    "\n",
    "        if use_rotary_pos_emb and (exists(rel_pos_emb_config) or exists(dim)):  # backwards compatible with old `rel_pos_emb_config` deprecated argument\n",
    "            if exists(rel_pos_emb_config):\n",
    "                dim = rel_pos_emb_config[0]\n",
    "\n",
    "            self.rel_pos = SinusoidalEmbeddings(\n",
    "                dim,\n",
    "                use_xpos = use_xpos,\n",
    "                scale_base = default(xpos_scale_base, window_size // 2)\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        q, k, v,\n",
    "        mask = None,\n",
    "        input_mask = None,\n",
    "        attn_bias = None,\n",
    "        window_size = None\n",
    "    ):\n",
    "\n",
    "        mask = default(mask, input_mask)\n",
    "\n",
    "        assert not (exists(window_size) and not self.use_xpos), 'cannot perform window size extrapolation if xpos is not turned on'\n",
    "\n",
    "        shape, autopad, pad_value, window_size, causal, look_backward, look_forward, shared_qk = q.shape, self.autopad, -1, default(window_size, self.window_size), self.causal, self.look_backward, self.look_forward, self.shared_qk\n",
    "\n",
    "        # https://github.com/arogozhnikov/einops/blob/master/docs/4-pack-and-unpack.ipynb\n",
    "        (q, packed_shape), (k, _), (v, _) = map(lambda t: pack([t], '* n d'), (q, k, v))\n",
    "\n",
    "        # auto padding\n",
    "\n",
    "        if autopad:\n",
    "            orig_seq_len = q.shape[1]\n",
    "            (needed_pad, q), (_, k), (_, v) = map(lambda t: pad_to_multiple(t, self.window_size, dim = -2), (q, k, v))\n",
    "\n",
    "        b, n, dim_head, device, dtype = *q.shape, q.device, q.dtype\n",
    "\n",
    "        scale = default(self.scale, dim_head ** -0.5)\n",
    "\n",
    "        assert (n % window_size) == 0, f'sequence length {n} must be divisible by window size {window_size} for local attention'\n",
    "\n",
    "        windows = n // window_size\n",
    "\n",
    "        if shared_qk:\n",
    "            k = l2norm(k)\n",
    "\n",
    "        seq = torch.arange(n, device = device)\n",
    "        b_t = rearrange(seq, '(w n) -> 1 w n', w = windows, n = window_size)\n",
    "\n",
    "        # bucketing\n",
    "\n",
    "        bq, bk, bv = map(lambda t: rearrange(t, 'b (w n) d -> b w n d', w = windows), (q, k, v))\n",
    "\n",
    "        bq = bq * scale\n",
    "\n",
    "        look_around_kwargs = dict(\n",
    "            backward =  look_backward,\n",
    "            forward =  look_forward,\n",
    "            pad_value = pad_value\n",
    "        )\n",
    "\n",
    "        bk = look_around(bk, **look_around_kwargs)\n",
    "        bv = look_around(bv, **look_around_kwargs)\n",
    "\n",
    "        # rotary embeddings\n",
    "\n",
    "        if exists(self.rel_pos):\n",
    "            pos_emb, xpos_scale = self.rel_pos(bk)\n",
    "            bq, bk = apply_rotary_pos_emb(bq, bk, pos_emb, scale = xpos_scale)\n",
    "\n",
    "        # calculate positions for masking\n",
    "\n",
    "        bq_t = b_t\n",
    "        bq_k = look_around(b_t, **look_around_kwargs)\n",
    "\n",
    "        bq_t = rearrange(bq_t, '... i -> ... i 1')\n",
    "        bq_k = rearrange(bq_k, '... j -> ... 1 j')\n",
    "\n",
    "        pad_mask = bq_k == pad_value\n",
    "\n",
    "        sim = einsum('b h i e, b h j e -> b h i j', bq, bk)\n",
    "\n",
    "        if exists(attn_bias):\n",
    "            heads = attn_bias.shape[0]\n",
    "            assert (b % heads) == 0\n",
    "\n",
    "            attn_bias = repeat(attn_bias, 'h i j -> (b h) 1 i j', b = b // heads)\n",
    "            sim = sim + attn_bias\n",
    "\n",
    "        mask_value = max_neg_value(sim)\n",
    "\n",
    "        if shared_qk:\n",
    "            self_mask = bq_t == bq_k\n",
    "            sim = sim.masked_fill(self_mask, TOKEN_SELF_ATTN_VALUE)\n",
    "            del self_mask\n",
    "\n",
    "        if causal:\n",
    "            causal_mask = bq_t < bq_k\n",
    "\n",
    "            if self.exact_windowsize:\n",
    "                max_causal_window_size = (self.window_size * self.look_backward)\n",
    "                causal_mask = causal_mask | (bq_t > (bq_k + max_causal_window_size))\n",
    "\n",
    "            sim = sim.masked_fill(causal_mask, mask_value)\n",
    "            del causal_mask\n",
    "\n",
    "        # masking out for exact window size for non-causal\n",
    "        # as well as masking out for padding value\n",
    "\n",
    "        if not causal and self.exact_windowsize:\n",
    "            max_backward_window_size = (self.window_size * self.look_backward)\n",
    "            max_forward_window_size = (self.window_size * self.look_forward)\n",
    "            window_mask = ((bq_k - max_forward_window_size) > bq_t) | (bq_t > (bq_k + max_backward_window_size)) | pad_mask\n",
    "            sim = sim.masked_fill(window_mask, mask_value)\n",
    "        else:\n",
    "            sim = sim.masked_fill(pad_mask, mask_value)\n",
    "\n",
    "        # take care of key padding mask passed in\n",
    "\n",
    "        if exists(mask):\n",
    "            batch = mask.shape[0]\n",
    "            assert (b % batch) == 0\n",
    "\n",
    "            h = b // mask.shape[0]\n",
    "\n",
    "            if autopad:\n",
    "                _, mask = pad_to_multiple(mask, window_size, dim = -1, value = False)\n",
    "\n",
    "            mask = rearrange(mask, '... (w n) -> (...) w n', w = windows, n = window_size)\n",
    "            mask = look_around(mask, **{**look_around_kwargs, 'pad_value': False})\n",
    "            mask = rearrange(mask, '... j -> ... 1 j')\n",
    "            mask = repeat(mask, 'b ... -> (b h) ...', h = h)\n",
    "            sim = sim.masked_fill(~mask, mask_value)\n",
    "            del mask\n",
    "\n",
    "        # attention\n",
    "\n",
    "        attn = sim.softmax(dim = -1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        # aggregation\n",
    "\n",
    "        out = einsum('b h i j, b h j e -> b h i e', attn, bv)\n",
    "        out = rearrange(out, 'b w n d -> b (w n) d')\n",
    "\n",
    "        if autopad:\n",
    "            out = out[:, :orig_seq_len, :]\n",
    "\n",
    "        out, *_ = unpack(out, packed_shape, '* n d')\n",
    "        return out\n",
    "\n",
    "\n",
    "class LSHSelfAttention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, bucket_size = 64, n_hashes = 8, causal = False, dim_head = None, attn_chunks = 1, random_rotations_per_head = False, attend_across_buckets = True, allow_duplicate_attention = True, num_mem_kv = 0, one_value_head = False, use_full_attn = False, full_attn_thres = None, return_attn = False, post_attn_dropout = 0., dropout = 0., n_local_attn_heads = 0, **kwargs):\n",
    "        super().__init__()\n",
    "        assert dim_head or (dim % heads) == 0, 'dimensions must be divisible by number of heads'\n",
    "        assert n_local_attn_heads < heads, 'local attention heads must be less than number of heads'\n",
    "\n",
    "        dim_head = default(dim_head, dim // heads)\n",
    "        dim_heads = dim_head * heads\n",
    "\n",
    "        self.dim = dim\n",
    "        self.heads = heads\n",
    "        self.dim_head = dim_head\n",
    "        self.attn_chunks = default(attn_chunks, 1)\n",
    "\n",
    "        self.v_head_repeats = (heads if one_value_head else 1)\n",
    "        v_dim = dim_heads // self.v_head_repeats\n",
    "\n",
    "        self.toqk = nn.Linear(dim, dim_heads, bias = False)\n",
    "        self.tov = nn.Linear(dim, v_dim, bias = False)\n",
    "        self.to_out = nn.Linear(dim_heads, dim)\n",
    "\n",
    "        self.bucket_size = bucket_size\n",
    "        self.lsh_attn = LSHAttention(bucket_size=bucket_size, n_hashes=n_hashes, causal=causal, random_rotations_per_head=random_rotations_per_head, attend_across_buckets = attend_across_buckets,  allow_duplicate_attention = allow_duplicate_attention, return_attn = return_attn, dropout = dropout, **kwargs)\n",
    "        self.full_attn = FullQKAttention(causal=causal, dropout=dropout)\n",
    "        self.post_attn_dropout = nn.Dropout(post_attn_dropout)\n",
    "\n",
    "        self.use_full_attn = use_full_attn\n",
    "        self.full_attn_thres = default(full_attn_thres, bucket_size)\n",
    "\n",
    "        self.num_mem_kv = num_mem_kv\n",
    "        self.mem_kv = nn.Parameter(torch.randn(1, num_mem_kv, dim, requires_grad=True)) if num_mem_kv > 0 else None\n",
    "\n",
    "        self.n_local_attn_heads = n_local_attn_heads\n",
    "        self.local_attn = LocalAttention(window_size=bucket_size * 2, causal=causal, dropout=dropout, shared_qk=True, look_forward=(1 if not causal else 0))\n",
    "\n",
    "        self.callback = None\n",
    "\n",
    "    def forward(self, x, keys = None, input_mask = None, input_attn_mask = None, context_mask = None, pos_emb = None, **kwargs):\n",
    "        device, dtype = x.device, x.dtype\n",
    "        b, t, e, h, dh, m, l_h = *x.shape, self.heads, self.dim_head, self.num_mem_kv, self.n_local_attn_heads\n",
    "\n",
    "        mem_kv = default(self.mem_kv, torch.empty(b, 0, e, dtype=dtype, device=device))\n",
    "        mem = mem_kv.expand(b, m, -1)\n",
    "\n",
    "        keys = default(keys, torch.empty(b, 0, e, dtype=dtype, device=device))\n",
    "        c = keys.shape[1]\n",
    "\n",
    "        kv_len = t + m + c\n",
    "        use_full_attn = self.use_full_attn or kv_len <= self.full_attn_thres\n",
    "\n",
    "        x = torch.cat((x, mem, keys), dim=1)\n",
    "        qk = self.toqk(x)\n",
    "        v = self.tov(x)\n",
    "        v = v.repeat(1, 1, self.v_head_repeats)\n",
    "\n",
    "        def merge_heads(v):\n",
    "            return v.view(b, kv_len, h, -1).transpose(1, 2)\n",
    "\n",
    "        def split_heads(v):\n",
    "            return v.view(b, h, t, -1).transpose(1, 2).contiguous()\n",
    "\n",
    "        merge_batch_and_heads = partial(merge_dims, 0, 1)\n",
    "\n",
    "        qk, v = map(merge_heads, (qk, v))\n",
    "\n",
    "        has_local = l_h > 0\n",
    "        lsh_h = h - l_h\n",
    "\n",
    "        split_index_fn = partial(split_at_index, 1, l_h)\n",
    "        (lqk, qk), (lv, v) = map(split_index_fn, (qk, v))\n",
    "        lqk, qk, lv, v = map(merge_batch_and_heads, (lqk, qk, lv, v))\n",
    "\n",
    "        masks = {}\n",
    "        if input_mask is not None or context_mask is not None:\n",
    "            default_mask = torch.tensor([True], device=device)\n",
    "            i_mask = default(input_mask, default_mask.expand(b, t))\n",
    "            m_mask = default_mask.expand(b, m)\n",
    "            c_mask = default(context_mask, default_mask.expand(b, c))\n",
    "            mask = torch.cat((i_mask, m_mask, c_mask), dim=1)\n",
    "            mask = merge_batch_and_heads(expand_dim(1, lsh_h, mask))\n",
    "            masks['input_mask'] = mask\n",
    "\n",
    "        if input_attn_mask is not None:\n",
    "            input_attn_mask = merge_batch_and_heads(expand_dim(1, lsh_h, input_attn_mask))\n",
    "            masks['input_attn_mask'] = input_attn_mask\n",
    "\n",
    "        attn_fn = self.lsh_attn if not use_full_attn else self.full_attn\n",
    "        partial_attn_fn = partial(attn_fn, query_len = t, pos_emb = pos_emb, **kwargs)\n",
    "        attn_fn_in_chunks = process_inputs_chunk(partial_attn_fn, chunks = self.attn_chunks)\n",
    "\n",
    "        out, attn, buckets = attn_fn_in_chunks(qk, v, **masks)\n",
    "\n",
    "        if self.callback is not None:\n",
    "            self.callback(attn.reshape(b, lsh_h, t, -1), buckets.reshape(b, lsh_h, -1))\n",
    "\n",
    "        if has_local:\n",
    "            lqk, lv = lqk[:, :t], lv[:, :t]\n",
    "            local_out = self.local_attn(lqk, lqk, lv, input_mask=input_mask)\n",
    "            local_out = local_out.reshape(b, l_h, t, -1)\n",
    "            out = out.reshape(b, lsh_h, t, -1)\n",
    "            out = torch.cat((local_out, out), dim=1)\n",
    "\n",
    "        out = split_heads(out).view(b, t, -1)\n",
    "        out = self.to_out(out)\n",
    "        return self.post_attn_dropout(out)\n",
    "\n",
    "\n",
    "class ReformerLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None, causal=False, bucket_size=4, n_hashes=4):\n",
    "        super().__init__()\n",
    "        self.bucket_size = bucket_size\n",
    "        self.attn = LSHSelfAttention(\n",
    "            dim=d_model,\n",
    "            heads=n_heads,\n",
    "            bucket_size=bucket_size,\n",
    "            n_hashes=n_hashes,\n",
    "            causal=causal\n",
    "        )\n",
    "\n",
    "    def fit_length(self, queries):\n",
    "        # inside reformer: assert N % (bucket_size * 2) == 0\n",
    "        B, N, C = queries.shape\n",
    "        if N % (self.bucket_size * 2) == 0:\n",
    "            return queries\n",
    "        else:\n",
    "            # fill the time series\n",
    "            fill_len = (self.bucket_size * 2) - (N % (self.bucket_size * 2))\n",
    "            return torch.cat([queries, torch.zeros([B, fill_len, C]).to(queries.device)], dim=1)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau, delta):\n",
    "        # in Reformer: defalut queries=keys\n",
    "        B, N, C = queries.shape\n",
    "        queries = self.attn(self.fit_length(queries))[:, :N, :]\n",
    "        return queries, None\n",
    "\n",
    "    \n",
    "# Reformer模型\n",
    "class Reformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Reformer with O(LlogL) complexity\n",
    "    \"\"\"\n",
    "    def __init__(self, task_name, pred_len, seq_len, label_len, enc_in, d_model, dropout, n_heads, d_ff, \n",
    "                 e_layers, c_out, embed, freq, bucket_size=4, n_hashes=4):\n",
    "        \"\"\"\n",
    "        bucket_size: int, \n",
    "        n_hashes: int, \n",
    "        \"\"\"\n",
    "        super(Reformer, self).__init__()\n",
    "        self.task_name = task_name\n",
    "        self.pred_len = pred_len\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    ReformerLayer(None, d_model, n_heads,\n",
    "                                  bucket_size=bucket_size, n_hashes=n_hashes),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu'\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        \n",
    "        self.projection = nn.Linear(d_model, c_out, bias=True)\n",
    "\n",
    "    def long_forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # add placeholder\n",
    "        x_enc = torch.cat([x_enc, x_dec[:, -self.pred_len:, :]], dim=1)\n",
    "        if x_mark_enc is not None:\n",
    "            x_mark_enc = torch.cat(\n",
    "                [x_mark_enc, x_mark_dec[:, -self.pred_len:, :]], dim=1)\n",
    "\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "        dec_out = self.projection(enc_out)\n",
    "\n",
    "        return dec_out  # [B, L, D]\n",
    "    \n",
    "    def short_forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # Normalization\n",
    "        mean_enc = x_enc.mean(1, keepdim=True).detach()  # B x 1 x E\n",
    "        x_enc = x_enc - mean_enc\n",
    "        std_enc = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach()  # B x 1 x E\n",
    "        x_enc = x_enc / std_enc\n",
    "\n",
    "        # add placeholder\n",
    "        x_enc = torch.cat([x_enc, x_dec[:, -self.pred_len:, :]], dim=1)\n",
    "        if x_mark_enc is not None:\n",
    "            x_mark_enc = torch.cat(\n",
    "                [x_mark_enc, x_mark_dec[:, -self.pred_len:, :]], dim=1)\n",
    "\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "        dec_out = self.projection(enc_out)\n",
    "\n",
    "        dec_out = dec_out * std_enc + mean_enc\n",
    "        return dec_out  # [B, L, D]\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
    "        if self.task_name == 'long_term_forecast':\n",
    "            dec_out = self.long_forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        if self.task_name == 'short_term_forecast':\n",
    "            dec_out = self.short_forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83970fc4",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2226bc48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:09.838035Z",
     "start_time": "2024-04-14T13:29:09.783632Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:31:29.692886Z",
     "iopub.status.busy": "2024-04-19T12:31:29.691887Z",
     "iopub.status.idle": "2024-04-19T12:31:29.761602Z",
     "shell.execute_reply": "2024-04-19T12:31:29.760574Z",
     "shell.execute_reply.started": "2024-04-19T12:31:29.692886Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f4c186b1-ee85-4485-9168-4e15422dd9cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:31:36.601862Z",
     "iopub.status.busy": "2024-04-19T12:31:36.601862Z",
     "iopub.status.idle": "2024-04-19T12:35:30.925433Z",
     "shell.execute_reply": "2024-04-19T12:35:30.924320Z",
     "shell.execute_reply.started": "2024-04-19T12:31:36.601862Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:11<03:35, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0048, Validation Loss: 0.0028\n",
      "Validation loss decreased (inf --> 0.002821).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:22<03:18, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0029, Validation Loss: 0.0018\n",
      "Validation loss decreased (0.002821 --> 0.001816).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:33<03:09, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0025, Validation Loss: 0.0018\n",
      "Validation loss decreased (0.001816 --> 0.001766).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [00:44<02:56, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0022, Validation Loss: 0.0017\n",
      "Validation loss decreased (0.001766 --> 0.001733).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [00:55<02:45, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0021, Validation Loss: 0.0017\n",
      "Validation loss decreased (0.001733 --> 0.001722).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [01:06<02:35, 11.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0020, Validation Loss: 0.0015\n",
      "Validation loss decreased (0.001722 --> 0.001460).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [01:19<02:31, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0019, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.001460 --> 0.001325).  Saving model ...\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [01:32<02:23, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0018, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.001325 --> 0.001323).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                             | 9/20 [01:44<02:13, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0017, Validation Loss: 0.0015\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 10/20 [01:56<01:59, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0017, Validation Loss: 0.0013\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████                                     | 11/20 [02:07<01:46, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0016, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.001323 --> 0.001302).  Saving model ...\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [02:19<01:34, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0016, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.001302 --> 0.001253).  Saving model ...\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [02:31<01:22, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0016, Validation Loss: 0.0012\n",
      "Validation loss decreased (0.001253 --> 0.001183).  Saving model ...\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [02:42<01:10, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0015, Validation Loss: 0.0012\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [02:54<00:57, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0015, Validation Loss: 0.0012\n",
      "Validation loss decreased (0.001183 --> 0.001181).  Saving model ...\n",
      "Updating learning rate to 0.00014644660940672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [03:05<00:46, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0015, Validation Loss: 0.0012\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [03:17<00:34, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0015, Validation Loss: 0.0012\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.449673790581611e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [03:28<00:23, 11.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0014, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.001181 --> 0.001128).  Saving model ...\n",
      "Updating learning rate to 2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [03:40<00:11, 11.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0014, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.001128 --> 0.001109).  Saving model ...\n",
      "Updating learning rate to 6.15582970243117e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [03:53<00:00, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0014, Validation Loss: 0.0011\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Reformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/Reformer\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'task_name': 'short_term_forecast',\n",
    "        'pred_len': 3, \n",
    "        'seq_len': 6,\n",
    "        \"label_len\": 0,\n",
    "        'd_model': 128,\n",
    "        'enc_in': 2,\n",
    "        'dropout': 0.1,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 1,\n",
    "        'c_out': 2,\n",
    "        'embed': 'fixed',\n",
    "        'freq': 'h',\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdfd732",
   "metadata": {},
   "source": [
    "# 基于TiDE的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3c261",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698dcc0",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7378f4c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:30.875563Z",
     "start_time": "2024-04-14T13:29:30.866151Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:35:49.825508Z",
     "iopub.status.busy": "2024-04-19T12:35:49.824510Z",
     "iopub.status.idle": "2024-04-19T12:35:49.850663Z",
     "shell.execute_reply": "2024-04-19T12:35:49.849706Z",
     "shell.execute_reply.started": "2024-04-19T12:35:49.825508Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bb102d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:32.390905Z",
     "start_time": "2024-04-14T13:29:32.312564Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:35:50.893323Z",
     "iopub.status.busy": "2024-04-19T12:35:50.892324Z",
     "iopub.status.idle": "2024-04-19T12:35:50.973653Z",
     "shell.execute_reply": "2024-04-19T12:35:50.972651Z",
     "shell.execute_reply.started": "2024-04-19T12:35:50.893323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "08a58347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:33.398587Z",
     "start_time": "2024-04-14T13:29:33.361912Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:35:51.747856Z",
     "iopub.status.busy": "2024-04-19T12:35:51.745855Z",
     "iopub.status.idle": "2024-04-19T12:35:51.798203Z",
     "shell.execute_reply": "2024-04-19T12:35:51.795992Z",
     "shell.execute_reply.started": "2024-04-19T12:35:51.747856Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cdb64ab2-8a5b-41c4-81fb-e8e456520dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:35:52.630991Z",
     "iopub.status.busy": "2024-04-19T12:35:52.629981Z",
     "iopub.status.idle": "2024-04-19T12:35:52.655234Z",
     "shell.execute_reply": "2024-04-19T12:35:52.653798Z",
     "shell.execute_reply.started": "2024-04-19T12:35:52.630991Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "495eb6f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:34.608193Z",
     "start_time": "2024-04-14T13:29:34.278114Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:35:54.814973Z",
     "iopub.status.busy": "2024-04-19T12:35:54.814973Z",
     "iopub.status.idle": "2024-04-19T12:35:54.883972Z",
     "shell.execute_reply": "2024-04-19T12:35:54.882844Z",
     "shell.execute_reply.started": "2024-04-19T12:35:54.814973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/TiDE'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "23961587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:35.584160Z",
     "start_time": "2024-04-14T13:29:35.560708Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:35:55.814542Z",
     "iopub.status.busy": "2024-04-19T12:35:55.812547Z",
     "iopub.status.idle": "2024-04-19T12:35:55.835394Z",
     "shell.execute_reply": "2024-04-19T12:35:55.834393Z",
     "shell.execute_reply.started": "2024-04-19T12:35:55.814542Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d8ebc2c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:37.525780Z",
     "start_time": "2024-04-14T13:29:36.648788Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:35:56.701776Z",
     "iopub.status.busy": "2024-04-19T12:35:56.699781Z",
     "iopub.status.idle": "2024-04-19T12:35:57.881691Z",
     "shell.execute_reply": "2024-04-19T12:35:57.880770Z",
     "shell.execute_reply.started": "2024-04-19T12:35:56.701776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 0,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9396a65",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "52c5cf50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:39.642782Z",
     "start_time": "2024-04-14T13:29:39.614925Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:35:59.024954Z",
     "iopub.status.busy": "2024-04-19T12:35:59.022996Z",
     "iopub.status.idle": "2024-04-19T12:35:59.092417Z",
     "shell.execute_reply": "2024-04-19T12:35:59.090809Z",
     "shell.execute_reply.started": "2024-04-19T12:35:59.024954Z"
    }
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias,\n",
    "                            1e-5)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 dropout=0.1,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim, bias=bias)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim, bias=bias)\n",
    "        self.fc3 = nn.Linear(input_dim, output_dim, bias=bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln = LayerNorm(output_dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out + self.fc3(x)\n",
    "        out = self.ln(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# TiDE模型\n",
    "class TiDE(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, label_len, d_model, e_layers, d_layers, freq, d_ff, dropout, c_out, \n",
    "                 bias=True, feature_encode_dim=2):\n",
    "        super(TiDE, self).__init__()\n",
    "        self.seq_len = seq_len  #L\n",
    "        self.pred_len = pred_len  #H\n",
    "        self.hidden_dim = d_model\n",
    "        self.res_hidden = d_model\n",
    "        self.encoder_num = e_layers\n",
    "        self.decoder_num = d_layers\n",
    "        self.freq = freq\n",
    "        self.feature_encode_dim = feature_encode_dim\n",
    "        self.decode_dim = c_out\n",
    "        self.temporalDecoderHidden = d_ff\n",
    "        dropout = dropout\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "\n",
    "        self.feature_dim = freq_map[self.freq]\n",
    "\n",
    "        flatten_dim = self.seq_len + (self.seq_len +\n",
    "                                      self.pred_len) * self.feature_encode_dim\n",
    "\n",
    "        self.feature_encoder = ResBlock(self.feature_dim, self.res_hidden,\n",
    "                                        self.feature_encode_dim, dropout, bias)\n",
    "        self.encoders = nn.Sequential(\n",
    "            ResBlock(flatten_dim, self.res_hidden, self.hidden_dim, dropout,\n",
    "                     bias),\n",
    "            *([\n",
    "                ResBlock(self.hidden_dim, self.res_hidden, self.hidden_dim,\n",
    "                         dropout, bias)\n",
    "            ] * (self.encoder_num - 1)))\n",
    "\n",
    "        self.decoders = nn.Sequential(\n",
    "            *([\n",
    "                ResBlock(self.hidden_dim, self.res_hidden, self.hidden_dim,\n",
    "                         dropout, bias)\n",
    "            ] * (self.decoder_num - 1)),\n",
    "            ResBlock(self.hidden_dim, self.res_hidden,\n",
    "                     self.decode_dim * self.pred_len, dropout, bias))\n",
    "        self.temporalDecoder = ResBlock(\n",
    "            self.decode_dim + self.feature_encode_dim,\n",
    "            self.temporalDecoderHidden, 1, dropout, bias)\n",
    "        self.residual_proj = nn.Linear(self.seq_len,\n",
    "                                       self.pred_len,\n",
    "                                       bias=bias)\n",
    "\n",
    "    def forecast(self, x_enc, x_mark_enc, x_dec, batch_y_mark):\n",
    "        # Normalization\n",
    "        means = x_enc.mean(1, keepdim=True).detach()\n",
    "        x_enc = x_enc - means\n",
    "        stdev = torch.sqrt(\n",
    "            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "        x_enc /= stdev\n",
    "\n",
    "        feature = self.feature_encoder(batch_y_mark)\n",
    "        hidden = self.encoders(\n",
    "            torch.cat([x_enc, feature.reshape(feature.shape[0], -1)], dim=-1))\n",
    "        decoded = self.decoders(hidden).reshape(hidden.shape[0], self.pred_len,\n",
    "                                                self.decode_dim)\n",
    "        dec_out = self.temporalDecoder(\n",
    "            torch.cat([feature[:, self.seq_len:], decoded],\n",
    "                      dim=-1)).squeeze(-1) + self.residual_proj(x_enc)\n",
    "\n",
    "        # De-Normalization\n",
    "        dec_out = dec_out * (stdev[:, 0].unsqueeze(1).repeat(1, self.pred_len))\n",
    "        dec_out = dec_out + (means[:, 0].unsqueeze(1).repeat(1, self.pred_len))\n",
    "        return dec_out\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, batch_y_mark, mask=None):\n",
    "        '''x_mark_enc is the exogenous dynamic feature described in the original paper'''\n",
    "        batch_y_mark = torch.concat(\n",
    "            [x_mark_enc, batch_y_mark[:, -self.pred_len:, :]], dim=1)\n",
    "        dec_out = torch.stack([\n",
    "            self.forecast(x_enc[:, :, feature], x_mark_enc, x_dec,\n",
    "                          batch_y_mark)\n",
    "            for feature in range(x_enc.shape[-1])\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return dec_out  # [B, L, D]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e33d0b",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4e592e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:29:42.136476Z",
     "start_time": "2024-04-14T13:29:42.096487Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:36:00.777072Z",
     "iopub.status.busy": "2024-04-19T12:36:00.775072Z",
     "iopub.status.idle": "2024-04-19T12:36:00.838771Z",
     "shell.execute_reply": "2024-04-19T12:36:00.836772Z",
     "shell.execute_reply.started": "2024-04-19T12:36:00.776333Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5b69938a-cf37-4552-86b2-2315648ef7c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:36:04.293738Z",
     "iopub.status.busy": "2024-04-19T12:36:04.291798Z",
     "iopub.status.idle": "2024-04-19T12:39:07.701204Z",
     "shell.execute_reply": "2024-04-19T12:39:07.700240Z",
     "shell.execute_reply.started": "2024-04-19T12:36:04.293738Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:09<02:54,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0120, Validation Loss: 0.0071\n",
      "Validation loss decreased (inf --> 0.007093).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:17<02:38,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0057, Validation Loss: 0.0047\n",
      "Validation loss decreased (0.007093 --> 0.004737).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:26<02:29,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0043, Validation Loss: 0.0041\n",
      "Validation loss decreased (0.004737 --> 0.004051).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [00:35<02:19,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0039, Validation Loss: 0.0038\n",
      "Validation loss decreased (0.004051 --> 0.003835).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [00:43<02:10,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0037, Validation Loss: 0.0037\n",
      "Validation loss decreased (0.003835 --> 0.003653).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [00:52<02:01,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0036, Validation Loss: 0.0035\n",
      "Validation loss decreased (0.003653 --> 0.003542).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [01:00<01:51,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0034, Validation Loss: 0.0034\n",
      "Validation loss decreased (0.003542 --> 0.003417).  Saving model ...\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [01:09<01:43,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0033, Validation Loss: 0.0033\n",
      "Validation loss decreased (0.003417 --> 0.003332).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                             | 9/20 [01:18<01:34,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0032, Validation Loss: 0.0032\n",
      "Validation loss decreased (0.003332 --> 0.003246).  Saving model ...\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 10/20 [01:26<01:26,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0032, Validation Loss: 0.0032\n",
      "Validation loss decreased (0.003246 --> 0.003173).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████                                     | 11/20 [01:35<01:18,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0031, Validation Loss: 0.0031\n",
      "Validation loss decreased (0.003173 --> 0.003127).  Saving model ...\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [01:44<01:10,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0031, Validation Loss: 0.0031\n",
      "Validation loss decreased (0.003127 --> 0.003082).  Saving model ...\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [01:55<01:05,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0030, Validation Loss: 0.0031\n",
      "Validation loss decreased (0.003082 --> 0.003058).  Saving model ...\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [02:06<00:59,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0030, Validation Loss: 0.0030\n",
      "Validation loss decreased (0.003058 --> 0.003043).  Saving model ...\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [02:17<00:50, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0030, Validation Loss: 0.0030\n",
      "Validation loss decreased (0.003043 --> 0.003025).  Saving model ...\n",
      "Updating learning rate to 0.00014644660940672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [02:26<00:39,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0030, Validation Loss: 0.0030\n",
      "Validation loss decreased (0.003025 --> 0.003010).  Saving model ...\n",
      "Updating learning rate to 9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [02:35<00:28,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0030, Validation Loss: 0.0030\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.449673790581611e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [02:44<00:18,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0030, Validation Loss: 0.0030\n",
      "Validation loss decreased (0.003010 --> 0.003000).  Saving model ...\n",
      "Updating learning rate to 2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [02:53<00:09,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0030, Validation Loss: 0.0030\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.15582970243117e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [03:02<00:00,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0030, Validation Loss: 0.0030\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": TiDE,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/TiDE\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        \"label_len\": 0,\n",
    "        'd_model': 128,\n",
    "        'd_layers': 1,\n",
    "        'd_ff': 128,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'freq': 'h',\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0572f0",
   "metadata": {},
   "source": [
    "# 基于Transformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068db957",
   "metadata": {},
   "source": [
    "## 多输入多输出多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b100a10",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "861d9802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:30:01.747288Z",
     "start_time": "2024-04-14T13:30:01.738536Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:41:31.490709Z",
     "iopub.status.busy": "2024-04-19T12:41:31.489709Z",
     "iopub.status.idle": "2024-04-19T12:41:31.513711Z",
     "shell.execute_reply": "2024-04-19T12:41:31.512711Z",
     "shell.execute_reply.started": "2024-04-19T12:41:31.490709Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_ = re.findall('[0-9]', freq)\n",
    "        if len(re_) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_))\n",
    "        # 生成时间间隔\n",
    "        time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                   end=pd.to_datetime(datetime) +\n",
    "                                   timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                   freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ac992088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:30:02.878328Z",
     "start_time": "2024-04-14T13:30:02.796284Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:41:33.625021Z",
     "iopub.status.busy": "2024-04-19T12:41:33.624025Z",
     "iopub.status.idle": "2024-04-19T12:41:33.708762Z",
     "shell.execute_reply": "2024-04-19T12:41:33.707805Z",
     "shell.execute_reply.started": "2024-04-19T12:41:33.625021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../test/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1e83d4b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:30:03.896097Z",
     "start_time": "2024-04-14T13:30:03.858768Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:41:34.720870Z",
     "iopub.status.busy": "2024-04-19T12:41:34.720870Z",
     "iopub.status.idle": "2024-04-19T12:41:34.770543Z",
     "shell.execute_reply": "2024-04-19T12:41:34.769575Z",
     "shell.execute_reply.started": "2024-04-19T12:41:34.720870Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "12ac9372-d0eb-4f58-ab54-26a52a0b0c14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:41:38.699711Z",
     "iopub.status.busy": "2024-04-19T12:41:38.697657Z",
     "iopub.status.idle": "2024-04-19T12:41:38.721679Z",
     "shell.execute_reply": "2024-04-19T12:41:38.720682Z",
     "shell.execute_reply.started": "2024-04-19T12:41:38.699711Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, valid_date, test_date, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "    test_stamp = test_stamp.transpose(1, 0)\n",
    "    test[x_feature_list] = x_scaler.transform(test)\n",
    "    xte = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    \n",
    "    # 数据合并，[训练集，测试集，时间戳]\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "    test = [xte, yte, test_stamp]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "19692d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:30:05.048531Z",
     "start_time": "2024-04-14T13:30:04.968650Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:41:44.499788Z",
     "iopub.status.busy": "2024-04-19T12:41:44.498789Z",
     "iopub.status.idle": "2024-04-19T12:41:44.576484Z",
     "shell.execute_reply": "2024-04-19T12:41:44.575521Z",
     "shell.execute_reply.started": "2024-04-19T12:41:44.499788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2) stamp_train shape: (23376, 4)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2) stamp_valid shape: (1464, 4)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2) stamp_test shape: (1464, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../test/scalers/Transformer'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "861e19ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:30:06.289302Z",
     "start_time": "2024-04-14T13:30:06.273728Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:41:45.721409Z",
     "iopub.status.busy": "2024-04-19T12:41:45.719978Z",
     "iopub.status.idle": "2024-04-19T12:41:45.761196Z",
     "shell.execute_reply": "2024-04-19T12:41:45.760205Z",
     "shell.execute_reply.started": "2024-04-19T12:41:45.721409Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    data_list：特征，目标，时间戳\n",
    "    seq_len：输入数据包含过去多少个时间步\n",
    "    pred_len：目标应该在未来多少个时间步之后\n",
    "    label_len：先验时间步\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(xs)\n",
    "        y_stamp.append(ys)\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "072de476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:30:08.319480Z",
     "start_time": "2024-04-14T13:30:07.506687Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:41:52.540779Z",
     "iopub.status.busy": "2024-04-19T12:41:52.539772Z",
     "iopub.status.idle": "2024-04-19T12:41:54.146741Z",
     "shell.execute_reply": "2024-04-19T12:41:54.145624Z",
     "shell.execute_reply.started": "2024-04-19T12:41:52.540779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 6,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 3,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b497a3",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f0713ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:30:10.753507Z",
     "start_time": "2024-04-14T13:30:10.686129Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:41:55.452914Z",
     "iopub.status.busy": "2024-04-19T12:41:55.451915Z",
     "iopub.status.idle": "2024-04-19T12:41:55.536965Z",
     "shell.execute_reply": "2024-04-19T12:41:55.535474Z",
     "shell.execute_reply.started": "2024-04-19T12:41:55.452914Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        second_size = 2\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.second_size = Embed(second_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        second_x = self.second_size(x[:, :, 5])\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x + second_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# Transformer_EncDec类\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "    \n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
    "                 dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask,\n",
    "            tau=tau, delta=None\n",
    "        )[0])\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )[0])\n",
    "\n",
    "        y = x = self.norm2(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm3(x + y)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask, tau=tau, delta=delta)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# 自编码类\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "    \n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "        \n",
    "        \n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "# Transformer模型\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "        embed: time features encoding, options:[timeF, fixed, learned]\n",
    "        freq: 'freq for time features encoding, options:[s:secondly, \n",
    "            t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], \n",
    "            you can also use more detailed freq like 15min or 3h'\n",
    "    \"\"\"\n",
    "    def __init__(self, pred_len, label_len, output_attention, enc_in, d_model, dropout, factor, n_heads, d_ff, \n",
    "                e_layers, dec_in, d_layers, c_out, embed, freq):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.output_attention = output_attention\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                      output_attention=output_attention), d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu'\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(True, factor, attention_dropout=dropout,\n",
    "                                      output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                      output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model),\n",
    "            projection=nn.Linear(d_model, c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out, x_mask=None, cross_mask=None)\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e292d",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d3f66bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T13:30:13.333548Z",
     "start_time": "2024-04-14T13:30:13.296351Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-19T12:41:57.572937Z",
     "iopub.status.busy": "2024-04-19T12:41:57.570943Z",
     "iopub.status.idle": "2024-04-19T12:41:57.639950Z",
     "shell.execute_reply": "2024-04-19T12:41:57.638949Z",
     "shell.execute_reply.started": "2024-04-19T12:41:57.572937Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4932dac0-46bb-4d96-8e93-0f8ff4bc73e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T12:42:04.394732Z",
     "iopub.status.busy": "2024-04-19T12:42:04.393733Z",
     "iopub.status.idle": "2024-04-19T12:47:29.293094Z",
     "shell.execute_reply": "2024-04-19T12:47:29.292120Z",
     "shell.execute_reply.started": "2024-04-19T12:42:04.393733Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:15<04:55, 15.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0199, Validation Loss: 0.0029\n",
      "Validation loss decreased (inf --> 0.002914).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:30<04:38, 15.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0049, Validation Loss: 0.0029\n",
      "Validation loss decreased (0.002914 --> 0.002910).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:46<04:23, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0038, Validation Loss: 0.0027\n",
      "Validation loss decreased (0.002910 --> 0.002657).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [01:01<04:05, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0031, Validation Loss: 0.0028\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [01:16<03:48, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0028, Validation Loss: 0.0020\n",
      "Validation loss decreased (0.002657 --> 0.001976).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 6/20 [01:32<03:37, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0025, Validation Loss: 0.0014\n",
      "Validation loss decreased (0.001976 --> 0.001393).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                      | 7/20 [01:48<03:21, 15.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0022, Validation Loss: 0.0013\n",
      "Validation loss decreased (0.001393 --> 0.001322).  Saving model ...\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [02:04<03:08, 15.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0021, Validation Loss: 0.0014\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                             | 9/20 [02:19<02:52, 15.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0019, Validation Loss: 0.0013\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 10/20 [02:35<02:36, 15.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0018, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.001322 --> 0.001098).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████                                     | 11/20 [02:51<02:20, 15.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0016, Validation Loss: 0.0009\n",
      "Validation loss decreased (0.001098 --> 0.000910).  Saving model ...\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [03:06<02:04, 15.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0015, Validation Loss: 0.0009\n",
      "Validation loss decreased (0.000910 --> 0.000861).  Saving model ...\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [03:23<01:51, 15.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0014, Validation Loss: 0.0011\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [03:40<01:37, 16.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0014, Validation Loss: 0.0009\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [03:56<01:20, 16.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0013, Validation Loss: 0.0007\n",
      "Validation loss decreased (0.000861 --> 0.000725).  Saving model ...\n",
      "Updating learning rate to 0.00014644660940672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [04:12<01:04, 16.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0013, Validation Loss: 0.0007\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [04:29<00:48, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0012, Validation Loss: 0.0008\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.449673790581611e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [04:48<00:34, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0012, Validation Loss: 0.0007\n",
      "Validation loss decreased (0.000725 --> 0.000723).  Saving model ...\n",
      "Updating learning rate to 2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [05:06<00:17, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0012, Validation Loss: 0.0007\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.15582970243117e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [05:24<00:00, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0011, Validation Loss: 0.0007\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Transformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"device\": 'cuda',\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../test/best_models/Transformer\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'pred_len': 3, \n",
    "        \"label_len\": 3,\n",
    "        'output_attention': True,\n",
    "        'embed': 'fixed',\n",
    "        'freq': 'h',\n",
    "        'd_model': 128,\n",
    "        'enc_in': 2,\n",
    "        'dec_in':2,\n",
    "        'dropout': 0.1,\n",
    "        'factor': 3,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426be23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 14,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "198.646px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
