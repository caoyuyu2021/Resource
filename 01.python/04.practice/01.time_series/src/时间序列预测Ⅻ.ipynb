{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2a49cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:39:21.719416Z",
     "start_time": "2024-04-12T09:39:21.703830Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.fft as fft\n",
    "import os\n",
    "from tqdm import tqdm # 打印进度条\n",
    "import math\n",
    "from einops import rearrange, repeat, reduce\n",
    "from scipy.fftpack import next_fast_len\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f85599",
   "metadata": {},
   "source": [
    "# 基于Crossformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2df08a",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c3731",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aff33a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:36.274377Z",
     "start_time": "2024-04-12T08:49:36.246845Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6fa305a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:37.648808Z",
     "start_time": "2024-04-12T08:49:37.531161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "960ea005",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:38.839628Z",
     "start_time": "2024-04-12T08:49:38.819755Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "893c75d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:48.041304Z",
     "start_time": "2024-04-12T08:49:47.982231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 1)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 1)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 1)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", \"temp\"],\n",
    "    \"y_feature_list\": [\"load\"],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fecd39e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:49.765403Z",
     "start_time": "2024-04-12T08:49:49.749906Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a52dd2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:53.021706Z",
     "start_time": "2024-04-12T08:49:52.242372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 1]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391071f0",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c56b6f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:58:43.488021Z",
     "start_time": "2024-04-12T08:58:43.379617Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "    \n",
    "    \n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, patch_len, stride, padding, dropout):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "        # Patching\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch_layer = nn.ReplicationPad1d((0, padding))\n",
    "\n",
    "        # Backbone, Input encoding: projection of feature vectors onto a d-dim vector space\n",
    "        self.value_embedding = nn.Linear(patch_len, d_model, bias=False)\n",
    "\n",
    "        # Positional embedding\n",
    "        self.position_embedding = PositionalEmbedding(d_model)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # do patching\n",
    "        n_vars = x.shape[1]\n",
    "        x = self.padding_patch_layer(x)\n",
    "        x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
    "        x = torch.reshape(x, (x.shape[0] * x.shape[1], x.shape[2], x.shape[3]))\n",
    "        # Input encoding\n",
    "        x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        return self.dropout(x), n_vars\n",
    "    \n",
    "    \n",
    "class TwoStageAttentionLayer(nn.Module):\n",
    "    '''\n",
    "    The Two Stage Attention (TSA) Layer\n",
    "    input/output shape: [batch_size, Data_dim(D), Seg_num(L), d_model]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, seg_num, factor, d_model, n_heads, output_attention, d_ff=None, dropout=0.1):\n",
    "        super(TwoStageAttentionLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.time_attention = AttentionLayer(FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                                           output_attention=output_attention), d_model, n_heads)\n",
    "        self.dim_sender = AttentionLayer(FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                                       output_attention=output_attention), d_model, n_heads)\n",
    "        self.dim_receiver = AttentionLayer(FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                                         output_attention=output_attention), d_model, n_heads)\n",
    "        self.router = nn.Parameter(torch.randn(seg_num, factor, d_model))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.norm4 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.MLP1 = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_ff, d_model))\n",
    "        self.MLP2 = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_ff, d_model))\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # Cross Time Stage: Directly apply MSA to each dimension\n",
    "        batch = x.shape[0]\n",
    "        time_in = rearrange(x, 'b ts_d seg_num d_model -> (b ts_d) seg_num d_model')\n",
    "        time_enc, attn = self.time_attention(\n",
    "            time_in, time_in, time_in, attn_mask=None, tau=None, delta=None\n",
    "        )\n",
    "        dim_in = time_in + self.dropout(time_enc)\n",
    "        dim_in = self.norm1(dim_in)\n",
    "        dim_in = dim_in + self.dropout(self.MLP1(dim_in))\n",
    "        dim_in = self.norm2(dim_in)\n",
    "\n",
    "        # Cross Dimension Stage: use a small set of learnable vectors to aggregate and distribute messages to build the D-to-D connection\n",
    "        dim_send = rearrange(dim_in, '(b ts_d) seg_num d_model -> (b seg_num) ts_d d_model', b=batch)\n",
    "        batch_router = repeat(self.router, 'seg_num factor d_model -> (repeat seg_num) factor d_model', repeat=batch)\n",
    "        dim_buffer, attn = self.dim_sender(batch_router, dim_send, dim_send, attn_mask=None, tau=None, delta=None)\n",
    "        dim_receive, attn = self.dim_receiver(dim_send, dim_buffer, dim_buffer, attn_mask=None, tau=None, delta=None)\n",
    "        dim_enc = dim_send + self.dropout(dim_receive)\n",
    "        dim_enc = self.norm3(dim_enc)\n",
    "        dim_enc = dim_enc + self.dropout(self.MLP2(dim_enc))\n",
    "        dim_enc = self.norm4(dim_enc)\n",
    "\n",
    "        final_out = rearrange(dim_enc, '(b seg_num) ts_d d_model -> b ts_d seg_num d_model', b=batch)\n",
    "\n",
    "        return final_out\n",
    "\n",
    "    \n",
    "class SegMerging(nn.Module):\n",
    "    def __init__(self, d_model, win_size, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.win_size = win_size\n",
    "        self.linear_trans = nn.Linear(win_size * d_model, d_model)\n",
    "        self.norm = norm_layer(win_size * d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, ts_d, seg_num, d_model = x.shape\n",
    "        pad_num = seg_num % self.win_size\n",
    "        if pad_num != 0:\n",
    "            pad_num = self.win_size - pad_num\n",
    "            x = torch.cat((x, x[:, :, -pad_num:, :]), dim=-2)\n",
    "\n",
    "        seg_to_merge = []\n",
    "        for i in range(self.win_size):\n",
    "            seg_to_merge.append(x[:, :, i::self.win_size, :])\n",
    "        x = torch.cat(seg_to_merge, -1)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.linear_trans(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class scale_block(nn.Module):\n",
    "    def __init__(self, win_size, d_model, n_heads, d_ff, depth, dropout, output_attention, \n",
    "                 seg_num=10, factor=10):\n",
    "        super(scale_block, self).__init__()\n",
    "\n",
    "        if win_size > 1:\n",
    "            self.merge_layer = SegMerging(d_model, win_size, nn.LayerNorm)\n",
    "        else:\n",
    "            self.merge_layer = None\n",
    "\n",
    "        self.encode_layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.encode_layers.append(TwoStageAttentionLayer(seg_num, factor, d_model, n_heads, output_attention, \n",
    "                                                             d_ff, dropout))\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        _, ts_dim, _, _ = x.shape\n",
    "\n",
    "        if self.merge_layer is not None:\n",
    "            x = self.merge_layer(x)\n",
    "\n",
    "        for layer in self.encode_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x, None\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encode_blocks = nn.ModuleList(attn_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encode_x = []\n",
    "        encode_x.append(x)\n",
    "\n",
    "        for block in self.encode_blocks:\n",
    "            x, attns = block(x)\n",
    "            encode_x.append(x)\n",
    "\n",
    "        return encode_x, None\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, seg_len, d_model, d_ff=None, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.MLP1 = nn.Sequential(nn.Linear(d_model, d_model),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_model, d_model))\n",
    "        self.linear_pred = nn.Linear(d_model, seg_len)\n",
    "\n",
    "    def forward(self, x, cross):\n",
    "        batch = x.shape[0]\n",
    "        x = self.self_attention(x)\n",
    "        x = rearrange(x, 'b ts_d out_seg_num d_model -> (b ts_d) out_seg_num d_model')\n",
    "\n",
    "        cross = rearrange(cross, 'b ts_d in_seg_num d_model -> (b ts_d) in_seg_num d_model')\n",
    "        tmp, attn = self.cross_attention(x, cross, cross, None, None, None,)\n",
    "        x = x + self.dropout(tmp)\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.MLP1(y)\n",
    "        dec_output = self.norm2(x + y)\n",
    "\n",
    "        dec_output = rearrange(dec_output, '(b ts_d) seg_dec_num d_model -> b ts_d seg_dec_num d_model', b=batch)\n",
    "        layer_predict = self.linear_pred(dec_output)\n",
    "        layer_predict = rearrange(layer_predict, 'b out_d seg_num seg_len -> b (out_d seg_num) seg_len')\n",
    "\n",
    "        return dec_output, layer_predict\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decode_layers = nn.ModuleList(layers)\n",
    "\n",
    "\n",
    "    def forward(self, x, cross):\n",
    "        final_predict = None\n",
    "        i = 0\n",
    "\n",
    "        ts_d = x.shape[1]\n",
    "        for layer in self.decode_layers:\n",
    "            cross_enc = cross[i]\n",
    "            x, layer_predict = layer(x, cross_enc)\n",
    "            if final_predict is None:\n",
    "                final_predict = layer_predict\n",
    "            else:\n",
    "                final_predict = final_predict + layer_predict\n",
    "            i += 1\n",
    "\n",
    "        final_predict = rearrange(final_predict, 'b (out_d seg_num) seg_len -> b (seg_num seg_len) out_d', out_d=ts_d)\n",
    "\n",
    "        return final_predict\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "    \n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "        \n",
    "        \n",
    "class FlattenHead(nn.Module):\n",
    "    def __init__(self, n_vars, nf, target_window, head_dropout=0):\n",
    "        super().__init__()\n",
    "        self.n_vars = n_vars\n",
    "        self.flatten = nn.Flatten(start_dim=-2)\n",
    "        self.linear = nn.Linear(nf, target_window)\n",
    "        self.dropout = nn.Dropout(head_dropout)\n",
    "\n",
    "    def forward(self, x):  # x: [bs x nvars x d_model x patch_num]\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "# Crossformer模型\n",
    "class Crossformer(nn.Module):\n",
    "    def __init__(self, enc_in, seq_len, pred_len, e_layers, d_layers, d_model, \n",
    "                 output_attention, n_heads, d_ff, dropout, factor):\n",
    "        super(Crossformer, self).__init__()\n",
    "        self.enc_in = enc_in\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.seg_len = 12\n",
    "        self.win_size = 2\n",
    "\n",
    "        # The padding operation to handle invisible sgemnet length\n",
    "        self.pad_in_len = math.ceil(1.0 * seq_len / self.seg_len) * self.seg_len\n",
    "        self.pad_out_len = math.ceil(1.0 * pred_len / self.seg_len) * self.seg_len\n",
    "        self.in_seg_num = self.pad_in_len // self.seg_len\n",
    "        self.out_seg_num = math.ceil(self.in_seg_num / (self.win_size ** (e_layers - 1)))\n",
    "        self.head_nf = d_model * self.out_seg_num\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_value_embedding = PatchEmbedding(d_model, self.seg_len, self.seg_len, self.pad_in_len - seq_len, 0)\n",
    "        self.enc_pos_embedding = nn.Parameter(\n",
    "            torch.randn(1, enc_in, self.in_seg_num, d_model))\n",
    "        self.pre_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                scale_block(1 if l is 0 else self.win_size, d_model, n_heads, d_ff, 1, dropout, output_attention, \n",
    "                            self.in_seg_num if l is 0 else math.ceil(self.in_seg_num / self.win_size ** l), factor\n",
    "                            ) for l in range(e_layers)\n",
    "            ]\n",
    "        )\n",
    "        # Decoder\n",
    "        self.dec_pos_embedding = nn.Parameter(\n",
    "            torch.randn(1, enc_in, (self.pad_out_len // self.seg_len), d_model))\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    TwoStageAttentionLayer((self.pad_out_len // self.seg_len), factor, d_model, n_heads, output_attention,\n",
    "                                           d_ff, dropout),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout, output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    self.seg_len,\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    # activation=configs.activation,\n",
    "                )\n",
    "                for l in range(d_layers + 1)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x_enc):\n",
    "        # embedding\n",
    "        x_enc, n_vars = self.enc_value_embedding(x_enc.permute(0, 2, 1))\n",
    "        x_enc = rearrange(x_enc, '(b d) seg_num d_model -> b d seg_num d_model', d = n_vars)\n",
    "        x_enc += self.enc_pos_embedding\n",
    "        x_enc = self.pre_norm(x_enc)\n",
    "        enc_out, attns = self.encoder(x_enc)\n",
    "\n",
    "        dec_in = repeat(self.dec_pos_embedding, 'b ts_d l d -> (repeat b) ts_d l d', repeat=x_enc.shape[0])\n",
    "        dec_out = self.decoder(dec_in, enc_out)\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f0c58",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "197350b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:58:45.598971Z",
     "start_time": "2024-04-12T08:58:45.533102Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c271620a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:09:58.467365Z",
     "start_time": "2024-04-12T08:59:28.093201Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:31<09:58, 31.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0158, Validation Loss: 0.0110\n",
      "Validation loss decreased (inf --> 0.011013).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [01:01<09:13, 30.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0057, Validation Loss: 0.0074\n",
      "Validation loss decreased (0.011013 --> 0.007376).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [01:32<08:39, 30.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0042, Validation Loss: 0.0044\n",
      "Validation loss decreased (0.007376 --> 0.004405).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [02:02<08:09, 30.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0033, Validation Loss: 0.0037\n",
      "Validation loss decreased (0.004405 --> 0.003723).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [02:33<07:37, 30.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0028, Validation Loss: 0.0042\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [03:04<07:10, 30.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0025, Validation Loss: 0.0033\n",
      "Validation loss decreased (0.003723 --> 0.003262).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████                                                      | 7/20 [03:36<06:44, 31.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0023, Validation Loss: 0.0044\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [04:07<06:13, 31.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0021, Validation Loss: 0.0032\n",
      "Validation loss decreased (0.003262 --> 0.003217).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [04:38<05:42, 31.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0019, Validation Loss: 0.0033\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [05:09<05:12, 31.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0018, Validation Loss: 0.0031\n",
      "Validation loss decreased (0.003217 --> 0.003125).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [05:41<04:41, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0017, Validation Loss: 0.0037\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [06:14<04:14, 31.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0016, Validation Loss: 0.0044\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [06:46<03:42, 31.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0015, Validation Loss: 0.0031\n",
      "Validation loss decreased (0.003125 --> 0.003071).  Saving model ...\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [07:16<03:08, 31.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0014, Validation Loss: 0.0037\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [07:48<02:37, 31.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0014, Validation Loss: 0.0033\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 0.00014644660940672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [08:19<02:05, 31.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0013, Validation Loss: 0.0029\n",
      "Validation loss decreased (0.003071 --> 0.002893).  Saving model ...\n",
      "Updating learning rate to 9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [08:51<01:34, 31.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0013, Validation Loss: 0.0032\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 5.449673790581611e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [09:24<01:03, 31.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0013, Validation Loss: 0.0031\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [09:57<00:32, 32.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0012, Validation Loss: 0.0031\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Updating learning rate to 6.15582970243117e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [10:29<00:00, 31.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0012, Validation Loss: 0.0030\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Updating learning rate to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load'],\n",
    "        \"features\": 'MS'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Crossformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 7,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 2 * 3,\n",
    "        'pred_len': 3,\n",
    "        'output_attention': False,\n",
    "        'd_model': 32,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 32,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'factor': 3\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795bcea",
   "metadata": {},
   "source": [
    "# 基于ETSformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b3b4c",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f458f952",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea9a8c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:30.392404Z",
     "start_time": "2024-04-12T09:58:30.381399Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b06190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:30.519326Z",
     "start_time": "2024-04-12T09:58:30.519326Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d134ab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:30.528327Z",
     "start_time": "2024-04-12T09:58:30.528327Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a5e38278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:36.809148Z",
     "start_time": "2024-04-12T09:58:36.730637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 1) y_train shape: (23376, 1)\n",
      "x_valid shape: (1464, 1) y_valid shape: (1464, 1)\n",
      "x_test shape: (1464, 1) y_test shape: (1464, 1)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\"],\n",
    "    \"y_feature_list\": [\"load\"],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8620e43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:38.100451Z",
     "start_time": "2024-04-12T09:58:38.083854Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd9450fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:40.172549Z",
     "start_time": "2024-04-12T09:58:39.490487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 1]),y_size: torch.Size([23368, 3, 1]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 1]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 1]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51480be9",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86260892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:01:22.853828Z",
     "start_time": "2024-04-12T10:01:22.717154Z"
    }
   },
   "outputs": [],
   "source": [
    "# 编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# 编码器和解码器\n",
    "class Transform:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def transform(self, x):\n",
    "        return self.jitter(self.shift(self.scale(x)))\n",
    "\n",
    "    def jitter(self, x):\n",
    "        return x + (torch.randn(x.shape).to(x.device) * self.sigma)\n",
    "\n",
    "    def scale(self, x):\n",
    "        return x * (torch.randn(x.size(-1)).to(x.device) * self.sigma + 1)\n",
    "\n",
    "    def shift(self, x):\n",
    "        return x + (torch.randn(x.size(-1)).to(x.device) * self.sigma)\n",
    "\n",
    "\n",
    "def conv1d_fft(f, g, dim=-1):\n",
    "    N = f.size(dim)\n",
    "    M = g.size(dim)\n",
    "\n",
    "    fast_len = next_fast_len(N + M - 1)\n",
    "\n",
    "    F_f = fft.rfft(f, fast_len, dim=dim)\n",
    "    F_g = fft.rfft(g, fast_len, dim=dim)\n",
    "\n",
    "    F_fg = F_f * F_g.conj()\n",
    "    out = fft.irfft(F_fg, fast_len, dim=dim)\n",
    "    out = out.roll((-1,), dims=(dim,))\n",
    "    idx = torch.as_tensor(range(fast_len - N, fast_len)).to(out.device)\n",
    "    out = out.index_select(dim, idx)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class ExponentialSmoothing(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, nhead, dropout=0.1, aux=False):\n",
    "        super().__init__()\n",
    "        self._smoothing_weight = nn.Parameter(torch.randn(nhead, 1))\n",
    "        self.v0 = nn.Parameter(torch.randn(1, 1, nhead, dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if aux:\n",
    "            self.aux_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, values, aux_values=None):\n",
    "        b, t, h, d = values.shape\n",
    "\n",
    "        init_weight, weight = self.get_exponential_weight(t)\n",
    "        output = conv1d_fft(self.dropout(values), weight, dim=1)\n",
    "        output = init_weight * self.v0 + output\n",
    "\n",
    "        if aux_values is not None:\n",
    "            aux_weight = weight / (1 - self.weight) * self.weight\n",
    "            aux_output = conv1d_fft(self.aux_dropout(aux_values), aux_weight)\n",
    "            output = output + aux_output\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_exponential_weight(self, T):\n",
    "        # Generate array [0, 1, ..., T-1]\n",
    "        powers = torch.arange(T, dtype=torch.float, device=self.weight.device)\n",
    "\n",
    "        # (1 - \\alpha) * \\alpha^t, for all t = T-1, T-2, ..., 0]\n",
    "        weight = (1 - self.weight) * (self.weight ** torch.flip(powers, dims=(0,)))\n",
    "\n",
    "        # \\alpha^t for all t = 1, 2, ..., T\n",
    "        init_weight = self.weight ** (powers + 1)\n",
    "\n",
    "        return rearrange(init_weight, 'h t -> 1 t h 1'), \\\n",
    "               rearrange(weight, 'h t -> 1 t h 1')\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return torch.sigmoid(self._smoothing_weight)\n",
    "\n",
    "\n",
    "class Feedforward(nn.Module):\n",
    "    def __init__(self, d_model, dim_feedforward, dropout=0.1, activation='sigmoid'):\n",
    "        # Implementation of Feedforward model\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward, bias=False)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model, bias=False)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = getattr(F, activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear2(self.dropout1(self.activation(self.linear1(x))))\n",
    "        return self.dropout2(x)\n",
    "\n",
    "\n",
    "class GrowthLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, d_head=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head or (d_model // nhead)\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "\n",
    "        self.z0 = nn.Parameter(torch.randn(self.nhead, self.d_head))\n",
    "        self.in_proj = nn.Linear(self.d_model, self.d_head * self.nhead)\n",
    "        self.es = ExponentialSmoothing(self.d_head, self.nhead, dropout=dropout)\n",
    "        self.out_proj = nn.Linear(self.d_head * self.nhead, self.d_model)\n",
    "\n",
    "        assert self.d_head * self.nhead == self.d_model, \"d_model must be divisible by nhead\"\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        :param inputs: shape: (batch, seq_len, dim)\n",
    "        :return: shape: (batch, seq_len, dim)\n",
    "        \"\"\"\n",
    "        b, t, d = inputs.shape\n",
    "        values = self.in_proj(inputs).view(b, t, self.nhead, -1)\n",
    "        values = torch.cat([repeat(self.z0, 'h d -> b 1 h d', b=b), values], dim=1)\n",
    "        values = values[:, 1:] - values[:, :-1]\n",
    "        out = self.es(values)\n",
    "        out = torch.cat([repeat(self.es.v0, '1 1 h d -> b 1 h d', b=b), out], dim=1)\n",
    "        out = rearrange(out, 'b t h d -> b t (h d)')\n",
    "        return self.out_proj(out)\n",
    "\n",
    "\n",
    "class FourierLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, pred_len, k=None, low_freq=1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pred_len = pred_len\n",
    "        self.k = k\n",
    "        self.low_freq = low_freq\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: (b, t, d)\"\"\"\n",
    "        b, t, d = x.shape\n",
    "        x_freq = fft.rfft(x, dim=1)\n",
    "\n",
    "        if t % 2 == 0:\n",
    "            x_freq = x_freq[:, self.low_freq:-1]\n",
    "            f = fft.rfftfreq(t)[self.low_freq:-1]\n",
    "        else:\n",
    "            x_freq = x_freq[:, self.low_freq:]\n",
    "            f = fft.rfftfreq(t)[self.low_freq:]\n",
    "\n",
    "        x_freq, index_tuple = self.topk_freq(x_freq)\n",
    "        f = repeat(f, 'f -> b f d', b=x_freq.size(0), d=x_freq.size(2))\n",
    "        f = rearrange(f[index_tuple], 'b f d -> b f () d').to(x_freq.device)\n",
    "\n",
    "        return self.extrapolate(x_freq, f, t)\n",
    "\n",
    "    def extrapolate(self, x_freq, f, t):\n",
    "        x_freq = torch.cat([x_freq, x_freq.conj()], dim=1)\n",
    "        f = torch.cat([f, -f], dim=1)\n",
    "        t_val = rearrange(torch.arange(t + self.pred_len, dtype=torch.float),\n",
    "                          't -> () () t ()').to(x_freq.device)\n",
    "\n",
    "        amp = rearrange(x_freq.abs() / t, 'b f d -> b f () d')\n",
    "        phase = rearrange(x_freq.angle(), 'b f d -> b f () d')\n",
    "\n",
    "        x_time = amp * torch.cos(2 * math.pi * f * t_val + phase)\n",
    "\n",
    "        return reduce(x_time, 'b f t d -> b t d', 'sum')\n",
    "\n",
    "    def topk_freq(self, x_freq):\n",
    "        values, indices = torch.topk(x_freq.abs(), self.k, dim=1, largest=True, sorted=True)\n",
    "        mesh_a, mesh_b = torch.meshgrid(torch.arange(x_freq.size(0)), torch.arange(x_freq.size(2)))\n",
    "        index_tuple = (mesh_a.unsqueeze(1), indices, mesh_b.unsqueeze(1))\n",
    "        x_freq = x_freq[index_tuple]\n",
    "\n",
    "        return x_freq, index_tuple\n",
    "\n",
    "\n",
    "class LevelLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, c_out, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.c_out = c_out\n",
    "\n",
    "        self.es = ExponentialSmoothing(1, self.c_out, dropout=dropout, aux=True)\n",
    "        self.growth_pred = nn.Linear(self.d_model, self.c_out)\n",
    "        self.season_pred = nn.Linear(self.d_model, self.c_out)\n",
    "\n",
    "    def forward(self, level, growth, season):\n",
    "        b, t, _ = level.shape\n",
    "        growth = self.growth_pred(growth).view(b, t, self.c_out, 1)\n",
    "        season = self.season_pred(season).view(b, t, self.c_out, 1)\n",
    "        growth = growth.view(b, t, self.c_out, 1)\n",
    "        season = season.view(b, t, self.c_out, 1)\n",
    "        level = level.view(b, t, self.c_out, 1)\n",
    "        out = self.es(level - season, aux_values=growth)\n",
    "        out = rearrange(out, 'b t h d -> b t (h d)')\n",
    "        return out\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, c_out, seq_len, pred_len, k, dim_feedforward=None, dropout=0.1,\n",
    "                 activation='sigmoid', layer_norm_eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.c_out = c_out\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        dim_feedforward = dim_feedforward or 4 * d_model\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.growth_layer = GrowthLayer(d_model, nhead, dropout=dropout)\n",
    "        self.seasonal_layer = FourierLayer(d_model, pred_len, k=k)\n",
    "        self.level_layer = LevelLayer(d_model, c_out, dropout=dropout)\n",
    "\n",
    "        # Implementation of Feedforward model\n",
    "        self.ff = Feedforward(d_model, dim_feedforward, dropout=dropout, activation=activation)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, res, level, attn_mask=None):\n",
    "        season = self._season_block(res)\n",
    "        res = res - season[:, :-self.pred_len]\n",
    "        growth = self._growth_block(res)\n",
    "        res = self.norm1(res - growth[:, 1:])\n",
    "        res = self.norm2(res + self.ff(res))\n",
    "\n",
    "        level = self.level_layer(level, growth[:, :-1], season[:, :-self.pred_len])\n",
    "        return res, level, growth, season\n",
    "\n",
    "    def _growth_block(self, x):\n",
    "        x = self.growth_layer(x)\n",
    "        return self.dropout1(x)\n",
    "\n",
    "    def _season_block(self, x):\n",
    "        x = self.seasonal_layer(x)\n",
    "        return self.dropout2(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, res, level, attn_mask=None):\n",
    "        growths = []\n",
    "        seasons = []\n",
    "        for layer in self.layers:\n",
    "            res, level, growth, season = layer(res, level, attn_mask=None)\n",
    "            growths.append(growth)\n",
    "            seasons.append(season)\n",
    "\n",
    "        return level, growths, seasons\n",
    "\n",
    "\n",
    "class DampingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, pred_len, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.nhead = nhead\n",
    "        self._damping_factor = nn.Parameter(torch.randn(1, nhead))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = repeat(x, 'b 1 d -> b t d', t=self.pred_len)\n",
    "        b, t, d = x.shape\n",
    "\n",
    "        powers = torch.arange(self.pred_len).to(self._damping_factor.device) + 1\n",
    "        powers = powers.view(self.pred_len, 1)\n",
    "        damping_factors = self.damping_factor ** powers\n",
    "        damping_factors = damping_factors.cumsum(dim=0)\n",
    "        x = x.view(b, t, self.nhead, -1)\n",
    "        x = self.dropout(x) * damping_factors.unsqueeze(-1)\n",
    "        return x.view(b, t, d)\n",
    "\n",
    "    @property\n",
    "    def damping_factor(self):\n",
    "        return torch.sigmoid(self._damping_factor)\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, c_out, pred_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.c_out = c_out\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        self.growth_damping = DampingLayer(pred_len, nhead, dropout=dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, growth, season):\n",
    "        growth_horizon = self.growth_damping(growth[:, -1:])\n",
    "        growth_horizon = self.dropout1(growth_horizon)\n",
    "\n",
    "        seasonal_horizon = season[:, -self.pred_len:]\n",
    "        return growth_horizon, seasonal_horizon\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.d_model = layers[0].d_model\n",
    "        self.c_out = layers[0].c_out\n",
    "        self.pred_len = layers[0].pred_len\n",
    "        self.nhead = layers[0].nhead\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.pred = nn.Linear(self.d_model, self.c_out)\n",
    "\n",
    "    def forward(self, growths, seasons):\n",
    "        growth_repr = []\n",
    "        season_repr = []\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            growth_horizon, season_horizon = layer(growths[idx], seasons[idx])\n",
    "            growth_repr.append(growth_horizon)\n",
    "            season_repr.append(season_horizon)\n",
    "        growth_repr = sum(growth_repr)\n",
    "        season_repr = sum(season_repr)\n",
    "        return self.pred(growth_repr), self.pred(season_repr)\n",
    "\n",
    "    \n",
    "# ETSformer模型\n",
    "class ETSformer(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, e_layers, d_layers, enc_in, d_model, \n",
    "                 dropout, n_heads, top_k, d_ff, c_out):\n",
    "        super(ETSformer, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        assert e_layers == d_layers, \"Encoder and decoder layers must be equal\"\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    d_model, n_heads, enc_in, seq_len, pred_len, top_k,\n",
    "                    dim_feedforward=d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                ) for _ in range(e_layers)\n",
    "            ]\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    d_model, n_heads, c_out, pred_len,\n",
    "                    dropout=dropout,\n",
    "                ) for _ in range(d_layers)\n",
    "            ],\n",
    "        )\n",
    "        self.transform = Transform(sigma=0.2)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc=None):\n",
    "        with torch.no_grad():\n",
    "            if self.training:\n",
    "                x_enc = self.transform.transform(x_enc)\n",
    "#         x_enc = self.transform.transform(x_enc)\n",
    "        res = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        level, growths, seasons = self.encoder(res, x_enc, attn_mask=None)\n",
    "\n",
    "        growth, season = self.decoder(growths, seasons)\n",
    "        dec_out = level[:, -1:] + growth + season\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e272698",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "829705a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:01:25.706451Z",
     "start_time": "2024-04-12T10:01:25.656901Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b0801446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T10:04:16.711389Z",
     "start_time": "2024-04-12T10:01:27.453659Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:31<09:59, 31.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0424, Validation Loss: 0.0397\n",
      "Validation loss decreased (inf --> 0.039718).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [01:23<13:08, 43.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0312, Validation Loss: 0.0315\n",
      "Validation loss decreased (0.039718 --> 0.031464).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [02:28<15:04, 53.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0300, Validation Loss: 0.0356\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [02:48<15:54, 56.16s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 35\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 构造参数字典\u001b[39;00m\n\u001b[0;32m      2\u001b[0m params3 \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_args\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     },\n\u001b[0;32m     34\u001b[0m }\n\u001b[1;32m---> 35\u001b[0m model \u001b[38;5;241m=\u001b[39m train(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams3)\n",
      "Cell \u001b[1;32mIn[71], line 125\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(task_args, train_args, model_args)\u001b[0m\n\u001b[0;32m    123\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, targets_batch)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# 反向传播计算得到每个参数的梯度值\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# 通过梯度下降执行一步参数更新\u001b[39;00m\n\u001b[0;32m    127\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load'],\n",
    "        \"target\": ['load'],\n",
    "        \"features\": 'S'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": ETSformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 7,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 1, \n",
    "        'seq_len': 2 * 3,\n",
    "        'pred_len': 3,\n",
    "        'top_k': 2,\n",
    "        'd_model': 128,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'c_out': 1\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae370d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "198.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
