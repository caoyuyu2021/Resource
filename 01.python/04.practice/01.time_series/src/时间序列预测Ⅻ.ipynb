{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b9aa0d",
   "metadata": {},
   "source": [
    "**时间序列预测前沿算法汇总Ⅱ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b2a49cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:43:41.556057Z",
     "start_time": "2024-04-13T09:43:41.549851Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.fft as fft\n",
    "import os\n",
    "from tqdm import tqdm # 打印进度条\n",
    "import math\n",
    "from einops import rearrange, repeat, reduce\n",
    "from scipy.fftpack import next_fast_len\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial, reduce, wraps\n",
    "from sympy import Poly, legendre, Symbol, chebyshevt\n",
    "from scipy.special import eval_legendre\n",
    "from scipy import signal\n",
    "from torch.nn.modules.linear import Linear\n",
    "from operator import mul\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f85599",
   "metadata": {},
   "source": [
    "# 基于Crossformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2df08a",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c3731",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aff33a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:36.274377Z",
     "start_time": "2024-04-12T08:49:36.246845Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6fa305a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:37.648808Z",
     "start_time": "2024-04-12T08:49:37.531161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "960ea005",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:38.839628Z",
     "start_time": "2024-04-12T08:49:38.819755Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "893c75d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:48.041304Z",
     "start_time": "2024-04-12T08:49:47.982231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 1)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 1)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 1)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", \"temp\"],\n",
    "    \"y_feature_list\": [\"load\"],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fecd39e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:49.765403Z",
     "start_time": "2024-04-12T08:49:49.749906Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a52dd2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:49:53.021706Z",
     "start_time": "2024-04-12T08:49:52.242372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 1]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391071f0",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c56b6f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:58:43.488021Z",
     "start_time": "2024-04-12T08:58:43.379617Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "    \n",
    "    \n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, patch_len, stride, padding, dropout):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "        # Patching\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch_layer = nn.ReplicationPad1d((0, padding))\n",
    "\n",
    "        # Backbone, Input encoding: projection of feature vectors onto a d-dim vector space\n",
    "        self.value_embedding = nn.Linear(patch_len, d_model, bias=False)\n",
    "\n",
    "        # Positional embedding\n",
    "        self.position_embedding = PositionalEmbedding(d_model)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # do patching\n",
    "        n_vars = x.shape[1]\n",
    "        x = self.padding_patch_layer(x)\n",
    "        x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
    "        x = torch.reshape(x, (x.shape[0] * x.shape[1], x.shape[2], x.shape[3]))\n",
    "        # Input encoding\n",
    "        x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        return self.dropout(x), n_vars\n",
    "    \n",
    "    \n",
    "class TwoStageAttentionLayer(nn.Module):\n",
    "    '''\n",
    "    The Two Stage Attention (TSA) Layer\n",
    "    input/output shape: [batch_size, Data_dim(D), Seg_num(L), d_model]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, seg_num, factor, d_model, n_heads, output_attention, d_ff=None, dropout=0.1):\n",
    "        super(TwoStageAttentionLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.time_attention = AttentionLayer(FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                                           output_attention=output_attention), d_model, n_heads)\n",
    "        self.dim_sender = AttentionLayer(FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                                       output_attention=output_attention), d_model, n_heads)\n",
    "        self.dim_receiver = AttentionLayer(FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                                         output_attention=output_attention), d_model, n_heads)\n",
    "        self.router = nn.Parameter(torch.randn(seg_num, factor, d_model))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.norm4 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.MLP1 = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_ff, d_model))\n",
    "        self.MLP2 = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_ff, d_model))\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # Cross Time Stage: Directly apply MSA to each dimension\n",
    "        batch = x.shape[0]\n",
    "        time_in = rearrange(x, 'b ts_d seg_num d_model -> (b ts_d) seg_num d_model')\n",
    "        time_enc, attn = self.time_attention(\n",
    "            time_in, time_in, time_in, attn_mask=None, tau=None, delta=None\n",
    "        )\n",
    "        dim_in = time_in + self.dropout(time_enc)\n",
    "        dim_in = self.norm1(dim_in)\n",
    "        dim_in = dim_in + self.dropout(self.MLP1(dim_in))\n",
    "        dim_in = self.norm2(dim_in)\n",
    "\n",
    "        # Cross Dimension Stage: use a small set of learnable vectors to aggregate and distribute messages to build the D-to-D connection\n",
    "        dim_send = rearrange(dim_in, '(b ts_d) seg_num d_model -> (b seg_num) ts_d d_model', b=batch)\n",
    "        batch_router = repeat(self.router, 'seg_num factor d_model -> (repeat seg_num) factor d_model', repeat=batch)\n",
    "        dim_buffer, attn = self.dim_sender(batch_router, dim_send, dim_send, attn_mask=None, tau=None, delta=None)\n",
    "        dim_receive, attn = self.dim_receiver(dim_send, dim_buffer, dim_buffer, attn_mask=None, tau=None, delta=None)\n",
    "        dim_enc = dim_send + self.dropout(dim_receive)\n",
    "        dim_enc = self.norm3(dim_enc)\n",
    "        dim_enc = dim_enc + self.dropout(self.MLP2(dim_enc))\n",
    "        dim_enc = self.norm4(dim_enc)\n",
    "\n",
    "        final_out = rearrange(dim_enc, '(b seg_num) ts_d d_model -> b ts_d seg_num d_model', b=batch)\n",
    "\n",
    "        return final_out\n",
    "\n",
    "    \n",
    "class SegMerging(nn.Module):\n",
    "    def __init__(self, d_model, win_size, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.win_size = win_size\n",
    "        self.linear_trans = nn.Linear(win_size * d_model, d_model)\n",
    "        self.norm = norm_layer(win_size * d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, ts_d, seg_num, d_model = x.shape\n",
    "        pad_num = seg_num % self.win_size\n",
    "        if pad_num != 0:\n",
    "            pad_num = self.win_size - pad_num\n",
    "            x = torch.cat((x, x[:, :, -pad_num:, :]), dim=-2)\n",
    "\n",
    "        seg_to_merge = []\n",
    "        for i in range(self.win_size):\n",
    "            seg_to_merge.append(x[:, :, i::self.win_size, :])\n",
    "        x = torch.cat(seg_to_merge, -1)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.linear_trans(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class scale_block(nn.Module):\n",
    "    def __init__(self, win_size, d_model, n_heads, d_ff, depth, dropout, output_attention, \n",
    "                 seg_num=10, factor=10):\n",
    "        super(scale_block, self).__init__()\n",
    "\n",
    "        if win_size > 1:\n",
    "            self.merge_layer = SegMerging(d_model, win_size, nn.LayerNorm)\n",
    "        else:\n",
    "            self.merge_layer = None\n",
    "\n",
    "        self.encode_layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.encode_layers.append(TwoStageAttentionLayer(seg_num, factor, d_model, n_heads, output_attention, \n",
    "                                                             d_ff, dropout))\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        _, ts_dim, _, _ = x.shape\n",
    "\n",
    "        if self.merge_layer is not None:\n",
    "            x = self.merge_layer(x)\n",
    "\n",
    "        for layer in self.encode_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x, None\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encode_blocks = nn.ModuleList(attn_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encode_x = []\n",
    "        encode_x.append(x)\n",
    "\n",
    "        for block in self.encode_blocks:\n",
    "            x, attns = block(x)\n",
    "            encode_x.append(x)\n",
    "\n",
    "        return encode_x, None\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, seg_len, d_model, d_ff=None, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.MLP1 = nn.Sequential(nn.Linear(d_model, d_model),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_model, d_model))\n",
    "        self.linear_pred = nn.Linear(d_model, seg_len)\n",
    "\n",
    "    def forward(self, x, cross):\n",
    "        batch = x.shape[0]\n",
    "        x = self.self_attention(x)\n",
    "        x = rearrange(x, 'b ts_d out_seg_num d_model -> (b ts_d) out_seg_num d_model')\n",
    "\n",
    "        cross = rearrange(cross, 'b ts_d in_seg_num d_model -> (b ts_d) in_seg_num d_model')\n",
    "        tmp, attn = self.cross_attention(x, cross, cross, None, None, None,)\n",
    "        x = x + self.dropout(tmp)\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.MLP1(y)\n",
    "        dec_output = self.norm2(x + y)\n",
    "\n",
    "        dec_output = rearrange(dec_output, '(b ts_d) seg_dec_num d_model -> b ts_d seg_dec_num d_model', b=batch)\n",
    "        layer_predict = self.linear_pred(dec_output)\n",
    "        layer_predict = rearrange(layer_predict, 'b out_d seg_num seg_len -> b (out_d seg_num) seg_len')\n",
    "\n",
    "        return dec_output, layer_predict\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decode_layers = nn.ModuleList(layers)\n",
    "\n",
    "\n",
    "    def forward(self, x, cross):\n",
    "        final_predict = None\n",
    "        i = 0\n",
    "\n",
    "        ts_d = x.shape[1]\n",
    "        for layer in self.decode_layers:\n",
    "            cross_enc = cross[i]\n",
    "            x, layer_predict = layer(x, cross_enc)\n",
    "            if final_predict is None:\n",
    "                final_predict = layer_predict\n",
    "            else:\n",
    "                final_predict = final_predict + layer_predict\n",
    "            i += 1\n",
    "\n",
    "        final_predict = rearrange(final_predict, 'b (out_d seg_num) seg_len -> b (seg_num seg_len) out_d', out_d=ts_d)\n",
    "\n",
    "        return final_predict\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "    \n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "        \n",
    "        \n",
    "class FlattenHead(nn.Module):\n",
    "    def __init__(self, n_vars, nf, target_window, head_dropout=0):\n",
    "        super().__init__()\n",
    "        self.n_vars = n_vars\n",
    "        self.flatten = nn.Flatten(start_dim=-2)\n",
    "        self.linear = nn.Linear(nf, target_window)\n",
    "        self.dropout = nn.Dropout(head_dropout)\n",
    "\n",
    "    def forward(self, x):  # x: [bs x nvars x d_model x patch_num]\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "# Crossformer模型\n",
    "class Crossformer(nn.Module):\n",
    "    def __init__(self, enc_in, seq_len, pred_len, e_layers, d_layers, d_model, \n",
    "                 output_attention, n_heads, d_ff, dropout, factor):\n",
    "        super(Crossformer, self).__init__()\n",
    "        self.enc_in = enc_in\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.seg_len = 12\n",
    "        self.win_size = 2\n",
    "\n",
    "        # The padding operation to handle invisible sgemnet length\n",
    "        self.pad_in_len = math.ceil(1.0 * seq_len / self.seg_len) * self.seg_len\n",
    "        self.pad_out_len = math.ceil(1.0 * pred_len / self.seg_len) * self.seg_len\n",
    "        self.in_seg_num = self.pad_in_len // self.seg_len\n",
    "        self.out_seg_num = math.ceil(self.in_seg_num / (self.win_size ** (e_layers - 1)))\n",
    "        self.head_nf = d_model * self.out_seg_num\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_value_embedding = PatchEmbedding(d_model, self.seg_len, self.seg_len, self.pad_in_len - seq_len, 0)\n",
    "        self.enc_pos_embedding = nn.Parameter(\n",
    "            torch.randn(1, enc_in, self.in_seg_num, d_model))\n",
    "        self.pre_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                scale_block(1 if l is 0 else self.win_size, d_model, n_heads, d_ff, 1, dropout, output_attention, \n",
    "                            self.in_seg_num if l is 0 else math.ceil(self.in_seg_num / self.win_size ** l), factor\n",
    "                            ) for l in range(e_layers)\n",
    "            ]\n",
    "        )\n",
    "        # Decoder\n",
    "        self.dec_pos_embedding = nn.Parameter(\n",
    "            torch.randn(1, enc_in, (self.pad_out_len // self.seg_len), d_model))\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    TwoStageAttentionLayer((self.pad_out_len // self.seg_len), factor, d_model, n_heads, output_attention,\n",
    "                                           d_ff, dropout),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout, output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    self.seg_len,\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    # activation=configs.activation,\n",
    "                )\n",
    "                for l in range(d_layers + 1)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x_enc):\n",
    "        # embedding\n",
    "        x_enc, n_vars = self.enc_value_embedding(x_enc.permute(0, 2, 1))\n",
    "        x_enc = rearrange(x_enc, '(b d) seg_num d_model -> b d seg_num d_model', d = n_vars)\n",
    "        x_enc += self.enc_pos_embedding\n",
    "        x_enc = self.pre_norm(x_enc)\n",
    "        enc_out, attns = self.encoder(x_enc)\n",
    "\n",
    "        dec_in = repeat(self.dec_pos_embedding, 'b ts_d l d -> (repeat b) ts_d l d', repeat=x_enc.shape[0])\n",
    "        dec_out = self.decoder(dec_in, enc_out)\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f0c58",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "197350b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:58:45.598971Z",
     "start_time": "2024-04-12T08:58:45.533102Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c271620a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:09:58.467365Z",
     "start_time": "2024-04-12T08:59:28.093201Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:31<09:58, 31.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0158, Validation Loss: 0.0110\n",
      "Validation loss decreased (inf --> 0.011013).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [01:01<09:13, 30.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0057, Validation Loss: 0.0074\n",
      "Validation loss decreased (0.011013 --> 0.007376).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [01:32<08:39, 30.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0042, Validation Loss: 0.0044\n",
      "Validation loss decreased (0.007376 --> 0.004405).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [02:02<08:09, 30.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0033, Validation Loss: 0.0037\n",
      "Validation loss decreased (0.004405 --> 0.003723).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [02:33<07:37, 30.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0028, Validation Loss: 0.0042\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [03:04<07:10, 30.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0025, Validation Loss: 0.0033\n",
      "Validation loss decreased (0.003723 --> 0.003262).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████                                                      | 7/20 [03:36<06:44, 31.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0023, Validation Loss: 0.0044\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [04:07<06:13, 31.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0021, Validation Loss: 0.0032\n",
      "Validation loss decreased (0.003262 --> 0.003217).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [04:38<05:42, 31.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0019, Validation Loss: 0.0033\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [05:09<05:12, 31.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0018, Validation Loss: 0.0031\n",
      "Validation loss decreased (0.003217 --> 0.003125).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [05:41<04:41, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0017, Validation Loss: 0.0037\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [06:14<04:14, 31.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0016, Validation Loss: 0.0044\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [06:46<03:42, 31.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0015, Validation Loss: 0.0031\n",
      "Validation loss decreased (0.003125 --> 0.003071).  Saving model ...\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [07:16<03:08, 31.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0014, Validation Loss: 0.0037\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [07:48<02:37, 31.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0014, Validation Loss: 0.0033\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 0.00014644660940672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [08:19<02:05, 31.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0013, Validation Loss: 0.0029\n",
      "Validation loss decreased (0.003071 --> 0.002893).  Saving model ...\n",
      "Updating learning rate to 9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [08:51<01:34, 31.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0013, Validation Loss: 0.0032\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 5.449673790581611e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [09:24<01:03, 31.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0013, Validation Loss: 0.0031\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [09:57<00:32, 32.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0012, Validation Loss: 0.0031\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Updating learning rate to 6.15582970243117e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [10:29<00:00, 31.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0012, Validation Loss: 0.0030\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Updating learning rate to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load'],\n",
    "        \"features\": 'MS'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Crossformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 7,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 2 * 3,\n",
    "        'pred_len': 3,\n",
    "        'output_attention': False,\n",
    "        'd_model': 32,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 32,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'factor': 3\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795bcea",
   "metadata": {},
   "source": [
    "# 基于ETSformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b3b4c",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f458f952",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea9a8c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T03:41:30.499387Z",
     "start_time": "2024-04-13T03:41:30.492105Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2b06190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T03:41:31.277545Z",
     "start_time": "2024-04-13T03:41:31.211248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d134ab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T03:41:32.713224Z",
     "start_time": "2024-04-13T03:41:32.704391Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5e38278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T03:41:39.627716Z",
     "start_time": "2024-04-13T03:41:39.600504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 1)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 1)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 1)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\"],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8620e43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T03:41:40.787112Z",
     "start_time": "2024-04-13T03:41:40.780792Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd9450fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T03:41:42.308039Z",
     "start_time": "2024-04-13T03:41:41.884289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 1]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51480be9",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86260892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T03:41:44.288456Z",
     "start_time": "2024-04-13T03:41:44.224524Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# 编码器和解码器\n",
    "class Transform:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def transform(self, x):\n",
    "        return self.jitter(self.shift(self.scale(x)))\n",
    "\n",
    "    def jitter(self, x):\n",
    "        return x + (torch.randn(x.shape).to(x.device) * self.sigma)\n",
    "\n",
    "    def scale(self, x):\n",
    "        return x * (torch.randn(x.size(-1)).to(x.device) * self.sigma + 1)\n",
    "\n",
    "    def shift(self, x):\n",
    "        return x + (torch.randn(x.size(-1)).to(x.device) * self.sigma)\n",
    "\n",
    "\n",
    "def conv1d_fft(f, g, dim=-1):\n",
    "    N = f.size(dim)\n",
    "    M = g.size(dim)\n",
    "\n",
    "    fast_len = next_fast_len(N + M - 1)\n",
    "\n",
    "    F_f = fft.rfft(f, fast_len, dim=dim)\n",
    "    F_g = fft.rfft(g, fast_len, dim=dim)\n",
    "\n",
    "    F_fg = F_f * F_g.conj()\n",
    "    out = fft.irfft(F_fg, fast_len, dim=dim)\n",
    "    out = out.roll((-1,), dims=(dim,))\n",
    "    idx = torch.as_tensor(range(fast_len - N, fast_len)).to(out.device)\n",
    "    out = out.index_select(dim, idx)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class ExponentialSmoothing(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, nhead, dropout=0.1, aux=False):\n",
    "        super().__init__()\n",
    "        self._smoothing_weight = nn.Parameter(torch.randn(nhead, 1))\n",
    "        self.v0 = nn.Parameter(torch.randn(1, 1, nhead, dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if aux:\n",
    "            self.aux_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, values, aux_values=None):\n",
    "        b, t, h, d = values.shape\n",
    "\n",
    "        init_weight, weight = self.get_exponential_weight(t)\n",
    "        output = conv1d_fft(self.dropout(values), weight, dim=1)\n",
    "        output = init_weight * self.v0 + output\n",
    "\n",
    "        if aux_values is not None:\n",
    "            aux_weight = weight / (1 - self.weight) * self.weight\n",
    "            aux_output = conv1d_fft(self.aux_dropout(aux_values), aux_weight)\n",
    "            output = output + aux_output\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_exponential_weight(self, T):\n",
    "        # Generate array [0, 1, ..., T-1]\n",
    "        powers = torch.arange(T, dtype=torch.float, device=self.weight.device)\n",
    "\n",
    "        # (1 - \\alpha) * \\alpha^t, for all t = T-1, T-2, ..., 0]\n",
    "        weight = (1 - self.weight) * (self.weight ** torch.flip(powers, dims=(0,)))\n",
    "\n",
    "        # \\alpha^t for all t = 1, 2, ..., T\n",
    "        init_weight = self.weight ** (powers + 1)\n",
    "\n",
    "        return rearrange(init_weight, 'h t -> 1 t h 1'), \\\n",
    "               rearrange(weight, 'h t -> 1 t h 1')\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return torch.sigmoid(self._smoothing_weight)\n",
    "\n",
    "\n",
    "class Feedforward(nn.Module):\n",
    "    def __init__(self, d_model, dim_feedforward, dropout=0.1, activation='sigmoid'):\n",
    "        # Implementation of Feedforward model\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward, bias=False)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model, bias=False)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = getattr(F, activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear2(self.dropout1(self.activation(self.linear1(x))))\n",
    "        return self.dropout2(x)\n",
    "\n",
    "\n",
    "class GrowthLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, d_head=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head or (d_model // nhead)\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "\n",
    "        self.z0 = nn.Parameter(torch.randn(self.nhead, self.d_head))\n",
    "        self.in_proj = nn.Linear(self.d_model, self.d_head * self.nhead)\n",
    "        self.es = ExponentialSmoothing(self.d_head, self.nhead, dropout=dropout)\n",
    "        self.out_proj = nn.Linear(self.d_head * self.nhead, self.d_model)\n",
    "\n",
    "        assert self.d_head * self.nhead == self.d_model, \"d_model must be divisible by nhead\"\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        :param inputs: shape: (batch, seq_len, dim)\n",
    "        :return: shape: (batch, seq_len, dim)\n",
    "        \"\"\"\n",
    "        b, t, d = inputs.shape\n",
    "        values = self.in_proj(inputs).view(b, t, self.nhead, -1)\n",
    "        values = torch.cat([repeat(self.z0, 'h d -> b 1 h d', b=b), values], dim=1)\n",
    "        values = values[:, 1:] - values[:, :-1]\n",
    "        out = self.es(values)\n",
    "        out = torch.cat([repeat(self.es.v0, '1 1 h d -> b 1 h d', b=b), out], dim=1)\n",
    "        out = rearrange(out, 'b t h d -> b t (h d)')\n",
    "        return self.out_proj(out)\n",
    "\n",
    "\n",
    "class FourierLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, pred_len, k=None, low_freq=1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pred_len = pred_len\n",
    "        self.k = k\n",
    "        self.low_freq = low_freq\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: (b, t, d)\"\"\"\n",
    "        b, t, d = x.shape\n",
    "        x_freq = fft.rfft(x, dim=1)\n",
    "\n",
    "        if t % 2 == 0:\n",
    "            x_freq = x_freq[:, self.low_freq:-1]\n",
    "            f = fft.rfftfreq(t)[self.low_freq:-1]\n",
    "        else:\n",
    "            x_freq = x_freq[:, self.low_freq:]\n",
    "            f = fft.rfftfreq(t)[self.low_freq:]\n",
    "\n",
    "        x_freq, index_tuple = self.topk_freq(x_freq)\n",
    "        f = repeat(f, 'f -> b f d', b=x_freq.size(0), d=x_freq.size(2))\n",
    "        f = rearrange(f[index_tuple], 'b f d -> b f () d').to(x_freq.device)\n",
    "\n",
    "        return self.extrapolate(x_freq, f, t)\n",
    "\n",
    "    def extrapolate(self, x_freq, f, t):\n",
    "        x_freq = torch.cat([x_freq, x_freq.conj()], dim=1)\n",
    "        f = torch.cat([f, -f], dim=1)\n",
    "        t_val = rearrange(torch.arange(t + self.pred_len, dtype=torch.float),\n",
    "                          't -> () () t ()').to(x_freq.device)\n",
    "\n",
    "        amp = rearrange(x_freq.abs() / t, 'b f d -> b f () d')\n",
    "        phase = rearrange(x_freq.angle(), 'b f d -> b f () d')\n",
    "\n",
    "        x_time = amp * torch.cos(2 * math.pi * f * t_val + phase)\n",
    "\n",
    "        return reduce(x_time, 'b f t d -> b t d', 'sum')\n",
    "\n",
    "    def topk_freq(self, x_freq):\n",
    "        values, indices = torch.topk(x_freq.abs(), self.k, dim=1, largest=True, sorted=True)\n",
    "        mesh_a, mesh_b = torch.meshgrid(torch.arange(x_freq.size(0)), torch.arange(x_freq.size(2)))\n",
    "        index_tuple = (mesh_a.unsqueeze(1), indices, mesh_b.unsqueeze(1))\n",
    "        x_freq = x_freq[index_tuple]\n",
    "\n",
    "        return x_freq, index_tuple\n",
    "\n",
    "\n",
    "class LevelLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, c_out, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.c_out = c_out\n",
    "\n",
    "        self.es = ExponentialSmoothing(1, self.c_out, dropout=dropout, aux=True)\n",
    "        self.growth_pred = nn.Linear(self.d_model, self.c_out)\n",
    "        self.season_pred = nn.Linear(self.d_model, self.c_out)\n",
    "\n",
    "    def forward(self, level, growth, season):\n",
    "        b, t, _ = level.shape\n",
    "        growth = self.growth_pred(growth).view(b, t, self.c_out, 1)\n",
    "        season = self.season_pred(season).view(b, t, self.c_out, 1)\n",
    "        growth = growth.view(b, t, self.c_out, 1)\n",
    "        season = season.view(b, t, self.c_out, 1)\n",
    "        level = level.view(b, t, self.c_out, 1)\n",
    "        out = self.es(level - season, aux_values=growth)\n",
    "        out = rearrange(out, 'b t h d -> b t (h d)')\n",
    "        return out\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, c_out, seq_len, pred_len, k, dim_feedforward=None, dropout=0.1,\n",
    "                 activation='sigmoid', layer_norm_eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.c_out = c_out\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        dim_feedforward = dim_feedforward or 4 * d_model\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.growth_layer = GrowthLayer(d_model, nhead, dropout=dropout)\n",
    "        self.seasonal_layer = FourierLayer(d_model, pred_len, k=k)\n",
    "        self.level_layer = LevelLayer(d_model, c_out, dropout=dropout)\n",
    "\n",
    "        # Implementation of Feedforward model\n",
    "        self.ff = Feedforward(d_model, dim_feedforward, dropout=dropout, activation=activation)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, res, level, attn_mask=None):\n",
    "        season = self._season_block(res)\n",
    "        res = res - season[:, :-self.pred_len]\n",
    "        growth = self._growth_block(res)\n",
    "        res = self.norm1(res - growth[:, 1:])\n",
    "        res = self.norm2(res + self.ff(res))\n",
    "\n",
    "        level = self.level_layer(level, growth[:, :-1], season[:, :-self.pred_len])\n",
    "        return res, level, growth, season\n",
    "\n",
    "    def _growth_block(self, x):\n",
    "        x = self.growth_layer(x)\n",
    "        return self.dropout1(x)\n",
    "\n",
    "    def _season_block(self, x):\n",
    "        x = self.seasonal_layer(x)\n",
    "        return self.dropout2(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, res, level, attn_mask=None):\n",
    "        growths = []\n",
    "        seasons = []\n",
    "        for layer in self.layers:\n",
    "            res, level, growth, season = layer(res, level, attn_mask=None)\n",
    "            growths.append(growth)\n",
    "            seasons.append(season)\n",
    "\n",
    "        return level, growths, seasons\n",
    "\n",
    "\n",
    "class DampingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, pred_len, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.nhead = nhead\n",
    "        self._damping_factor = nn.Parameter(torch.randn(1, nhead))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = repeat(x, 'b 1 d -> b t d', t=self.pred_len)\n",
    "        b, t, d = x.shape\n",
    "\n",
    "        powers = torch.arange(self.pred_len).to(self._damping_factor.device) + 1\n",
    "        powers = powers.view(self.pred_len, 1)\n",
    "        damping_factors = self.damping_factor ** powers\n",
    "        damping_factors = damping_factors.cumsum(dim=0)\n",
    "        x = x.view(b, t, self.nhead, -1)\n",
    "        x = self.dropout(x) * damping_factors.unsqueeze(-1)\n",
    "        return x.view(b, t, d)\n",
    "\n",
    "    @property\n",
    "    def damping_factor(self):\n",
    "        return torch.sigmoid(self._damping_factor)\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, c_out, pred_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.c_out = c_out\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        self.growth_damping = DampingLayer(pred_len, nhead, dropout=dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, growth, season):\n",
    "        growth_horizon = self.growth_damping(growth[:, -1:])\n",
    "        growth_horizon = self.dropout1(growth_horizon)\n",
    "\n",
    "        seasonal_horizon = season[:, -self.pred_len:]\n",
    "        return growth_horizon, seasonal_horizon\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.d_model = layers[0].d_model\n",
    "        self.c_out = layers[0].c_out\n",
    "        self.pred_len = layers[0].pred_len\n",
    "        self.nhead = layers[0].nhead\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.pred = nn.Linear(self.d_model, self.c_out)\n",
    "\n",
    "    def forward(self, growths, seasons):\n",
    "        growth_repr = []\n",
    "        season_repr = []\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            growth_horizon, season_horizon = layer(growths[idx], seasons[idx])\n",
    "            growth_repr.append(growth_horizon)\n",
    "            season_repr.append(season_horizon)\n",
    "        growth_repr = sum(growth_repr)\n",
    "        season_repr = sum(season_repr)\n",
    "        return self.pred(growth_repr), self.pred(season_repr)\n",
    "\n",
    "    \n",
    "# ETSformer模型\n",
    "class ETSformer(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, e_layers, d_layers, enc_in, d_model, \n",
    "                 dropout, n_heads, top_k, d_ff, c_out):\n",
    "        super(ETSformer, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        assert e_layers == d_layers, \"Encoder and decoder layers must be equal\"\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    d_model, n_heads, enc_in, seq_len, pred_len, top_k,\n",
    "                    dim_feedforward=d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                ) for _ in range(e_layers)\n",
    "            ]\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    d_model, n_heads, c_out, pred_len,\n",
    "                    dropout=dropout,\n",
    "                ) for _ in range(d_layers)\n",
    "            ],\n",
    "        )\n",
    "        self.transform = Transform(sigma=0.2)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc=None):\n",
    "        with torch.no_grad():\n",
    "            if self.training:\n",
    "                x_enc = self.transform.transform(x_enc)\n",
    "#         x_enc = self.transform.transform(x_enc)\n",
    "        res = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        level, growths, seasons = self.encoder(res, x_enc, attn_mask=None)\n",
    "\n",
    "        growth, season = self.decoder(growths, seasons)\n",
    "        dec_out = level[:, -1:] + growth + season\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e272698",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "829705a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T03:41:46.418499Z",
     "start_time": "2024-04-13T03:41:46.394923Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0801446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T03:47:27.657391Z",
     "start_time": "2024-04-13T03:41:59.792503Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:30<09:36, 30.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0563, Validation Loss: 0.0322\n",
      "Validation loss decreased (inf --> 0.032186).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [01:02<09:20, 31.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0354, Validation Loss: 0.0269\n",
      "Validation loss decreased (0.032186 --> 0.026853).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [01:31<08:36, 30.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0338, Validation Loss: 0.0271\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [02:00<07:59, 29.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0329, Validation Loss: 0.0220\n",
      "Validation loss decreased (0.026853 --> 0.021952).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [02:29<07:19, 29.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0321, Validation Loss: 0.0255\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [02:59<06:53, 29.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0315, Validation Loss: 0.0264\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████                                                      | 7/20 [03:29<06:27, 29.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0310, Validation Loss: 0.0254\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [04:00<06:01, 30.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0299, Validation Loss: 0.0318\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [04:29<05:29, 29.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0302, Validation Loss: 0.0264\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [04:58<04:56, 29.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0295, Validation Loss: 0.0286\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [05:27<05:27, 32.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0291, Validation Loss: 0.0276\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load'],\n",
    "        \"features\": 'MS'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": ETSformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 7,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 2 * 3,\n",
    "        'pred_len': 3,\n",
    "        'top_k': 2,\n",
    "        'd_model': 128,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'c_out': 1\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e78031",
   "metadata": {},
   "source": [
    "# 基于FEDformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59e8f4",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd9834",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3077c42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T04:56:34.412183Z",
     "start_time": "2024-04-13T04:56:34.405489Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19668802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T04:56:35.414899Z",
     "start_time": "2024-04-13T04:56:35.362963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aba21a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T04:56:36.464298Z",
     "start_time": "2024-04-13T04:56:36.455763Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2f92385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T04:56:37.575909Z",
     "start_time": "2024-04-13T04:56:37.552534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 1)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 1)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 1)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\"],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08234d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T04:56:38.577927Z",
     "start_time": "2024-04-13T04:56:38.572475Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e299e35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T04:56:40.225119Z",
     "start_time": "2024-04-13T04:56:39.821508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 1]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920fcf1e",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "404f30a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:03:38.240783Z",
     "start_time": "2024-04-13T05:03:37.817788Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# AutoCorrelationLayer类\n",
    "class AutoCorrelation(nn.Module):\n",
    "    \"\"\"\n",
    "    AutoCorrelation Mechanism with the following two phases:\n",
    "    (1) period-based dependencies discovery\n",
    "    (2) time delay aggregation\n",
    "    This block can replace the self-attention family mechanism seamlessly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_flag=True, factor=1, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(AutoCorrelation, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def time_delay_agg_training(self, values, corr):\n",
    "        \"\"\"\n",
    "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
    "        This is for the training phase.\n",
    "        \"\"\"\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
    "        index = torch.topk(torch.mean(mean_value, dim=0), top_k, dim=-1)[1]\n",
    "        weights = torch.stack([mean_value[:, index[i]] for i in range(top_k)], dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            pattern = torch.roll(tmp_values, -int(index[i]), -1)\n",
    "            delays_agg = delays_agg + pattern * \\\n",
    "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
    "        return delays_agg\n",
    "\n",
    "    def time_delay_agg_inference(self, values, corr):\n",
    "        \"\"\"\n",
    "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
    "        This is for the inference phase.\n",
    "        \"\"\"\n",
    "        batch = values.shape[0]\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # index init\n",
    "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0).repeat(batch, head, channel, 1).cuda()\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
    "        weights, delay = torch.topk(mean_value, top_k, dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values.repeat(1, 1, 1, 2)\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            tmp_delay = init_index + delay[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length)\n",
    "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
    "            delays_agg = delays_agg + pattern * \\\n",
    "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
    "        return delays_agg\n",
    "\n",
    "    def time_delay_agg_full(self, values, corr):\n",
    "        \"\"\"\n",
    "        Standard version of Autocorrelation\n",
    "        \"\"\"\n",
    "        batch = values.shape[0]\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # index init\n",
    "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0).repeat(batch, head, channel, 1).cuda()\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        weights, delay = torch.topk(corr, top_k, dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values.repeat(1, 1, 1, 2)\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            tmp_delay = init_index + delay[..., i].unsqueeze(-1)\n",
    "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
    "            delays_agg = delays_agg + pattern * (tmp_corr[..., i].unsqueeze(-1))\n",
    "        return delays_agg\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        if L > S:\n",
    "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
    "            values = torch.cat([values, zeros], dim=1)\n",
    "            keys = torch.cat([keys, zeros], dim=1)\n",
    "        else:\n",
    "            values = values[:, :L, :, :]\n",
    "            keys = keys[:, :L, :, :]\n",
    "\n",
    "        # period-based dependencies\n",
    "        q_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "        k_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "        res = q_fft * torch.conj(k_fft)\n",
    "        corr = torch.fft.irfft(res, dim=-1)\n",
    "\n",
    "        # time delay agg\n",
    "        if self.training:\n",
    "            V = self.time_delay_agg_training(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
    "        else:\n",
    "            V = self.time_delay_agg_inference(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), corr.permute(0, 3, 1, 2))\n",
    "        else:\n",
    "            return (V.contiguous(), None)\n",
    "\n",
    "\n",
    "class AutoCorrelationLayer(nn.Module):\n",
    "    def __init__(self, correlation, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AutoCorrelationLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_correlation = correlation\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_correlation(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "# 傅里叶层\n",
    "def get_frequency_modes(seq_len, modes=64, mode_select_method='random'):\n",
    "    \"\"\"\n",
    "    get modes on frequency domain:\n",
    "    'random' means sampling randomly;\n",
    "    'else' means sampling the lowest modes;\n",
    "    \"\"\"\n",
    "    modes = min(modes, seq_len // 2)\n",
    "    if mode_select_method == 'random':\n",
    "        index = list(range(0, seq_len // 2))\n",
    "        np.random.shuffle(index)\n",
    "        index = index[:modes]\n",
    "    else:\n",
    "        index = list(range(0, modes))\n",
    "    index.sort()\n",
    "    return index\n",
    "\n",
    "\n",
    "# ########## fourier layer #############\n",
    "class FourierBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, seq_len, modes=0, mode_select_method='random'):\n",
    "        super(FourierBlock, self).__init__()\n",
    "        print('fourier enhanced block used!')\n",
    "        \"\"\"\n",
    "        1D Fourier block. It performs representation learning on frequency domain, \n",
    "        it does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "        # get modes on frequency domain\n",
    "        self.index = get_frequency_modes(seq_len, modes=modes, mode_select_method=mode_select_method)\n",
    "        print('modes={}, index={}'.format(modes, self.index))\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(\n",
    "            self.scale * torch.rand(8, in_channels // 8, out_channels // 8, len(self.index), dtype=torch.float))\n",
    "        self.weights2 = nn.Parameter(\n",
    "            self.scale * torch.rand(8, in_channels // 8, out_channels // 8, len(self.index), dtype=torch.float))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul1d(self, order, x, weights):\n",
    "        x_flag = True\n",
    "        w_flag = True\n",
    "        if not torch.is_complex(x):\n",
    "            x_flag = False\n",
    "            x = torch.complex(x, torch.zeros_like(x).to(x.device))\n",
    "        if not torch.is_complex(weights):\n",
    "            w_flag = False\n",
    "            weights = torch.complex(weights, torch.zeros_like(weights).to(weights.device))\n",
    "        if x_flag or w_flag:\n",
    "            return torch.complex(torch.einsum(order, x.real, weights.real) - torch.einsum(order, x.imag, weights.imag),\n",
    "                                 torch.einsum(order, x.real, weights.imag) + torch.einsum(order, x.imag, weights.real))\n",
    "        else:\n",
    "            return torch.einsum(order, x.real, weights.real)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # size = [B, L, H, E]\n",
    "        B, L, H, E = q.shape\n",
    "        x = q.permute(0, 2, 3, 1)\n",
    "        # Compute Fourier coefficients\n",
    "        x_ft = torch.fft.rfft(x, dim=-1)\n",
    "        # Perform Fourier neural operations\n",
    "        out_ft = torch.zeros(B, H, E, L // 2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        for wi, i in enumerate(self.index):\n",
    "            if i >= x_ft.shape[3] or wi >= out_ft.shape[3]:\n",
    "                continue\n",
    "            out_ft[:, :, :, wi] = self.compl_mul1d(\"bhi,hio->bho\", x_ft[:, :, :, i],\n",
    "                                                   torch.complex(self.weights1, self.weights2)[:, :, :, wi])\n",
    "        # Return to time domain\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return (x, None)\n",
    "\n",
    "\n",
    "# ########## Fourier Cross Former ####################\n",
    "class FourierCrossAttention(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, seq_len_q, seq_len_kv, modes=64, mode_select_method='random',\n",
    "                 activation='tanh', policy=0, num_heads=8):\n",
    "        super(FourierCrossAttention, self).__init__()\n",
    "        print('fourier enhanced cross attention used!')\n",
    "        \"\"\"\n",
    "        1D Fourier Cross Attention layer. It does FFT, linear transform, attention mechanism and Inverse FFT.    \n",
    "        \"\"\"\n",
    "        self.activation = activation\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        # get modes for queries and keys (& values) on frequency domain\n",
    "        self.index_q = get_frequency_modes(seq_len_q, modes=modes, mode_select_method=mode_select_method)\n",
    "        self.index_kv = get_frequency_modes(seq_len_kv, modes=modes, mode_select_method=mode_select_method)\n",
    "\n",
    "        print('modes_q={}, index_q={}'.format(len(self.index_q), self.index_q))\n",
    "        print('modes_kv={}, index_kv={}'.format(len(self.index_kv), self.index_kv))\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(\n",
    "            self.scale * torch.rand(num_heads, in_channels // num_heads, out_channels // num_heads, len(self.index_q), dtype=torch.float))\n",
    "        self.weights2 = nn.Parameter(\n",
    "            self.scale * torch.rand(num_heads, in_channels // num_heads, out_channels // num_heads, len(self.index_q), dtype=torch.float))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul1d(self, order, x, weights):\n",
    "        x_flag = True\n",
    "        w_flag = True\n",
    "        if not torch.is_complex(x):\n",
    "            x_flag = False\n",
    "            x = torch.complex(x, torch.zeros_like(x).to(x.device))\n",
    "        if not torch.is_complex(weights):\n",
    "            w_flag = False\n",
    "            weights = torch.complex(weights, torch.zeros_like(weights).to(weights.device))\n",
    "        if x_flag or w_flag:\n",
    "            return torch.complex(torch.einsum(order, x.real, weights.real) - torch.einsum(order, x.imag, weights.imag),\n",
    "                                 torch.einsum(order, x.real, weights.imag) + torch.einsum(order, x.imag, weights.real))\n",
    "        else:\n",
    "            return torch.einsum(order, x.real, weights.real)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # size = [B, L, H, E]\n",
    "        B, L, H, E = q.shape\n",
    "        xq = q.permute(0, 2, 3, 1)  # size = [B, H, E, L]\n",
    "        xk = k.permute(0, 2, 3, 1)\n",
    "        xv = v.permute(0, 2, 3, 1)\n",
    "\n",
    "        # Compute Fourier coefficients\n",
    "        xq_ft_ = torch.zeros(B, H, E, len(self.index_q), device=xq.device, dtype=torch.cfloat)\n",
    "        xq_ft = torch.fft.rfft(xq, dim=-1)\n",
    "        for i, j in enumerate(self.index_q):\n",
    "            if j >= xq_ft.shape[3]:\n",
    "                continue\n",
    "            xq_ft_[:, :, :, i] = xq_ft[:, :, :, j]\n",
    "        xk_ft_ = torch.zeros(B, H, E, len(self.index_kv), device=xq.device, dtype=torch.cfloat)\n",
    "        xk_ft = torch.fft.rfft(xk, dim=-1)\n",
    "        for i, j in enumerate(self.index_kv):\n",
    "            if j >= xk_ft.shape[3]:\n",
    "                continue\n",
    "            xk_ft_[:, :, :, i] = xk_ft[:, :, :, j]\n",
    "\n",
    "        # perform attention mechanism on frequency domain\n",
    "        xqk_ft = (self.compl_mul1d(\"bhex,bhey->bhxy\", xq_ft_, xk_ft_))\n",
    "        if self.activation == 'tanh':\n",
    "            xqk_ft = torch.complex(xqk_ft.real.tanh(), xqk_ft.imag.tanh())\n",
    "        elif self.activation == 'softmax':\n",
    "            xqk_ft = torch.softmax(abs(xqk_ft), dim=-1)\n",
    "            xqk_ft = torch.complex(xqk_ft, torch.zeros_like(xqk_ft))\n",
    "        else:\n",
    "            raise Exception('{} actiation function is not implemented'.format(self.activation))\n",
    "        xqkv_ft = self.compl_mul1d(\"bhxy,bhey->bhex\", xqk_ft, xk_ft_)\n",
    "        xqkvw = self.compl_mul1d(\"bhex,heox->bhox\", xqkv_ft, torch.complex(self.weights1, self.weights2))\n",
    "        out_ft = torch.zeros(B, H, E, L // 2 + 1, device=xq.device, dtype=torch.cfloat)\n",
    "        for i, j in enumerate(self.index_q):\n",
    "            if i >= xqkvw.shape[3] or j >= out_ft.shape[3]:\n",
    "                continue\n",
    "            out_ft[:, :, :, j] = xqkvw[:, :, :, i]\n",
    "        # Return to time domain\n",
    "        out = torch.fft.irfft(out_ft / self.in_channels / self.out_channels, n=xq.size(-1))\n",
    "        return (out, None)\n",
    "    \n",
    "\n",
    "# MultiWaveletCorrelation类\n",
    "def legendreDer(k, x):\n",
    "    def _legendre(k, x):\n",
    "        return (2 * k + 1) * eval_legendre(k, x)\n",
    "\n",
    "    out = 0\n",
    "    for i in np.arange(k - 1, -1, -2):\n",
    "        out += _legendre(i, x)\n",
    "    return out\n",
    "\n",
    "\n",
    "def phi_(phi_c, x, lb=0, ub=1):\n",
    "    mask = np.logical_or(x < lb, x > ub) * 1.0\n",
    "    return np.polynomial.polynomial.Polynomial(phi_c)(x) * (1 - mask)\n",
    "\n",
    "\n",
    "def get_phi_psi(k, base):\n",
    "    x = Symbol('x')\n",
    "    phi_coeff = np.zeros((k, k))\n",
    "    phi_2x_coeff = np.zeros((k, k))\n",
    "    if base == 'legendre':\n",
    "        for ki in range(k):\n",
    "            coeff_ = Poly(legendre(ki, 2 * x - 1), x).all_coeffs()\n",
    "            phi_coeff[ki, :ki + 1] = np.flip(np.sqrt(2 * ki + 1) * np.array(coeff_).astype(np.float64))\n",
    "            coeff_ = Poly(legendre(ki, 4 * x - 1), x).all_coeffs()\n",
    "            phi_2x_coeff[ki, :ki + 1] = np.flip(np.sqrt(2) * np.sqrt(2 * ki + 1) * np.array(coeff_).astype(np.float64))\n",
    "\n",
    "        psi1_coeff = np.zeros((k, k))\n",
    "        psi2_coeff = np.zeros((k, k))\n",
    "        for ki in range(k):\n",
    "            psi1_coeff[ki, :] = phi_2x_coeff[ki, :]\n",
    "            for i in range(k):\n",
    "                a = phi_2x_coeff[ki, :ki + 1]\n",
    "                b = phi_coeff[i, :i + 1]\n",
    "                prod_ = np.convolve(a, b)\n",
    "                prod_[np.abs(prod_) < 1e-8] = 0\n",
    "                proj_ = (prod_ * 1 / (np.arange(len(prod_)) + 1) * np.power(0.5, 1 + np.arange(len(prod_)))).sum()\n",
    "                psi1_coeff[ki, :] -= proj_ * phi_coeff[i, :]\n",
    "                psi2_coeff[ki, :] -= proj_ * phi_coeff[i, :]\n",
    "            for j in range(ki):\n",
    "                a = phi_2x_coeff[ki, :ki + 1]\n",
    "                b = psi1_coeff[j, :]\n",
    "                prod_ = np.convolve(a, b)\n",
    "                prod_[np.abs(prod_) < 1e-8] = 0\n",
    "                proj_ = (prod_ * 1 / (np.arange(len(prod_)) + 1) * np.power(0.5, 1 + np.arange(len(prod_)))).sum()\n",
    "                psi1_coeff[ki, :] -= proj_ * psi1_coeff[j, :]\n",
    "                psi2_coeff[ki, :] -= proj_ * psi2_coeff[j, :]\n",
    "\n",
    "            a = psi1_coeff[ki, :]\n",
    "            prod_ = np.convolve(a, a)\n",
    "            prod_[np.abs(prod_) < 1e-8] = 0\n",
    "            norm1 = (prod_ * 1 / (np.arange(len(prod_)) + 1) * np.power(0.5, 1 + np.arange(len(prod_)))).sum()\n",
    "\n",
    "            a = psi2_coeff[ki, :]\n",
    "            prod_ = np.convolve(a, a)\n",
    "            prod_[np.abs(prod_) < 1e-8] = 0\n",
    "            norm2 = (prod_ * 1 / (np.arange(len(prod_)) + 1) * (1 - np.power(0.5, 1 + np.arange(len(prod_))))).sum()\n",
    "            norm_ = np.sqrt(norm1 + norm2)\n",
    "            psi1_coeff[ki, :] /= norm_\n",
    "            psi2_coeff[ki, :] /= norm_\n",
    "            psi1_coeff[np.abs(psi1_coeff) < 1e-8] = 0\n",
    "            psi2_coeff[np.abs(psi2_coeff) < 1e-8] = 0\n",
    "\n",
    "        phi = [np.poly1d(np.flip(phi_coeff[i, :])) for i in range(k)]\n",
    "        psi1 = [np.poly1d(np.flip(psi1_coeff[i, :])) for i in range(k)]\n",
    "        psi2 = [np.poly1d(np.flip(psi2_coeff[i, :])) for i in range(k)]\n",
    "\n",
    "    elif base == 'chebyshev':\n",
    "        for ki in range(k):\n",
    "            if ki == 0:\n",
    "                phi_coeff[ki, :ki + 1] = np.sqrt(2 / np.pi)\n",
    "                phi_2x_coeff[ki, :ki + 1] = np.sqrt(2 / np.pi) * np.sqrt(2)\n",
    "            else:\n",
    "                coeff_ = Poly(chebyshevt(ki, 2 * x - 1), x).all_coeffs()\n",
    "                phi_coeff[ki, :ki + 1] = np.flip(2 / np.sqrt(np.pi) * np.array(coeff_).astype(np.float64))\n",
    "                coeff_ = Poly(chebyshevt(ki, 4 * x - 1), x).all_coeffs()\n",
    "                phi_2x_coeff[ki, :ki + 1] = np.flip(\n",
    "                    np.sqrt(2) * 2 / np.sqrt(np.pi) * np.array(coeff_).astype(np.float64))\n",
    "\n",
    "        phi = [partial(phi_, phi_coeff[i, :]) for i in range(k)]\n",
    "\n",
    "        x = Symbol('x')\n",
    "        kUse = 2 * k\n",
    "        roots = Poly(chebyshevt(kUse, 2 * x - 1)).all_roots()\n",
    "        x_m = np.array([rt.evalf(20) for rt in roots]).astype(np.float64)\n",
    "        # x_m[x_m==0.5] = 0.5 + 1e-8 # add small noise to avoid the case of 0.5 belonging to both phi(2x) and phi(2x-1)\n",
    "        # not needed for our purpose here, we use even k always to avoid\n",
    "        wm = np.pi / kUse / 2\n",
    "\n",
    "        psi1_coeff = np.zeros((k, k))\n",
    "        psi2_coeff = np.zeros((k, k))\n",
    "\n",
    "        psi1 = [[] for _ in range(k)]\n",
    "        psi2 = [[] for _ in range(k)]\n",
    "\n",
    "        for ki in range(k):\n",
    "            psi1_coeff[ki, :] = phi_2x_coeff[ki, :]\n",
    "            for i in range(k):\n",
    "                proj_ = (wm * phi[i](x_m) * np.sqrt(2) * phi[ki](2 * x_m)).sum()\n",
    "                psi1_coeff[ki, :] -= proj_ * phi_coeff[i, :]\n",
    "                psi2_coeff[ki, :] -= proj_ * phi_coeff[i, :]\n",
    "\n",
    "            for j in range(ki):\n",
    "                proj_ = (wm * psi1[j](x_m) * np.sqrt(2) * phi[ki](2 * x_m)).sum()\n",
    "                psi1_coeff[ki, :] -= proj_ * psi1_coeff[j, :]\n",
    "                psi2_coeff[ki, :] -= proj_ * psi2_coeff[j, :]\n",
    "\n",
    "            psi1[ki] = partial(phi_, psi1_coeff[ki, :], lb=0, ub=0.5)\n",
    "            psi2[ki] = partial(phi_, psi2_coeff[ki, :], lb=0.5, ub=1)\n",
    "\n",
    "            norm1 = (wm * psi1[ki](x_m) * psi1[ki](x_m)).sum()\n",
    "            norm2 = (wm * psi2[ki](x_m) * psi2[ki](x_m)).sum()\n",
    "\n",
    "            norm_ = np.sqrt(norm1 + norm2)\n",
    "            psi1_coeff[ki, :] /= norm_\n",
    "            psi2_coeff[ki, :] /= norm_\n",
    "            psi1_coeff[np.abs(psi1_coeff) < 1e-8] = 0\n",
    "            psi2_coeff[np.abs(psi2_coeff) < 1e-8] = 0\n",
    "\n",
    "            psi1[ki] = partial(phi_, psi1_coeff[ki, :], lb=0, ub=0.5 + 1e-16)\n",
    "            psi2[ki] = partial(phi_, psi2_coeff[ki, :], lb=0.5 + 1e-16, ub=1)\n",
    "\n",
    "    return phi, psi1, psi2\n",
    "\n",
    "\n",
    "def get_filter(base, k):\n",
    "    def psi(psi1, psi2, i, inp):\n",
    "        mask = (inp <= 0.5) * 1.0\n",
    "        return psi1[i](inp) * mask + psi2[i](inp) * (1 - mask)\n",
    "\n",
    "    if base not in ['legendre', 'chebyshev']:\n",
    "        raise Exception('Base not supported')\n",
    "\n",
    "    x = Symbol('x')\n",
    "    H0 = np.zeros((k, k))\n",
    "    H1 = np.zeros((k, k))\n",
    "    G0 = np.zeros((k, k))\n",
    "    G1 = np.zeros((k, k))\n",
    "    PHI0 = np.zeros((k, k))\n",
    "    PHI1 = np.zeros((k, k))\n",
    "    phi, psi1, psi2 = get_phi_psi(k, base)\n",
    "    if base == 'legendre':\n",
    "        roots = Poly(legendre(k, 2 * x - 1)).all_roots()\n",
    "        x_m = np.array([rt.evalf(20) for rt in roots]).astype(np.float64)\n",
    "        wm = 1 / k / legendreDer(k, 2 * x_m - 1) / eval_legendre(k - 1, 2 * x_m - 1)\n",
    "\n",
    "        for ki in range(k):\n",
    "            for kpi in range(k):\n",
    "                H0[ki, kpi] = 1 / np.sqrt(2) * (wm * phi[ki](x_m / 2) * phi[kpi](x_m)).sum()\n",
    "                G0[ki, kpi] = 1 / np.sqrt(2) * (wm * psi(psi1, psi2, ki, x_m / 2) * phi[kpi](x_m)).sum()\n",
    "                H1[ki, kpi] = 1 / np.sqrt(2) * (wm * phi[ki]((x_m + 1) / 2) * phi[kpi](x_m)).sum()\n",
    "                G1[ki, kpi] = 1 / np.sqrt(2) * (wm * psi(psi1, psi2, ki, (x_m + 1) / 2) * phi[kpi](x_m)).sum()\n",
    "\n",
    "        PHI0 = np.eye(k)\n",
    "        PHI1 = np.eye(k)\n",
    "\n",
    "    elif base == 'chebyshev':\n",
    "        x = Symbol('x')\n",
    "        kUse = 2 * k\n",
    "        roots = Poly(chebyshevt(kUse, 2 * x - 1)).all_roots()\n",
    "        x_m = np.array([rt.evalf(20) for rt in roots]).astype(np.float64)\n",
    "        # x_m[x_m==0.5] = 0.5 + 1e-8 # add small noise to avoid the case of 0.5 belonging to both phi(2x) and phi(2x-1)\n",
    "        # not needed for our purpose here, we use even k always to avoid\n",
    "        wm = np.pi / kUse / 2\n",
    "\n",
    "        for ki in range(k):\n",
    "            for kpi in range(k):\n",
    "                H0[ki, kpi] = 1 / np.sqrt(2) * (wm * phi[ki](x_m / 2) * phi[kpi](x_m)).sum()\n",
    "                G0[ki, kpi] = 1 / np.sqrt(2) * (wm * psi(psi1, psi2, ki, x_m / 2) * phi[kpi](x_m)).sum()\n",
    "                H1[ki, kpi] = 1 / np.sqrt(2) * (wm * phi[ki]((x_m + 1) / 2) * phi[kpi](x_m)).sum()\n",
    "                G1[ki, kpi] = 1 / np.sqrt(2) * (wm * psi(psi1, psi2, ki, (x_m + 1) / 2) * phi[kpi](x_m)).sum()\n",
    "\n",
    "                PHI0[ki, kpi] = (wm * phi[ki](2 * x_m) * phi[kpi](2 * x_m)).sum() * 2\n",
    "                PHI1[ki, kpi] = (wm * phi[ki](2 * x_m - 1) * phi[kpi](2 * x_m - 1)).sum() * 2\n",
    "\n",
    "        PHI0[np.abs(PHI0) < 1e-8] = 0\n",
    "        PHI1[np.abs(PHI1) < 1e-8] = 0\n",
    "\n",
    "    H0[np.abs(H0) < 1e-8] = 0\n",
    "    H1[np.abs(H1) < 1e-8] = 0\n",
    "    G0[np.abs(G0) < 1e-8] = 0\n",
    "    G1[np.abs(G1) < 1e-8] = 0\n",
    "\n",
    "    return H0, H1, G0, G1, PHI0, PHI1\n",
    "\n",
    "\n",
    "class MultiWaveletTransform(nn.Module):\n",
    "    \"\"\"\n",
    "    1D multiwavelet block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ich=1, k=8, alpha=16, c=128,\n",
    "                 nCZ=1, L=0, base='legendre', attention_dropout=0.1):\n",
    "        super(MultiWaveletTransform, self).__init__()\n",
    "        print('base', base)\n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.L = L\n",
    "        self.nCZ = nCZ\n",
    "        self.Lk0 = nn.Linear(ich, c * k)\n",
    "        self.Lk1 = nn.Linear(c * k, ich)\n",
    "        self.ich = ich\n",
    "        self.MWT_CZ = nn.ModuleList(MWT_CZ1d(k, alpha, L, c, base) for i in range(nCZ))\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        if L > S:\n",
    "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
    "            values = torch.cat([values, zeros], dim=1)\n",
    "            keys = torch.cat([keys, zeros], dim=1)\n",
    "        else:\n",
    "            values = values[:, :L, :, :]\n",
    "            keys = keys[:, :L, :, :]\n",
    "        values = values.view(B, L, -1)\n",
    "\n",
    "        V = self.Lk0(values).view(B, L, self.c, -1)\n",
    "        for i in range(self.nCZ):\n",
    "            V = self.MWT_CZ[i](V)\n",
    "            if i < self.nCZ - 1:\n",
    "                V = F.relu(V)\n",
    "\n",
    "        V = self.Lk1(V.view(B, L, -1))\n",
    "        V = V.view(B, L, -1, D)\n",
    "        return (V.contiguous(), None)\n",
    "\n",
    "\n",
    "class MultiWaveletCross(nn.Module):\n",
    "    \"\"\"\n",
    "    1D Multiwavelet Cross Attention layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, seq_len_q, seq_len_kv, modes, c=64,\n",
    "                 k=8, ich=512,\n",
    "                 L=0,\n",
    "                 base='legendre',\n",
    "                 mode_select_method='random',\n",
    "                 initializer=None, activation='tanh',\n",
    "                 **kwargs):\n",
    "        super(MultiWaveletCross, self).__init__()\n",
    "        print('base', base)\n",
    "\n",
    "        self.c = c\n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0 @ PHI0\n",
    "        G0r = G0 @ PHI0\n",
    "        H1r = H1 @ PHI1\n",
    "        G1r = G1 @ PHI1\n",
    "\n",
    "        H0r[np.abs(H0r) < 1e-8] = 0\n",
    "        H1r[np.abs(H1r) < 1e-8] = 0\n",
    "        G0r[np.abs(G0r) < 1e-8] = 0\n",
    "        G1r[np.abs(G1r) < 1e-8] = 0\n",
    "        self.max_item = 3\n",
    "\n",
    "        self.attn1 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.attn2 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.attn3 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.attn4 = FourierCrossAttentionW(in_channels=in_channels, out_channels=out_channels, seq_len_q=seq_len_q,\n",
    "                                            seq_len_kv=seq_len_kv, modes=modes, activation=activation,\n",
    "                                            mode_select_method=mode_select_method)\n",
    "        self.T0 = nn.Linear(k, k)\n",
    "        self.register_buffer('ec_s', torch.Tensor(\n",
    "            np.concatenate((H0.T, H1.T), axis=0)))\n",
    "        self.register_buffer('ec_d', torch.Tensor(\n",
    "            np.concatenate((G0.T, G1.T), axis=0)))\n",
    "\n",
    "        self.register_buffer('rc_e', torch.Tensor(\n",
    "            np.concatenate((H0r, G0r), axis=0)))\n",
    "        self.register_buffer('rc_o', torch.Tensor(\n",
    "            np.concatenate((H1r, G1r), axis=0)))\n",
    "\n",
    "        self.Lk = nn.Linear(ich, c * k)\n",
    "        self.Lq = nn.Linear(ich, c * k)\n",
    "        self.Lv = nn.Linear(ich, c * k)\n",
    "        self.out = nn.Linear(c * k, ich)\n",
    "        self.modes1 = modes\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        B, N, H, E = q.shape  # (B, N, H, E) torch.Size([3, 768, 8, 2])\n",
    "        _, S, _, _ = k.shape  # (B, S, H, E) torch.Size([3, 96, 8, 2])\n",
    "\n",
    "        q = q.view(q.shape[0], q.shape[1], -1)\n",
    "        k = k.view(k.shape[0], k.shape[1], -1)\n",
    "        v = v.view(v.shape[0], v.shape[1], -1)\n",
    "        q = self.Lq(q)\n",
    "        q = q.view(q.shape[0], q.shape[1], self.c, self.k)\n",
    "        k = self.Lk(k)\n",
    "        k = k.view(k.shape[0], k.shape[1], self.c, self.k)\n",
    "        v = self.Lv(v)\n",
    "        v = v.view(v.shape[0], v.shape[1], self.c, self.k)\n",
    "\n",
    "        if N > S:\n",
    "            zeros = torch.zeros_like(q[:, :(N - S), :]).float()\n",
    "            v = torch.cat([v, zeros], dim=1)\n",
    "            k = torch.cat([k, zeros], dim=1)\n",
    "        else:\n",
    "            v = v[:, :N, :, :]\n",
    "            k = k[:, :N, :, :]\n",
    "\n",
    "        ns = math.floor(np.log2(N))\n",
    "        nl = pow(2, math.ceil(np.log2(N)))\n",
    "        extra_q = q[:, 0:nl - N, :, :]\n",
    "        extra_k = k[:, 0:nl - N, :, :]\n",
    "        extra_v = v[:, 0:nl - N, :, :]\n",
    "        q = torch.cat([q, extra_q], 1)\n",
    "        k = torch.cat([k, extra_k], 1)\n",
    "        v = torch.cat([v, extra_v], 1)\n",
    "\n",
    "        Ud_q = torch.jit.annotate(List[Tuple[Tensor]], [])\n",
    "        Ud_k = torch.jit.annotate(List[Tuple[Tensor]], [])\n",
    "        Ud_v = torch.jit.annotate(List[Tuple[Tensor]], [])\n",
    "\n",
    "        Us_q = torch.jit.annotate(List[Tensor], [])\n",
    "        Us_k = torch.jit.annotate(List[Tensor], [])\n",
    "        Us_v = torch.jit.annotate(List[Tensor], [])\n",
    "\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "\n",
    "        # decompose\n",
    "        for i in range(ns - self.L):\n",
    "            # print('q shape',q.shape)\n",
    "            d, q = self.wavelet_transform(q)\n",
    "            Ud_q += [tuple([d, q])]\n",
    "            Us_q += [d]\n",
    "        for i in range(ns - self.L):\n",
    "            d, k = self.wavelet_transform(k)\n",
    "            Ud_k += [tuple([d, k])]\n",
    "            Us_k += [d]\n",
    "        for i in range(ns - self.L):\n",
    "            d, v = self.wavelet_transform(v)\n",
    "            Ud_v += [tuple([d, v])]\n",
    "            Us_v += [d]\n",
    "        for i in range(ns - self.L):\n",
    "            dk, sk = Ud_k[i], Us_k[i]\n",
    "            dq, sq = Ud_q[i], Us_q[i]\n",
    "            dv, sv = Ud_v[i], Us_v[i]\n",
    "            Ud += [self.attn1(dq[0], dk[0], dv[0], mask)[0] + self.attn2(dq[1], dk[1], dv[1], mask)[0]]\n",
    "            Us += [self.attn3(sq, sk, sv, mask)[0]]\n",
    "        v = self.attn4(q, k, v, mask)[0]\n",
    "\n",
    "        # reconstruct\n",
    "        for i in range(ns - 1 - self.L, -1, -1):\n",
    "            v = v + Us[i]\n",
    "            v = torch.cat((v, Ud[i]), -1)\n",
    "            v = self.evenOdd(v)\n",
    "        v = self.out(v[:, :N, :, :].contiguous().view(B, N, -1))\n",
    "        return (v.contiguous(), None)\n",
    "\n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat([x[:, ::2, :, :],\n",
    "                        x[:, 1::2, :, :],\n",
    "                        ], -1)\n",
    "        d = torch.matmul(xa, self.ec_d)\n",
    "        s = torch.matmul(xa, self.ec_s)\n",
    "        return d, s\n",
    "\n",
    "    def evenOdd(self, x):\n",
    "        B, N, c, ich = x.shape  # (B, N, c, k)\n",
    "        assert ich == 2 * self.k\n",
    "        x_e = torch.matmul(x, self.rc_e)\n",
    "        x_o = torch.matmul(x, self.rc_o)\n",
    "\n",
    "        x = torch.zeros(B, N * 2, c, self.k,\n",
    "                        device=x.device)\n",
    "        x[..., ::2, :, :] = x_e\n",
    "        x[..., 1::2, :, :] = x_o\n",
    "        return x\n",
    "\n",
    "\n",
    "class FourierCrossAttentionW(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, seq_len_q, seq_len_kv, modes=16, activation='tanh',\n",
    "                 mode_select_method='random'):\n",
    "        super(FourierCrossAttentionW, self).__init__()\n",
    "        print('corss fourier correlation used!')\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes\n",
    "        self.activation = activation\n",
    "\n",
    "    def compl_mul1d(self, order, x, weights):\n",
    "        x_flag = True\n",
    "        w_flag = True\n",
    "        if not torch.is_complex(x):\n",
    "            x_flag = False\n",
    "            x = torch.complex(x, torch.zeros_like(x).to(x.device))\n",
    "        if not torch.is_complex(weights):\n",
    "            w_flag = False\n",
    "            weights = torch.complex(weights, torch.zeros_like(weights).to(weights.device))\n",
    "        if x_flag or w_flag:\n",
    "            return torch.complex(torch.einsum(order, x.real, weights.real) - torch.einsum(order, x.imag, weights.imag),\n",
    "                                 torch.einsum(order, x.real, weights.imag) + torch.einsum(order, x.imag, weights.real))\n",
    "        else:\n",
    "            return torch.einsum(order, x.real, weights.real)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        B, L, E, H = q.shape\n",
    "\n",
    "        xq = q.permute(0, 3, 2, 1)  # size = [B, H, E, L] torch.Size([3, 8, 64, 512])\n",
    "        xk = k.permute(0, 3, 2, 1)\n",
    "        xv = v.permute(0, 3, 2, 1)\n",
    "        self.index_q = list(range(0, min(int(L // 2), self.modes1)))\n",
    "        self.index_k_v = list(range(0, min(int(xv.shape[3] // 2), self.modes1)))\n",
    "\n",
    "        # Compute Fourier coefficients\n",
    "        xq_ft_ = torch.zeros(B, H, E, len(self.index_q), device=xq.device, dtype=torch.cfloat)\n",
    "        xq_ft = torch.fft.rfft(xq, dim=-1)\n",
    "        for i, j in enumerate(self.index_q):\n",
    "            xq_ft_[:, :, :, i] = xq_ft[:, :, :, j]\n",
    "\n",
    "        xk_ft_ = torch.zeros(B, H, E, len(self.index_k_v), device=xq.device, dtype=torch.cfloat)\n",
    "        xk_ft = torch.fft.rfft(xk, dim=-1)\n",
    "        for i, j in enumerate(self.index_k_v):\n",
    "            xk_ft_[:, :, :, i] = xk_ft[:, :, :, j]\n",
    "        xqk_ft = (self.compl_mul1d(\"bhex,bhey->bhxy\", xq_ft_, xk_ft_))\n",
    "        if self.activation == 'tanh':\n",
    "            xqk_ft = torch.complex(xqk_ft.real.tanh(), xqk_ft.imag.tanh())\n",
    "        elif self.activation == 'softmax':\n",
    "            xqk_ft = torch.softmax(abs(xqk_ft), dim=-1)\n",
    "            xqk_ft = torch.complex(xqk_ft, torch.zeros_like(xqk_ft))\n",
    "        else:\n",
    "            raise Exception('{} actiation function is not implemented'.format(self.activation))\n",
    "        xqkv_ft = self.compl_mul1d(\"bhxy,bhey->bhex\", xqk_ft, xk_ft_)\n",
    "\n",
    "        xqkvw = xqkv_ft\n",
    "        out_ft = torch.zeros(B, H, E, L // 2 + 1, device=xq.device, dtype=torch.cfloat)\n",
    "        for i, j in enumerate(self.index_q):\n",
    "            out_ft[:, :, :, j] = xqkvw[:, :, :, i]\n",
    "\n",
    "        out = torch.fft.irfft(out_ft / self.in_channels / self.out_channels, n=xq.size(-1)).permute(0, 3, 2, 1)\n",
    "        # size = [B, L, H, E]\n",
    "        return (out, None)\n",
    "\n",
    "\n",
    "class sparseKernelFT1d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k, alpha, c=1,\n",
    "                 nl=1,\n",
    "                 initializer=None,\n",
    "                 **kwargs):\n",
    "        super(sparseKernelFT1d, self).__init__()\n",
    "\n",
    "        self.modes1 = alpha\n",
    "        self.scale = (1 / (c * k * c * k))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(c * k, c * k, self.modes1, dtype=torch.float))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(c * k, c * k, self.modes1, dtype=torch.float))\n",
    "        self.weights1.requires_grad = True\n",
    "        self.weights2.requires_grad = True\n",
    "        self.k = k\n",
    "\n",
    "    def compl_mul1d(self, order, x, weights):\n",
    "        x_flag = True\n",
    "        w_flag = True\n",
    "        if not torch.is_complex(x):\n",
    "            x_flag = False\n",
    "            x = torch.complex(x, torch.zeros_like(x).to(x.device))\n",
    "        if not torch.is_complex(weights):\n",
    "            w_flag = False\n",
    "            weights = torch.complex(weights, torch.zeros_like(weights).to(weights.device))\n",
    "        if x_flag or w_flag:\n",
    "            return torch.complex(torch.einsum(order, x.real, weights.real) - torch.einsum(order, x.imag, weights.imag),\n",
    "                                 torch.einsum(order, x.real, weights.imag) + torch.einsum(order, x.imag, weights.real))\n",
    "        else:\n",
    "            return torch.einsum(order, x.real, weights.real)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, c, k = x.shape  # (B, N, c, k)\n",
    "\n",
    "        x = x.view(B, N, -1)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x_fft = torch.fft.rfft(x)\n",
    "        # Multiply relevant Fourier modes\n",
    "        l = min(self.modes1, N // 2 + 1)\n",
    "        out_ft = torch.zeros(B, c * k, N // 2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        out_ft[:, :, :l] = self.compl_mul1d(\"bix,iox->box\", x_fft[:, :, :l],\n",
    "                                            torch.complex(self.weights1, self.weights2)[:, :, :l])\n",
    "        x = torch.fft.irfft(out_ft, n=N)\n",
    "        x = x.permute(0, 2, 1).view(B, N, c, k)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ##\n",
    "class MWT_CZ1d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k=3, alpha=64,\n",
    "                 L=0, c=1,\n",
    "                 base='legendre',\n",
    "                 initializer=None,\n",
    "                 **kwargs):\n",
    "        super(MWT_CZ1d, self).__init__()\n",
    "\n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0 @ PHI0\n",
    "        G0r = G0 @ PHI0\n",
    "        H1r = H1 @ PHI1\n",
    "        G1r = G1 @ PHI1\n",
    "\n",
    "        H0r[np.abs(H0r) < 1e-8] = 0\n",
    "        H1r[np.abs(H1r) < 1e-8] = 0\n",
    "        G0r[np.abs(G0r) < 1e-8] = 0\n",
    "        G1r[np.abs(G1r) < 1e-8] = 0\n",
    "        self.max_item = 3\n",
    "\n",
    "        self.A = sparseKernelFT1d(k, alpha, c)\n",
    "        self.B = sparseKernelFT1d(k, alpha, c)\n",
    "        self.C = sparseKernelFT1d(k, alpha, c)\n",
    "\n",
    "        self.T0 = nn.Linear(k, k)\n",
    "\n",
    "        self.register_buffer('ec_s', torch.Tensor(\n",
    "            np.concatenate((H0.T, H1.T), axis=0)))\n",
    "        self.register_buffer('ec_d', torch.Tensor(\n",
    "            np.concatenate((G0.T, G1.T), axis=0)))\n",
    "\n",
    "        self.register_buffer('rc_e', torch.Tensor(\n",
    "            np.concatenate((H0r, G0r), axis=0)))\n",
    "        self.register_buffer('rc_o', torch.Tensor(\n",
    "            np.concatenate((H1r, G1r), axis=0)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, c, k = x.shape  # (B, N, k)\n",
    "        ns = math.floor(np.log2(N))\n",
    "        nl = pow(2, math.ceil(np.log2(N)))\n",
    "        extra_x = x[:, 0:nl - N, :, :]\n",
    "        x = torch.cat([x, extra_x], 1)\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "        for i in range(ns - self.L):\n",
    "            d, x = self.wavelet_transform(x)\n",
    "            Ud += [self.A(d) + self.B(x)]\n",
    "            Us += [self.C(d)]\n",
    "        x = self.T0(x)  # coarsest scale transform\n",
    "\n",
    "        #        reconstruct\n",
    "        for i in range(ns - 1 - self.L, -1, -1):\n",
    "            x = x + Us[i]\n",
    "            x = torch.cat((x, Ud[i]), -1)\n",
    "            x = self.evenOdd(x)\n",
    "        x = x[:, :N, :, :]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat([x[:, ::2, :, :],\n",
    "                        x[:, 1::2, :, :],\n",
    "                        ], -1)\n",
    "        d = torch.matmul(xa, self.ec_d)\n",
    "        s = torch.matmul(xa, self.ec_s)\n",
    "        return d, s\n",
    "\n",
    "    def evenOdd(self, x):\n",
    "\n",
    "        B, N, c, ich = x.shape  # (B, N, c, k)\n",
    "        assert ich == 2 * self.k\n",
    "        x_e = torch.matmul(x, self.rc_e)\n",
    "        x_o = torch.matmul(x, self.rc_o)\n",
    "\n",
    "        x = torch.zeros(B, N * 2, c, self.k,\n",
    "                        device=x.device)\n",
    "        x[..., ::2, :, :] = x_e\n",
    "        x[..., 1::2, :, :] = x_o\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "# Autoformer_EncDec类\n",
    "class my_Layernorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Special designed layernorm for the seasonal part\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super(my_Layernorm, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_hat = self.layernorm(x)\n",
    "        bias = torch.mean(x_hat, dim=1).unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        return x_hat - bias\n",
    "\n",
    "\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "\n",
    "class series_decomp_multi(nn.Module):\n",
    "    \"\"\"\n",
    "    Multiple Series decomposition block from FEDformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp_multi, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.series_decomp = [series_decomp(kernel) for kernel in kernel_size]\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = []\n",
    "        res = []\n",
    "        for func in self.series_decomp:\n",
    "            sea, moving_avg = func(x)\n",
    "            moving_mean.append(moving_avg)\n",
    "            res.append(sea)\n",
    "\n",
    "        sea = sum(res) / len(res)\n",
    "        moving_mean = sum(moving_mean) / len(moving_mean)\n",
    "        return sea, moving_mean\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder layer with the progressive decomposition architecture\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, attention, d_model, d_ff=None, moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
    "        self.decomp1 = series_decomp(moving_avg)\n",
    "        self.decomp2 = series_decomp(moving_avg)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "        x, _ = self.decomp1(x)\n",
    "        y = x\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        res, _ = self.decomp2(x + y)\n",
    "        return res, attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer decoder layer with the progressive decomposition architecture\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, self_attention, cross_attention, d_model, c_out, d_ff=None,\n",
    "                 moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
    "        self.decomp1 = series_decomp(moving_avg)\n",
    "        self.decomp2 = series_decomp(moving_avg)\n",
    "        self.decomp3 = series_decomp(moving_avg)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.projection = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=3, stride=1, padding=1,\n",
    "                                    padding_mode='circular', bias=False)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask\n",
    "        )[0])\n",
    "        x, trend1 = self.decomp1(x)\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask\n",
    "        )[0])\n",
    "        x, trend2 = self.decomp2(x)\n",
    "        y = x\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        x, trend3 = self.decomp3(x + y)\n",
    "\n",
    "        residual_trend = trend1 + trend2 + trend3\n",
    "        residual_trend = self.projection(residual_trend.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x, residual_trend\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, trend=None):\n",
    "        for layer in self.layers:\n",
    "            x, residual_trend = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
    "            trend = trend + residual_trend\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x, trend\n",
    "    \n",
    "    \n",
    "# FEDformer模块\n",
    "class FEDformer(nn.Module):\n",
    "    def __init__(self, seq_len, label_len, pred_len, moving_avg, enc_in, dec_in, d_model, dropout, n_heads, d_ff, \n",
    "                 e_layers, c_out, d_layers, version='fourier', mode_select='random', modes=32):\n",
    "        \"\"\"\n",
    "        version: str, for FEDformer, there are two versions to choose, options: [Fourier, Wavelets].\n",
    "        mode_select: str, for FEDformer, there are two mode selection method, options: [random, low].\n",
    "        modes: int, modes to be selected.\n",
    "        \"\"\"\n",
    "        super(FEDformer, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = pred_len\n",
    "        self.version = version\n",
    "        self.mode_select = mode_select\n",
    "        self.modes = modes\n",
    "\n",
    "        # Decomp\n",
    "        self.decomp = series_decomp(moving_avg)\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, dropout)\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, dropout)\n",
    "\n",
    "        if self.version == 'Wavelets':\n",
    "            encoder_self_att = MultiWaveletTransform(ich=d_model, L=1, base='legendre')\n",
    "            decoder_self_att = MultiWaveletTransform(ich=d_model, L=1, base='legendre')\n",
    "            decoder_cross_att = MultiWaveletCross(in_channels=d_model,\n",
    "                                                  out_channels=d_model,\n",
    "                                                  seq_len_q=self.seq_len // 2 + self.pred_len,\n",
    "                                                  seq_len_kv=self.seq_len,\n",
    "                                                  modes=self.modes,\n",
    "                                                  ich=d_model,\n",
    "                                                  base='legendre',\n",
    "                                                  activation='tanh')\n",
    "        else:\n",
    "            encoder_self_att = FourierBlock(in_channels=d_model,\n",
    "                                            out_channels=d_model,\n",
    "                                            seq_len=self.seq_len,\n",
    "                                            modes=self.modes,\n",
    "                                            mode_select_method=self.mode_select)\n",
    "            decoder_self_att = FourierBlock(in_channels=d_model,\n",
    "                                            out_channels=d_model,\n",
    "                                            seq_len=self.seq_len // 2 + self.pred_len,\n",
    "                                            modes=self.modes,\n",
    "                                            mode_select_method=self.mode_select)\n",
    "            decoder_cross_att = FourierCrossAttention(in_channels=d_model,\n",
    "                                                      out_channels=d_model,\n",
    "                                                      seq_len_q=self.seq_len // 2 + self.pred_len,\n",
    "                                                      seq_len_kv=self.seq_len,\n",
    "                                                      modes=self.modes,\n",
    "                                                      mode_select_method=self.mode_select,\n",
    "                                                      num_heads=n_heads)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        encoder_self_att,  # instead of multi-head attention in transformer\n",
    "                        d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    moving_avg=moving_avg,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu'\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        decoder_self_att, d_model, n_heads),\n",
    "                    AutoCorrelationLayer(\n",
    "                        decoder_cross_att, d_model, n_heads),\n",
    "                    d_model,\n",
    "                    c_out,\n",
    "                    d_ff,\n",
    "                    moving_avg=moving_avg,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(d_model),\n",
    "            projection=nn.Linear(d_model, c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc=None, x_dec=None, x_mark_dec=None):\n",
    "        # decomp init\n",
    "        mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\n",
    "        seasonal_init, trend_init = self.decomp(x_enc)  # x - moving_avg, moving_avg\n",
    "        # decoder input\n",
    "        trend_init = torch.cat([trend_init[:, -self.label_len:, :], mean], dim=1)\n",
    "        seasonal_init = F.pad(seasonal_init[:, -self.label_len:, :], (0, 0, 0, self.pred_len))\n",
    "        # enc\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        dec_out = self.dec_embedding(seasonal_init, x_mark_dec)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "        # dec\n",
    "        seasonal_part, trend_part = self.decoder(dec_out, enc_out, x_mask=None, cross_mask=None, trend=trend_init)\n",
    "        # final\n",
    "        dec_out = trend_part + seasonal_part\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fe96f",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b184f28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:03:39.887121Z",
     "start_time": "2024-04-13T05:03:39.863791Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b868730a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:38:49.038373Z",
     "start_time": "2024-04-13T05:05:36.522987Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourier enhanced block used!\n",
      "modes=32, index=[0, 1, 2]\n",
      "fourier enhanced block used!\n",
      "modes=32, index=[0, 1, 2]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=3, index_q=[0, 1, 2]\n",
      "modes_kv=3, index_kv=[0, 1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [01:29<28:15, 89.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0198, Validation Loss: 0.0476\n",
      "Validation loss decreased (inf --> 0.047645).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [02:56<26:29, 88.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0044, Validation Loss: 0.0278\n",
      "Validation loss decreased (0.047645 --> 0.027761).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [04:27<25:20, 89.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0034, Validation Loss: 0.0110\n",
      "Validation loss decreased (0.027761 --> 0.011029).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [06:08<25:02, 93.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0027, Validation Loss: 0.0081\n",
      "Validation loss decreased (0.011029 --> 0.008139).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [07:48<24:03, 96.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0022, Validation Loss: 0.0088\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [09:29<22:50, 97.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0021, Validation Loss: 0.0066\n",
      "Validation loss decreased (0.008139 --> 0.006619).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▋                                                     | 7/20 [11:16<21:48, 100.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0019, Validation Loss: 0.0037\n",
      "Validation loss decreased (0.006619 --> 0.003686).  Saving model ...\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 8/20 [12:58<20:14, 101.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0019, Validation Loss: 0.0035\n",
      "Validation loss decreased (0.003686 --> 0.003529).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▉                                             | 9/20 [14:39<18:33, 101.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0018, Validation Loss: 0.0035\n",
      "Validation loss decreased (0.003529 --> 0.003522).  Saving model ...\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▌                                        | 10/20 [16:22<16:56, 101.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0017, Validation Loss: 0.0030\n",
      "Validation loss decreased (0.003522 --> 0.002999).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▌                                    | 11/20 [18:01<15:08, 100.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0016, Validation Loss: 0.0029\n",
      "Validation loss decreased (0.002999 --> 0.002929).  Saving model ...\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▌                                | 12/20 [19:41<13:25, 100.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0015, Validation Loss: 0.0037\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████▋                            | 13/20 [21:23<11:46, 100.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0014, Validation Loss: 0.0043\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▋                        | 14/20 [23:07<10:11, 101.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0014, Validation Loss: 0.0028\n",
      "Validation loss decreased (0.002929 --> 0.002814).  Saving model ...\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████▊                    | 15/20 [24:49<08:29, 101.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0013, Validation Loss: 0.0035\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.00014644660940672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▊                | 16/20 [26:28<06:43, 100.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0012, Validation Loss: 0.0035\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████▊            | 17/20 [28:09<05:02, 100.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0012, Validation Loss: 0.0034\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Updating learning rate to 5.449673790581611e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████▉        | 18/20 [29:49<03:21, 100.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0012, Validation Loss: 0.0032\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Updating learning rate to 2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████████████████████████████████████████▉    | 19/20 [31:31<01:41, 101.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0011, Validation Loss: 0.0031\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Updating learning rate to 6.15582970243117e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [33:12<00:00, 99.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0011, Validation Loss: 0.0031\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Updating learning rate to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load'],\n",
    "        \"features\": 'MS'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": FEDformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 7,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'dec_in': 2,\n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'label_len': 3,\n",
    "        'moving_avg': 3,\n",
    "        'd_model': 128,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': None,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'c_out': 128\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cefa5b",
   "metadata": {},
   "source": [
    "# 基于FiLM的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72af68",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c613a21c",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7e7047a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:38:55.553644Z",
     "start_time": "2024-04-13T05:38:55.545980Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0502843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:38:56.494310Z",
     "start_time": "2024-04-13T05:38:56.442988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5f03197",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:38:57.752356Z",
     "start_time": "2024-04-13T05:38:57.744228Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94510130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:38:59.205734Z",
     "start_time": "2024-04-13T05:38:59.179254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 1)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 1)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 1)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\"],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "437dbe70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:39:00.489867Z",
     "start_time": "2024-04-13T05:39:00.483341Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60657bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:39:02.203638Z",
     "start_time": "2024-04-13T05:39:01.789766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 1]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc791901",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bcbd4b41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:49:07.078683Z",
     "start_time": "2024-04-13T05:49:07.052705Z"
    }
   },
   "outputs": [],
   "source": [
    "def transition(N):\n",
    "    Q = np.arange(N, dtype=np.float64)\n",
    "    R = (2 * Q + 1)[:, None]  # / theta\n",
    "    j, i = np.meshgrid(Q, Q)\n",
    "    A = np.where(i < j, -1, (-1.) ** (i - j + 1)) * R\n",
    "    B = (-1.) ** Q[:, None] * R\n",
    "    return A, B\n",
    "\n",
    "\n",
    "class HiPPO_LegT(nn.Module):\n",
    "    def __init__(self, N, dt=1.0, discretization='bilinear'):\n",
    "        \"\"\"\n",
    "        N: the order of the HiPPO projection\n",
    "        dt: discretization step size - should be roughly inverse to the length of the sequence\n",
    "        \"\"\"\n",
    "        super(HiPPO_LegT, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.N = N\n",
    "        A, B = transition(N)\n",
    "        C = np.ones((1, N))\n",
    "        D = np.zeros((1,))\n",
    "        A, B, _, _, _ = signal.cont2discrete((A, B, C, D), dt=dt, method=discretization)\n",
    "\n",
    "        B = B.squeeze(-1)\n",
    "\n",
    "        self.register_buffer('A', torch.Tensor(A).to(self.device))\n",
    "        self.register_buffer('B', torch.Tensor(B).to(self.device))\n",
    "        vals = np.arange(0.0, 1.0, dt)\n",
    "        self.register_buffer('eval_matrix', torch.Tensor(eval_legendre(np.arange(N)[:, None], 1 - 2 * vals).T).to(self.device))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs : (length, ...)\n",
    "        output : (length, ..., N) where N is the order of the HiPPO projection\n",
    "        \"\"\"\n",
    "        c = torch.zeros(inputs.shape[:-1] + tuple([self.N])).to(self.device)\n",
    "        cs = []\n",
    "        for f in inputs.permute([-1, 0, 1]):\n",
    "            f = f.unsqueeze(-1)\n",
    "            new = f @ self.B.unsqueeze(0)\n",
    "            c = F.linear(c, self.A) + new\n",
    "            cs.append(c)\n",
    "        return torch.stack(cs, dim=0)\n",
    "\n",
    "    def reconstruct(self, c):\n",
    "        return (self.eval_matrix @ c.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "\n",
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, seq_len, ratio=0.5):\n",
    "        \"\"\"\n",
    "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
    "        \"\"\"\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.ratio = ratio\n",
    "        self.modes = min(32, seq_len // 2)\n",
    "        self.index = list(range(0, self.modes))\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights_real = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, len(self.index), dtype=torch.float))\n",
    "        self.weights_imag = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, len(self.index), dtype=torch.float))\n",
    "\n",
    "    def compl_mul1d(self, order, x, weights_real, weights_imag):\n",
    "        return torch.complex(torch.einsum(order, x.real, weights_real) - torch.einsum(order, x.imag, weights_imag),\n",
    "                                 torch.einsum(order, x.real, weights_imag) + torch.einsum(order, x.imag, weights_real))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H, E, N = x.shape\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "        out_ft = torch.zeros(B, H, self.out_channels, x.size(-1) // 2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        a = x_ft[:, :, :, :self.modes]\n",
    "        out_ft[:, :, :, :self.modes] = self.compl_mul1d(\"bjix,iox->bjox\", a, self.weights_real, self.weights_imag)\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x\n",
    "\n",
    "# FiLM模型\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, seq_len, label_len, pred_len, enc_in):\n",
    "        super(FiLM, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = seq_len if pred_len == 0 else pred_len\n",
    "\n",
    "        self.seq_len_all = self.seq_len + self.label_len\n",
    "\n",
    "        # b, s, f means b, f\n",
    "        self.affine_weight = nn.Parameter(torch.ones(1, 1, enc_in))\n",
    "        self.affine_bias = nn.Parameter(torch.zeros(1, 1, enc_in))\n",
    "\n",
    "        self.multiscale = [1, 2, 4]\n",
    "        self.window_size = [256]\n",
    "        ratio = 0.5\n",
    "        self.legts = nn.ModuleList(\n",
    "            [HiPPO_LegT(N=n, dt=1. / self.pred_len / i) for n in self.window_size for i in self.multiscale])\n",
    "        self.spec_conv_1 = nn.ModuleList([SpectralConv1d(in_channels=n, out_channels=n,\n",
    "                                                         seq_len=min(self.pred_len, self.seq_len),\n",
    "                                                         ratio=ratio) for n in\n",
    "                                          self.window_size for _ in range(len(self.multiscale))])\n",
    "        self.mlp = nn.Linear(len(self.multiscale) * len(self.window_size), 1)\n",
    "\n",
    "    def forward(self, x_enc):\n",
    "        # Normalization from Non-stationary Transformer\n",
    "        means = x_enc.mean(1, keepdim=True).detach()\n",
    "        x_enc = x_enc - means\n",
    "        stdev = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach()\n",
    "        x_enc /= stdev\n",
    "\n",
    "        x_enc = x_enc * self.affine_weight + self.affine_bias\n",
    "        x_decs = []\n",
    "        jump_dist = 0\n",
    "        for i in range(0, len(self.multiscale) * len(self.window_size)):\n",
    "            x_in_len = self.multiscale[i % len(self.multiscale)] * self.pred_len\n",
    "            x_in = x_enc[:, -x_in_len:]\n",
    "            legt = self.legts[i]\n",
    "            x_in_c = legt(x_in.transpose(1, 2)).permute([1, 2, 3, 0])[:, :, :, jump_dist:]\n",
    "            out1 = self.spec_conv_1[i](x_in_c)\n",
    "            if self.seq_len >= self.pred_len:\n",
    "                x_dec_c = out1.transpose(2, 3)[:, :, self.pred_len - 1 - jump_dist, :]\n",
    "            else:\n",
    "                x_dec_c = out1.transpose(2, 3)[:, :, -1, :]\n",
    "            x_dec = x_dec_c @ legt.eval_matrix[-self.pred_len:, :].T\n",
    "            x_decs.append(x_dec)\n",
    "        x_dec = torch.stack(x_decs, dim=-1)\n",
    "        x_dec = self.mlp(x_dec).squeeze(-1).permute(0, 2, 1)\n",
    "\n",
    "        # De-Normalization from Non-stationary Transformer\n",
    "        x_dec = x_dec - self.affine_bias\n",
    "        x_dec = x_dec / (self.affine_weight + 1e-10)\n",
    "        x_dec = x_dec * stdev\n",
    "        dec_out = x_dec + means\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8d572",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9274aa96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T05:49:09.319034Z",
     "start_time": "2024-04-13T05:49:09.296122Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ff66ae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:23:44.486700Z",
     "start_time": "2024-04-13T05:49:11.085636Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                              | 1/20 [02:21<44:57, 141.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0098, Validation Loss: 0.0121\n",
      "Validation loss decreased (inf --> 0.012093).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▏                                                                         | 2/20 [04:46<43:02, 143.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0054, Validation Loss: 0.0099\n",
      "Validation loss decreased (0.012093 --> 0.009889).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▎                                                                     | 3/20 [07:17<41:37, 146.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0049, Validation Loss: 0.0093\n",
      "Validation loss decreased (0.009889 --> 0.009323).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 4/20 [09:44<39:10, 146.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0047, Validation Loss: 0.0092\n",
      "Validation loss decreased (0.009323 --> 0.009176).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▌                                                             | 5/20 [12:10<36:36, 146.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0047, Validation Loss: 0.0091\n",
      "Validation loss decreased (0.009176 --> 0.009058).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                         | 6/20 [14:33<33:56, 145.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0047, Validation Loss: 0.0091\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▋                                                     | 7/20 [16:58<31:30, 145.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0047, Validation Loss: 0.0091\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 8/20 [19:21<28:53, 144.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0047, Validation Loss: 0.0091\n",
      "Validation loss decreased (0.009058 --> 0.009054).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▉                                             | 9/20 [21:45<26:26, 144.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0046, Validation Loss: 0.0090\n",
      "Validation loss decreased (0.009054 --> 0.009011).  Saving model ...\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▌                                        | 10/20 [24:10<24:07, 144.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0046, Validation Loss: 0.0090\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▌                                    | 11/20 [26:35<21:42, 144.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0046, Validation Loss: 0.0090\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▌                                | 12/20 [29:05<19:31, 146.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0046, Validation Loss: 0.0091\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████▋                            | 13/20 [31:25<16:51, 144.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0046, Validation Loss: 0.0091\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▋                        | 14/20 [33:51<14:29, 144.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0046, Validation Loss: 0.0090\n",
      "Validation loss decreased (0.009011 --> 0.009010).  Saving model ...\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▋                        | 14/20 [34:33<14:48, 148.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 28\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 构造参数字典\u001b[39;00m\n\u001b[0;32m      2\u001b[0m params3 \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_args\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     },\n\u001b[0;32m     27\u001b[0m }\n\u001b[1;32m---> 28\u001b[0m model \u001b[38;5;241m=\u001b[39m train(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams3)\n",
      "Cell \u001b[1;32mIn[61], line 125\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(task_args, train_args, model_args)\u001b[0m\n\u001b[0;32m    123\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, targets_batch)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# 反向传播计算得到每个参数的梯度值\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# 通过梯度下降执行一步参数更新\u001b[39;00m\n\u001b[0;32m    127\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load'],\n",
    "        \"features\": 'MS'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": FiLM,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 7,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'label_len': 3,\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d8b27",
   "metadata": {},
   "source": [
    "# 基于Koopa的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf2ba6",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13a7b5",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affd3f52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:43:52.244372Z",
     "start_time": "2024-04-13T06:43:52.238052Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b2b13f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:43:52.931966Z",
     "start_time": "2024-04-13T06:43:52.869949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7bb731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:43:53.821232Z",
     "start_time": "2024-04-13T06:43:53.813976Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f686ff4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:43:54.770270Z",
     "start_time": "2024-04-13T06:43:54.746904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 1)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 1)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 1)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\"],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10123319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:43:55.679832Z",
     "start_time": "2024-04-13T06:43:55.673848Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b725980e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:43:56.981335Z",
     "start_time": "2024-04-13T06:43:56.577851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 1]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda04ab3",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a085a4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:43:58.914704Z",
     "start_time": "2024-04-13T06:43:58.877602Z"
    }
   },
   "outputs": [],
   "source": [
    "class FourierFilter(nn.Module):\n",
    "    \"\"\"\n",
    "    Fourier Filter: to time-variant and time-invariant term\n",
    "    \"\"\"\n",
    "    def __init__(self, mask_spectrum):\n",
    "        super(FourierFilter, self).__init__()\n",
    "        self.mask_spectrum = mask_spectrum\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xf = torch.fft.rfft(x, dim=1)\n",
    "        mask = torch.ones_like(xf)\n",
    "        mask[:, self.mask_spectrum, :] = 0\n",
    "        x_var = torch.fft.irfft(xf*mask, dim=1)\n",
    "        x_inv = x - x_var\n",
    "        \n",
    "        return x_var, x_inv\n",
    "    \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    '''\n",
    "    Multilayer perceptron to encode/decode high dimension representation of sequential data\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 f_in, \n",
    "                 f_out, \n",
    "                 hidden_dim=128, \n",
    "                 hidden_layers=2, \n",
    "                 dropout=0.05,\n",
    "                 activation='tanh'): \n",
    "        super(MLP, self).__init__()\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.dropout = dropout\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        layers = [nn.Linear(self.f_in, self.hidden_dim), \n",
    "                  self.activation, nn.Dropout(self.dropout)]\n",
    "        for i in range(self.hidden_layers-2):\n",
    "            layers += [nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "                       self.activation, nn.Dropout(dropout)]\n",
    "        \n",
    "        layers += [nn.Linear(hidden_dim, f_out)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x:     B x S x f_in\n",
    "        # y:     B x S x f_out\n",
    "        y = self.layers(x)\n",
    "        return y\n",
    "    \n",
    "\n",
    "class KPLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Find koopman transition of linear system by DMD with one step approximation\n",
    "    \"\"\"\n",
    "    def __init__(self): \n",
    "        super(KPLayer, self).__init__()\n",
    "        \n",
    "        self.K = None # B E E\n",
    "\n",
    "    def one_step_forward(self, z, return_rec=False, return_K=False):\n",
    "        B, input_len, E = z.shape\n",
    "        assert input_len > 1, 'snapshots number should be larger than 1'\n",
    "        x, y = z[:, :-1], z[:, 1:]\n",
    "\n",
    "        # solve linear system\n",
    "        self.K = torch.linalg.lstsq(x, y).solution # B E E\n",
    "        if torch.isnan(self.K).any():\n",
    "            print('Encounter K with nan, replace K by identity matrix')\n",
    "            self.K = torch.eye(self.K.shape[1]).to(self.K.device).unsqueeze(0).repeat(B, 1, 1)\n",
    "\n",
    "        z_pred = torch.bmm(z[:, -1:], self.K)\n",
    "        if return_rec:\n",
    "            z_rec = torch.cat((z[:, :1], torch.bmm(x, self.K)), dim=1)\n",
    "            return z_rec, z_pred\n",
    "\n",
    "        return z_pred\n",
    "    \n",
    "    def forward(self, z, pred_len=1):\n",
    "        z_rec, z_pred= self.one_step_forward(z, return_rec=True)\n",
    "        z_preds = []\n",
    "        for i in range(pred_len):\n",
    "            z_pred = torch.bmm(z_pred, self.K)\n",
    "            z_preds.append(z_pred)\n",
    "        z_preds = torch.cat(z_preds, dim=1)\n",
    "        return z_rec, z_preds\n",
    "\n",
    "\n",
    "class KPLayerApprox(nn.Module):\n",
    "    \"\"\"\n",
    "    Find koopman transition of linear system by DMD with multistep K approximation\n",
    "    \"\"\"\n",
    "    def __init__(self): \n",
    "        super(KPLayerApprox, self).__init__()\n",
    "        \n",
    "        self.K = None # B E E\n",
    "        self.K_step = None # B E E\n",
    "\n",
    "    def forward(self, z, pred_len=1):\n",
    "        # z:       B L E, koopman invariance space representation\n",
    "        # z_rec:   B L E, reconstructed representation\n",
    "        # z_pred:  B S E, forecasting representation\n",
    "        B, input_len, E = z.shape\n",
    "        assert input_len > 1, 'snapshots number should be larger than 1'\n",
    "        x, y = z[:, :-1], z[:, 1:]\n",
    "\n",
    "        # solve linear system\n",
    "        self.K = torch.linalg.lstsq(x, y).solution # B E E\n",
    "\n",
    "        if torch.isnan(self.K).any():\n",
    "            print('Encounter K with nan, replace K by identity matrix')\n",
    "            self.K = torch.eye(self.K.shape[1]).to(self.K.device).unsqueeze(0).repeat(B, 1, 1)\n",
    "\n",
    "        z_rec = torch.cat((z[:, :1], torch.bmm(x, self.K)), dim=1) # B L E\n",
    "        \n",
    "        if pred_len <= input_len:\n",
    "            self.K_step = torch.linalg.matrix_power(self.K, pred_len)\n",
    "            if torch.isnan(self.K_step).any():\n",
    "                print('Encounter multistep K with nan, replace it by identity matrix')\n",
    "                self.K_step = torch.eye(self.K_step.shape[1]).to(self.K_step.device).unsqueeze(0).repeat(B, 1, 1)\n",
    "            z_pred = torch.bmm(z[:, -pred_len:, :], self.K_step)\n",
    "        else:\n",
    "            self.K_step = torch.linalg.matrix_power(self.K, input_len)\n",
    "            if torch.isnan(self.K_step).any():\n",
    "                print('Encounter multistep K with nan, replace it by identity matrix')\n",
    "                self.K_step = torch.eye(self.K_step.shape[1]).to(self.K_step.device).unsqueeze(0).repeat(B, 1, 1)\n",
    "            temp_z_pred, all_pred = z, []\n",
    "            for _ in range(math.ceil(pred_len / input_len)):\n",
    "                temp_z_pred = torch.bmm(temp_z_pred, self.K_step)\n",
    "                all_pred.append(temp_z_pred)\n",
    "            z_pred = torch.cat(all_pred, dim=1)[:, :pred_len, :]\n",
    "\n",
    "        return z_rec, z_pred\n",
    "    \n",
    "\n",
    "class TimeVarKP(nn.Module):\n",
    "    \"\"\"\n",
    "    Koopman Predictor with DMD (analysitical solution of Koopman operator)\n",
    "    Utilize local variations within individual sliding window to predict the future of time-variant term\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 enc_in=8,\n",
    "                 input_len=96,\n",
    "                 pred_len=96,\n",
    "                 seg_len=24,\n",
    "                 dynamic_dim=128,\n",
    "                 encoder=None,\n",
    "                 decoder=None,\n",
    "                 multistep=False,\n",
    "                ):\n",
    "        super(TimeVarKP, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in = enc_in\n",
    "        self.seg_len = seg_len\n",
    "        self.dynamic_dim = dynamic_dim\n",
    "        self.multistep = multistep\n",
    "        self.encoder, self.decoder = encoder, decoder            \n",
    "        self.freq = math.ceil(self.input_len / self.seg_len)  # segment number of input\n",
    "        self.step = math.ceil(self.pred_len / self.seg_len)   # segment number of output\n",
    "        self.padding_len = self.seg_len * self.freq - self.input_len\n",
    "        # Approximate mulitstep K by KPLayerApprox when pred_len is large\n",
    "        self.dynamics = KPLayerApprox() if self.multistep else KPLayer() \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: B L C\n",
    "        B, L, C = x.shape\n",
    "\n",
    "        res = torch.cat((x[:, L-self.padding_len:, :], x) ,dim=1)\n",
    "\n",
    "        res = res.chunk(self.freq, dim=1)     # F x B P C, P means seg_len\n",
    "        res = torch.stack(res, dim=1).reshape(B, self.freq, -1)   # B F PC\n",
    "\n",
    "        res = self.encoder(res) # B F H\n",
    "        x_rec, x_pred = self.dynamics(res, self.step) # B F H, B S H\n",
    "\n",
    "        x_rec = self.decoder(x_rec) # B F PC\n",
    "        x_rec = x_rec.reshape(B, self.freq, self.seg_len, self.enc_in)\n",
    "        x_rec = x_rec.reshape(B, -1, self.enc_in)[:, :self.input_len, :]  # B L C\n",
    "        \n",
    "        x_pred = self.decoder(x_pred)     # B S PC\n",
    "        x_pred = x_pred.reshape(B, self.step, self.seg_len, self.enc_in)\n",
    "        x_pred = x_pred.reshape(B, -1, self.enc_in)[:, :self.pred_len, :] # B S C\n",
    "\n",
    "        return x_rec, x_pred\n",
    "\n",
    "\n",
    "class TimeInvKP(nn.Module):\n",
    "    \"\"\"\n",
    "    Koopman Predictor with learnable Koopman operator\n",
    "    Utilize lookback and forecast window snapshots to predict the future of time-invariant term\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_len=96,\n",
    "                 pred_len=96,\n",
    "                 dynamic_dim=128,\n",
    "                 encoder=None,\n",
    "                 decoder=None):\n",
    "        super(TimeInvKP, self).__init__()\n",
    "        self.dynamic_dim = dynamic_dim\n",
    "        self.input_len = input_len\n",
    "        self.pred_len = pred_len\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        K_init = torch.randn(self.dynamic_dim, self.dynamic_dim)\n",
    "        U, _, V = torch.svd(K_init) # stable initialization\n",
    "        self.K = nn.Linear(self.dynamic_dim, self.dynamic_dim, bias=False)\n",
    "        self.K.weight.data = torch.mm(U, V.t())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: B L C\n",
    "        res = x.transpose(1, 2) # B C L\n",
    "        res = self.encoder(res) # B C H\n",
    "        res = self.K(res) # B C H\n",
    "        res = self.decoder(res) # B C S\n",
    "        res = res.transpose(1, 2) # B S C\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "# Koopa模型\n",
    "class Koopa(nn.Module):\n",
    "    def __init__(self, enc_in, seq_len, pred_len, train_loader, dynamic_dim=128, hidden_dim=64, \n",
    "                 hidden_layers=2, num_blocks=3, multistep=False):\n",
    "        \"\"\"\n",
    "        mask_spectrum: list, shared frequency spectrums\n",
    "        seg_len: int, segment length of time series\n",
    "        dynamic_dim: int, latent dimension of koopman embedding\n",
    "        hidden_dim: int, hidden dimension of en/decoder\n",
    "        hidden_layers: int, number of hidden layers of en/decoder\n",
    "        num_blocks: int, number of Koopa blocks\n",
    "        multistep: bool, whether to use approximation for multistep K\n",
    "        alpha: float, spectrum filter ratio\n",
    "        \"\"\"\n",
    "        super(Koopa, self).__init__()\n",
    "        self.enc_in = enc_in\n",
    "        self.input_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        self.seg_len = self.pred_len\n",
    "        self.num_blocks = num_blocks\n",
    "        self.dynamic_dim = dynamic_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.multistep = multistep\n",
    "        self.alpha = 0.2\n",
    "        self.mask_spectrum = self._get_mask_spectrum(train_loader)\n",
    "\n",
    "        self.disentanglement = FourierFilter(self.mask_spectrum)\n",
    "\n",
    "        # shared encoder/decoder to make koopman embedding consistent\n",
    "        self.time_inv_encoder = MLP(f_in=self.input_len, f_out=self.dynamic_dim, activation='relu',\n",
    "                    hidden_dim=self.hidden_dim, hidden_layers=self.hidden_layers)\n",
    "        self.time_inv_decoder = MLP(f_in=self.dynamic_dim, f_out=self.pred_len, activation='relu',\n",
    "                           hidden_dim=self.hidden_dim, hidden_layers=self.hidden_layers)\n",
    "        self.time_inv_kps = self.time_var_kps = nn.ModuleList([\n",
    "                                TimeInvKP(input_len=self.input_len,\n",
    "                                    pred_len=self.pred_len, \n",
    "                                    dynamic_dim=self.dynamic_dim,\n",
    "                                    encoder=self.time_inv_encoder, \n",
    "                                    decoder=self.time_inv_decoder)\n",
    "                                for _ in range(self.num_blocks)])\n",
    "\n",
    "        # shared encoder/decoder to make koopman embedding consistent\n",
    "        self.time_var_encoder = MLP(f_in=self.seg_len*self.enc_in, f_out=self.dynamic_dim, activation='tanh',\n",
    "                           hidden_dim=self.hidden_dim, hidden_layers=self.hidden_layers)\n",
    "        self.time_var_decoder = MLP(f_in=self.dynamic_dim, f_out=self.seg_len*self.enc_in, activation='tanh',\n",
    "                           hidden_dim=self.hidden_dim, hidden_layers=self.hidden_layers)\n",
    "        self.time_var_kps = nn.ModuleList([\n",
    "                    TimeVarKP(enc_in=configs.enc_in,\n",
    "                        input_len=self.input_len,\n",
    "                        pred_len=self.pred_len,\n",
    "                        seg_len=self.seg_len,\n",
    "                        dynamic_dim=self.dynamic_dim,\n",
    "                        encoder=self.time_var_encoder,\n",
    "                        decoder=self.time_var_decoder,\n",
    "                        multistep=self.multistep)\n",
    "                    for _ in range(self.num_blocks)])\n",
    "\n",
    "    def _get_mask_spectrum(self, train_loader):\n",
    "        \"\"\"\n",
    "        get shared frequency spectrums\n",
    "        \"\"\"\n",
    "#         train_data, train_loader = data_provider(configs, 'train')\n",
    "        amps = 0.0\n",
    "        for data in train_loader:\n",
    "            lookback_window = data[0]\n",
    "            amps += abs(torch.fft.rfft(lookback_window, dim=1)).mean(dim=0).mean(dim=1)\n",
    "        mask_spectrum = amps.topk(int(amps.shape[0]*self.alpha)).indices\n",
    "        return mask_spectrum # as the spectrums of time-invariant component\n",
    "    \n",
    "    def forward(self, x_enc):\n",
    "        # Series Stationarization adopted from NSformer\n",
    "        mean_enc = x_enc.mean(1, keepdim=True).detach() # B x 1 x E\n",
    "        x_enc = x_enc - mean_enc\n",
    "        std_enc = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach()\n",
    "        x_enc = x_enc / std_enc\n",
    "\n",
    "        # Koopman Forecasting\n",
    "        residual, forecast = x_enc, None\n",
    "        for i in range(self.num_blocks):\n",
    "            time_var_input, time_inv_input = self.disentanglement(residual)\n",
    "            time_inv_output = self.time_inv_kps[i](time_inv_input)\n",
    "            time_var_backcast, time_var_output = self.time_var_kps[i](time_var_input)\n",
    "            residual = residual - time_var_backcast\n",
    "            if forecast is None:\n",
    "                forecast = (time_inv_output + time_var_output)\n",
    "            else:\n",
    "                forecast += (time_inv_output + time_var_output)\n",
    "\n",
    "        # Series Stationarization adopted from NSformer\n",
    "        dec_out = forecast * std_enc + mean_enc\n",
    "\n",
    "        output = dec_out[:, -self.pred_len:, :] # [B, L, D]\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bbdc4",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5952dbbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:44:00.973585Z",
     "start_time": "2024-04-13T06:44:00.952615Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319a795a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:44:04.420809Z",
     "start_time": "2024-04-13T06:44:03.633603Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "svd: LAPACK library not found in compilation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 28\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 构造参数字典\u001b[39;00m\n\u001b[0;32m      2\u001b[0m params3 \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_args\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     },\n\u001b[0;32m     27\u001b[0m }\n\u001b[1;32m---> 28\u001b[0m model \u001b[38;5;241m=\u001b[39m train(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams3)\n",
      "Cell \u001b[1;32mIn[9], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(task_args, train_args, model_args)\u001b[0m\n\u001b[0;32m     19\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 创建模型和优化器\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m model_name(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m     24\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[1;32mIn[8], line 264\u001b[0m, in \u001b[0;36mKoopa.__init__\u001b[1;34m(self, enc_in, seq_len, pred_len, train_loader, dynamic_dim, hidden_dim, hidden_layers, num_blocks, multistep)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_inv_encoder \u001b[38;5;241m=\u001b[39m MLP(f_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_len, f_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    261\u001b[0m             hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim, hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_inv_decoder \u001b[38;5;241m=\u001b[39m MLP(f_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim, f_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    263\u001b[0m                    hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim, hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers)\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_inv_kps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_var_kps \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[0;32m    265\u001b[0m                         TimeInvKP(input_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_len,\n\u001b[0;32m    266\u001b[0m                             pred_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len, \n\u001b[0;32m    267\u001b[0m                             dynamic_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim,\n\u001b[0;32m    268\u001b[0m                             encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_inv_encoder, \n\u001b[0;32m    269\u001b[0m                             decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_inv_decoder)\n\u001b[0;32m    270\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_blocks)])\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# shared encoder/decoder to make koopman embedding consistent\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_var_encoder \u001b[38;5;241m=\u001b[39m MLP(f_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseg_len\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_in, f_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    274\u001b[0m                    hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim, hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers)\n",
      "Cell \u001b[1;32mIn[8], line 265\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_inv_encoder \u001b[38;5;241m=\u001b[39m MLP(f_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_len, f_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    261\u001b[0m             hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim, hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_inv_decoder \u001b[38;5;241m=\u001b[39m MLP(f_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim, f_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    263\u001b[0m                    hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim, hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_inv_kps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_var_kps \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m--> 265\u001b[0m                         TimeInvKP(input_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_len,\n\u001b[0;32m    266\u001b[0m                             pred_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len, \n\u001b[0;32m    267\u001b[0m                             dynamic_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim,\n\u001b[0;32m    268\u001b[0m                             encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_inv_encoder, \n\u001b[0;32m    269\u001b[0m                             decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_inv_decoder)\n\u001b[0;32m    270\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_blocks)])\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# shared encoder/decoder to make koopman embedding consistent\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_var_encoder \u001b[38;5;241m=\u001b[39m MLP(f_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseg_len\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_in, f_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    274\u001b[0m                    hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim, hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers)\n",
      "Cell \u001b[1;32mIn[8], line 214\u001b[0m, in \u001b[0;36mTimeInvKP.__init__\u001b[1;34m(self, input_len, pred_len, dynamic_dim, encoder, decoder)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m decoder\n\u001b[0;32m    213\u001b[0m K_init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim)\n\u001b[1;32m--> 214\u001b[0m U, _, V \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msvd(K_init) \u001b[38;5;66;03m# stable initialization\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_dim, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(U, V\u001b[38;5;241m.\u001b[39mt())\n",
      "\u001b[1;31mRuntimeError\u001b[0m: svd: LAPACK library not found in compilation"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load'],\n",
    "        \"features\": 'MS'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Koopa,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'train_loader': train_loader,\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd0701",
   "metadata": {},
   "source": [
    "# 基于LightTS的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b98b6",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773c5f3",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3774513a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:46:36.591468Z",
     "start_time": "2024-04-13T06:46:36.585992Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01289bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:46:45.572296Z",
     "start_time": "2024-04-13T06:46:45.522696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf04d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:46:54.117442Z",
     "start_time": "2024-04-13T06:46:54.110108Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00c2f379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:47:02.969763Z",
     "start_time": "2024-04-13T06:47:02.946477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 1)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 1)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 1)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\"],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0482dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:47:11.903203Z",
     "start_time": "2024-04-13T06:47:11.898208Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "892e7676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T06:47:21.771827Z",
     "start_time": "2024-04-13T06:47:21.366722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 1]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0aa3e",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c194077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:00:31.243789Z",
     "start_time": "2024-04-13T07:00:31.226631Z"
    }
   },
   "outputs": [],
   "source": [
    "class IEBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, output_dim, num_node):\n",
    "        super(IEBlock, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_node = num_node\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        self.spatial_proj = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hid_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hid_dim, self.hid_dim // 4)\n",
    "        )\n",
    "\n",
    "        self.channel_proj = nn.Linear(self.num_node, self.num_node)\n",
    "        torch.nn.init.eye_(self.channel_proj.weight)\n",
    "\n",
    "        self.output_proj = nn.Linear(self.hid_dim // 4, self.output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spatial_proj(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1) + self.channel_proj(x.permute(0, 2, 1))\n",
    "        x = self.output_proj(x.permute(0, 2, 1))\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# LightTS模型\n",
    "class LightTS(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, chunk_size, d_model, enc_in, dropout):\n",
    "        \"\"\"\n",
    "        chunk_size: int, reshape T into [num_chunks, chunk_size]\n",
    "        \"\"\"\n",
    "        super(LightTS, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        self.chunk_size = min(pred_len, seq_len, chunk_size)\n",
    "        assert (self.seq_len % self.chunk_size == 0)\n",
    "        self.num_chunks = self.seq_len // self.chunk_size\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.enc_in = enc_in\n",
    "        self.dropout = dropout\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        self.layer_1 = IEBlock(\n",
    "            input_dim=self.chunk_size,\n",
    "            hid_dim=self.d_model // 4,\n",
    "            output_dim=self.d_model // 4,\n",
    "            num_node=self.num_chunks\n",
    "        )\n",
    "\n",
    "        self.chunk_proj_1 = nn.Linear(self.num_chunks, 1)\n",
    "\n",
    "        self.layer_2 = IEBlock(\n",
    "            input_dim=self.chunk_size,\n",
    "            hid_dim=self.d_model // 4,\n",
    "            output_dim=self.d_model // 4,\n",
    "            num_node=self.num_chunks\n",
    "        )\n",
    "\n",
    "        self.chunk_proj_2 = nn.Linear(self.num_chunks, 1)\n",
    "\n",
    "        self.layer_3 = IEBlock(\n",
    "            input_dim=self.d_model // 2,\n",
    "            hid_dim=self.d_model // 2,\n",
    "            output_dim=self.pred_len,\n",
    "            num_node=self.enc_in\n",
    "        )\n",
    "\n",
    "        self.ar = nn.Linear(self.seq_len, self.pred_len)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        B, T, N = x.size()\n",
    "\n",
    "        highway = self.ar(x.permute(0, 2, 1))\n",
    "        highway = highway.permute(0, 2, 1)\n",
    "\n",
    "        # continuous sampling\n",
    "        x1 = x.reshape(B, self.num_chunks, self.chunk_size, N)\n",
    "        x1 = x1.permute(0, 3, 2, 1)\n",
    "        x1 = x1.reshape(-1, self.chunk_size, self.num_chunks)\n",
    "        x1 = self.layer_1(x1)\n",
    "        x1 = self.chunk_proj_1(x1).squeeze(dim=-1)\n",
    "\n",
    "        # interval sampling\n",
    "        x2 = x.reshape(B, self.chunk_size, self.num_chunks, N)\n",
    "        x2 = x2.permute(0, 3, 1, 2)\n",
    "        x2 = x2.reshape(-1, self.chunk_size, self.num_chunks)\n",
    "        x2 = self.layer_2(x2)\n",
    "        x2 = self.chunk_proj_2(x2).squeeze(dim=-1)\n",
    "\n",
    "        x3 = torch.cat([x1, x2], dim=-1)\n",
    "\n",
    "        x3 = x3.reshape(B, N, -1)\n",
    "        x3 = x3.permute(0, 2, 1)\n",
    "\n",
    "        out = self.layer_3(x3)\n",
    "\n",
    "        out = out + highway\n",
    "        return out\n",
    "\n",
    "    def forward(self, x_enc):\n",
    "        dec_out = self.encoder(x_enc)\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c4dda3",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dcad24b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:01:22.197738Z",
     "start_time": "2024-04-13T07:01:22.173900Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52e7c02a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:08:39.509589Z",
     "start_time": "2024-04-13T07:05:22.330579Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:12<04:06, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0065, Validation Loss: 0.0087\n",
      "Validation loss decreased (inf --> 0.008701).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [00:27<04:08, 13.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0036, Validation Loss: 0.0065\n",
      "Validation loss decreased (0.008701 --> 0.006549).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [00:41<03:54, 13.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0029, Validation Loss: 0.0063\n",
      "Validation loss decreased (0.006549 --> 0.006340).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [00:54<03:40, 13.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0026, Validation Loss: 0.0060\n",
      "Validation loss decreased (0.006340 --> 0.005990).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [01:09<03:29, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0024, Validation Loss: 0.0058\n",
      "Validation loss decreased (0.005990 --> 0.005816).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [01:24<03:24, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0022, Validation Loss: 0.0050\n",
      "Validation loss decreased (0.005816 --> 0.004968).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████                                                      | 7/20 [01:41<03:18, 15.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0022, Validation Loss: 0.0058\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [01:58<03:07, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0020, Validation Loss: 0.0055\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [02:14<02:54, 15.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0019, Validation Loss: 0.0043\n",
      "Validation loss decreased (0.004968 --> 0.004256).  Saving model ...\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [02:29<02:37, 15.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0019, Validation Loss: 0.0042\n",
      "Validation loss decreased (0.004256 --> 0.004223).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [02:46<02:22, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0018, Validation Loss: 0.0045\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [03:01<02:06, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0017, Validation Loss: 0.0044\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [03:16<02:11, 16.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0016, Validation Loss: 0.0047\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load'],\n",
    "        \"features\": 'MS'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": LightTS,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'd_model': 512,\n",
    "        'chunk_size': 3,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cebc78",
   "metadata": {},
   "source": [
    "# 基于MICN的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4df734",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f233cf90",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95abb636",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:33:29.985196Z",
     "start_time": "2024-04-13T07:33:29.978849Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b037cc4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:33:31.479688Z",
     "start_time": "2024-04-13T07:33:31.433688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf2145bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:33:32.784277Z",
     "start_time": "2024-04-13T07:33:32.776440Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a7671ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:33:40.590247Z",
     "start_time": "2024-04-13T07:33:40.565739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9735e4c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:33:41.911075Z",
     "start_time": "2024-04-13T07:33:41.905563Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b26f9013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:33:43.954235Z",
     "start_time": "2024-04-13T07:33:43.537161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd312df",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1da8a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:33:45.977262Z",
     "start_time": "2024-04-13T07:33:45.931835Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# 编码器和解码器\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "\n",
    "class series_decomp_multi(nn.Module):\n",
    "    \"\"\"\n",
    "    Multiple Series decomposition block from FEDformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp_multi, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.series_decomp = [series_decomp(kernel) for kernel in kernel_size]\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = []\n",
    "        res = []\n",
    "        for func in self.series_decomp:\n",
    "            sea, moving_avg = func(x)\n",
    "            moving_mean.append(moving_avg)\n",
    "            res.append(sea)\n",
    "\n",
    "        sea = sum(res) / len(res)\n",
    "        moving_mean = sum(moving_mean) / len(moving_mean)\n",
    "        return sea, moving_mean\n",
    "    \n",
    "    \n",
    "class MIC(nn.Module):\n",
    "    \"\"\"\n",
    "    MIC layer to extract local and global features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_size=512, n_heads=8, dropout=0.05, decomp_kernel=[32], conv_kernel=[24],\n",
    "                 isometric_kernel=[18, 6]):\n",
    "        super(MIC, self).__init__()\n",
    "        self.conv_kernel = conv_kernel\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # isometric convolution\n",
    "        self.isometric_conv = nn.ModuleList([nn.Conv1d(in_channels=feature_size, out_channels=feature_size,\n",
    "                                                       kernel_size=i, padding=0, stride=1)\n",
    "                                             for i in isometric_kernel])\n",
    "\n",
    "        # downsampling convolution: padding=i//2, stride=i\n",
    "        self.conv = nn.ModuleList([nn.Conv1d(in_channels=feature_size, out_channels=feature_size,\n",
    "                                             kernel_size=i, padding=i // 2, stride=i)\n",
    "                                   for i in conv_kernel])\n",
    "\n",
    "        # upsampling convolution\n",
    "        self.conv_trans = nn.ModuleList([nn.ConvTranspose1d(in_channels=feature_size, out_channels=feature_size,\n",
    "                                                            kernel_size=i, padding=0, stride=i)\n",
    "                                         for i in conv_kernel])\n",
    "\n",
    "        self.decomp = nn.ModuleList([series_decomp(k) for k in decomp_kernel])\n",
    "        self.merge = torch.nn.Conv2d(in_channels=feature_size, out_channels=feature_size,\n",
    "                                     kernel_size=(len(self.conv_kernel), 1))\n",
    "\n",
    "        # feedforward network\n",
    "        self.conv1 = nn.Conv1d(in_channels=feature_size, out_channels=feature_size * 4, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=feature_size * 4, out_channels=feature_size, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(feature_size)\n",
    "        self.norm2 = nn.LayerNorm(feature_size)\n",
    "\n",
    "        self.norm = torch.nn.LayerNorm(feature_size)\n",
    "        self.act = torch.nn.Tanh()\n",
    "        self.drop = torch.nn.Dropout(0.05)\n",
    "\n",
    "    def conv_trans_conv(self, input, conv1d, conv1d_trans, isometric):\n",
    "        batch, seq_len, channel = input.shape\n",
    "        x = input.permute(0, 2, 1)\n",
    "\n",
    "        # downsampling convolution\n",
    "        x1 = self.drop(self.act(conv1d(x)))\n",
    "        x = x1\n",
    "\n",
    "        # isometric convolution\n",
    "        zeros = torch.zeros((x.shape[0], x.shape[1], x.shape[2] - 1), device=self.device)\n",
    "        x = torch.cat((zeros, x), dim=-1)\n",
    "        x = self.drop(self.act(isometric(x)))\n",
    "        x = self.norm((x + x1).permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        # upsampling convolution\n",
    "        x = self.drop(self.act(conv1d_trans(x)))\n",
    "        x = x[:, :, :seq_len]  # truncate\n",
    "\n",
    "        x = self.norm(x.permute(0, 2, 1) + input)\n",
    "        return x\n",
    "\n",
    "    def forward(self, src):\n",
    "        # multi-scale\n",
    "        multi = []\n",
    "        for i in range(len(self.conv_kernel)):\n",
    "            src_out, trend1 = self.decomp[i](src)\n",
    "            src_out = self.conv_trans_conv(src_out, self.conv[i], self.conv_trans[i], self.isometric_conv[i])\n",
    "            multi.append(src_out)\n",
    "\n",
    "            # merge\n",
    "        mg = torch.tensor([], device=self.device)\n",
    "        for i in range(len(self.conv_kernel)):\n",
    "            mg = torch.cat((mg, multi[i].unsqueeze(1)), dim=1)\n",
    "        mg = self.merge(mg.permute(0, 3, 1, 2)).squeeze(-2).permute(0, 2, 1)\n",
    "\n",
    "        y = self.norm1(mg)\n",
    "        y = self.conv2(self.conv1(y.transpose(-1, 1))).transpose(-1, 1)\n",
    "\n",
    "        return self.norm2(mg + y)\n",
    "\n",
    "\n",
    "class SeasonalPrediction(nn.Module):\n",
    "    def __init__(self, embedding_size=512, n_heads=8, dropout=0.05, d_layers=1, decomp_kernel=[32], c_out=1,\n",
    "                 conv_kernel=[2, 4], isometric_kernel=[18, 6]):\n",
    "        super(SeasonalPrediction, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.mic = nn.ModuleList([MIC(feature_size=embedding_size, n_heads=n_heads,\n",
    "                                      decomp_kernel=decomp_kernel, conv_kernel=conv_kernel,\n",
    "                                      isometric_kernel=isometric_kernel)\n",
    "                                  for i in range(d_layers)])\n",
    "\n",
    "        self.projection = nn.Linear(embedding_size, c_out)\n",
    "\n",
    "    def forward(self, dec):\n",
    "        for mic_layer in self.mic:\n",
    "            dec = mic_layer(dec)\n",
    "        return self.projection(dec)\n",
    "\n",
    "\n",
    "# MICN模型\n",
    "class MICN(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, enc_in, d_model, dropout, n_heads, d_layers, c_out, \n",
    "                 conv_kernel=[12, 16]):\n",
    "        \"\"\"\n",
    "        conv_kernel: downsampling and upsampling convolution kernel_size\n",
    "        \"\"\"\n",
    "        super(MICN, self).__init__()\n",
    "\n",
    "        decomp_kernel = []  # kernel of decomposition operation\n",
    "        isometric_kernel = []  # kernel of isometric convolution\n",
    "        for ii in conv_kernel:\n",
    "            if ii % 2 == 0:  # the kernel of decomposition operation must be odd\n",
    "                decomp_kernel.append(ii + 1)\n",
    "                isometric_kernel.append((seq_len + pred_len + ii) // ii)\n",
    "            else:\n",
    "                decomp_kernel.append(ii)\n",
    "                isometric_kernel.append((seq_len + pred_len + ii - 1) // ii)\n",
    "\n",
    "        self.pred_len = pred_len\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Multiple Series decomposition block from FEDformer\n",
    "        self.decomp_multi = series_decomp_multi(decomp_kernel)\n",
    "\n",
    "        # embedding\n",
    "        self.dec_embedding = DataEmbedding(enc_in, d_model, dropout)\n",
    "\n",
    "        self.conv_trans = SeasonalPrediction(embedding_size=d_model, n_heads=n_heads,\n",
    "                                             dropout=dropout, d_layers=d_layers, decomp_kernel=decomp_kernel,\n",
    "                                             c_out=c_out, conv_kernel=conv_kernel,\n",
    "                                             isometric_kernel=isometric_kernel)\n",
    "        # refer to DLinear\n",
    "        self.regression = nn.Linear(seq_len, pred_len)\n",
    "        self.regression.weight = nn.Parameter((1 / pred_len) * torch.ones([pred_len, seq_len]), requires_grad=True)\n",
    "\n",
    "    def forward(self, x_enc, x_dec, x_mark_enc=None, x_mark_dec=None):\n",
    "        # Multi-scale Hybrid Decomposition\n",
    "        seasonal_init_enc, trend = self.decomp_multi(x_enc)\n",
    "        trend = self.regression(trend.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        # embedding\n",
    "        zeros = torch.zeros([x_dec.shape[0], self.pred_len, x_dec.shape[2]], device=x_enc.device)\n",
    "        seasonal_init_dec = torch.cat([seasonal_init_enc[:, -self.seq_len:, :], zeros], dim=1)\n",
    "        dec_out = self.dec_embedding(seasonal_init_dec, x_mark_dec)\n",
    "        dec_out = self.conv_trans(dec_out)\n",
    "        dec_out = dec_out[:, -self.pred_len:, :] + trend[:, -self.pred_len:, :]\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658e3ff",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dd094f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:33:49.112727Z",
     "start_time": "2024-04-13T07:33:49.092261Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch, targets_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch, targets_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6a01af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:41:44.650081Z",
     "start_time": "2024-04-13T07:34:12.149808Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:32<10:16, 32.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0260, Validation Loss: 0.0067\n",
      "Validation loss decreased (inf --> 0.006736).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [01:05<09:45, 32.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0024, Validation Loss: 0.0039\n",
      "Validation loss decreased (0.006736 --> 0.003865).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [01:38<09:21, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0018, Validation Loss: 0.0037\n",
      "Validation loss decreased (0.003865 --> 0.003698).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [02:12<08:53, 33.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0016, Validation Loss: 0.0031\n",
      "Validation loss decreased (0.003698 --> 0.003123).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [02:45<08:19, 33.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0015, Validation Loss: 0.0036\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [03:18<07:44, 33.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0014, Validation Loss: 0.0030\n",
      "Validation loss decreased (0.003123 --> 0.003018).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████                                                      | 7/20 [03:53<07:16, 33.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0013, Validation Loss: 0.0029\n",
      "Validation loss decreased (0.003018 --> 0.002908).  Saving model ...\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [04:28<06:49, 34.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0012, Validation Loss: 0.0033\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [05:04<06:23, 34.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0012, Validation Loss: 0.0038\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [05:41<05:52, 35.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0011, Validation Loss: 0.0028\n",
      "Validation loss decreased (0.002908 --> 0.002841).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [06:17<05:19, 35.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0011, Validation Loss: 0.0030\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [06:54<04:48, 36.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0010, Validation Loss: 0.0030\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [07:32<05:01, 37.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0010, Validation Loss: 0.0031\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": MICN,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'd_model': 128,\n",
    "        'n_heads': 8,\n",
    "        'dropout': 0.1,\n",
    "        'd_layers': 1,\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaf496",
   "metadata": {},
   "source": [
    "# 基于Nonstationary_Transformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47cb66",
   "metadata": {},
   "source": [
    "非平稳时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1363432",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad9466",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18fea494",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:43:24.903457Z",
     "start_time": "2024-04-13T07:43:24.897185Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ec9a5ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:43:26.380729Z",
     "start_time": "2024-04-13T07:43:26.332596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "770724f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:43:28.280015Z",
     "start_time": "2024-04-13T07:43:28.272952Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88d19b82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:43:29.824483Z",
     "start_time": "2024-04-13T07:43:29.801350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f77dbfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:43:31.386639Z",
     "start_time": "2024-04-13T07:43:31.380974Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22a9a9d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T07:43:33.279246Z",
     "start_time": "2024-04-13T07:43:32.865151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20496d35",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c17c68c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:19:03.662807Z",
     "start_time": "2024-04-13T08:19:03.257809Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "# Transformer_EncDec类\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
    "                 dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask,\n",
    "            tau=tau, delta=None\n",
    "        )[0])\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )[0])\n",
    "\n",
    "        y = x = self.norm2(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm3(x + y)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask, tau=tau, delta=delta)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# 掩码层\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask    \n",
    "    \n",
    "    \n",
    "# 自注意力层\n",
    "class DSAttention(nn.Module):\n",
    "    '''De-stationary Attention'''\n",
    "\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(DSAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        tau = 1.0 if tau is None else tau.unsqueeze(\n",
    "            1).unsqueeze(1)  # B x 1 x 1 x 1\n",
    "        delta = 0.0 if delta is None else delta.unsqueeze(\n",
    "            1).unsqueeze(1)  # B x 1 x 1 x S\n",
    "\n",
    "        # De-stationary Attention, rescaling pre-softmax score with learned de-stationary factors\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys) * tau + delta\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "    \n",
    "    \n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "class Projector(nn.Module):\n",
    "    '''\n",
    "    MLP to learn the De-stationary factors\n",
    "    '''\n",
    "\n",
    "    def __init__(self, enc_in, seq_len, hidden_dims, hidden_layers, output_dim, kernel_size=3):\n",
    "        super(Projector, self).__init__()\n",
    "\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.series_conv = nn.Conv1d(in_channels=seq_len, out_channels=1, kernel_size=kernel_size, padding=padding,\n",
    "                                     padding_mode='circular', bias=False)\n",
    "\n",
    "        layers = [nn.Linear(2 * enc_in, hidden_dims[0]), nn.ReLU()]\n",
    "        for i in range(hidden_layers - 1):\n",
    "            layers += [nn.Linear(hidden_dims[i], hidden_dims[i + 1]), nn.ReLU()]\n",
    "\n",
    "        layers += [nn.Linear(hidden_dims[-1], output_dim, bias=False)]\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, stats):\n",
    "        # x:     B x S x E\n",
    "        # stats: B x 1 x E\n",
    "        # y:     B x O\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.series_conv(x)  # B x 1 x E\n",
    "        x = torch.cat([x, stats], dim=1)  # B x 2 x E\n",
    "        x = x.view(batch_size, -1)  # B x 2E\n",
    "        y = self.backbone(x)  # B x O\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "# Nonstationary_Transformer模型\n",
    "class Nonstationary_Transformer(nn.Module):\n",
    "    def __init__(self, pred_len, seq_len, label_len, output_attention, enc_in, d_model, \n",
    "                 dropout, factor, n_heads, d_ff, e_layers, d_layers, dec_in, c_out, p_hidden_dims, \n",
    "                p_hidden_layers):\n",
    "        super(Nonstationary_Transformer, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.output_attention = output_attention\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        DSAttention(False, factor, attention_dropout=dropout,\n",
    "                                    output_attention=output_attention), d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu'\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, dropout)\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        DSAttention(True, factor, attention_dropout=dropout,\n",
    "                                    output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    AttentionLayer(\n",
    "                        DSAttention(False, factor, attention_dropout=dropout,\n",
    "                                    output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model),\n",
    "            projection=nn.Linear(d_model, c_out, bias=True)\n",
    "        )\n",
    "\n",
    "        self.tau_learner = Projector(enc_in=enc_in, seq_len=seq_len, hidden_dims=p_hidden_dims,\n",
    "                                     hidden_layers=p_hidden_layers, output_dim=1)\n",
    "        self.delta_learner = Projector(enc_in=enc_in, seq_len=seq_len,\n",
    "                                       hidden_dims=p_hidden_dims, hidden_layers=p_hidden_layers,\n",
    "                                       output_dim=seq_len)\n",
    "\n",
    "    def forward(self, x_enc, x_dec, x_mark_enc=None, x_mark_dec=None):\n",
    "        x_raw = x_enc.clone().detach()\n",
    "\n",
    "        # Normalization\n",
    "        mean_enc = x_enc.mean(1, keepdim=True).detach()  # B x 1 x E\n",
    "        x_enc = x_enc - mean_enc\n",
    "        std_enc = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach()  # B x 1 x E\n",
    "        x_enc = x_enc / std_enc\n",
    "        # B x S x E, B x 1 x E -> B x 1, positive scalar\n",
    "        tau = self.tau_learner(x_raw, std_enc).exp()\n",
    "        # B x S x E, B x 1 x E -> B x S\n",
    "        delta = self.delta_learner(x_raw, mean_enc)\n",
    "\n",
    "        x_dec_new = torch.cat([x_enc[:, -self.label_len:, :], torch.zeros_like(x_dec[:, -self.pred_len:, :])],\n",
    "                              dim=1).to(x_enc.device).clone()\n",
    "\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None, tau=tau, delta=delta)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec_new, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out, x_mask=None, cross_mask=None, tau=tau, delta=delta)\n",
    "        dec_out = dec_out * std_enc + mean_enc\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f79d78",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7aa9f8b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:19:06.127049Z",
     "start_time": "2024-04-13T08:19:06.104638Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch, targets_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch, targets_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2878c71f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:32:32.320521Z",
     "start_time": "2024-04-13T08:19:08.064414Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [01:31<28:50, 91.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0025, Validation Loss: 0.0030\n",
      "Validation loss decreased (inf --> 0.003025).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [03:05<27:57, 93.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0016, Validation Loss: 0.0027\n",
      "Validation loss decreased (0.003025 --> 0.002745).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [04:49<27:43, 97.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0012, Validation Loss: 0.0025\n",
      "Validation loss decreased (0.002745 --> 0.002495).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [06:26<26:01, 97.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0011, Validation Loss: 0.0025\n",
      "Validation loss decreased (0.002495 --> 0.002466).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [08:08<24:50, 99.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0010, Validation Loss: 0.0023\n",
      "Validation loss decreased (0.002466 --> 0.002283).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                         | 6/20 [09:58<23:58, 102.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0010, Validation Loss: 0.0025\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▋                                                     | 7/20 [11:44<22:29, 103.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0009, Validation Loss: 0.0029\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▋                                                     | 7/20 [13:24<24:53, 114.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0009, Validation Loss: 0.0024\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Nonstationary_Transformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'pred_len': 3, \n",
    "        'seq_len': 6,\n",
    "        'label_len': 3,\n",
    "        'd_model': 128,\n",
    "        'output_attention': False,\n",
    "        'enc_in': 2,\n",
    "        'dec_in': 2,\n",
    "        'dropout': 0.1,\n",
    "        'factor': 3, \n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'p_hidden_dims': [256, 256],\n",
    "        'p_hidden_layers': 1,\n",
    "        'c_out': 2,\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10d82f",
   "metadata": {},
   "source": [
    "# 基于Pyraformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d27401",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84b5940",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "accdf4bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:47:02.364131Z",
     "start_time": "2024-04-13T08:47:02.357313Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad782b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:47:03.614503Z",
     "start_time": "2024-04-13T08:47:03.561516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b154ca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:47:04.826105Z",
     "start_time": "2024-04-13T08:47:04.819025Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d8c8a495",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:47:06.544119Z",
     "start_time": "2024-04-13T08:47:06.518142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 1)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 1)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 1)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\"],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c115f8e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:47:08.040123Z",
     "start_time": "2024-04-13T08:47:08.034522Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "acee0507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:47:09.939355Z",
     "start_time": "2024-04-13T08:47:09.534420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 1]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 1]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2885a8ec",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "796c6adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:51:52.796996Z",
     "start_time": "2024-04-13T08:51:52.734329Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# 自注意力模块\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "    \n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "        \n",
    "        \n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "# Pyraformer_EncDec模块\n",
    "def get_mask(input_size, window_size, inner_size):\n",
    "    \"\"\"Get the attention mask of PAM-Naive\"\"\"\n",
    "    # Get the size of all layers\n",
    "    all_size = []\n",
    "    all_size.append(input_size)\n",
    "    for i in range(len(window_size)):\n",
    "        layer_size = math.floor(all_size[i] / window_size[i])\n",
    "        all_size.append(layer_size)\n",
    "\n",
    "    seq_length = sum(all_size)\n",
    "    mask = torch.zeros(seq_length, seq_length)\n",
    "\n",
    "    # get intra-scale mask\n",
    "    inner_window = inner_size // 2\n",
    "    for layer_idx in range(len(all_size)):\n",
    "        start = sum(all_size[:layer_idx])\n",
    "        for i in range(start, start + all_size[layer_idx]):\n",
    "            left_side = max(i - inner_window, start)\n",
    "            right_side = min(i + inner_window + 1, start + all_size[layer_idx])\n",
    "            mask[i, left_side:right_side] = 1\n",
    "\n",
    "    # get inter-scale mask\n",
    "    for layer_idx in range(1, len(all_size)):\n",
    "        start = sum(all_size[:layer_idx])\n",
    "        for i in range(start, start + all_size[layer_idx]):\n",
    "            left_side = (start - all_size[layer_idx - 1]) + \\\n",
    "                (i - start) * window_size[layer_idx - 1]\n",
    "            if i == (start + all_size[layer_idx] - 1):\n",
    "                right_side = start\n",
    "            else:\n",
    "                right_side = (\n",
    "                    start - all_size[layer_idx - 1]) + (i - start + 1) * window_size[layer_idx - 1]\n",
    "            mask[i, left_side:right_side] = 1\n",
    "            mask[left_side:right_side, i] = 1\n",
    "\n",
    "    mask = (1 - mask).bool()\n",
    "\n",
    "    return mask, all_size\n",
    "\n",
    "\n",
    "def refer_points(all_sizes, window_size):\n",
    "    \"\"\"Gather features from PAM's pyramid sequences\"\"\"\n",
    "    input_size = all_sizes[0]\n",
    "    indexes = torch.zeros(input_size, len(all_sizes))\n",
    "\n",
    "    for i in range(input_size):\n",
    "        indexes[i][0] = i\n",
    "        former_index = i\n",
    "        for j in range(1, len(all_sizes)):\n",
    "            start = sum(all_sizes[:j])\n",
    "            inner_layer_idx = former_index - (start - all_sizes[j - 1])\n",
    "            former_index = start + \\\n",
    "                min(inner_layer_idx // window_size[j - 1], all_sizes[j] - 1)\n",
    "            indexes[i][j] = former_index\n",
    "\n",
    "    indexes = indexes.unsqueeze(0).unsqueeze(3)\n",
    "\n",
    "    return indexes.long()\n",
    "\n",
    "\n",
    "class RegularMask():\n",
    "    def __init__(self, mask):\n",
    "        self._mask = mask.unsqueeze(1)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\" Compose with two layers \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_inner, n_head, dropout=0.1, normalize_before=True):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.slf_attn = AttentionLayer(\n",
    "            FullAttention(mask_flag=True, factor=0,\n",
    "                          attention_dropout=dropout, output_attention=False),\n",
    "            d_model, n_head)\n",
    "        self.pos_ffn = PositionwiseFeedForward(\n",
    "            d_model, d_inner, dropout=dropout, normalize_before=normalize_before)\n",
    "\n",
    "    def forward(self, enc_input, slf_attn_mask=None):\n",
    "        attn_mask = RegularMask(slf_attn_mask)\n",
    "        enc_output, _ = self.slf_attn(\n",
    "            enc_input, enc_input, enc_input, attn_mask=attn_mask)\n",
    "        enc_output = self.pos_ffn(enc_output)\n",
    "        return enc_output\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" A encoder model with self attention mechanism. \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, seq_len, d_ff, n_heads, dropout, e_layers, enc_in, \n",
    "                 window_size, inner_size):\n",
    "        super().__init__()\n",
    "\n",
    "        d_bottleneck = d_model//4\n",
    "\n",
    "        self.mask, self.all_size = get_mask(seq_len, window_size, inner_size)\n",
    "        self.indexes = refer_points(self.all_size, window_size)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, d_ff, n_heads, dropout=dropout,\n",
    "                         normalize_before=False) for _ in range(e_layers)\n",
    "        ])  # naive pyramid attention\n",
    "\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, dropout)\n",
    "        self.conv_layers = Bottleneck_Construct(d_model, window_size, d_bottleneck)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc=None):\n",
    "        seq_enc = self.enc_embedding(x_enc, x_mark_enc)\n",
    "\n",
    "        mask = self.mask.repeat(len(seq_enc), 1, 1).to(x_enc.device)\n",
    "        seq_enc = self.conv_layers(seq_enc)\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            seq_enc = self.layers[i](seq_enc, mask)\n",
    "\n",
    "        indexes = self.indexes.repeat(seq_enc.size(\n",
    "            0), 1, 1, seq_enc.size(2)).to(seq_enc.device)\n",
    "        indexes = indexes.view(seq_enc.size(0), -1, seq_enc.size(2))\n",
    "        all_enc = torch.gather(seq_enc, 1, indexes)\n",
    "        seq_enc = all_enc.view(seq_enc.size(0), self.all_size[0], -1)\n",
    "\n",
    "        return seq_enc\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, c_in, window_size):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.downConv = nn.Conv1d(in_channels=c_in,\n",
    "                                  out_channels=c_in,\n",
    "                                  kernel_size=window_size,\n",
    "                                  stride=window_size)\n",
    "        self.norm = nn.BatchNorm1d(c_in)\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downConv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bottleneck_Construct(nn.Module):\n",
    "    \"\"\"Bottleneck convolution CSCM\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, window_size, d_inner):\n",
    "        super(Bottleneck_Construct, self).__init__()\n",
    "        if not isinstance(window_size, list):\n",
    "            self.conv_layers = nn.ModuleList([\n",
    "                ConvLayer(d_inner, window_size),\n",
    "                ConvLayer(d_inner, window_size),\n",
    "                ConvLayer(d_inner, window_size)\n",
    "            ])\n",
    "        else:\n",
    "            self.conv_layers = []\n",
    "            for i in range(len(window_size)):\n",
    "                self.conv_layers.append(ConvLayer(d_inner, window_size[i]))\n",
    "            self.conv_layers = nn.ModuleList(self.conv_layers)\n",
    "        self.up = Linear(d_inner, d_model)\n",
    "        self.down = Linear(d_model, d_inner)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, enc_input):\n",
    "        temp_input = self.down(enc_input).permute(0, 2, 1)\n",
    "        all_inputs = []\n",
    "        for i in range(len(self.conv_layers)):\n",
    "            temp_input = self.conv_layers[i](temp_input)\n",
    "            all_inputs.append(temp_input)\n",
    "\n",
    "        all_inputs = torch.cat(all_inputs, dim=2).transpose(1, 2)\n",
    "        all_inputs = self.up(all_inputs)\n",
    "        all_inputs = torch.cat([enc_input, all_inputs], dim=1)\n",
    "\n",
    "        all_inputs = self.norm(all_inputs)\n",
    "        return all_inputs\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\" Two-layer position-wise feed-forward neural network. \"\"\"\n",
    "\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1, normalize_before=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.normalize_before = normalize_before\n",
    "\n",
    "        self.w_1 = nn.Linear(d_in, d_hid)\n",
    "        self.w_2 = nn.Linear(d_hid, d_in)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_in, eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.normalize_before:\n",
    "            x = self.layer_norm(x)\n",
    "\n",
    "        x = F.gelu(self.w_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.w_2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + residual\n",
    "\n",
    "        if not self.normalize_before:\n",
    "            x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# Pyraformer模型\n",
    "class Pyraformer(nn.Module):\n",
    "    \"\"\" \n",
    "    Pyraformer: Pyramidal attention to reduce complexity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, task_name, pred_len, d_model, seq_len, d_ff, n_heads, dropout, e_layers, enc_in,\n",
    "                 window_size=[4,4], inner_size=5):\n",
    "        \"\"\"\n",
    "        window_size: list, the downsample window size in pyramidal attention.\n",
    "        inner_size: int, the size of neighbour attention\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.task_name = task_name\n",
    "        self.pred_len = pred_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "        if self.task_name == 'short_term_forecast':\n",
    "            window_size = [2,2]\n",
    "        self.encoder = Encoder(d_model, seq_len, d_ff, n_heads, dropout, e_layers, enc_in, \n",
    "                 window_size, inner_size)\n",
    "\n",
    "        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n",
    "            self.projection = nn.Linear(\n",
    "                (len(window_size)+1)*self.d_model, self.pred_len * enc_in)\n",
    "\n",
    "    def long_forecast(self, x_enc, x_mark_enc):\n",
    "        enc_out = self.encoder(x_enc, x_mark_enc)[:, -1, :]\n",
    "        dec_out = self.projection(enc_out).view(\n",
    "            enc_out.size(0), self.pred_len, -1)\n",
    "        return dec_out\n",
    "    \n",
    "    def short_forecast(self, x_enc, x_mark_enc):\n",
    "        # Normalization\n",
    "        mean_enc = x_enc.mean(1, keepdim=True).detach()  # B x 1 x E\n",
    "        x_enc = x_enc - mean_enc\n",
    "        std_enc = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach()  # B x 1 x E\n",
    "        x_enc = x_enc / std_enc\n",
    "\n",
    "        enc_out = self.encoder(x_enc, x_mark_enc)[:, -1, :]\n",
    "        dec_out = self.projection(enc_out).view(\n",
    "            enc_out.size(0), self.pred_len, -1)\n",
    "        \n",
    "        dec_out = dec_out * std_enc + mean_enc\n",
    "        return dec_out\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc=None):\n",
    "        if self.task_name == 'long_term_forecast':\n",
    "            dec_out = self.long_forecast(x_enc, x_mark_enc)\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        if self.task_name == 'short_term_forecast':\n",
    "            dec_out = self.short_forecast(x_enc, x_mark_enc)\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9112cc97",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a944cfbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T08:51:57.774356Z",
     "start_time": "2024-04-13T08:51:57.748357Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68f150b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:11:18.330550Z",
     "start_time": "2024-04-13T08:51:59.105284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [01:00<19:00, 60.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0035, Validation Loss: 0.0046\n",
      "Validation loss decreased (inf --> 0.004638).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [02:03<18:32, 61.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0026, Validation Loss: 0.0037\n",
      "Validation loss decreased (0.004638 --> 0.003724).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [03:00<16:59, 59.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0024, Validation Loss: 0.0034\n",
      "Validation loss decreased (0.003724 --> 0.003406).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [04:01<16:04, 60.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0023, Validation Loss: 0.0031\n",
      "Validation loss decreased (0.003406 --> 0.003099).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [04:59<14:50, 59.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0021, Validation Loss: 0.0032\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [05:56<13:41, 58.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0021, Validation Loss: 0.0029\n",
      "Validation loss decreased (0.003099 --> 0.002947).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████                                                      | 7/20 [06:54<12:38, 58.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0019, Validation Loss: 0.0034\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [07:49<11:27, 57.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0018, Validation Loss: 0.0039\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [08:47<10:33, 57.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0018, Validation Loss: 0.0032\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [09:47<09:42, 58.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0018, Validation Loss: 0.0028\n",
      "Validation loss decreased (0.002947 --> 0.002831).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [10:44<08:40, 57.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0017, Validation Loss: 0.0030\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [11:42<07:42, 57.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0016, Validation Loss: 0.0027\n",
      "Validation loss decreased (0.002831 --> 0.002737).  Saving model ...\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [12:36<06:38, 56.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0016, Validation Loss: 0.0029\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [13:34<05:43, 57.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0015, Validation Loss: 0.0026\n",
      "Validation loss decreased (0.002737 --> 0.002588).  Saving model ...\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [14:34<04:49, 57.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0015, Validation Loss: 0.0025\n",
      "Validation loss decreased (0.002588 --> 0.002524).  Saving model ...\n",
      "Updating learning rate to 0.00014644660940672628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [15:31<03:50, 57.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0014, Validation Loss: 0.0025\n",
      "Validation loss decreased (0.002524 --> 0.002475).  Saving model ...\n",
      "Updating learning rate to 9.549150281252633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [16:27<02:51, 57.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0014, Validation Loss: 0.0024\n",
      "Validation loss decreased (0.002475 --> 0.002380).  Saving model ...\n",
      "Updating learning rate to 5.449673790581611e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [17:24<01:54, 57.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0014, Validation Loss: 0.0025\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Updating learning rate to 2.4471741852423235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [18:22<00:57, 57.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0014, Validation Loss: 0.0024\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Updating learning rate to 6.15582970243117e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [19:18<00:00, 57.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0014, Validation Loss: 0.0024\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Updating learning rate to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load'],\n",
    "        \"features\": 'MS'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Pyraformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 7,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'enc_in': 2, \n",
    "        'task_name': 'short_term_forecast',\n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'd_model': 128,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afffa2f",
   "metadata": {},
   "source": [
    "# 基于Reformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14414277",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad49d3ef",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8271a52a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:22:47.580999Z",
     "start_time": "2024-04-13T09:22:47.574993Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "599595a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:22:48.583663Z",
     "start_time": "2024-04-13T09:22:48.537237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c2db148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:22:49.608438Z",
     "start_time": "2024-04-13T09:22:49.600989Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ccb51c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:22:50.830172Z",
     "start_time": "2024-04-13T09:22:50.806228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f6d84a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:22:52.478621Z",
     "start_time": "2024-04-13T09:22:52.472509Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8e773fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:22:54.490260Z",
     "start_time": "2024-04-13T09:22:54.077995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f17fa",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d258926d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:50:18.236007Z",
     "start_time": "2024-04-13T09:50:18.137095Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# Transformer_EncDec类\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "    \n",
    "    \n",
    "# 自编码类\n",
    "TOKEN_SELF_ATTN_VALUE = -5e4 # carefully set for half precision to work\n",
    "\n",
    "def max_neg_value(tensor):\n",
    "    return -torch.finfo(tensor.dtype).max\n",
    "\n",
    "\n",
    "def batched_index_select(values, indices):\n",
    "    last_dim = values.shape[-1]\n",
    "    return values.gather(1, indices[:, :, None].expand(-1, -1, last_dim))\n",
    "\n",
    "\n",
    "def sort_key_val(t1, t2, dim=-1):\n",
    "    values, indices = t1.sort(dim=dim)\n",
    "    t2 = t2.expand_as(t1)\n",
    "    return values, t2.gather(dim, indices)\n",
    "\n",
    "\n",
    "def process_inputs_chunk(fn, chunks=1, dim=0):\n",
    "    def inner_fn(*args, **kwargs):\n",
    "        keys, values, len_args = kwargs.keys(), kwargs.values(), len(args)\n",
    "        chunked_args = list(zip(*map(lambda x: x.chunk(chunks, dim=dim), list(args) + list(values))))\n",
    "        all_args = map(lambda x: (x[:len_args], dict(zip(keys, x[len_args:]))), chunked_args)\n",
    "        outputs = [fn(*c_args, **c_kwargs) for c_args, c_kwargs in all_args]\n",
    "        return tuple(map(lambda x: torch.cat(x, dim=dim), zip(*outputs)))\n",
    "    return inner_fn\n",
    "\n",
    "\n",
    "def split_at_index(dim, index, t):\n",
    "    pre_slices = (slice(None),) * dim\n",
    "    l = (*pre_slices, slice(None, index))\n",
    "    r = (*pre_slices, slice(index, None))\n",
    "    return t[l], t[r]\n",
    "\n",
    "\n",
    "def merge_dims(ind_from, ind_to, tensor):\n",
    "    shape = list(tensor.shape)\n",
    "    arr_slice = slice(ind_from, ind_to + 1)\n",
    "    shape[arr_slice] = [reduce(mul, shape[arr_slice])]\n",
    "    return tensor.reshape(*shape)\n",
    "\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "\n",
    "def default(val, default_val):\n",
    "    return default_val if val is None else val\n",
    "\n",
    "\n",
    "def cache_method_decorator(cache_attr, cache_namespace, reexecute = False):\n",
    "    def inner_fn(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapper(self, *args, key_namespace=None, fetch=False, set_cache=True, **kwargs):\n",
    "            namespace_str = str(default(key_namespace, ''))\n",
    "            _cache = getattr(self, cache_attr)\n",
    "            _keyname = f'{cache_namespace}:{namespace_str}'\n",
    "\n",
    "            if fetch:\n",
    "                val = _cache[_keyname]\n",
    "                if reexecute:\n",
    "                    fn(self, *args, **kwargs)\n",
    "            else:\n",
    "                val = fn(self, *args, **kwargs)\n",
    "                if set_cache:\n",
    "                    setattr(self, cache_attr, {**_cache, **{_keyname: val}})\n",
    "            return val\n",
    "        return wrapper\n",
    "    return inner_fn\n",
    "\n",
    "\n",
    "class FullQKAttention(nn.Module):\n",
    "    def __init__(self, causal = False, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.causal = causal\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, qk, v, query_len = None, input_mask = None, input_attn_mask = None, **kwargs):\n",
    "        b, seq_len, dim = qk.shape\n",
    "        query_len = default(query_len, seq_len)\n",
    "        t = query_len\n",
    "\n",
    "        q = qk[:, 0:query_len]\n",
    "        qk = F.normalize(qk, 2, dim=-1).type_as(q)\n",
    "\n",
    "        dot = torch.einsum('bie,bje->bij', q, qk) * (dim ** -0.5)\n",
    "\n",
    "        # qk attention requires tokens not attend to self\n",
    "        i = torch.arange(t)\n",
    "        dot[:, i, i] = TOKEN_SELF_ATTN_VALUE\n",
    "        masked_value = max_neg_value(dot)\n",
    "\n",
    "        # Input mask for padding in variable lengthed sequences\n",
    "        if input_mask is not None:\n",
    "            mask = input_mask[:, 0:query_len, None] * input_mask[:, None, :]\n",
    "            mask = F.pad(mask, (0, seq_len - mask.shape[-1]), value=True)\n",
    "            dot.masked_fill_(~mask, masked_value)\n",
    "\n",
    "        # Mask for post qk attention logits of the input sequence\n",
    "        if input_attn_mask is not None:\n",
    "            input_attn_mask = F.pad(input_attn_mask, (0, seq_len - input_attn_mask.shape[-1]), value=True)\n",
    "            dot.masked_fill_(~input_attn_mask, masked_value)\n",
    "\n",
    "        if self.causal:\n",
    "            i, j = torch.triu_indices(t, t, 1)\n",
    "            dot[:, i, j] = masked_value\n",
    "\n",
    "        dot = dot.softmax(dim=-1)\n",
    "        dot = self.dropout(dot)\n",
    "\n",
    "        out = torch.einsum('bij,bje->bie', dot, v)\n",
    "\n",
    "        return out, dot, torch.empty(0)\n",
    "\n",
    "    \n",
    "class LocalAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_size,\n",
    "        causal = False,\n",
    "        look_backward = 1,\n",
    "        look_forward = None,\n",
    "        dropout = 0.,\n",
    "        shared_qk = False,\n",
    "        rel_pos_emb_config = None,\n",
    "        dim = None,\n",
    "        autopad = False,\n",
    "        exact_windowsize = False,\n",
    "        scale = None,\n",
    "        use_rotary_pos_emb = True,\n",
    "        use_xpos = False,\n",
    "        xpos_scale_base = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        look_forward = default(look_forward, 0 if causal else 1)\n",
    "        assert not (causal and look_forward > 0), 'you cannot look forward if causal'\n",
    "\n",
    "        self.scale = scale\n",
    "\n",
    "        self.window_size = window_size\n",
    "        self.autopad = autopad\n",
    "        self.exact_windowsize = exact_windowsize\n",
    "\n",
    "        self.causal = causal\n",
    "\n",
    "        self.look_backward = look_backward\n",
    "        self.look_forward = look_forward\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.shared_qk = shared_qk\n",
    "\n",
    "        # relative positions\n",
    "\n",
    "        self.rel_pos = None\n",
    "        self.use_xpos = use_xpos\n",
    "\n",
    "        if use_rotary_pos_emb and (exists(rel_pos_emb_config) or exists(dim)):  # backwards compatible with old `rel_pos_emb_config` deprecated argument\n",
    "            if exists(rel_pos_emb_config):\n",
    "                dim = rel_pos_emb_config[0]\n",
    "\n",
    "            self.rel_pos = SinusoidalEmbeddings(\n",
    "                dim,\n",
    "                use_xpos = use_xpos,\n",
    "                scale_base = default(xpos_scale_base, window_size // 2)\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        q, k, v,\n",
    "        mask = None,\n",
    "        input_mask = None,\n",
    "        attn_bias = None,\n",
    "        window_size = None\n",
    "    ):\n",
    "\n",
    "        mask = default(mask, input_mask)\n",
    "\n",
    "        assert not (exists(window_size) and not self.use_xpos), 'cannot perform window size extrapolation if xpos is not turned on'\n",
    "\n",
    "        shape, autopad, pad_value, window_size, causal, look_backward, look_forward, shared_qk = q.shape, self.autopad, -1, default(window_size, self.window_size), self.causal, self.look_backward, self.look_forward, self.shared_qk\n",
    "\n",
    "        # https://github.com/arogozhnikov/einops/blob/master/docs/4-pack-and-unpack.ipynb\n",
    "        (q, packed_shape), (k, _), (v, _) = map(lambda t: pack([t], '* n d'), (q, k, v))\n",
    "\n",
    "        # auto padding\n",
    "\n",
    "        if autopad:\n",
    "            orig_seq_len = q.shape[1]\n",
    "            (needed_pad, q), (_, k), (_, v) = map(lambda t: pad_to_multiple(t, self.window_size, dim = -2), (q, k, v))\n",
    "\n",
    "        b, n, dim_head, device, dtype = *q.shape, q.device, q.dtype\n",
    "\n",
    "        scale = default(self.scale, dim_head ** -0.5)\n",
    "\n",
    "        assert (n % window_size) == 0, f'sequence length {n} must be divisible by window size {window_size} for local attention'\n",
    "\n",
    "        windows = n // window_size\n",
    "\n",
    "        if shared_qk:\n",
    "            k = l2norm(k)\n",
    "\n",
    "        seq = torch.arange(n, device = device)\n",
    "        b_t = rearrange(seq, '(w n) -> 1 w n', w = windows, n = window_size)\n",
    "\n",
    "        # bucketing\n",
    "\n",
    "        bq, bk, bv = map(lambda t: rearrange(t, 'b (w n) d -> b w n d', w = windows), (q, k, v))\n",
    "\n",
    "        bq = bq * scale\n",
    "\n",
    "        look_around_kwargs = dict(\n",
    "            backward =  look_backward,\n",
    "            forward =  look_forward,\n",
    "            pad_value = pad_value\n",
    "        )\n",
    "\n",
    "        bk = look_around(bk, **look_around_kwargs)\n",
    "        bv = look_around(bv, **look_around_kwargs)\n",
    "\n",
    "        # rotary embeddings\n",
    "\n",
    "        if exists(self.rel_pos):\n",
    "            pos_emb, xpos_scale = self.rel_pos(bk)\n",
    "            bq, bk = apply_rotary_pos_emb(bq, bk, pos_emb, scale = xpos_scale)\n",
    "\n",
    "        # calculate positions for masking\n",
    "\n",
    "        bq_t = b_t\n",
    "        bq_k = look_around(b_t, **look_around_kwargs)\n",
    "\n",
    "        bq_t = rearrange(bq_t, '... i -> ... i 1')\n",
    "        bq_k = rearrange(bq_k, '... j -> ... 1 j')\n",
    "\n",
    "        pad_mask = bq_k == pad_value\n",
    "\n",
    "        sim = einsum('b h i e, b h j e -> b h i j', bq, bk)\n",
    "\n",
    "        if exists(attn_bias):\n",
    "            heads = attn_bias.shape[0]\n",
    "            assert (b % heads) == 0\n",
    "\n",
    "            attn_bias = repeat(attn_bias, 'h i j -> (b h) 1 i j', b = b // heads)\n",
    "            sim = sim + attn_bias\n",
    "\n",
    "        mask_value = max_neg_value(sim)\n",
    "\n",
    "        if shared_qk:\n",
    "            self_mask = bq_t == bq_k\n",
    "            sim = sim.masked_fill(self_mask, TOKEN_SELF_ATTN_VALUE)\n",
    "            del self_mask\n",
    "\n",
    "        if causal:\n",
    "            causal_mask = bq_t < bq_k\n",
    "\n",
    "            if self.exact_windowsize:\n",
    "                max_causal_window_size = (self.window_size * self.look_backward)\n",
    "                causal_mask = causal_mask | (bq_t > (bq_k + max_causal_window_size))\n",
    "\n",
    "            sim = sim.masked_fill(causal_mask, mask_value)\n",
    "            del causal_mask\n",
    "\n",
    "        # masking out for exact window size for non-causal\n",
    "        # as well as masking out for padding value\n",
    "\n",
    "        if not causal and self.exact_windowsize:\n",
    "            max_backward_window_size = (self.window_size * self.look_backward)\n",
    "            max_forward_window_size = (self.window_size * self.look_forward)\n",
    "            window_mask = ((bq_k - max_forward_window_size) > bq_t) | (bq_t > (bq_k + max_backward_window_size)) | pad_mask\n",
    "            sim = sim.masked_fill(window_mask, mask_value)\n",
    "        else:\n",
    "            sim = sim.masked_fill(pad_mask, mask_value)\n",
    "\n",
    "        # take care of key padding mask passed in\n",
    "\n",
    "        if exists(mask):\n",
    "            batch = mask.shape[0]\n",
    "            assert (b % batch) == 0\n",
    "\n",
    "            h = b // mask.shape[0]\n",
    "\n",
    "            if autopad:\n",
    "                _, mask = pad_to_multiple(mask, window_size, dim = -1, value = False)\n",
    "\n",
    "            mask = rearrange(mask, '... (w n) -> (...) w n', w = windows, n = window_size)\n",
    "            mask = look_around(mask, **{**look_around_kwargs, 'pad_value': False})\n",
    "            mask = rearrange(mask, '... j -> ... 1 j')\n",
    "            mask = repeat(mask, 'b ... -> (b h) ...', h = h)\n",
    "            sim = sim.masked_fill(~mask, mask_value)\n",
    "            del mask\n",
    "\n",
    "        # attention\n",
    "\n",
    "        attn = sim.softmax(dim = -1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        # aggregation\n",
    "\n",
    "        out = einsum('b h i j, b h j e -> b h i e', attn, bv)\n",
    "        out = rearrange(out, 'b w n d -> b (w n) d')\n",
    "\n",
    "        if autopad:\n",
    "            out = out[:, :orig_seq_len, :]\n",
    "\n",
    "        out, *_ = unpack(out, packed_shape, '* n d')\n",
    "        return out\n",
    "\n",
    "\n",
    "class LSHSelfAttention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, bucket_size = 64, n_hashes = 8, causal = False, dim_head = None, attn_chunks = 1, random_rotations_per_head = False, attend_across_buckets = True, allow_duplicate_attention = True, num_mem_kv = 0, one_value_head = False, use_full_attn = False, full_attn_thres = None, return_attn = False, post_attn_dropout = 0., dropout = 0., n_local_attn_heads = 0, **kwargs):\n",
    "        super().__init__()\n",
    "        assert dim_head or (dim % heads) == 0, 'dimensions must be divisible by number of heads'\n",
    "        assert n_local_attn_heads < heads, 'local attention heads must be less than number of heads'\n",
    "\n",
    "        dim_head = default(dim_head, dim // heads)\n",
    "        dim_heads = dim_head * heads\n",
    "\n",
    "        self.dim = dim\n",
    "        self.heads = heads\n",
    "        self.dim_head = dim_head\n",
    "        self.attn_chunks = default(attn_chunks, 1)\n",
    "\n",
    "        self.v_head_repeats = (heads if one_value_head else 1)\n",
    "        v_dim = dim_heads // self.v_head_repeats\n",
    "\n",
    "        self.toqk = nn.Linear(dim, dim_heads, bias = False)\n",
    "        self.tov = nn.Linear(dim, v_dim, bias = False)\n",
    "        self.to_out = nn.Linear(dim_heads, dim)\n",
    "\n",
    "        self.bucket_size = bucket_size\n",
    "        self.lsh_attn = LSHAttention(bucket_size=bucket_size, n_hashes=n_hashes, causal=causal, random_rotations_per_head=random_rotations_per_head, attend_across_buckets = attend_across_buckets,  allow_duplicate_attention = allow_duplicate_attention, return_attn = return_attn, dropout = dropout, **kwargs)\n",
    "        self.full_attn = FullQKAttention(causal=causal, dropout=dropout)\n",
    "        self.post_attn_dropout = nn.Dropout(post_attn_dropout)\n",
    "\n",
    "        self.use_full_attn = use_full_attn\n",
    "        self.full_attn_thres = default(full_attn_thres, bucket_size)\n",
    "\n",
    "        self.num_mem_kv = num_mem_kv\n",
    "        self.mem_kv = nn.Parameter(torch.randn(1, num_mem_kv, dim, requires_grad=True)) if num_mem_kv > 0 else None\n",
    "\n",
    "        self.n_local_attn_heads = n_local_attn_heads\n",
    "        self.local_attn = LocalAttention(window_size=bucket_size * 2, causal=causal, dropout=dropout, shared_qk=True, look_forward=(1 if not causal else 0))\n",
    "\n",
    "        self.callback = None\n",
    "\n",
    "    def forward(self, x, keys = None, input_mask = None, input_attn_mask = None, context_mask = None, pos_emb = None, **kwargs):\n",
    "        device, dtype = x.device, x.dtype\n",
    "        b, t, e, h, dh, m, l_h = *x.shape, self.heads, self.dim_head, self.num_mem_kv, self.n_local_attn_heads\n",
    "\n",
    "        mem_kv = default(self.mem_kv, torch.empty(b, 0, e, dtype=dtype, device=device))\n",
    "        mem = mem_kv.expand(b, m, -1)\n",
    "\n",
    "        keys = default(keys, torch.empty(b, 0, e, dtype=dtype, device=device))\n",
    "        c = keys.shape[1]\n",
    "\n",
    "        kv_len = t + m + c\n",
    "        use_full_attn = self.use_full_attn or kv_len <= self.full_attn_thres\n",
    "\n",
    "        x = torch.cat((x, mem, keys), dim=1)\n",
    "        qk = self.toqk(x)\n",
    "        v = self.tov(x)\n",
    "        v = v.repeat(1, 1, self.v_head_repeats)\n",
    "\n",
    "        def merge_heads(v):\n",
    "            return v.view(b, kv_len, h, -1).transpose(1, 2)\n",
    "\n",
    "        def split_heads(v):\n",
    "            return v.view(b, h, t, -1).transpose(1, 2).contiguous()\n",
    "\n",
    "        merge_batch_and_heads = partial(merge_dims, 0, 1)\n",
    "\n",
    "        qk, v = map(merge_heads, (qk, v))\n",
    "\n",
    "        has_local = l_h > 0\n",
    "        lsh_h = h - l_h\n",
    "\n",
    "        split_index_fn = partial(split_at_index, 1, l_h)\n",
    "        (lqk, qk), (lv, v) = map(split_index_fn, (qk, v))\n",
    "        lqk, qk, lv, v = map(merge_batch_and_heads, (lqk, qk, lv, v))\n",
    "\n",
    "        masks = {}\n",
    "        if input_mask is not None or context_mask is not None:\n",
    "            default_mask = torch.tensor([True], device=device)\n",
    "            i_mask = default(input_mask, default_mask.expand(b, t))\n",
    "            m_mask = default_mask.expand(b, m)\n",
    "            c_mask = default(context_mask, default_mask.expand(b, c))\n",
    "            mask = torch.cat((i_mask, m_mask, c_mask), dim=1)\n",
    "            mask = merge_batch_and_heads(expand_dim(1, lsh_h, mask))\n",
    "            masks['input_mask'] = mask\n",
    "\n",
    "        if input_attn_mask is not None:\n",
    "            input_attn_mask = merge_batch_and_heads(expand_dim(1, lsh_h, input_attn_mask))\n",
    "            masks['input_attn_mask'] = input_attn_mask\n",
    "\n",
    "        attn_fn = self.lsh_attn if not use_full_attn else self.full_attn\n",
    "        partial_attn_fn = partial(attn_fn, query_len = t, pos_emb = pos_emb, **kwargs)\n",
    "        attn_fn_in_chunks = process_inputs_chunk(partial_attn_fn, chunks = self.attn_chunks)\n",
    "\n",
    "        out, attn, buckets = attn_fn_in_chunks(qk, v, **masks)\n",
    "\n",
    "        if self.callback is not None:\n",
    "            self.callback(attn.reshape(b, lsh_h, t, -1), buckets.reshape(b, lsh_h, -1))\n",
    "\n",
    "        if has_local:\n",
    "            lqk, lv = lqk[:, :t], lv[:, :t]\n",
    "            local_out = self.local_attn(lqk, lqk, lv, input_mask=input_mask)\n",
    "            local_out = local_out.reshape(b, l_h, t, -1)\n",
    "            out = out.reshape(b, lsh_h, t, -1)\n",
    "            out = torch.cat((local_out, out), dim=1)\n",
    "\n",
    "        out = split_heads(out).view(b, t, -1)\n",
    "        out = self.to_out(out)\n",
    "        return self.post_attn_dropout(out)\n",
    "\n",
    "    \n",
    "class LSHSelfAttention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, bucket_size = 64, n_hashes = 8, causal = False, dim_head = None, attn_chunks = 1, random_rotations_per_head = False, attend_across_buckets = True, allow_duplicate_attention = True, num_mem_kv = 0, one_value_head = False, use_full_attn = False, full_attn_thres = None, return_attn = False, post_attn_dropout = 0., dropout = 0., n_local_attn_heads = 0, **kwargs):\n",
    "        super().__init__()\n",
    "        assert dim_head or (dim % heads) == 0, 'dimensions must be divisible by number of heads'\n",
    "        assert n_local_attn_heads < heads, 'local attention heads must be less than number of heads'\n",
    "\n",
    "        dim_head = default(dim_head, dim // heads)\n",
    "        dim_heads = dim_head * heads\n",
    "\n",
    "        self.dim = dim\n",
    "        self.heads = heads\n",
    "        self.dim_head = dim_head\n",
    "        self.attn_chunks = default(attn_chunks, 1)\n",
    "\n",
    "        self.v_head_repeats = (heads if one_value_head else 1)\n",
    "        v_dim = dim_heads // self.v_head_repeats\n",
    "\n",
    "        self.toqk = nn.Linear(dim, dim_heads, bias = False)\n",
    "        self.tov = nn.Linear(dim, v_dim, bias = False)\n",
    "        self.to_out = nn.Linear(dim_heads, dim)\n",
    "\n",
    "        self.bucket_size = bucket_size\n",
    "        self.lsh_attn = LSHAttention(bucket_size=bucket_size, n_hashes=n_hashes, causal=causal, random_rotations_per_head=random_rotations_per_head, attend_across_buckets = attend_across_buckets,  allow_duplicate_attention = allow_duplicate_attention, return_attn = return_attn, dropout = dropout, **kwargs)\n",
    "        self.full_attn = FullQKAttention(causal=causal, dropout=dropout)\n",
    "        self.post_attn_dropout = nn.Dropout(post_attn_dropout)\n",
    "\n",
    "        self.use_full_attn = use_full_attn\n",
    "        self.full_attn_thres = default(full_attn_thres, bucket_size)\n",
    "\n",
    "        self.num_mem_kv = num_mem_kv\n",
    "        self.mem_kv = nn.Parameter(torch.randn(1, num_mem_kv, dim, requires_grad=True)) if num_mem_kv > 0 else None\n",
    "\n",
    "        self.n_local_attn_heads = n_local_attn_heads\n",
    "        self.local_attn = LocalAttention(window_size=bucket_size * 2, causal=causal, dropout=dropout, shared_qk=True, look_forward=(1 if not causal else 0))\n",
    "\n",
    "        self.callback = None\n",
    "\n",
    "    def forward(self, x, keys = None, input_mask = None, input_attn_mask = None, context_mask = None, pos_emb = None, **kwargs):\n",
    "        device, dtype = x.device, x.dtype\n",
    "        b, t, e, h, dh, m, l_h = *x.shape, self.heads, self.dim_head, self.num_mem_kv, self.n_local_attn_heads\n",
    "\n",
    "        mem_kv = default(self.mem_kv, torch.empty(b, 0, e, dtype=dtype, device=device))\n",
    "        mem = mem_kv.expand(b, m, -1)\n",
    "\n",
    "        keys = default(keys, torch.empty(b, 0, e, dtype=dtype, device=device))\n",
    "        c = keys.shape[1]\n",
    "\n",
    "        kv_len = t + m + c\n",
    "        use_full_attn = self.use_full_attn or kv_len <= self.full_attn_thres\n",
    "\n",
    "        x = torch.cat((x, mem, keys), dim=1)\n",
    "        qk = self.toqk(x)\n",
    "        v = self.tov(x)\n",
    "        v = v.repeat(1, 1, self.v_head_repeats)\n",
    "\n",
    "        def merge_heads(v):\n",
    "            return v.view(b, kv_len, h, -1).transpose(1, 2)\n",
    "\n",
    "        def split_heads(v):\n",
    "            return v.view(b, h, t, -1).transpose(1, 2).contiguous()\n",
    "\n",
    "        merge_batch_and_heads = partial(merge_dims, 0, 1)\n",
    "\n",
    "        qk, v = map(merge_heads, (qk, v))\n",
    "\n",
    "        has_local = l_h > 0\n",
    "        lsh_h = h - l_h\n",
    "\n",
    "        split_index_fn = partial(split_at_index, 1, l_h)\n",
    "        (lqk, qk), (lv, v) = map(split_index_fn, (qk, v))\n",
    "        lqk, qk, lv, v = map(merge_batch_and_heads, (lqk, qk, lv, v))\n",
    "\n",
    "        masks = {}\n",
    "        if input_mask is not None or context_mask is not None:\n",
    "            default_mask = torch.tensor([True], device=device)\n",
    "            i_mask = default(input_mask, default_mask.expand(b, t))\n",
    "            m_mask = default_mask.expand(b, m)\n",
    "            c_mask = default(context_mask, default_mask.expand(b, c))\n",
    "            mask = torch.cat((i_mask, m_mask, c_mask), dim=1)\n",
    "            mask = merge_batch_and_heads(expand_dim(1, lsh_h, mask))\n",
    "            masks['input_mask'] = mask\n",
    "\n",
    "        if input_attn_mask is not None:\n",
    "            input_attn_mask = merge_batch_and_heads(expand_dim(1, lsh_h, input_attn_mask))\n",
    "            masks['input_attn_mask'] = input_attn_mask\n",
    "\n",
    "        attn_fn = self.lsh_attn if not use_full_attn else self.full_attn\n",
    "        partial_attn_fn = partial(attn_fn, query_len = t, pos_emb = pos_emb, **kwargs)\n",
    "        attn_fn_in_chunks = process_inputs_chunk(partial_attn_fn, chunks = self.attn_chunks)\n",
    "\n",
    "        out, attn, buckets = attn_fn_in_chunks(qk, v, **masks)\n",
    "\n",
    "        if self.callback is not None:\n",
    "            self.callback(attn.reshape(b, lsh_h, t, -1), buckets.reshape(b, lsh_h, -1))\n",
    "\n",
    "        if has_local:\n",
    "            lqk, lv = lqk[:, :t], lv[:, :t]\n",
    "            local_out = self.local_attn(lqk, lqk, lv, input_mask=input_mask)\n",
    "            local_out = local_out.reshape(b, l_h, t, -1)\n",
    "            out = out.reshape(b, lsh_h, t, -1)\n",
    "            out = torch.cat((local_out, out), dim=1)\n",
    "\n",
    "        out = split_heads(out).view(b, t, -1)\n",
    "        out = self.to_out(out)\n",
    "        return self.post_attn_dropout(out)\n",
    "\n",
    "\n",
    "class ReformerLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None, causal=False, bucket_size=4, n_hashes=4):\n",
    "        super().__init__()\n",
    "        self.bucket_size = bucket_size\n",
    "        self.attn = LSHSelfAttention(\n",
    "            dim=d_model,\n",
    "            heads=n_heads,\n",
    "            bucket_size=bucket_size,\n",
    "            n_hashes=n_hashes,\n",
    "            causal=causal\n",
    "        )\n",
    "\n",
    "    def fit_length(self, queries):\n",
    "        # inside reformer: assert N % (bucket_size * 2) == 0\n",
    "        B, N, C = queries.shape\n",
    "        if N % (self.bucket_size * 2) == 0:\n",
    "            return queries\n",
    "        else:\n",
    "            # fill the time series\n",
    "            fill_len = (self.bucket_size * 2) - (N % (self.bucket_size * 2))\n",
    "            return torch.cat([queries, torch.zeros([B, fill_len, C]).to(queries.device)], dim=1)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau, delta):\n",
    "        # in Reformer: defalut queries=keys\n",
    "        B, N, C = queries.shape\n",
    "        queries = self.attn(self.fit_length(queries))[:, :N, :]\n",
    "        return queries, None\n",
    "\n",
    "    \n",
    "# Reformer模型\n",
    "class Reformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Reformer with O(LlogL) complexity\n",
    "    \"\"\"\n",
    "    def __init__(self, task_name, pred_len, seq_len, enc_in, d_model, dropout, n_heads, d_ff, \n",
    "                 e_layers, c_out, bucket_size=4, n_hashes=4):\n",
    "        \"\"\"\n",
    "        bucket_size: int, \n",
    "        n_hashes: int, \n",
    "        \"\"\"\n",
    "        super(Reformer, self).__init__()\n",
    "        self.task_name = task_name\n",
    "        self.pred_len = pred_len\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, dropout)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    ReformerLayer(None, d_model, n_heads,\n",
    "                                  bucket_size=bucket_size, n_hashes=n_hashes),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu'\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        \n",
    "        self.projection = nn.Linear(d_model, c_out, bias=True)\n",
    "\n",
    "    def long_forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # add placeholder\n",
    "        x_enc = torch.cat([x_enc, x_dec[:, -self.pred_len:, :]], dim=1)\n",
    "        if x_mark_enc is not None:\n",
    "            x_mark_enc = torch.cat(\n",
    "                [x_mark_enc, x_mark_dec[:, -self.pred_len:, :]], dim=1)\n",
    "\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "        dec_out = self.projection(enc_out)\n",
    "\n",
    "        return dec_out  # [B, L, D]\n",
    "    \n",
    "    def short_forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # Normalization\n",
    "        mean_enc = x_enc.mean(1, keepdim=True).detach()  # B x 1 x E\n",
    "        x_enc = x_enc - mean_enc\n",
    "        std_enc = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5).detach()  # B x 1 x E\n",
    "        x_enc = x_enc / std_enc\n",
    "\n",
    "        # add placeholder\n",
    "        x_enc = torch.cat([x_enc, x_dec[:, -self.pred_len:, :]], dim=1)\n",
    "        if x_mark_enc is not None:\n",
    "            x_mark_enc = torch.cat(\n",
    "                [x_mark_enc, x_mark_dec[:, -self.pred_len:, :]], dim=1)\n",
    "\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "        dec_out = self.projection(enc_out)\n",
    "\n",
    "        dec_out = dec_out * std_enc + mean_enc\n",
    "        return dec_out  # [B, L, D]\n",
    "\n",
    "    def forward(self, x_enc, x_dec, x_mark_enc=None, x_mark_dec=None, mask=None):\n",
    "        if self.task_name == 'long_term_forecast':\n",
    "            dec_out = self.long_forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        if self.task_name == 'short_term_forecast':\n",
    "            dec_out = self.short_forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83970fc4",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2226bc48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T09:50:20.438858Z",
     "start_time": "2024-04-13T09:50:20.414211Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch, targets_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch, targets_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "360b3cca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:26:02.175011Z",
     "start_time": "2024-04-13T09:50:36.337779Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                              | 1/20 [02:12<41:51, 132.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0033, Validation Loss: 0.0039\n",
      "Validation loss decreased (inf --> 0.003921).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▏                                                                         | 2/20 [04:35<41:35, 138.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0019, Validation Loss: 0.0036\n",
      "Validation loss decreased (0.003921 --> 0.003631).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▎                                                                     | 3/20 [07:01<40:17, 142.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0017, Validation Loss: 0.0030\n",
      "Validation loss decreased (0.003631 --> 0.003043).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 4/20 [09:30<38:38, 144.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0015, Validation Loss: 0.0029\n",
      "Validation loss decreased (0.003043 --> 0.002912).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▌                                                             | 5/20 [11:59<36:33, 146.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0014, Validation Loss: 0.0027\n",
      "Validation loss decreased (0.002912 --> 0.002697).  Saving model ...\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                         | 6/20 [14:26<34:13, 146.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0013, Validation Loss: 0.0026\n",
      "Validation loss decreased (0.002697 --> 0.002555).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▋                                                     | 7/20 [16:55<31:52, 147.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0012, Validation Loss: 0.0024\n",
      "Validation loss decreased (0.002555 --> 0.002448).  Saving model ...\n",
      "Updating learning rate to 0.0007269952498697733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 8/20 [19:29<29:51, 149.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.0012, Validation Loss: 0.0023\n",
      "Validation loss decreased (0.002448 --> 0.002289).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▉                                             | 9/20 [22:03<27:39, 150.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.0011, Validation Loss: 0.0024\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0005782172325201155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▌                                        | 10/20 [24:35<25:12, 151.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0011, Validation Loss: 0.0022\n",
      "Validation loss decreased (0.002289 --> 0.002211).  Saving model ...\n",
      "Updating learning rate to 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▌                                    | 11/20 [27:05<22:37, 150.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0010, Validation Loss: 0.0023\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0004217827674798845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▌                                | 12/20 [29:34<20:03, 150.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0010, Validation Loss: 0.0023\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00034549150281252633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████▋                            | 13/20 [32:04<17:30, 150.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0010, Validation Loss: 0.0021\n",
      "Validation loss decreased (0.002211 --> 0.002085).  Saving model ...\n",
      "Updating learning rate to 0.00027300475013022663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▋                        | 14/20 [34:33<14:59, 149.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0009, Validation Loss: 0.0021\n",
      "Validation loss decreased (0.002085 --> 0.002058).  Saving model ...\n",
      "Updating learning rate to 0.00020610737385376348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▋                        | 14/20 [35:25<15:10, 151.79s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 34\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 构造参数字典\u001b[39;00m\n\u001b[0;32m      2\u001b[0m params3 \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_args\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     },\n\u001b[0;32m     33\u001b[0m }\n\u001b[1;32m---> 34\u001b[0m model \u001b[38;5;241m=\u001b[39m train(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams3)\n",
      "Cell \u001b[1;32mIn[140], line 118\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(task_args, train_args, model_args)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# 清空梯度\u001b[39;00m\n\u001b[0;32m    117\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 118\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs_batch, targets_batch)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMS\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    120\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs[:, :, f_dim: f_dim\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[139], line 803\u001b[0m, in \u001b[0;36mReformer.forward\u001b[1;34m(self, x_enc, x_dec, x_mark_enc, x_mark_dec, mask)\u001b[0m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dec_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len:, :]  \u001b[38;5;66;03m# [B, L, D]\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshort_term_forecast\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 803\u001b[0m     dec_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshort_forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dec_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len:, :]  \u001b[38;5;66;03m# [B, L, D]\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[139], line 792\u001b[0m, in \u001b[0;36mReformer.short_forecast\u001b[1;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec)\u001b[0m\n\u001b[0;32m    788\u001b[0m     x_mark_enc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m    789\u001b[0m         [x_mark_enc, x_mark_dec[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len:, :]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    791\u001b[0m enc_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_embedding(x_enc, x_mark_enc)  \u001b[38;5;66;03m# [B,T,C]\u001b[39;00m\n\u001b[1;32m--> 792\u001b[0m enc_out, attns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(enc_out, attn_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    793\u001b[0m dec_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(enc_out)\n\u001b[0;32m    795\u001b[0m dec_out \u001b[38;5;241m=\u001b[39m dec_out \u001b[38;5;241m*\u001b[39m std_enc \u001b[38;5;241m+\u001b[39m mean_enc\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[139], line 170\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x, attn_mask, tau, delta)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attn_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_layers:\n\u001b[1;32m--> 170\u001b[0m         x, attn \u001b[38;5;241m=\u001b[39m attn_layer(x, attn_mask\u001b[38;5;241m=\u001b[39mattn_mask, tau\u001b[38;5;241m=\u001b[39mtau, delta\u001b[38;5;241m=\u001b[39mdelta)\n\u001b[0;32m    171\u001b[0m         attns\u001b[38;5;241m.\u001b[39mappend(attn)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[139], line 136\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[1;34m(self, x, attn_mask, tau, delta)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, attn_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tau\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 136\u001b[0m     new_x, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m    137\u001b[0m         x, x, x,\n\u001b[0;32m    138\u001b[0m         attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[0;32m    139\u001b[0m         tau\u001b[38;5;241m=\u001b[39mtau, delta\u001b[38;5;241m=\u001b[39mdelta\n\u001b[0;32m    140\u001b[0m     )\n\u001b[0;32m    141\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(new_x)\n\u001b[0;32m    143\u001b[0m     y \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[139], line 727\u001b[0m, in \u001b[0;36mReformerLayer.forward\u001b[1;34m(self, queries, keys, values, attn_mask, tau, delta)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, queries, keys, values, attn_mask, tau, delta):\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;66;03m# in Reformer: defalut queries=keys\u001b[39;00m\n\u001b[0;32m    726\u001b[0m     B, N, C \u001b[38;5;241m=\u001b[39m queries\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 727\u001b[0m     queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_length(queries))[:, :N, :]\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m queries, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[139], line 684\u001b[0m, in \u001b[0;36mLSHSelfAttention.forward\u001b[1;34m(self, x, keys, input_mask, input_attn_mask, context_mask, pos_emb, **kwargs)\u001b[0m\n\u001b[0;32m    681\u001b[0m partial_attn_fn \u001b[38;5;241m=\u001b[39m partial(attn_fn, query_len \u001b[38;5;241m=\u001b[39m t, pos_emb \u001b[38;5;241m=\u001b[39m pos_emb, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    682\u001b[0m attn_fn_in_chunks \u001b[38;5;241m=\u001b[39m process_inputs_chunk(partial_attn_fn, chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_chunks)\n\u001b[1;32m--> 684\u001b[0m out, attn, buckets \u001b[38;5;241m=\u001b[39m attn_fn_in_chunks(qk, v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmasks)\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback(attn\u001b[38;5;241m.\u001b[39mreshape(b, lsh_h, t, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), buckets\u001b[38;5;241m.\u001b[39mreshape(b, lsh_h, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[139], line 202\u001b[0m, in \u001b[0;36mprocess_inputs_chunk.<locals>.inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m chunked_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mchunk(chunks, dim\u001b[38;5;241m=\u001b[39mdim), \u001b[38;5;28mlist\u001b[39m(args) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(values))))\n\u001b[0;32m    201\u001b[0m all_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x[:len_args], \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, x[len_args:]))), chunked_args)\n\u001b[1;32m--> 202\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [fn(\u001b[38;5;241m*\u001b[39mc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mc_kwargs) \u001b[38;5;28;01mfor\u001b[39;00m c_args, c_kwargs \u001b[38;5;129;01min\u001b[39;00m all_args]\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: torch\u001b[38;5;241m.\u001b[39mcat(x, dim\u001b[38;5;241m=\u001b[39mdim), \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39moutputs)))\n",
      "Cell \u001b[1;32mIn[139], line 202\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    200\u001b[0m chunked_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mchunk(chunks, dim\u001b[38;5;241m=\u001b[39mdim), \u001b[38;5;28mlist\u001b[39m(args) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(values))))\n\u001b[0;32m    201\u001b[0m all_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x[:len_args], \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, x[len_args:]))), chunked_args)\n\u001b[1;32m--> 202\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [fn(\u001b[38;5;241m*\u001b[39mc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mc_kwargs) \u001b[38;5;28;01mfor\u001b[39;00m c_args, c_kwargs \u001b[38;5;129;01min\u001b[39;00m all_args]\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: torch\u001b[38;5;241m.\u001b[39mcat(x, dim\u001b[38;5;241m=\u001b[39mdim), \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39moutputs)))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[97], line 421\u001b[0m, in \u001b[0;36mLSHAttention.forward\u001b[1;34m(self, qk, v, query_len, input_mask, input_attn_mask, pos_emb, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m dots \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(dots \u001b[38;5;241m-\u001b[39m dots_logsumexp)\u001b[38;5;241m.\u001b[39mtype_as(dots)\n\u001b[0;32m    419\u001b[0m dropped_dots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(dots)\n\u001b[1;32m--> 421\u001b[0m bo \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuij,buje->buie\u001b[39m\u001b[38;5;124m'\u001b[39m, dropped_dots, bv)\n\u001b[0;32m    422\u001b[0m so \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(bo, (batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dim))\n\u001b[0;32m    423\u001b[0m slogits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(dots_logsumexp, (batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\functional.py:378\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39meinsum(equation, operands)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    380\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Reformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'task_name': 'short_term_forecast',\n",
    "        'pred_len': 3, \n",
    "        'seq_len': 6,\n",
    "        'd_model': 128,\n",
    "        'enc_in': 2,\n",
    "        'dropout': 0.1,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 1,\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdfd732",
   "metadata": {},
   "source": [
    "# 基于TiDE的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3c261",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698dcc0",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7378f4c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T11:11:06.518647Z",
     "start_time": "2024-04-13T11:11:06.511599Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bb102d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T11:11:07.393219Z",
     "start_time": "2024-04-13T11:11:07.344123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "08a58347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T11:11:08.659283Z",
     "start_time": "2024-04-13T11:11:08.651379Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "495eb6f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T11:11:17.168678Z",
     "start_time": "2024-04-13T11:11:17.144495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "23961587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T11:11:18.477367Z",
     "start_time": "2024-04-13T11:11:18.471380Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d8ebc2c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T11:11:20.090706Z",
     "start_time": "2024-04-13T11:11:19.669757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9396a65",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "52c5cf50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T11:19:45.266651Z",
     "start_time": "2024-04-13T11:19:45.247898Z"
    }
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias,\n",
    "                            1e-5)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 dropout=0.1,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim, bias=bias)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim, bias=bias)\n",
    "        self.fc3 = nn.Linear(input_dim, output_dim, bias=bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln = LayerNorm(output_dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out + self.fc3(x)\n",
    "        out = self.ln(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# TiDE模型\n",
    "class TiDE(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, d_model, e_layers, d_layers, freq, d_ff, dropout, c_out, \n",
    "                 bias=True, feature_encode_dim=2):\n",
    "        super(TiDE, self).__init__()\n",
    "        self.seq_len = seq_len  #L\n",
    "        self.pred_len = pred_len  #H\n",
    "        self.hidden_dim = d_model\n",
    "        self.res_hidden = d_model\n",
    "        self.encoder_num = e_layers\n",
    "        self.decoder_num = d_layers\n",
    "        self.freq = freq\n",
    "        self.feature_encode_dim = feature_encode_dim\n",
    "        self.decode_dim = c_out\n",
    "        self.temporalDecoderHidden = d_ff\n",
    "        dropout = dropout\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "\n",
    "        self.feature_dim = freq_map[self.freq]\n",
    "\n",
    "        flatten_dim = self.seq_len + (self.seq_len +\n",
    "                                      self.pred_len) * self.feature_encode_dim\n",
    "\n",
    "        self.feature_encoder = ResBlock(self.feature_dim, self.res_hidden,\n",
    "                                        self.feature_encode_dim, dropout, bias)\n",
    "        self.encoders = nn.Sequential(\n",
    "            ResBlock(flatten_dim, self.res_hidden, self.hidden_dim, dropout,\n",
    "                     bias),\n",
    "            *([\n",
    "                ResBlock(self.hidden_dim, self.res_hidden, self.hidden_dim,\n",
    "                         dropout, bias)\n",
    "            ] * (self.encoder_num - 1)))\n",
    "\n",
    "        self.decoders = nn.Sequential(\n",
    "            *([\n",
    "                ResBlock(self.hidden_dim, self.res_hidden, self.hidden_dim,\n",
    "                         dropout, bias)\n",
    "            ] * (self.decoder_num - 1)),\n",
    "            ResBlock(self.hidden_dim, self.res_hidden,\n",
    "                     self.decode_dim * self.pred_len, dropout, bias))\n",
    "        self.temporalDecoder = ResBlock(\n",
    "            self.decode_dim + self.feature_encode_dim,\n",
    "            self.temporalDecoderHidden, 1, dropout, bias)\n",
    "        self.residual_proj = nn.Linear(self.seq_len,\n",
    "                                       self.pred_len,\n",
    "                                       bias=bias)\n",
    "\n",
    "    def forecast(self, x_enc, x_mark_enc, x_dec, batch_y_mark):\n",
    "        # Normalization\n",
    "        means = x_enc.mean(1, keepdim=True).detach()\n",
    "        x_enc = x_enc - means\n",
    "        stdev = torch.sqrt(\n",
    "            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "        x_enc /= stdev\n",
    "\n",
    "        feature = self.feature_encoder(batch_y_mark)\n",
    "        hidden = self.encoders(\n",
    "            torch.cat([x_enc, feature.reshape(feature.shape[0], -1)], dim=-1))\n",
    "        decoded = self.decoders(hidden).reshape(hidden.shape[0], self.pred_len,\n",
    "                                                self.decode_dim)\n",
    "        dec_out = self.temporalDecoder(\n",
    "            torch.cat([feature[:, self.seq_len:], decoded],\n",
    "                      dim=-1)).squeeze(-1) + self.residual_proj(x_enc)\n",
    "\n",
    "        # De-Normalization\n",
    "        dec_out = dec_out * (stdev[:, 0].unsqueeze(1).repeat(1, self.pred_len))\n",
    "        dec_out = dec_out + (means[:, 0].unsqueeze(1).repeat(1, self.pred_len))\n",
    "        return dec_out\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, batch_y_mark, x_dec=None, mask=None):\n",
    "        '''x_mark_enc is the exogenous dynamic feature described in the original paper'''\n",
    "        batch_y_mark = torch.concat(\n",
    "            [x_mark_enc, batch_y_mark[:, -self.pred_len:, :]], dim=1)\n",
    "        dec_out = torch.stack([\n",
    "            self.forecast(x_enc[:, :, feature], x_mark_enc, x_dec,\n",
    "                          batch_y_mark)\n",
    "            for feature in range(x_enc.shape[-1])\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return dec_out  # [B, L, D]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e33d0b",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4e592e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T11:19:47.839070Z",
     "start_time": "2024-04-13T11:19:47.815952Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b6ab60f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T11:21:49.721741Z",
     "start_time": "2024-04-13T11:21:49.645966Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TiDE.forward() missing 2 required positional arguments: 'x_mark_enc' and 'batch_y_mark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[186], line 33\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 构造参数字典\u001b[39;00m\n\u001b[0;32m      2\u001b[0m params3 \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_args\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     },\n\u001b[0;32m     32\u001b[0m }\n\u001b[1;32m---> 33\u001b[0m model \u001b[38;5;241m=\u001b[39m train(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams3)\n",
      "Cell \u001b[1;32mIn[183], line 118\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(task_args, train_args, model_args)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# 清空梯度\u001b[39;00m\n\u001b[0;32m    117\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 118\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs_batch)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMS\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    120\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs[:, :, f_dim: f_dim\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: TiDE.forward() missing 2 required positional arguments: 'x_mark_enc' and 'batch_y_mark'"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load'],\n",
    "        \"features\": 'MS'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": TiDE,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 7,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'seq_len': 6,\n",
    "        'pred_len': 3,\n",
    "        'd_model': 128,\n",
    "        'd_layers': 1,\n",
    "        'd_ff': 128,\n",
    "        'dropout': 0.1,\n",
    "        'e_layers': 1,\n",
    "        'freq': 's',\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0572f0",
   "metadata": {},
   "source": [
    "# 基于Transformer的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068db957",
   "metadata": {},
   "source": [
    "## 多变量多步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b100a10",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "861d9802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:26:13.912080Z",
     "start_time": "2024-04-13T10:26:13.905989Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def get_dataset(path, time_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    rows = data.shape[0]\n",
    "    now = datetime.now()\n",
    "    newtime = now.replace(microsecond=0)\n",
    "    if time_col == None:\n",
    "        # 如果没有时间列，生成时间戳范围\n",
    "        time_index = pd.date_range(start=datetime.now() -\n",
    "                                   timedelta(seconds=rows - 1),\n",
    "                                   end=datetime.now(),\n",
    "                                   freq='S')\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit='s'),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac992088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:26:15.294250Z",
     "start_time": "2024-04-13T10:26:15.243550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/energy.csv\"\n",
    "ts_data = get_dataset(path, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1e83d4b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:26:16.393891Z",
     "start_time": "2024-04-13T10:26:16.386786Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divide_dataset(df, valid_date, test_date, x_feature_list, y_feature_list):\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy()[df.index < valid_date][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.fit_transform(train)\n",
    "    train = train.values.astype('float32')\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy()[(df.index >= valid_date) & (df.index < test_date)][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.fit_transform(valid)\n",
    "    valid = valid.values.astype('float32')\n",
    "\n",
    "    #测试集\n",
    "    test = df.copy()[test_date:][x_feature_list]\n",
    "    test[x_feature_list] = x_scaler.fit_transform(test)\n",
    "    test = test.values.astype('float32')\n",
    "\n",
    "    #标签\n",
    "    ytr = df.copy()[df.index < valid_date][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.fit_transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "\n",
    "    yva = df.copy()[(df.index >= valid_date) & (df.index < test_date)][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.fit_transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "\n",
    "    yte = df.copy()[test_date:][y_feature_list]\n",
    "    yte[y_feature_list] = y_scaler.fit_transform(yte)\n",
    "    yte = yte.values.astype('float32')\n",
    "    return y_scaler, train, valid, test, ytr, yva, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "19692d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:26:18.241872Z",
     "start_time": "2024-04-13T10:26:18.215794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23376, 2) y_train shape: (23376, 2)\n",
      "x_valid shape: (1464, 2) y_valid shape: (1464, 2)\n",
      "x_test shape: (1464, 2) y_test shape: (1464, 2)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"valid_date\": \"2014-09-01 00:00:00\",\n",
    "    \"test_date\": \"2014-11-01 00:00:00\",\n",
    "    \"x_feature_list\": [\"load\", 'temp'],\n",
    "    \"y_feature_list\": [\"load\", 'temp'],\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "scaler, x_train, x_valid, x_test, y_train, y_valid, y_test = divide_dataset(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(x_valid.shape, y_valid.shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "861e19ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:26:19.474188Z",
     "start_time": "2024-04-13T10:26:19.468779Z"
    }
   },
   "outputs": [],
   "source": [
    "#利用前lookback个数据，预测下delay个数据\n",
    "def create_dataset(feature, target, lookback, delay, step, batch_size):\n",
    "    \"\"\"\n",
    "    @参数设置：\n",
    "    feat：输入向量\n",
    "    tar：输出向量\n",
    "    lookback：输入数据包含过去多少个时间步\n",
    "    delay：目标应该在未来多少个时间步之后\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    lookback = lookback - 1 #包含当前时间点\n",
    "    #循环生成数据\n",
    "    for i in range(lookback, len(feature) - delay, step):\n",
    "        feat = feature[i - lookback:i + 1]\n",
    "        tar = target[i + 1:i + 1 + delay]\n",
    "        X.append(feat)\n",
    "        y.append(tar)\n",
    "    #转为张量\n",
    "    X = torch.as_tensor(X)\n",
    "    y = torch.as_tensor(y)\n",
    "    #创建dataloader\n",
    "    loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "    return X, y, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "072de476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:26:21.205550Z",
     "start_time": "2024-04-13T10:26:20.783778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([23368, 6, 2]),y_size: torch.Size([23368, 3, 2]),loader_len: 731\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n",
      "X_size: torch.Size([1456, 6, 2]),y_size: torch.Size([1456, 3, 2]),loader_len: 46\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"lookback\": 6,\n",
    "    \"delay\": 3,\n",
    "    \"step\": 1, \n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, train_loader = create_dataset(x_train, y_train, **params2)\n",
    "X_valid, y_valid, valid_loader = create_dataset(x_valid, y_valid, **params2)\n",
    "X_test, y_test, test_loader = create_dataset(x_test, y_test, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b497a3",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f0713ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:27:31.874616Z",
     "start_time": "2024-04-13T10:27:31.828617Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# Transformer_EncDec类\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "    \n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
    "                 dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask,\n",
    "            tau=tau, delta=None\n",
    "        )[0])\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )[0])\n",
    "\n",
    "        y = x = self.norm2(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm3(x + y)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask, tau=tau, delta=delta)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# 自编码类\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "    \n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "        \n",
    "        \n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "# Transformer模型\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, pred_len, output_attention, enc_in, d_model, dropout, factor, n_heads, d_ff, \n",
    "                e_layers, dec_in, d_layers, c_out):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.output_attention = output_attention\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, dropout)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                      output_attention=output_attention), d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu'\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, dropout)\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(True, factor, attention_dropout=dropout,\n",
    "                                      output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                      output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model),\n",
    "            projection=nn.Linear(d_model, c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_dec, x_mark_enc=None, x_mark_dec=None):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out, x_mask=None, cross_mask=None)\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e292d",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d3f66bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:27:57.079148Z",
     "start_time": "2024-04-13T10:27:57.055943Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    path = train_args['path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = loss\n",
    "    \n",
    "    # 损失函数值\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            f_dim = col_dict[target]\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs_batch, targets_batch in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            inputs_batch = inputs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch, targets_batch)\n",
    "            if features == 'MS':\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = loss_fn(outputs, targets_batch)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for inputs_batch, targets_batch in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                inputs_batch = inputs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "                val_outputs = model(inputs_batch, targets_batch)\n",
    "                if features == 'MS':\n",
    "                    val_outputs = val_outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    val_outputs = val_outputs[:, :, f_dim:]\n",
    "                val_loss = loss_fn(val_outputs, targets_batch)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        \n",
    "    # 加载最佳模型\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ed24cc1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:35:59.150113Z",
     "start_time": "2024-04-13T10:28:04.970030Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [01:10<22:11, 70.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0139, Validation Loss: 0.0014\n",
      "Validation loss decreased (inf --> 0.001389).  Saving model ...\n",
      "Updating learning rate to 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [02:18<20:46, 69.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.0015, Validation Loss: 0.0010\n",
      "Validation loss decreased (0.001389 --> 0.001035).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [03:27<19:30, 68.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.0010, Validation Loss: 0.0008\n",
      "Validation loss decreased (0.001035 --> 0.000830).  Saving model ...\n",
      "Updating learning rate to 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [04:34<18:10, 68.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.0008, Validation Loss: 0.0006\n",
      "Validation loss decreased (0.000830 --> 0.000553).  Saving model ...\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [05:41<16:55, 67.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.0006, Validation Loss: 0.0006\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0008535533905932737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [06:48<15:47, 67.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.0005, Validation Loss: 0.0006\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [07:53<18:25, 78.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.0005, Validation Loss: 0.0006\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"task_args\":{\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M'\n",
    "    },\n",
    "    \"train_args\": {\n",
    "        \"model_name\": Transformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 20,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 3,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"path\": \"../models/test\",\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'pred_len': 3, \n",
    "        'output_attention': True,\n",
    "        'd_model': 128,\n",
    "        'enc_in': 2,\n",
    "        'dec_in':2,\n",
    "        'dropout': 0.1,\n",
    "        'factor': 3,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 1,\n",
    "        'd_layers': 1,\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426be23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": "7",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "198.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
