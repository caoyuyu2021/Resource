{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75581be8-ef29-4b44-ad1d-3973e11ec40c",
   "metadata": {},
   "source": [
    "# 生成式对抗网络(GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59260159-3577-4b09-ad24-6af690fed0d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:44:12.317659Z",
     "iopub.status.busy": "2024-12-27T07:44:12.316100Z",
     "iopub.status.idle": "2024-12-27T07:44:39.737344Z",
     "shell.execute_reply": "2024-12-27T07:44:39.735284Z",
     "shell.execute_reply.started": "2024-12-27T07:44:12.317659Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from datetime import timedelta\n",
    "from numpy import ndarray\n",
    "from typing import Union, List, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # 打印进度条\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import vgg16\n",
    "import torchvision.utils as vutils\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from pandas.tseries import offsets\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409986c3-b2ad-4dd3-b419-e2d1842b589e",
   "metadata": {},
   "source": [
    "## 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42834f-033b-4ac7-ac96-d5f4290f5ad7",
   "metadata": {},
   "source": [
    "生成式对抗网络迫使生成图像与真实图像在统计上几乎无法区别，从而生成相当逼真的合成图像。GAN由一个生成器网络(generator)和一个判别式网络(discriminator)组成。判别器的训练目的是能够区分生成器的输出与来自训练集的真实图像，生成器的训练目的是欺骗判别器。生成器从未直接见过训练集中的图像，它所知道的关于数据的信息都来自于判别器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b45182-c39c-4f86-b8df-402f09d05f72",
   "metadata": {},
   "source": [
    "生成器生成假数据，然后将生成的假数据和真数据都输入判别器，判别器要判断出哪些是真的哪些是假的。判别器第一次判别出来的肯定有很大的误差，然后我们根据误差来优化判别器。现在判别器水平提高了，生成器生成的数据很难再骗过判别器了，所以我们得反过来优化生成器，之后生成器水平提高了，然后反过来继续训练判别器，判别器水平又提高了，再反过来训练生成器，就这样循环往复，直到达到纳什均衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692fb5ec-4674-4271-aa80-a0cbf032666e",
   "metadata": {},
   "source": [
    "**生成网络的损失函数：**\n",
    "$$L_G=H(1,D(G(z)))$$\n",
    "上式中，$G$ 代表生成网络，$D $代表判别网络，$H$ 代表交叉熵，$z$ 是输入随机数据。$D(G(z))$是对生成数据的判断概率，1代表数据绝对真实，0代表数据绝对虚假。$H(1,D(G(z)))$代表判断结果与1的距离。显然生成网络想取得良好的效果，那就要做到，让判别器将生成数据判别为真数据（即$D(G(z))$与1的距离越小越好）。\n",
    "\n",
    "**判别网络的损失函数：**\n",
    "$$L_D=H(1,D(x))+H(0,D(G(z)))$$\n",
    "上式中，$x$是真实数据，这里要注意的是，$H(1,D(x))$代表真实数据与1的距离，$H(0,D(G(z)))$代表生成数据与0的距离。显然，识别网络要想取得良好的效果，那么就要做到，在它眼里，真实数据就是真实数据，生成数据就是虚假数据（即真实数据与1的距离小，生成数据与0的距离小）。\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66ac40-0f09-470f-8773-4906953084a2",
   "metadata": {},
   "source": [
    "**理想的损失趋势**\n",
    "- 生成器的损失 (Generator Loss)：\n",
    "\n",
    "    - 初期较高，随着训练的进行逐渐下降。\n",
    "    - 稳定后维持在一个较低水平，但不是接近 0，因为生成器需要不断与判别器竞争。\n",
    "- 判别器的损失 (Discriminator Loss)：\n",
    "\n",
    "    - 初期较低，表示判别器能够轻松区分真实样本和生成样本。\n",
    "    - 随着生成器的改进，判别器的损失逐渐上升，趋于约 0.5（随机猜测的水平）。\n",
    "  \n",
    "两者在一个理想的平衡点上达到动态稳定：生成器和判别器互相逼近彼此的最优性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0080b5ff-5fea-4cc3-b19f-e9729505bd43",
   "metadata": {},
   "source": [
    "**优化原理**：生成网络和判别网络有了损失函数，就可以基于各自的损失函数，利用误差反向传播（Backpropagation）(BP)反向传播算法和最优化方法(如梯度下降法)来实现参数的调整），不断提高生成网络和判别网络的性能（最终生成网络和判别网络的成熟状态就是学习到了合理的映射函数）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24d0e28-bce5-41f7-80a2-7ac8dbf396ed",
   "metadata": {},
   "source": [
    "### DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e685c-1c88-4602-b103-0526534e0898",
   "metadata": {},
   "source": [
    "DCGAN（Deep Convolutional Generative Adversarial Network，深度卷积生成对抗网络）是一种生成对抗网络（GAN）的变体，由 Radford 等人在 2015 年提出，专注于利用卷积神经网络（CNN）改进 GAN 的生成能力。它是 GAN 在生成高质量图像任务上的重要发展。\n",
    "\n",
    "**DCGAN 的特点**  \n",
    "- 卷积神经网络架构\n",
    "\n",
    "    - 在生成器和判别器中均使用卷积神经网络（CNN）架构，而非全连接网络。\n",
    "    - 卷积操作有助于捕获局部特征，从而生成更加真实和细节丰富的图像。\n",
    "- 批归一化（Batch Normalization）\n",
    "\n",
    "    - 在生成器和判别器的每一层中都加入批归一化，这有助于稳定训练过程，并加快收敛速度。\n",
    "- 不使用全连接层\n",
    "\n",
    "    - DCGAN 避免使用全连接层，特别是在生成器中。这减少了参数量，使得模型更高效。\n",
    "- ReLU 和 LeakyReLU 激活函数\n",
    "\n",
    "    - 在生成器中，使用 ReLU（Rectified Linear Unit）作为主要激活函数，输出层除外（输出层使用 tanh 激活函数）。\n",
    "    - 判别器使用 LeakyReLU 激活函数，使得负梯度部分也能得到一些梯度信号。\n",
    "- 输出范围归一化\n",
    "\n",
    "    - DCGAN 的生成器输出范围通过 tanh 激活函数归一化到 [−1,1]，使训练更加稳定。\n",
    "\n",
    "**DCGAN 的结构**\n",
    "- 生成器（Generator）\n",
    "\n",
    "    - 输入：随机噪声向量 z（通常从标准正态分布中采样）。\n",
    "    - 通过一系列的转置卷积（Transposed Convolution 或 Fractionally-Strided Convolution）逐步将低维向量扩展为高分辨率图像。\n",
    "    - 最终输出目标分辨率的生成图像。\n",
    "- 判别器（Discriminator）\n",
    "\n",
    "    - 输入：真实图像或生成图像。\n",
    "    - 通过卷积层提取图像特征，最终输出一个概率值，用于判断输入图像是真实的还是生成的。\n",
    "\n",
    "**DCGAN 的缺点**\n",
    "- 训练不稳定\n",
    "\n",
    "    - GAN 类模型本身训练容易不稳定，生成器和判别器需要精细调节。\n",
    "    - 容易出现模式崩塌（Mode Collapse）问题，即生成器总是生成相似的图像。\n",
    "- 难以处理高分辨率图像\n",
    "\n",
    "    - **虽然相比普通 GAN 有较大改进，但 DCGAN 在生成非常高分辨率图像时仍有困难**。\n",
    "- 对超参数敏感\n",
    "\n",
    "    - 网络深度、学习率、批量大小等超参数对生成效果影响显著。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb975dd7-a2c2-4ef7-9fa4-021495db04cf",
   "metadata": {},
   "source": [
    "## 深度卷积生成对抗网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e29f9-c814-4046-b43a-4ed48507be01",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb75898a-d0fc-4bbc-8121-2ab30b3df31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:44:54.016812Z",
     "iopub.status.busy": "2024-12-27T07:44:54.016812Z",
     "iopub.status.idle": "2024-12-27T07:44:54.032404Z",
     "shell.execute_reply": "2024-12-27T07:44:54.031415Z",
     "shell.execute_reply.started": "2024-12-27T07:44:54.016812Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载图像并生成批次数据\n",
    "def generator(data_path, batch_size):\n",
    "    \"\"\"\n",
    "    读取图像，并生成批次数据\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        图像文件夹地址\n",
    "    batch_size : {int} \n",
    "        输入数据的批次大小，正整数\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data_loader : {torch.utils.data.dataloader.DataLoader}\n",
    "        数据加载器，[批次，目标，特征时间编码，目标时间编码]\n",
    "    \"\"\"\n",
    "    # 定义图像变换操作\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),         # 调整图像大小\n",
    "        transforms.ToTensor(),                  # 转换为张量\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # 标准化\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.CIFAR10(root=data_path, download=True, transform=transform)\n",
    "    # 筛选标签为4的索引\n",
    "    indices = [i for i, (_, label) in enumerate(dataset) if label == 4]\n",
    "    # 创建只包含标签为4数据的子集\n",
    "    dataset = Subset(dataset, indices)\n",
    "    \n",
    "    # dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "    print(f\"图像个数：{len(dataset)}, 尺寸：{dataset[0][0].shape}\")\n",
    "    \n",
    "    # 数据加载器\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 查看一个批次数据\n",
    "    images, labels = next(iter(dataloader))\n",
    "    print(f\"图像批次大小: {images.shape}\")\n",
    "    print(f\"标签批次大小: {labels.shape}\")\n",
    "    print(f\"图像批次个数: {len(dataloader)}\")\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccd5def-7f14-4a12-95e1-c6a6e5c6bfcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:44:59.449908Z",
     "iopub.status.busy": "2024-12-27T07:44:59.449908Z",
     "iopub.status.idle": "2024-12-27T07:45:15.881022Z",
     "shell.execute_reply": "2024-12-27T07:45:15.880099Z",
     "shell.execute_reply.started": "2024-12-27T07:44:59.449908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集：\n",
      "Files already downloaded and verified\n",
      "图像个数：5000, 尺寸：torch.Size([3, 32, 32])\n",
      "图像批次大小: torch.Size([128, 3, 32, 32])\n",
      "标签批次大小: torch.Size([128])\n",
      "图像批次个数: 40\n"
     ]
    }
   ],
   "source": [
    "# 训练集\n",
    "params1 = {\n",
    "    \"data_path\": \"../../../../../data/02.cv/cifar-10/\",\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "print(\"训练集：\")\n",
    "data_loader = generator(**params1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9ef0e-1544-4d22-b0cf-de10038afae1",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63138c05-6349-48ac-a4df-7b4b3785a82f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T09:51:12.132552Z",
     "iopub.status.busy": "2024-12-27T09:51:12.131555Z",
     "iopub.status.idle": "2024-12-27T09:51:12.149590Z",
     "shell.execute_reply": "2024-12-27T09:51:12.148115Z",
     "shell.execute_reply.started": "2024-12-27T09:51:12.132552Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成器（Generator）\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 输入：潜在向量 latent_dim -> 特征图 (512, 4, 4)\n",
    "            nn.ConvTranspose2d(latent_dim, 512, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 上采样：512 -> 256, (4, 4) -> (8, 8)\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 上采样：256 -> 128, (8, 8) -> (16, 16)\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 上采样：128 -> channels, (16, 16) -> (32, 32)\n",
    "            nn.ConvTranspose2d(128, channels, kernel_size=4, stride=2, padding=1),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            # nn.ReLU(inplace=True),\n",
    "\n",
    "            # # 输出层：64 -> channels (图像通道数)，(32, 32)\n",
    "            # nn.ConvTranspose2d(64, channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()  # 将输出限制在 [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        # 输入 z 的形状为 (batch_size, latent_dim)\n",
    "        # 需要将 z 变为 (batch_size, latent_dim, 1, 1) 才能输入转置卷积\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        return self.model(z)\n",
    "\n",
    "# 判别器（Discriminator）\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 输入：图像通道数 channels -> 特征图 64, (32, 32) -> (16, 16)\n",
    "            nn.Conv2d(channels, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 下采样：64 -> 128, (16, 16) -> (8, 8)\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 下采样：128 -> 256, (8, 8) -> (4, 4)\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 下采样：256 -> 1, (4, 4)\n",
    "            nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=0),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # # 输出层：512 -> 1\n",
    "            # nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid()  # 输出范围在 [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        # 输入 img 的形状为 (batch_size, channels, height, width)\n",
    "        return self.model(img).view(-1, 1)  # 展平为 (batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd7c1d-9a6f-4ed0-bb1f-e833ef76bc18",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ac3ae7a-0c16-454b-bc5f-fa719ff903af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T09:51:13.335733Z",
     "iopub.status.busy": "2024-12-27T09:51:13.334629Z",
     "iopub.status.idle": "2024-12-27T09:51:13.417312Z",
     "shell.execute_reply": "2024-12-27T09:51:13.415361Z",
     "shell.execute_reply.started": "2024-12-27T09:51:13.335733Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_args, generator_args, discriminator_args):\n",
    "    # 参数配置\n",
    "    generator_name = train_args['generator_name']\n",
    "    discriminator_name = train_args['discriminator_name']\n",
    "    data_loader = train_args['data_loader']\n",
    "    n_epochs = train_args['n_epochs']\n",
    "    learning_rate = train_args['learning_rate']\n",
    "    lradj = train_args['lradj']\n",
    "    model_path = train_args['model_path']\n",
    "    image_path = train_args['image_path']\n",
    "    verbose = train_args['verbose']\n",
    "    plots = train_args['plots']\n",
    "    device = train_args['device']\n",
    "    clip_value = train_args['clip_value']\n",
    "    loss = train_args['loss']\n",
    "    latent_dim = generator_args['latent_dim']\n",
    "    channels = generator_args['channels']\n",
    "    noise_level = train_args.get('noise_level', 0.1)  # 默认噪声强度\n",
    "\n",
    "    # 检查可用 device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # 添加噪声\n",
    "    def add_noise(images, noise_level=0.1):\n",
    "        noise = torch.randn_like(images) * noise_level\n",
    "        noisy_images = images + noise\n",
    "        return noisy_images.clamp(0.0, 1.0)  # 保证像素值在 [0, 1] 范围内\n",
    "\n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate / 2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "\n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 定义感知损失\n",
    "    class PerceptualLoss(nn.Module):\n",
    "        def __init__(self, feature_layer_idx=9):\n",
    "            super(PerceptualLoss, self).__init__()\n",
    "            vgg = vgg16(pretrained=True).features[:feature_layer_idx].eval()\n",
    "            for param in vgg.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.vgg = vgg.to(device)\n",
    "\n",
    "        def forward(self, x, y):\n",
    "            x_features = self.vgg(x)\n",
    "            y_features = self.vgg(y)\n",
    "            loss = nn.functional.mse_loss(x_features, y_features)\n",
    "            return loss\n",
    "    perceptual_loss_fn = PerceptualLoss().to(device)\n",
    "\n",
    "    # 定义模型和损失函数\n",
    "    generator = generator_name(**generator_args).to(device)\n",
    "    discriminator = discriminator_name(**discriminator_args).to(device)\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    criterion = loss\n",
    "\n",
    "    # 损失记录\n",
    "    G_losses, D_losses = [], []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        total_G_loss = 0\n",
    "        total_D_loss = 0\n",
    "        for i, (imgs, _) in enumerate(data_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            noisy_real_imgs = add_noise(imgs, noise_level=noise_level)\n",
    "\n",
    "            # 标签平滑\n",
    "            real_labels = torch.full((imgs.size(0), 1), 0.9).to(device)\n",
    "            fake_labels = torch.full((imgs.size(0), 1), 0.1).to(device)\n",
    "\n",
    "            # 生成假图像并添加噪声\n",
    "            z = torch.randn(imgs.size(0), latent_dim).to(device)\n",
    "            fake_imgs = generator(z)\n",
    "            noisy_fake_imgs = add_noise(fake_imgs, noise_level=noise_level)\n",
    "\n",
    "            # 判别器损失\n",
    "            real_loss = criterion(discriminator(noisy_real_imgs), real_labels) # 判别器对真实图像的损失\n",
    "            fake_loss = criterion(discriminator(noisy_fake_imgs.detach()), fake_labels) # 判别器对假图像的损失\n",
    "            loss_D = real_loss + fake_loss\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(discriminator.parameters(), clip_value)\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # 生成器损失：判别器损失 + 感知损失\n",
    "            adv_loss = criterion(discriminator(noisy_fake_imgs), real_labels)\n",
    "            perc_loss = perceptual_loss_fn(noisy_fake_imgs, noisy_real_imgs)\n",
    "            loss_G = adv_loss + 0.1 * perc_loss  # 调整感知损失的权重，生成器希望生成的图像被判别为真实\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            loss_G.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(generator.parameters(), clip_value)\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # 记录损失\n",
    "            total_G_loss += loss_G.item()\n",
    "            total_D_loss += loss_D.item()\n",
    "\n",
    "        # 计算每个 epoch 的平均损失\n",
    "        avg_G_loss = total_G_loss / len(data_loader)\n",
    "        avg_D_loss = total_D_loss / len(data_loader)\n",
    "        G_losses.append(avg_G_loss)\n",
    "        D_losses.append(avg_D_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch}/{n_epochs}], Generator Loss: {avg_G_loss:.4f}, Discriminator Loss: {avg_D_loss:.4f}')\n",
    "\n",
    "        # 保存生成的图像\n",
    "        fake_imgs = fake_imgs.view(fake_imgs.size(0), channels, latent_dim, latent_dim)\n",
    "        vutils.save_image(fake_imgs[:25], f\"{image_path}/output_epoch_{epoch+1}.png\", nrow=5, normalize=True)\n",
    "\n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer_G, epoch + 1, lradj, learning_rate, n_epochs)\n",
    "        adjust_learning_rate(optimizer_D, epoch + 1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    def plot_loss(G_losses, D_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper')\n",
    "        plt.grid(axis='y', linewidth=0.35)\n",
    "        plt.plot(G_losses, linestyle='-', color='#11b3b6')\n",
    "        plt.plot(D_losses, linestyle='-', color='#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training Progress\")\n",
    "        plt.legend([\"Generator\", \"Discriminator\"])\n",
    "        plt.show()\n",
    "\n",
    "    if plots:\n",
    "        plot_loss(G_losses, D_losses)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d758f0-1eef-4eca-b8b3-b118af8aadb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T09:51:13.842966Z",
     "iopub.status.busy": "2024-12-27T09:51:13.841944Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                              | 1/100 [03:35<5:55:55, 215.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Generator Loss: 3.2411, Discriminator Loss: 0.9668\n",
      "Updating learning rate to 0.00019995065603657316\n",
      "Updating learning rate to 0.00019995065603657316\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"train_args\": {\n",
    "        \"generator_name\": Generator,\n",
    "        \"discriminator_name\": Discriminator,\n",
    "        \"data_loader\": data_loader,\n",
    "        \"n_epochs\": 100,\n",
    "        \"patience\": 50,\n",
    "        \"learning_rate\": 0.0002,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../outputs/best_models/DCGAN\",\n",
    "        \"image_path\": \"../outputs/images\",\n",
    "        \"device\": 'cuda',\n",
    "        \"loss\": nn.BCELoss(),\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "        \"clip_value\": 0.1,\n",
    "    },\n",
    "    \"generator_args\": {\n",
    "        'latent_dim': 32,\n",
    "        'channels': 3,\n",
    "    },\n",
    "    \"discriminator_args\": {\n",
    "        'channels': 3,\n",
    "    },\n",
    "}\n",
    "generator = train(**params2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede1ec3-c9e3-4997-a71b-bc5372bf9e29",
   "metadata": {},
   "source": [
    "### 图像生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77e521-112e-41d7-a7cc-3d6742f4e176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
