{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75581be8-ef29-4b44-ad1d-3973e11ec40c",
   "metadata": {},
   "source": [
    "# 生成式对抗网络(GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59260159-3577-4b09-ad24-6af690fed0d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:17:12.306596Z",
     "iopub.status.busy": "2024-12-27T07:17:12.306596Z",
     "iopub.status.idle": "2024-12-27T07:17:31.571006Z",
     "shell.execute_reply": "2024-12-27T07:17:31.570060Z",
     "shell.execute_reply.started": "2024-12-27T07:17:12.306596Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from datetime import timedelta\n",
    "from numpy import ndarray\n",
    "from typing import Union, List, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # 打印进度条\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.utils as vutils\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from pandas.tseries import offsets\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409986c3-b2ad-4dd3-b419-e2d1842b589e",
   "metadata": {},
   "source": [
    "## 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42834f-033b-4ac7-ac96-d5f4290f5ad7",
   "metadata": {},
   "source": [
    "生成式对抗网络迫使生成图像与真实图像在统计上几乎无法区别，从而生成相当逼真的合成图像。GAN由一个生成器网络(generator)和一个判别式网络(discriminator)组成。判别器的训练目的是能够区分生成器的输出与来自训练集的真实图像，生成器的训练目的是欺骗判别器。生成器从未直接见过训练集中的图像，它所知道的关于数据的信息都来自于判别器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b45182-c39c-4f86-b8df-402f09d05f72",
   "metadata": {},
   "source": [
    "生成器生成假数据，然后将生成的假数据和真数据都输入判别器，判别器要判断出哪些是真的哪些是假的。判别器第一次判别出来的肯定有很大的误差，然后我们根据误差来优化判别器。现在判别器水平提高了，生成器生成的数据很难再骗过判别器了，所以我们得反过来优化生成器，之后生成器水平提高了，然后反过来继续训练判别器，判别器水平又提高了，再反过来训练生成器，就这样循环往复，直到达到纳什均衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692fb5ec-4674-4271-aa80-a0cbf032666e",
   "metadata": {},
   "source": [
    "**生成网络的损失函数：**\n",
    "$$L_G=H(1,D(G(z)))$$\n",
    "上式中，$G$ 代表生成网络，$D $代表判别网络，$H$ 代表交叉熵，$z$ 是输入随机数据。$D(G(z))$是对生成数据的判断概率，1代表数据绝对真实，0代表数据绝对虚假。$H(1,D(G(z)))$代表判断结果与1的距离。显然生成网络想取得良好的效果，那就要做到，让判别器将生成数据判别为真数据（即$D(G(z))$与1的距离越小越好）。\n",
    "\n",
    "**判别网络的损失函数：**\n",
    "$$L_D=H(1,D(x))+H(0,D(G(z)))$$\n",
    "上式中，$x$是真实数据，这里要注意的是，$H(1,D(x))$代表真实数据与1的距离，$H(0,D(G(z)))$代表生成数据与0的距离。显然，识别网络要想取得良好的效果，那么就要做到，在它眼里，真实数据就是真实数据，生成数据就是虚假数据（即真实数据与1的距离小，生成数据与0的距离小）。\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66ac40-0f09-470f-8773-4906953084a2",
   "metadata": {},
   "source": [
    "**理想的损失趋势**\n",
    "- 生成器的损失 (Generator Loss)：\n",
    "\n",
    "    - 初期较高，随着训练的进行逐渐下降。\n",
    "    - 稳定后维持在一个较低水平，但不是接近 0，因为生成器需要不断与判别器竞争。\n",
    "- 判别器的损失 (Discriminator Loss)：\n",
    "\n",
    "    - 初期较低，表示判别器能够轻松区分真实样本和生成样本。\n",
    "    - 随着生成器的改进，判别器的损失逐渐上升，趋于约 0.5（随机猜测的水平）。\n",
    "  \n",
    "两者在一个理想的平衡点上达到动态稳定：生成器和判别器互相逼近彼此的最优性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0080b5ff-5fea-4cc3-b19f-e9729505bd43",
   "metadata": {},
   "source": [
    "**优化原理**：生成网络和判别网络有了损失函数，就可以基于各自的损失函数，利用误差反向传播（Backpropagation）(BP)反向传播算法和最优化方法(如梯度下降法)来实现参数的调整），不断提高生成网络和判别网络的性能（最终生成网络和判别网络的成熟状态就是学习到了合理的映射函数）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24d0e28-bce5-41f7-80a2-7ac8dbf396ed",
   "metadata": {},
   "source": [
    "### DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e685c-1c88-4602-b103-0526534e0898",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "484e29f9-c814-4046-b43a-4ed48507be01",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb75898a-d0fc-4bbc-8121-2ab30b3df31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:17:38.066335Z",
     "iopub.status.busy": "2024-12-27T07:17:38.065791Z",
     "iopub.status.idle": "2024-12-27T07:17:38.082935Z",
     "shell.execute_reply": "2024-12-27T07:17:38.081940Z",
     "shell.execute_reply.started": "2024-12-27T07:17:38.066335Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载图像并生成批次数据\n",
    "def generator(data_path, batch_size):\n",
    "    \"\"\"\n",
    "    读取图像，并生成批次数据\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        图像文件夹地址\n",
    "    batch_size : {int} \n",
    "        输入数据的批次大小，正整数\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data_loader : {torch.utils.data.dataloader.DataLoader}\n",
    "        数据加载器，[批次，目标，特征时间编码，目标时间编码]\n",
    "    \"\"\"\n",
    "    # 定义图像变换操作\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),         # 调整图像大小\n",
    "        transforms.ToTensor(),                  # 转换为张量\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # 标准化\n",
    "    ])\n",
    "    \n",
    "    # dataset = datasets.CIFAR10(root=data_path, download=True, transform=transform)\n",
    "    # # 筛选标签为6的索引\n",
    "    # indices = [i for i, (_, label) in enumerate(dataset) if label == 6]\n",
    "    # # 创建只包含标签为6数据的子集\n",
    "    # dataset = Subset(dataset, indices)\n",
    "    \n",
    "    dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "    print(f\"图像个数：{len(dataset)}, 尺寸：{dataset[0][0].shape}\")\n",
    "    \n",
    "    # 数据加载器\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 查看一个批次数据\n",
    "    images, labels = next(iter(dataloader))\n",
    "    print(f\"图像批次大小: {images.shape}\")\n",
    "    print(f\"标签批次大小: {labels.shape}\")\n",
    "    print(f\"图像批次个数: {len(dataloader)}\")\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccd5def-7f14-4a12-95e1-c6a6e5c6bfcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:17:42.979278Z",
     "iopub.status.busy": "2024-12-27T07:17:42.979278Z",
     "iopub.status.idle": "2024-12-27T07:17:43.233618Z",
     "shell.execute_reply": "2024-12-27T07:17:43.232647Z",
     "shell.execute_reply.started": "2024-12-27T07:17:42.979278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集：\n",
      "图像个数：2000, 尺寸：torch.Size([3, 224, 224])\n",
      "图像批次大小: torch.Size([16, 3, 224, 224])\n",
      "标签批次大小: torch.Size([16])\n",
      "图像批次个数: 125\n"
     ]
    }
   ],
   "source": [
    "# 训练集\n",
    "params1 = {\n",
    "    \"data_path\": \"../data/cats_and_dogs_small/train/\",\n",
    "    \"batch_size\": 16,\n",
    "}\n",
    "print(\"训练集：\")\n",
    "data_loader = generator(**params1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9ef0e-1544-4d22-b0cf-de10038afae1",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8cb2a-806a-4f23-8b49-8275d65404a7",
   "metadata": {},
   "source": [
    "### 自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8982286-8f84-4421-89a5-c4c01d84e773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:23:24.831517Z",
     "iopub.status.busy": "2024-12-27T07:23:24.828874Z",
     "iopub.status.idle": "2024-12-27T07:23:24.869164Z",
     "shell.execute_reply": "2024-12-27T07:23:24.867270Z",
     "shell.execute_reply.started": "2024-12-27T07:23:24.830876Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义生成器网络\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 1. 全连接层：将潜在向量 (latent_dim) 投影并展平为形状 (128, 8, 8)\n",
    "            nn.Linear(latent_dim, 512 * 8 * 8),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            nn.Unflatten(1, (512, 8, 8)),  # 转换为形状 (batch, 128, 8, 8)\n",
    "\n",
    "            # 2. 转置卷积层：第一次上采样，(128, 8, 8) -> (128, 16, 16)\n",
    "            nn.ConvTranspose2d(512, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "\n",
    "            # 3. 转置卷积层：第二次上采样，(128, 16, 16) -> (64, 32, 32)\n",
    "            nn.ConvTranspose2d(512, 224, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(224),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "\n",
    "            # 4. 卷积层：输出通道调整为图像通道数 (64, 32, 32) -> (3, 32, 32)\n",
    "            nn.Conv2d(224, channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()  # 将输出范围限制在 [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, latent_dim, channels):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.model = nn.Sequential(\n",
    "#             # 1. 全连接层，生成16*16*128的特征图，输出维度：(batch_size, 128 * 16 * 16)\n",
    "#             nn.Linear(latent_dim, 128 * 16 * 16),  \n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Unflatten(1, (128, 16, 16)),  # 重塑为特征图，输出维度：(batch_size, 128, 16, 16)\n",
    "            \n",
    "#             # 2. 卷积操作，输出维度：(batch_size, 256, 16, 16)\n",
    "#             nn.Conv2d(128, 256, kernel_size=5, padding=2),  \n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "#             # 3. 上采样为32x32，输出维度：(batch_size, 256, 32, 32)\n",
    "#             nn.ConvTranspose2d(256, 256, kernel_size=4, stride=2, padding=1),  \n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "#             # 4. 卷积操作，输出维度：(batch_size, 256, 32, 32)\n",
    "#             nn.Conv2d(256, 256, kernel_size=5, padding=2),  \n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "#             # 5. 再次卷积操作，输出维度：(batch_size, 256, 32, 32)\n",
    "#             nn.Conv2d(256, 256, kernel_size=5, padding=2),  \n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "#             # 6. 输出图像，padding=3保持输出尺寸不变，输出维度：(batch_size, channels, 32, 32)\n",
    "#             nn.Conv2d(256, channels, kernel_size=7, padding=3),  \n",
    "#             nn.Tanh()  # 输出激活函数\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "\n",
    "# 定义判别器网络\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 1. 卷积层：初始通道从图像通道数增加到 128，(3, 32, 32) -> (128, 32, 32)\n",
    "            nn.Conv2d(channels, 128, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 2. 卷积层：下采样，(128, 32, 32) -> (128, 16, 16)\n",
    "            nn.Conv2d(128, 128, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 3. 卷积层：下采样，(128, 16, 16) -> (128, 8, 8)\n",
    "            nn.Conv2d(128, 128, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 4. 卷积层：下采样，(128, 8, 8) -> (128, 4, 4)\n",
    "            nn.Conv2d(128, 128, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 5. 展平层：将 (128, 4, 4) 展平为向量 (128 * 4 * 4)\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.4),  # 添加 Dropout 防止过拟合\n",
    "\n",
    "            # 6. 全连接层：映射到单个输出值 (即概率)\n",
    "            nn.Linear(128 * 31 * 31, 1),\n",
    "            nn.Sigmoid()  # 使用 Sigmoid 输出范围在 [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78678732-f8a5-4866-9ed4-2d1d6855317f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:27:42.814615Z",
     "iopub.status.busy": "2024-12-27T07:27:42.812694Z",
     "iopub.status.idle": "2024-12-27T07:27:42.842195Z",
     "shell.execute_reply": "2024-12-27T07:27:42.841287Z",
     "shell.execute_reply.started": "2024-12-27T07:27:42.814615Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 全连接层：将潜在向量映射为形状 (512, 14, 14)\n",
    "            nn.Linear(latent_dim, 512 * 14 * 14),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            nn.Unflatten(1, (512, 14, 14)),  # 转换为形状 (batch, 512, 14, 14)\n",
    "\n",
    "            # 转置卷积层：第一次上采样 (512, 14, 14) -> (256, 28, 28)\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "\n",
    "            # 第二次上采样 (256, 28, 28) -> (128, 56, 56)\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "\n",
    "            # 第三次上采样 (128, 56, 56) -> (64, 112, 112)\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "\n",
    "            # 第四次上采样 (64, 112, 112) -> (channels, 224, 224)\n",
    "            nn.ConvTranspose2d(64, channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()  # 输出范围限制在 [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 卷积层：初始通道从图像通道数增加到 64，(3, 224, 224) -> (64, 112, 112)\n",
    "            nn.Conv2d(channels, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 卷积层：下采样，(64, 112, 112) -> (128, 56, 56)\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 卷积层：下采样，(128, 56, 56) -> (256, 28, 28)\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 卷积层：下采样，(256, 28, 28) -> (512, 14, 14)\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 卷积层：下采样，(512, 14, 14) -> (1024, 7, 7)\n",
    "            nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 展平层：将 (1024, 7, 7) 展平为向量 (1024 * 7 * 7)\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            # 全连接层：映射到单个输出值 (即概率)\n",
    "            nn.Linear(1024 * 7 * 7, 1),\n",
    "            nn.Sigmoid()  # 输出范围在 [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3e39b-b98d-4d5e-b9a6-9393baffc4bf",
   "metadata": {},
   "source": [
    "### 预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f8f7a5-32f2-4e5f-92f6-79974f9b67ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:20:49.601215Z",
     "iopub.status.busy": "2024-12-27T07:20:49.597280Z",
     "iopub.status.idle": "2024-12-27T07:20:49.633001Z",
     "shell.execute_reply": "2024-12-27T07:20:49.631630Z",
     "shell.execute_reply.started": "2024-12-27T07:20:49.601215Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        vgg = models.vgg16(pretrained=True)\n",
    "\n",
    "        # 如果输入通道数不为3，则添加自定义的卷积层\n",
    "        if channels != 3:\n",
    "            self.input_layer = nn.Conv2d(channels, 3, kernel_size=3, stride=1, padding=1)\n",
    "        else:\n",
    "            self.input_layer = nn.Identity()  # 不改变输入\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*list(vgg.features[:10]))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 14 * 14, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = self.input_layer(img)  # 调整输入通道数\n",
    "        with torch.no_grad():  # 冻结预训练模型的参数\n",
    "            features = self.feature_extractor(img)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        print(features.shape)\n",
    "        validity = self.fc(features)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8a85a-aca7-4f64-a911-19f9a7b3d25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07dd7c1d-9a6f-4ed0-bb1f-e833ef76bc18",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d86146a-1425-474c-ae4c-21fde07a852a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:27:46.370368Z",
     "iopub.status.busy": "2024-12-27T07:27:46.370368Z",
     "iopub.status.idle": "2024-12-27T07:27:46.406386Z",
     "shell.execute_reply": "2024-12-27T07:27:46.405497Z",
     "shell.execute_reply.started": "2024-12-27T07:27:46.370368Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_args, generator_args, discriminator_args):\n",
    "    # 参数配置\n",
    "    generator_name = train_args['generator_name']  # 生成器模型名称\n",
    "    discriminator_name = train_args['discriminator_name']  # 判别器模型名称\n",
    "    data_loader = train_args['data_loader']  # 训练集\n",
    "    n_epochs = train_args['n_epochs']  # 训练次数\n",
    "    learning_rate = train_args['learning_rate']  # 学习率\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path']  # 模型保存路径\n",
    "    image_path = train_args['image_path']  # 生成图像路径\n",
    "    verbose = train_args['verbose']  # 打印训练过程\n",
    "    plots = train_args['plots']  # 绘制损失图\n",
    "    device = train_args['device']  # 可选'cuda'和'cpu'\n",
    "    clip_value = train_args['clip_value'] # 裁剪值\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    latent_dim = generator_args['latent_dim'] # 潜在向量维度，图像尺寸\n",
    "    channels = generator_args['channels'] # 颜色通道数\n",
    "\n",
    "    # 检查可用device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "\n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 定义模型和损失函数\n",
    "    generator = generator_name(**generator_args).to(device)\n",
    "    discriminator = discriminator_name(**discriminator_args).to(device)\n",
    "\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    criterion = loss\n",
    "\n",
    "    # 损失函数值\n",
    "    G_losses, D_losses = [], []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        # generator.train()\n",
    "        # discriminator.train()\n",
    "        total_G_loss = 0\n",
    "        total_D_loss = 0\n",
    "        for i, (imgs, _) in enumerate(data_loader):\n",
    "            # 将输入数据移至device\n",
    "            imgs = imgs.to(device)\n",
    "\n",
    "            # 创建真实标签和假标签\n",
    "            real_labels = torch.ones(imgs.size(0), 1).to(device)  # 真实图像标签为 1\n",
    "            fake_labels = torch.zeros(imgs.size(0), 1).to(device) # 生成图像标签为 0\n",
    "\n",
    "            # 训练判别器\n",
    "            z = torch.randn(imgs.size(0), latent_dim).to(device)  # 从标准正态分布中采样潜在向量\n",
    "            fake_imgs = generator(z)  # 使用生成器生成假图像\n",
    "    \n",
    "            real_loss = criterion(discriminator(imgs), real_labels)  # 判别器对真实图像的损失\n",
    "            fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)  # 判别器对假图像的损失\n",
    "            loss_D = real_loss + fake_loss  # 判别器总损失\n",
    "    \n",
    "            optimizer_D.zero_grad()  # 清空梯度\n",
    "            loss_D.backward()  # 反向传播\n",
    "            torch.nn.utils.clip_grad_norm_(discriminator.parameters(), clip_value) # 判别器梯度裁剪\n",
    "            optimizer_D.step()  # 更新判别器参数\n",
    "    \n",
    "            # 训练生成器\n",
    "            loss_G = criterion(discriminator(fake_imgs), real_labels)  # 生成器希望生成的图像被判别为真实\n",
    "    \n",
    "            optimizer_G.zero_grad()  # 清空梯度\n",
    "            loss_G.backward()  # 反向传播\n",
    "            torch.nn.utils.clip_grad_norm_(generator.parameters(), clip_value) # 生成器梯度裁剪\n",
    "            optimizer_G.step()  # 更新生成器参数\n",
    "\n",
    "            # 计算每个batch的loss和\n",
    "            total_G_loss += loss_G.item()\n",
    "            total_D_loss += loss_D.item()\n",
    "\n",
    "        # 计算每个epoch的损失平均\n",
    "        avg_G_loss = total_G_loss / len(data_loader)\n",
    "        avg_D_loss = total_D_loss / len(data_loader)\n",
    "\n",
    "        # 记录所有epoch的loss\n",
    "        G_losses.append(avg_G_loss)\n",
    "        D_losses.append(avg_D_loss)\n",
    "\n",
    "        # 打印训练过程\n",
    "        print(\n",
    "            f'Epoch [{epoch}/{n_epochs}], Generator Loss: {avg_G_loss:.4f}, Discriminator Loss: {avg_D_loss:.4f}')\n",
    "\n",
    "        # 每个 epoch 保存生成的图片\n",
    "        fake_imgs = fake_imgs.view(fake_imgs.size(0), channels, latent_dim, latent_dim)\n",
    "        vutils.save_image(fake_imgs[:25], f\"{image_path}/output_epoch_{epoch+1}.png\", nrow=5, normalize=True)\n",
    "\n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer_G, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        adjust_learning_rate(optimizer_D, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    # 绘制损失函数图\n",
    "    def plot_loss(G_losses, D_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper')  # 绘制背景色\n",
    "        plt.grid(axis='y', linewidth=0.35)  # 绘制网格\n",
    "        plt.plot(G_losses, linestyle='-', color='#11b3b6')\n",
    "        plt.plot(D_losses, linestyle='-', color='#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Generator\", \"Discriminator\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(G_losses, D_losses)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0d758f0-1eef-4eca-b8b3-b118af8aadb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T07:27:47.106378Z",
     "iopub.status.busy": "2024-12-27T07:27:47.105214Z",
     "iopub.status.idle": "2024-12-27T07:44:05.703621Z",
     "shell.execute_reply": "2024-12-27T07:44:05.701824Z",
     "shell.execute_reply.started": "2024-12-27T07:27:47.106260Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [16:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 27\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 构造参数字典\u001b[39;00m\n\u001b[0;32m      2\u001b[0m params2 \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: Generator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     },\n\u001b[0;32m     26\u001b[0m }\n\u001b[1;32m---> 27\u001b[0m generator \u001b[38;5;241m=\u001b[39m train(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams2)\n",
      "Cell \u001b[1;32mIn[27], line 87\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_args, generator_args, discriminator_args)\u001b[0m\n\u001b[0;32m     85\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# 清空梯度\u001b[39;00m\n\u001b[0;32m     86\u001b[0m loss_G\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# 反向传播\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 生成器梯度裁剪\u001b[39;00m\n\u001b[0;32m     88\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# 更新生成器参数\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# 计算每个batch的loss和\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\cv\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), [grads]) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m foreach) \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(grads, device\u001b[38;5;241m=\u001b[39mdevice):\n\u001b[1;32m---> 76\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_coef_clamped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"train_args\": {\n",
    "        \"generator_name\": Generator,\n",
    "        \"discriminator_name\": Discriminator,\n",
    "        \"data_loader\": data_loader,\n",
    "        \"n_epochs\": 100,\n",
    "        \"patience\": 50,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../outputs/best_models/DCGAN\",\n",
    "        \"image_path\": \"../outputs/images\",\n",
    "        \"device\": 'cuda',\n",
    "        \"loss\": nn.BCELoss(),\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "        \"clip_value\": 1.0,\n",
    "    },\n",
    "    \"generator_args\": {\n",
    "        'latent_dim': 224,\n",
    "        'channels': 3,\n",
    "    },\n",
    "    \"discriminator_args\": {\n",
    "        'channels': 3,\n",
    "    },\n",
    "}\n",
    "generator = train(**params2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede1ec3-c9e3-4997-a71b-bc5372bf9e29",
   "metadata": {},
   "source": [
    "## 图像生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77e521-112e-41d7-a7cc-3d6742f4e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_args, generator_args, discriminator_args):\n",
    "    # 参数配置\n",
    "    generator_name = train_args['generator_name']  # 生成器模型名称\n",
    "    discriminator_name = train_args['discriminator_name']  # 判别器模型名称\n",
    "    data_loader = train_args['data_loader']  # 训练集\n",
    "    n_epochs = train_args['n_epochs']  # 训练次数\n",
    "    learning_rate = train_args['learning_rate']  # 学习率\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path']  # 模型保存路径\n",
    "    image_path = train_args['image_path']  # 生成图像路径\n",
    "    verbose = train_args['verbose']  # 打印训练过程\n",
    "    plots = train_args['plots']  # 绘制损失图\n",
    "    device = train_args['device']  # 可选'cuda'和'cpu'\n",
    "    clip_value = train_args['clip_value'] # 裁剪值\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    latent_dim = generator_args['latent_dim'] # 潜在向量维度，图像尺寸\n",
    "    channels = generator_args['channels'] # 颜色通道数\n",
    "\n",
    "    # 检查可用device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "\n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 定义模型和损失函数\n",
    "    generator = generator_name(**generator_args).to(device)\n",
    "    discriminator = discriminator_name(**discriminator_args).to(device)\n",
    "\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    criterion = loss\n",
    "\n",
    "    # 损失函数值\n",
    "    G_losses, D_losses = [], []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        # generator.train()\n",
    "        # discriminator.train()\n",
    "        total_G_loss = 0\n",
    "        total_D_loss = 0\n",
    "        for i, (imgs, _) in enumerate(data_loader):\n",
    "            # 将输入数据移至device\n",
    "            imgs = imgs.to(device)\n",
    "\n",
    "            # 创建真实标签和假标签\n",
    "            real_labels = torch.ones(imgs.size(0), 1).to(device)  # 真实图像标签为 1\n",
    "            fake_labels = torch.zeros(imgs.size(0), 1).to(device) # 生成图像标签为 0\n",
    "\n",
    "            # 训练判别器\n",
    "            z = torch.randn(imgs.size(0), latent_dim).to(device)  # 从标准正态分布中采样潜在向量\n",
    "            fake_imgs = generator(z)  # 使用生成器生成假图像\n",
    "    \n",
    "            real_loss = criterion(discriminator(imgs), real_labels)  # 判别器对真实图像的损失\n",
    "            fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)  # 判别器对假图像的损失\n",
    "            loss_D = real_loss + fake_loss  # 判别器总损失\n",
    "    \n",
    "            optimizer_D.zero_grad()  # 清空梯度\n",
    "            loss_D.backward()  # 反向传播\n",
    "            torch.nn.utils.clip_grad_norm_(discriminator.parameters(), clip_value) # 判别器梯度裁剪\n",
    "            optimizer_D.step()  # 更新判别器参数\n",
    "    \n",
    "            # 训练生成器\n",
    "            loss_G = criterion(discriminator(fake_imgs), real_labels)  # 生成器希望生成的图像被判别为真实\n",
    "    \n",
    "            optimizer_G.zero_grad()  # 清空梯度\n",
    "            loss_G.backward()  # 反向传播\n",
    "            torch.nn.utils.clip_grad_norm_(generator.parameters(), clip_value) # 生成器梯度裁剪\n",
    "            optimizer_G.step()  # 更新生成器参数\n",
    "\n",
    "            # 计算每个batch的loss和\n",
    "            total_G_loss += loss_G.item()\n",
    "            total_D_loss += loss_D.item()\n",
    "\n",
    "        # 计算每个epoch的损失平均\n",
    "        avg_G_loss = total_G_loss / len(data_loader)\n",
    "        avg_D_loss = total_D_loss / len(data_loader)\n",
    "\n",
    "        # 记录所有epoch的loss\n",
    "        G_losses.append(avg_G_loss)\n",
    "        D_losses.append(avg_D_loss)\n",
    "\n",
    "        # 打印训练过程\n",
    "        print(\n",
    "            f'Epoch [{epoch}/{n_epochs}], Generator Loss: {avg_G_loss:.4f}, Discriminator Loss: {avg_D_loss:.4f}')\n",
    "\n",
    "        # 每个 epoch 保存生成的图片\n",
    "        fake_imgs = fake_imgs.view(fake_imgs.size(0), channels, latent_dim, latent_dim)\n",
    "        vutils.save_image(fake_imgs[:25], f\"{image_path}/output_epoch_{epoch+1}.png\", nrow=5, normalize=True)\n",
    "\n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer_G, epoch+1, lradj, learning_rate, n_epochs)\n",
    "        adjust_learning_rate(optimizer_D, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    # 绘制损失函数图\n",
    "    def plot_loss(G_losses, D_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper')  # 绘制背景色\n",
    "        plt.grid(axis='y', linewidth=0.35)  # 绘制网格\n",
    "        plt.plot(G_losses, linestyle='-', color='#11b3b6')\n",
    "        plt.plot(D_losses, linestyle='-', color='#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Generator\", \"Discriminator\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(G_losses, D_losses)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dece94f-22a3-48ef-b895-68a55eeccd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_args, generator_args, discriminator_args):\n",
    "    # 参数配置\n",
    "    generator_name = train_args['generator_name']\n",
    "    discriminator_name = train_args['discriminator_name']\n",
    "    data_loader = train_args['data_loader']\n",
    "    n_epochs = train_args['n_epochs']\n",
    "    learning_rate = train_args['learning_rate']\n",
    "    lradj = train_args['lradj']\n",
    "    model_path = train_args['model_path']\n",
    "    image_path = train_args['image_path']\n",
    "    verbose = train_args['verbose']\n",
    "    plots = train_args['plots']\n",
    "    device = train_args['device']\n",
    "    clip_value = train_args['clip_value']\n",
    "    loss = train_args['loss']\n",
    "    latent_dim = generator_args['latent_dim']\n",
    "    channels = generator_args['channels']\n",
    "    noise_level = train_args.get('noise_level', 0.1)  # 默认噪声强度\n",
    "\n",
    "    # 检查可用device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # 添加噪声\n",
    "    def add_noise(images, noise_level=0.1):\n",
    "        \"\"\"\n",
    "        对图像添加随机噪声\n",
    "        :param images: 输入图像张量\n",
    "        :param noise_level: 噪声强度（默认0.1）\n",
    "        :return: 添加噪声后的图像张量\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(images) * noise_level\n",
    "        noisy_images = images + noise\n",
    "        return noisy_images.clamp(0.0, 1.0)  # 保证像素值在[0, 1]范围内\n",
    "\n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate / 2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "\n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 定义模型和损失函数\n",
    "    generator = generator_name(**generator_args).to(device)\n",
    "    discriminator = discriminator_name(**discriminator_args).to(device)\n",
    "\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    criterion = loss\n",
    "\n",
    "    # 损失函数值\n",
    "    G_losses, D_losses = [], []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        total_G_loss = 0\n",
    "        total_D_loss = 0\n",
    "        for i, (imgs, _) in enumerate(data_loader):\n",
    "            # 将输入数据移至device\n",
    "            imgs = imgs.to(device)\n",
    "\n",
    "            # 对真实图像添加噪声\n",
    "            noisy_real_imgs = add_noise(imgs, noise_level=noise_level)\n",
    "\n",
    "            # 创建真实标签和假标签\n",
    "            # real_labels = torch.ones(imgs.size(0), 1).to(device)\n",
    "            # fake_labels = torch.zeros(imgs.size(0), 1).to(device)\n",
    "            # 使用标签平滑\n",
    "            real_labels = torch.full((imgs.size(0), 1), 0.9).to(device)  # 真实标签平滑到 0.9\n",
    "            fake_labels = torch.full((imgs.size(0), 1), 0.1).to(device)  # 假标签平滑到 0.1\n",
    "\n",
    "            # 生成假图像\n",
    "            z = torch.randn(imgs.size(0), latent_dim).to(device)\n",
    "            fake_imgs = generator(z)\n",
    "            noisy_fake_imgs = add_noise(fake_imgs, noise_level=noise_level)\n",
    "\n",
    "            # 判别器损失计算\n",
    "            real_loss = criterion(discriminator(noisy_real_imgs), real_labels)\n",
    "            fake_loss = criterion(discriminator(noisy_fake_imgs.detach()), fake_labels)\n",
    "            loss_D = real_loss + fake_loss\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(discriminator.parameters(), clip_value)\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # 训练生成器\n",
    "            loss_G = criterion(discriminator(noisy_fake_imgs), real_labels)\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            loss_G.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(generator.parameters(), clip_value)\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # 记录损失\n",
    "            total_G_loss += loss_G.item()\n",
    "            total_D_loss += loss_D.item()\n",
    "\n",
    "        # 计算每个epoch的损失平均\n",
    "        avg_G_loss = total_G_loss / len(data_loader)\n",
    "        avg_D_loss = total_D_loss / len(data_loader)\n",
    "\n",
    "        # 记录所有epoch的loss\n",
    "        G_losses.append(avg_G_loss)\n",
    "        D_losses.append(avg_D_loss)\n",
    "\n",
    "        # 打印训练过程\n",
    "        print(\n",
    "            f'Epoch [{epoch}/{n_epochs}], Generator Loss: {avg_G_loss:.4f}, Discriminator Loss: {avg_D_loss:.4f}')\n",
    "\n",
    "        # 每个 epoch 保存生成的图片\n",
    "        fake_imgs = fake_imgs.view(fake_imgs.size(0), channels, latent_dim, latent_dim)\n",
    "        vutils.save_image(fake_imgs[:25], f\"{image_path}/output_epoch_{epoch+1}.png\", nrow=5, normalize=True)\n",
    "\n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer_G, epoch + 1, lradj, learning_rate, n_epochs)\n",
    "        adjust_learning_rate(optimizer_D, epoch + 1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    # 绘制损失函数图\n",
    "    def plot_loss(G_losses, D_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper')\n",
    "        plt.grid(axis='y', linewidth=0.35)\n",
    "        plt.plot(G_losses, linestyle='-', color='#11b3b6')\n",
    "        plt.plot(D_losses, linestyle='-', color='#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Generator\", \"Discriminator\"])\n",
    "        plt.show()\n",
    "\n",
    "    if plots:\n",
    "        plot_loss(G_losses, D_losses)\n",
    "\n",
    "    return generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f370b38-bb00-4ea4-8b1e-c175ddd86abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器网络\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 1. 全连接层：将潜在向量 (latent_dim) 投影并展平为形状 (128, 8, 8)\n",
    "            nn.Linear(latent_dim, 128 * 8 * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Unflatten(1, (128, 8, 8)),  # 转换为形状 (batch, 128, 8, 8)\n",
    "\n",
    "            # 2. 转置卷积层：第一次上采样，(128, 8, 8) -> (128, 16, 16)\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 3. 转置卷积层：第二次上采样，(128, 16, 16) -> (64, 32, 32)\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 4. 卷积层：输出通道调整为图像通道数 (64, 32, 32) -> (3, 32, 32)\n",
    "            nn.Conv2d(64, channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()  # 将输出范围限制在 [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# 定义判别器网络\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 1. 卷积层：初始通道从图像通道数增加到 128，(3, 32, 32) -> (128, 32, 32)\n",
    "            nn.Conv2d(channels, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 2. 卷积层：下采样，(128, 32, 32) -> (128, 16, 16)\n",
    "            nn.Conv2d(128, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 3. 卷积层：下采样，(128, 16, 16) -> (128, 8, 8)\n",
    "            nn.Conv2d(128, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 4. 卷积层：下采样，(128, 8, 8) -> (128, 4, 4)\n",
    "            nn.Conv2d(128, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 5. 展平层：将 (128, 4, 4) 展平为向量 (128 * 4 * 4)\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.4),  # 添加 Dropout 防止过拟合\n",
    "\n",
    "            # 6. 全连接层：映射到单个输出值 (即概率)\n",
    "            nn.Linear(128 * 4 * 4, 1),\n",
    "            nn.Sigmoid()  # 使用 Sigmoid 输出范围在 [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
