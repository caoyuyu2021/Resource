{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb737ec2-af5f-4b50-8a01-27ceb80321e9",
   "metadata": {},
   "source": [
    "# 模型量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef80db7f-e7e5-4c9f-9d2d-1fc8c8a348c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:10:29.605496Z",
     "iopub.status.busy": "2024-12-29T09:10:29.605496Z",
     "iopub.status.idle": "2024-12-29T09:11:26.203415Z",
     "shell.execute_reply": "2024-12-29T09:11:26.202415Z",
     "shell.execute_reply.started": "2024-12-29T09:10:29.605496Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from datetime import timedelta\n",
    "from numpy import ndarray\n",
    "from typing import Union, List, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.quantization import quantize_dynamic\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # 打印进度条\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from pandas.tseries import offsets\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58eaec9-a5bf-4d15-800e-7fb59516f48f",
   "metadata": {},
   "source": [
    "在 PyTorch 中，模型量化是一种优化技术，可以减少模型的大小和计算复杂性，同时尽可能保持精度。以下是 PyTorch 支持的几种模型量化方法："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a9945-75c8-4fac-b313-0a74f96d7da7",
   "metadata": {},
   "source": [
    "## 动态量化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d457a8-92e2-48ac-9b74-5256a365e4b8",
   "metadata": {},
   "source": [
    "动态量化是在推理过程中将权重和激活值按需量化。这种方法适用于 CPU 上的推理，尤其是对于 Transformer 模型等序列模型。需要直接保存模型，而不是保存模型权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606113bd-b8d8-4ed2-9196-dd9c2d31fdb1",
   "metadata": {},
   "source": [
    "动态量化简单直接，但仅支持 Linear 层，不支持 Conv1d。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fadf6a6-4eb9-434e-b2f5-e48751dba3b4",
   "metadata": {},
   "source": [
    "### 初始模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefeef4b-98b4-4797-9558-57f209db5340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:11:30.244378Z",
     "iopub.status.busy": "2024-12-29T09:11:30.241373Z",
     "iopub.status.idle": "2024-12-29T09:11:30.286960Z",
     "shell.execute_reply": "2024-12-29T09:11:30.285960Z",
     "shell.execute_reply.started": "2024-12-29T09:11:30.243382Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "\n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_1 = re.findall('[0-9]', freq)\n",
    "        re_2 = re.findall('[a-z]', freq)\n",
    "        # 识别数字频率\n",
    "        if len(re_1) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_1))\n",
    "        # 识别频率\n",
    "        fr = re_2[0]\n",
    "        # 生成时间间隔\n",
    "        if fr == 's':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(\n",
    "                                           seconds=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 't':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(\n",
    "                                           minutes=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 'h':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(\n",
    "                                           hours=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 'd':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(\n",
    "                                           days=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col]  # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f105e4b5-2f41-4caa-97bf-1f17f1c3cbc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T08:26:29.617165Z",
     "iopub.status.busy": "2024-12-29T08:26:29.616129Z",
     "iopub.status.idle": "2024-12-29T08:26:29.742463Z",
     "shell.execute_reply": "2024-12-29T08:26:29.741562Z",
     "shell.execute_reply.started": "2024-12-29T08:26:29.617165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72470fab-3922-43f3-9bc0-a024d1846319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:11:32.872212Z",
     "iopub.status.busy": "2024-12-29T09:11:32.871209Z",
     "iopub.status.idle": "2024-12-29T09:11:32.891598Z",
     "shell.execute_reply": "2024-12-29T09:11:32.890263Z",
     "shell.execute_reply.started": "2024-12-29T09:11:32.872212Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60185e12-4296-4f88-851f-9e39ca4ca7b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:11:33.526209Z",
     "iopub.status.busy": "2024-12-29T09:11:33.523524Z",
     "iopub.status.idle": "2024-12-29T09:11:33.601800Z",
     "shell.execute_reply": "2024-12-29T09:11:33.599904Z",
     "shell.execute_reply.started": "2024-12-29T09:11:33.526209Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "def divider(df, train_ratio, valid_ratio, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    \"\"\"\n",
    "    读取数据，并对数据进行划分\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    df : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据\n",
    "    train_ratio : {float}\n",
    "        用于训练的数据集占比:将数据按照一定比例进行切分，取值范围为(0,1)\n",
    "    valid_ratio : {float}\n",
    "        用于验证的数据集占比:将数据按照一定比例进行切分，取值范围为(0,1)\n",
    "    x_feature_list : {list[str]} \n",
    "        训练特征列，不包含时间列\n",
    "    y_feature_list : {list[str]} \n",
    "        目标特征列，不包含时间列\n",
    "    freq : {str}\n",
    "        用来编码时间特征的频率，可选[s:秒,t:分,h:时,d:天,b:工作日,w:周,m:月]，频率越低，模型可能越精确\n",
    "    scaler_path : {str} \n",
    "        数据归一化模型保存地址\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    x_scaler : {sklearn.preprocessing.MinMaxScaler}\n",
    "        训练特征列归一化器\n",
    "    y_scaler : {sklearn.preprocessing.MinMaxScaler}\n",
    "        目标特征列归一化器\n",
    "    train : {list[DataFrame]}\n",
    "        训练特征数据，目标特征数据，时间特征数据\n",
    "    valid : {list[DataFrame]}\n",
    "        验证特征数据，目标特征数据，时间特征数据\n",
    "    test : {list[DataFrame]}\n",
    "        测试特征数据，目标特征数据，时间特征数据\n",
    "    \"\"\"\n",
    "    # 归一化\n",
    "    x_scaler = MinMaxScaler()  # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list])\n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    # 测试集\n",
    "    train = df.copy().iloc[:int(df.shape[0]*train_ratio), :][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "    ytr = df.copy().iloc[:int(df.shape[0]*train_ratio), :][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "\n",
    "    # 验证集\n",
    "    if train_ratio != 1:\n",
    "        valid = df.copy().iloc[int(df.shape[0]*train_ratio)\n",
    "                        : int(df.shape[0]*(train_ratio+valid_ratio)), :][x_feature_list]\n",
    "        valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "        valid_stamp = valid_stamp.transpose(1, 0)\n",
    "        valid[x_feature_list] = x_scaler.transform(valid)\n",
    "        xva = valid.values.astype('float32')\n",
    "        yva = df.copy().iloc[int(df.shape[0]*train_ratio)\n",
    "                      : int(df.shape[0]*(train_ratio+valid_ratio)), :][y_feature_list]\n",
    "        yva[y_feature_list] = y_scaler.transform(yva)\n",
    "        yva = yva.values.astype('float32')\n",
    "        valid = [xva, yva, valid_stamp]\n",
    "    else:\n",
    "        valid = [np.array(0), np.array(0), np.array(0)]\n",
    "\n",
    "    # 测试集\n",
    "    if train_ratio + valid_ratio != 1:\n",
    "        test = df.copy().iloc[int(\n",
    "            df.shape[0]*(train_ratio+valid_ratio)):, :][x_feature_list]\n",
    "        test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "        test_stamp = test_stamp.transpose(1, 0)\n",
    "        test[x_feature_list] = x_scaler.transform(test)\n",
    "        xte = test.values.astype('float32')\n",
    "        yte = df.copy().iloc[int(\n",
    "            df.shape[0]*(train_ratio+valid_ratio)):, :][y_feature_list]\n",
    "        yte[y_feature_list] = y_scaler.transform(yte)\n",
    "        yte = yte.values.astype('float32')\n",
    "        test = [xte, yte, test_stamp]\n",
    "    else:\n",
    "        test = [np.array(0), np.array(0), np.array(0)]\n",
    "\n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a74f800-0a6e-4b34-9976-dbc807a452b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T08:26:57.657770Z",
     "iopub.status.busy": "2024-12-29T08:26:57.656771Z",
     "iopub.status.idle": "2024-12-29T08:26:57.758276Z",
     "shell.execute_reply": "2024-12-29T08:26:57.757277Z",
     "shell.execute_reply.started": "2024-12-29T08:26:57.657770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (18412, 2) y_train shape: (18412, 2) stamp_train shape: (18412, 4)\n",
      "x_valid shape: (2631, 2) y_valid shape: (2631, 2) stamp_valid shape: (2631, 4)\n",
      "x_test shape: (5261, 2) y_test shape: (5261, 2) stamp_test shape: (5261, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"train_ratio\": 0.7,\n",
    "    \"valid_ratio\": 0.1,\n",
    "    \"x_feature_list\": ['load', 'temp'],\n",
    "    \"y_feature_list\": ['load', 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../outputs/scalers/Transformer'\n",
    "}\n",
    "\n",
    "# 函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(\n",
    "    train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(\n",
    "    valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(\n",
    "    test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b41ed026-1c94-42fa-89ae-5890af74ed52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:11:35.759734Z",
     "iopub.status.busy": "2024-12-29T09:11:35.756716Z",
     "iopub.status.idle": "2024-12-29T09:11:35.795959Z",
     "shell.execute_reply": "2024-12-29T09:11:35.794776Z",
     "shell.execute_reply.started": "2024-12-29T09:11:35.758807Z"
    }
   },
   "outputs": [],
   "source": [
    "# 利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size, sample_freq: int = 1):\n",
    "    \"\"\"\n",
    "    读取数据，并对数据进行划分\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_list : {list[DataFrame]}\n",
    "        输入特征数据，目标特征数据，时间特征数据\n",
    "    seq_len : {int}\n",
    "        输入数据包含过去多少个时间步，正整数\n",
    "    pred_len : {int}\n",
    "        目标应该在未来多少个时间步之后，正整数\n",
    "    label_len : {int} \n",
    "        先验时间步\n",
    "    batch_size : {int} \n",
    "        输入数据的批次大小，正整数\n",
    "    sample_freq : {int} \n",
    "        采样频率，正整数\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    X : {torch.Tensor}\n",
    "        特征数据张量\n",
    "    y : {torch.Tensor}\n",
    "        目标数据张量\n",
    "    X_stamp : {torch.Tensor}\n",
    "        特征时间编码张量\n",
    "    y_stamp : {torch.Tensor}\n",
    "        目标时间编码张量\n",
    "    data_loader : {torch.utils.data.dataloader.DataLoader}\n",
    "        数据加载器，[特征，目标，特征时间编码，目标时间编码]\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0]  # 特征\n",
    "    target = data_list[1]  # 目标\n",
    "    stamp = data_list[2]  # 时间戳，不包含未来的时间\n",
    "\n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "\n",
    "    for index in range(0, len(feature) - seq_len - pred_len + 1, sample_freq):\n",
    "        # 起点\n",
    "        s_begin = index\n",
    "        # 终点(起点 + 回视窗口)\n",
    "        s_end = s_begin + seq_len\n",
    "        # (终点 - 先验序列窗口)\n",
    "        r_begin = s_end - label_len\n",
    "        # (终点 + 预测序列长度)\n",
    "        r_end = r_begin + label_len + pred_len\n",
    "\n",
    "        # 数据维度\n",
    "        feat = feature[s_begin: s_end]\n",
    "        tar = target[r_begin: r_end]\n",
    "        X.append(np.array(feat))\n",
    "        y.append(np.array(tar))\n",
    "\n",
    "        # 时间维度\n",
    "        xs = stamp[s_begin: s_end]\n",
    "        ys = stamp[r_begin: r_end]\n",
    "        X_stamp.append(np.array(xs))\n",
    "        y_stamp.append(np.array(ys))\n",
    "\n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "\n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "\n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(\n",
    "        X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d4ccb26-79c7-4382-be07-367148b229d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T08:27:12.689300Z",
     "iopub.status.busy": "2024-12-29T08:27:12.688302Z",
     "iopub.status.idle": "2024-12-29T08:27:18.346848Z",
     "shell.execute_reply": "2024-12-29T08:27:18.345850Z",
     "shell.execute_reply.started": "2024-12-29T08:27:12.689300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([18350, 60, 2]),y_size: torch.Size([18350, 13, 2]),loader_len: 574\n",
      "X_size: torch.Size([2569, 60, 2]),y_size: torch.Size([2569, 13, 2]),loader_len: 81\n",
      "X_size: torch.Size([5199, 60, 2]),y_size: torch.Size([5199, 13, 2]),loader_len: 163\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 60,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 10,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(\n",
    "    train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(\n",
    "    valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(\n",
    "    test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(\n",
    "    X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(\n",
    "    X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(\n",
    "    X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed0ee65-85b8-4fea-a9b3-43082ea4bca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:11:37.910402Z",
     "iopub.status.busy": "2024-12-29T09:11:37.909782Z",
     "iopub.status.idle": "2024-12-29T09:11:37.993166Z",
     "shell.execute_reply": "2024-12-29T09:11:37.991517Z",
     "shell.execute_reply.started": "2024-12-29T09:11:37.910402Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "        \n",
    "        # freq拆分\n",
    "        number = re.findall('[0-9]', freq)\n",
    "        number = 1 if len(number)==0 else int(''.join(number))\n",
    "        string = re.findall('[a-z]', freq)[0]\n",
    "        if string == 'h':\n",
    "            hour_size = int(24 / number)\n",
    "        elif string == 't':\n",
    "            hour_size = 24\n",
    "            minute_size = int(60 / number)\n",
    "        elif string == 's':\n",
    "            hour_size = 24\n",
    "            minute_size = 60\n",
    "            second_size = int(60 / number)\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        if freq == 's':\n",
    "            self.second_embed = Embed(second_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        second_x = self.second_embed(x[:, :, 5]) if hasattr(\n",
    "            self, 'second_embed') else 0.\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x + second_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# Transformer_EncDec类\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "    \n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
    "                 dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask,\n",
    "            tau=tau, delta=None\n",
    "        )[0])\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )[0])\n",
    "\n",
    "        y = x = self.norm2(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm3(x + y)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask, tau=tau, delta=delta)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# 自编码类\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "    \n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "        \n",
    "        \n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "# Transformer模型\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "        embed: time features encoding, options:[timeF, fixed, learned]\n",
    "        freq: 'freq for time features encoding, options:[s:secondly, \n",
    "            t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], \n",
    "            you can also use more detailed freq like 15min or 3h'\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len, pred_len, label_len, output_attention, enc_in, d_model, dropout, factor, n_heads, d_ff, \n",
    "                e_layers, dec_in, d_layers, c_out, embed, freq):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.output_attention = output_attention\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                      output_attention=output_attention), d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu'\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(True, factor, attention_dropout=dropout,\n",
    "                                      output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                      output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model),\n",
    "            projection=nn.Linear(d_model, c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out, x_mask=None, cross_mask=None)\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "822c75d6-ce3d-41fc-bdf5-57876d420254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T08:29:13.999796Z",
     "iopub.status.busy": "2024-12-29T08:29:13.998686Z",
     "iopub.status.idle": "2024-12-29T08:29:14.066250Z",
     "shell.execute_reply": "2024-12-29T08:29:14.065319Z",
     "shell.execute_reply.started": "2024-12-29T08:29:13.999686Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_args, model_args):\n",
    "    # 参数配置\n",
    "    features = train_args['features']  # 模型预测模式\n",
    "    model_name = train_args['model_name']  # 模型名称\n",
    "    train_loader = train_args['train_loader']  # 训练集\n",
    "    valid_loader = train_args['valid_loader']  # 验证集\n",
    "    n_epochs = train_args['n_epochs']  # 训练次数\n",
    "    learning_rate = train_args['learning_rate']  # 学习率\n",
    "    loss = train_args['loss']  # 损失函数\n",
    "    patience = train_args['patience']  # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj']  # 学习率函数\n",
    "    model_path = train_args['model_path']  # 模型保存路径\n",
    "    verbose = train_args['verbose']  # 打印训练过程\n",
    "    plots = train_args['plots']  # 绘制损失图\n",
    "    device = train_args['device']  # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len']  # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "\n",
    "    # 检查可用device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "\n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate / 2 *\n",
    "                         (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "\n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience  # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(\n",
    "                    f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(\n",
    "                    f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model, path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "\n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            # 将数据移至 device\n",
    "            batch_x = batch_x.to(device)  # 会用到实际数据\n",
    "            batch_y = batch_y.to(device)  # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            f_dim = -1 if features == 'MS' else 0\n",
    "            outputs = outputs[:, -pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -pred_len:, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            # 每个batch的loss和\n",
    "            total_train_loss += train_loss.item()  # .item()表示只包含一个元素的tensor中提取值\n",
    "\n",
    "        # 每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # 所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # 评估模型\n",
    "        model.eval()\n",
    "        # 关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                # 将数据移至 device\n",
    "                batch_x = batch_x.to(device)  # 会用到实际数据\n",
    "                batch_y = batch_y.to(device)  # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if features == 'MS' else 0\n",
    "                outputs = outputs[:, -pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -pred_len:, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                # 每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "        # 每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "\n",
    "        # 所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # 打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj,\n",
    "                             learning_rate, n_epochs)\n",
    "\n",
    "    # 绘制损失函数图\n",
    "    def plot_loss(train_loss, val_loss):\n",
    "        \"\"\"\n",
    "        绘制训练和验证损失曲线\n",
    "\n",
    "        参数:\n",
    "        - train_loss: 训练损失数组\n",
    "        - val_loss: 验证损失数组\n",
    "        \"\"\"\n",
    "        # 自动生成 epochs（假设train_loss和val_loss长度一致）\n",
    "        epochs = np.arange(len(train_loss))\n",
    "\n",
    "        # 使用 Seaborn 设置白色背景样式\n",
    "        sns.set(style=\"white\")\n",
    "\n",
    "        # 创建图形并优化细节\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # 绘制训练和验证曲线\n",
    "        plt.plot(epochs, train_loss, label='Training', color='#d62728', linewidth=2, marker='o', markersize=6)\n",
    "        plt.plot(epochs, val_loss, label='Validation', color='#1f77b4', linewidth=2, marker='s', markersize=6)\n",
    "\n",
    "        # 添加标题和标签\n",
    "        plt.title('Training and Validation Loss', fontsize=18, fontweight='bold', color='black')\n",
    "        plt.xlabel('Epoch', fontsize=14)\n",
    "        plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "        # 添加图例\n",
    "        plt.legend(fontsize=12, loc='upper right')\n",
    "\n",
    "        # 启用横向网格线\n",
    "        plt.grid(True, axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        # 去掉顶部和右侧的边框，仅显示左侧和底部的边框\n",
    "        plt.gca().spines['top'].set_visible(False)\n",
    "        plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "        # 可选：修改左侧和底部边框的样式\n",
    "        plt.gca().spines['left'].set_linewidth(1.5)\n",
    "        plt.gca().spines['bottom'].set_linewidth(1.5)\n",
    "\n",
    "        plt.gca().spines['left'].set_visible(True)\n",
    "        plt.gca().spines['bottom'].set_visible(True)\n",
    "\n",
    "        plt.gca().tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "        # 调整布局以防止标签重叠\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 展示图形\n",
    "        plt.show()\n",
    "\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecd094f1-e25d-40d1-b8f5-9628e7cb7d73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T08:29:51.566578Z",
     "iopub.status.busy": "2024-12-29T08:29:51.565581Z",
     "iopub.status.idle": "2024-12-29T08:38:50.579875Z",
     "shell.execute_reply": "2024-12-29T08:38:50.578527Z",
     "shell.execute_reply.started": "2024-12-29T08:29:51.566578Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                 | 1/50 [01:04<52:31, 64.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 0.1204, Validation Loss: 0.0022\n",
      "Validation loss decreased (inf --> 0.002218).  Saving model ...\n",
      "Updating learning rate to 0.0009990133642141358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 2/50 [02:08<51:29, 64.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Training Loss: 0.0041, Validation Loss: 0.0029\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.000996057350657239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                              | 3/50 [03:19<52:40, 67.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Training Loss: 0.0025, Validation Loss: 0.0009\n",
      "Validation loss decreased (0.002218 --> 0.000903).  Saving model ...\n",
      "Updating learning rate to 0.0009911436253643444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                            | 4/50 [04:27<51:44, 67.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Training Loss: 0.0016, Validation Loss: 0.0013\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0009842915805643156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 5/50 [05:35<50:44, 67.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Training Loss: 0.0013, Validation Loss: 0.0025\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▉                                                                         | 6/50 [06:42<49:30, 67.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Training Loss: 0.0012, Validation Loss: 0.0013\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 0.0009648882429441257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▌                                                                       | 7/50 [07:49<48:19, 67.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Training Loss: 0.0010, Validation Loss: 0.0014\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 0.0009524135262330098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▌                                                                       | 7/50 [08:56<54:58, 76.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Training Loss: 0.0010, Validation Loss: 0.0009\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"train_args\": {\n",
    "        \"features\": 'M',\n",
    "        \"model_name\": Transformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 50,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 5,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../outputs/best_models/Transformer\",\n",
    "        \"device\": 'cuda',\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'seq_len': 60,\n",
    "        'pred_len': 3, \n",
    "        'label_len': 10,\n",
    "        'output_attention': True,\n",
    "        'embed': 'timeF', # 可选'timeF','fixed'和'learned'\n",
    "        'freq': 'h',\n",
    "        'd_model': 512,\n",
    "        'enc_in': 2,\n",
    "        'dec_in': 2,\n",
    "        'dropout': 0.1,\n",
    "        'factor': 3,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 2,\n",
    "        'd_layers': 2,\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b94e3-b8b8-4c2d-8bc3-4b0533bdeb7a",
   "metadata": {},
   "source": [
    "### 加载训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ba060b-1d42-488d-8762-7104e702b2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T08:53:55.603469Z",
     "iopub.status.busy": "2024-12-29T08:53:55.601480Z",
     "iopub.status.idle": "2024-12-29T08:53:56.559612Z",
     "shell.execute_reply": "2024-12-29T08:53:56.558626Z",
     "shell.execute_reply.started": "2024-12-29T08:53:55.603469Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = '../outputs/best_models/Transformer/checkpoint.pth'\n",
    "transformer_model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ff597-a755-4dfd-b69d-6f762dea57c6",
   "metadata": {},
   "source": [
    "### 对模型进行量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ca1baf-aaa0-4028-ac52-030858036b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T08:54:19.189807Z",
     "iopub.status.busy": "2024-12-29T08:54:19.189807Z",
     "iopub.status.idle": "2024-12-29T08:54:20.377670Z",
     "shell.execute_reply": "2024-12-29T08:54:20.376774Z",
     "shell.execute_reply.started": "2024-12-29T08:54:19.189807Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对模型进行动态量化\n",
    "quantized_model = quantize_dynamic(\n",
    "    transformer_model,  # 模型\n",
    "    {torch.nn.Linear},  # 需要量化的层，仅支持Linear层\n",
    "    dtype=torch.qint8  # 量化类型\n",
    ")\n",
    "\n",
    "# 保存动态量化后的模型\n",
    "torch.save(quantized_model, '../outputs/best_models/Transformer/quantized_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f1695-62ae-43f6-8e1f-d4dd39dd74f9",
   "metadata": {},
   "source": [
    "### 加载量化后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12831bc-b8b5-44b1-82f4-335f5c18eacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:11:43.246064Z",
     "iopub.status.busy": "2024-12-29T09:11:43.242809Z",
     "iopub.status.idle": "2024-12-29T09:11:43.377896Z",
     "shell.execute_reply": "2024-12-29T09:11:43.376634Z",
     "shell.execute_reply.started": "2024-12-29T09:11:43.246064Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = '../outputs/best_models/Transformer/quantized_model.pth'\n",
    "quantized_model = torch.load(model_path, map_location='cpu') # 只能在cpu上加载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3580876-0852-4f26-a60e-7bd7b2ed456f",
   "metadata": {},
   "source": [
    "### 使用量化模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74f99bb7-e46c-4884-a57b-363cbbf7ee8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:11:46.024013Z",
     "iopub.status.busy": "2024-12-29T09:11:46.023018Z",
     "iopub.status.idle": "2024-12-29T09:11:46.052249Z",
     "shell.execute_reply": "2024-12-29T09:11:46.051218Z",
     "shell.execute_reply.started": "2024-12-29T09:11:46.024013Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(task_args, predict_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns']\n",
    "    target = task_args['target']\n",
    "    features = task_args['features']\n",
    "    mode = task_args['mode'] # 可选'online'和'offline'\n",
    "    time_col = predict_args['time_col']\n",
    "    freq = predict_args['freq']\n",
    "    model_name = predict_args['model_name']\n",
    "    x_true = predict_args['x_true']\n",
    "    scaler_path = predict_args['scaler_path']\n",
    "    model = predict_args['model']\n",
    "    device = predict_args['device']  # 可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len']\n",
    "    label_len = model_args['label_len']\n",
    "    seq_len = model_args['seq_len']\n",
    "\n",
    "    # 检查可用device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # 读取归一化参数\n",
    "    x_scaler = joblib.load(scaler_path + \"/x_scaler.pkl\")\n",
    "    y_scaler = joblib.load(scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    # 预测模式\n",
    "    if mode == 'online':\n",
    "        # 生成固定长度的时间范围\n",
    "        x_true = loader(data_path=None, data=x_true, time_col=time_col)  # 原始数据\n",
    "        x_true = x_true[columns]\n",
    "        timedelta = x_true.index[-1] - x_true.index[-2]  # 时间差\n",
    "        if label_len != 0:\n",
    "            y_stamp = pd.date_range(start=x_true.index[-label_len],\n",
    "                                    end=x_true.index[-label_len] +\n",
    "                                    timedelta*(label_len+pred_len-1),\n",
    "                                    freq=freq)\n",
    "        else:\n",
    "            y_stamp = pd.date_range(start=x_true.index[-1]+timedelta*(label_len+1),\n",
    "                                    end=x_true.index[-1] +\n",
    "                                    timedelta*(label_len+pred_len),\n",
    "                                    freq=freq)\n",
    "        x_stamp = time_features(pd.to_datetime(x_true.index), freq=freq)  # x时间戳数据\n",
    "        x_stamp = x_stamp.transpose(1, 0)\n",
    "        y_time = y_stamp\n",
    "        y_stamp = time_features(y_stamp, freq=freq)  # y时间戳数据\n",
    "        y_stamp = y_stamp.transpose(1, 0)\n",
    "    \n",
    "        # 转换类型\n",
    "        x_true[columns] = x_scaler.transform(x_true)  # 归一化\n",
    "        x_true = x_true.values.astype('float32')\n",
    "        x_true = torch.as_tensor(x_true).unsqueeze(0).float()  # 转为张量\n",
    "        x_stamp = torch.as_tensor(x_stamp).unsqueeze(0).float()\n",
    "        y_stamp = torch.as_tensor(y_stamp).unsqueeze(0).float()\n",
    "    \n",
    "        # 关闭自动求导功能\n",
    "        model.eval()  # 一定要有\n",
    "        with torch.no_grad():\n",
    "            x_true = x_true.to(device)\n",
    "            x_stamp = x_stamp.to(device)\n",
    "            y_stamp = y_stamp.to(device)\n",
    "            # decoder输入\n",
    "            B, _, _ = x_true.shape\n",
    "            dec_inp = torch.zeros((B, pred_len + label_len, len(target))).float().to(device) # 占位符\n",
    "            y_pred = model(x_true, x_stamp, dec_inp, y_stamp)\n",
    "            y_pred = y_pred.cpu().detach().numpy()\n",
    "            f_dim = -1 if features == 'MS' else 0\n",
    "            y_pred = y_pred[:, -pred_len:, f_dim:]\n",
    "            y_pred = y_scaler.inverse_transform(y_pred[-1, :, :])  # 反归一化\n",
    "    \n",
    "        # 输出为dataframe\n",
    "        y_pred = pd.DataFrame(\n",
    "            data=y_pred, index=y_time[-pred_len:], columns=target)\n",
    "    # 离线模式\n",
    "    else:\n",
    "        # 构造数据集\n",
    "        x_true_ = loader(data_path=None, data=x_true, time_col=time_col)  # 原始数据\n",
    "        time_columns = x_true_.index  # 获取时间列\n",
    "        x_true_ = x_true_.copy()[columns]\n",
    "    \n",
    "        # X时间编码\n",
    "        x_stamp = pd.to_datetime(x_true_.index)\n",
    "        x_stamp = time_features(x_stamp, freq=freq)\n",
    "        x_stamp = x_stamp.transpose(1, 0)\n",
    "    \n",
    "        # y时间编码，包含未来的时间\n",
    "        timedelta = x_true_.index[-1] - x_true_.index[-2]  # 时间差\n",
    "        y_stamp = pd.date_range(start=x_true_.index[0],\n",
    "                                end=x_true_.index[-1] +\n",
    "                                timedelta*(pred_len),\n",
    "                                freq=freq)\n",
    "        y_stamp = time_features(y_stamp, freq=freq)\n",
    "        y_stamp = y_stamp.transpose(1, 0)\n",
    "    \n",
    "        # X归一化\n",
    "        x_true_[columns] = x_scaler.transform(x_true_)\n",
    "        x_true_ = x_true_.values.astype('float32')\n",
    "    \n",
    "        # 生成预测张量\n",
    "        X_true, X_stamp, Y_stamp = [], [], []\n",
    "        sample_freq = 1\n",
    "        for index in range(0, len(x_true) - seq_len + 1, sample_freq):\n",
    "            # 起点\n",
    "            s_begin = index\n",
    "            # 终点(起点 + 回视窗口)\n",
    "            s_end = s_begin + seq_len\n",
    "            # (终点 - 先验序列窗口)\n",
    "            r_begin = s_end - label_len\n",
    "            # (终点 + 预测序列长度)\n",
    "            r_end = r_begin + label_len + pred_len\n",
    "    \n",
    "            # 数据维度\n",
    "            feat = x_true_[s_begin: s_end]\n",
    "            X_true.append(np.array(feat))\n",
    "    \n",
    "            # 时间维度\n",
    "            xs = x_stamp[s_begin: s_end]\n",
    "            ys = y_stamp[r_begin: r_end]\n",
    "            X_stamp.append(np.array(xs))\n",
    "            Y_stamp.append(np.array(ys))\n",
    "        X_true = torch.as_tensor(X_true).float()\n",
    "        X_stamp = torch.as_tensor(X_stamp).float()\n",
    "        Y_stamp = torch.as_tensor(Y_stamp).float()\n",
    "    \n",
    "        # 模型预测\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_true = X_true.to(device)\n",
    "            X_stamp = X_stamp.to(device)\n",
    "            Y_stamp = Y_stamp.to(device)\n",
    "    \n",
    "            # decoder输入\n",
    "            B, _, _ = X_true.shape\n",
    "            dec_inp = torch.zeros(\n",
    "                (B, pred_len + label_len, len(target))).float().to(device)\n",
    "            y_pred = model(X_true, X_stamp, dec_inp, Y_stamp)\n",
    "            y_pred = y_pred.cpu().detach().numpy()\n",
    "            f_dim = -1 if features == 'MS' else 0\n",
    "            y_pred = y_pred[:, -pred_len:, f_dim:]\n",
    "    \n",
    "        # y_pred的形状为 (batch_size, pred_len, feature_dim)\n",
    "        batch_size, pred_len, feature_dim = y_pred.shape\n",
    "        time_index = time_columns[seq_len-1:]\n",
    "    \n",
    "        # 初始化一个空的 DataFrame，每行是初始时间，每列是递增的预测步\n",
    "        # 列名格式为 target_i，例如 target_1 表示预测步1，target_2 表示预测步2，依此类推\n",
    "        columns = [f\"{t}_{i+1}\" for i in range(pred_len) for t in target]\n",
    "        result_df = pd.DataFrame(index=time_index, columns=columns)\n",
    "    \n",
    "        # 填充 DataFrame，每一行是一个时间点的预测序列\n",
    "        for i in range(batch_size):\n",
    "            # 当前时间点的预测\n",
    "            pred_data = y_scaler.inverse_transform(\n",
    "                y_pred[i, :, :])  # 形状 (pred_len, feature_dim)\n",
    "            pred_flattened = pred_data.flatten()  # 将预测结果展平\n",
    "    \n",
    "            # 将展平的预测步依次填入当前行\n",
    "            result_df.iloc[i] = pred_flattened\n",
    "    \n",
    "        # 将原始数据与预测数据合并输出\n",
    "        result_df = result_df.reset_index().rename(columns={'index': time_col})\n",
    "        select_columns = [time_col] + target\n",
    "        y_pred = pd.merge(x_true[select_columns], result_df, on=time_col, how='left')\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45a07079-e6a9-4b63-bbc0-06e145c09069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:11:55.173264Z",
     "iopub.status.busy": "2024-12-29T09:11:55.172258Z",
     "iopub.status.idle": "2024-12-29T09:17:57.632427Z",
     "shell.execute_reply": "2024-12-29T09:17:57.609159Z",
     "shell.execute_reply.started": "2024-12-29T09:11:55.173264Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"../data/energy.csv\"\n",
    "ts_data = pd.read_csv(data_path)\n",
    "# ts_data = ts_data.iloc[:300, :]\n",
    "ts_data['time'] = pd.to_datetime(ts_data['time'])\n",
    "# 构造参数字典\n",
    "params5 = {\n",
    "    \"task_args\": {\n",
    "        \"columns\": ['load', 'temp'],\n",
    "        \"target\": ['load', 'temp'],\n",
    "        \"features\": 'M',\n",
    "        \"mode\": 'offline'\n",
    "    },\n",
    "    \"predict_args\": {\n",
    "        \"time_col\": 'time',\n",
    "        \"freq\": 'h',\n",
    "        \"model_name\": Transformer,\n",
    "        \"model\": quantized_model,\n",
    "        \"x_true\": ts_data,\n",
    "        \"scaler_path\": '../outputs/scalers/Transformer',\n",
    "        \"device\": 'cpu'\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'seq_len': 60,\n",
    "        'pred_len': 3, \n",
    "        'label_len': 10,\n",
    "        'output_attention': True,\n",
    "        'embed': 'timeF', # 可选'timeF','fixed'和'learned'\n",
    "        'freq': 'h',\n",
    "        'd_model': 512,\n",
    "        'enc_in': 2,\n",
    "        'dec_in': 2,\n",
    "        'dropout': 0.1,\n",
    "        'factor': 3,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 2,\n",
    "        'd_layers': 2,\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "y_pred = predict(**params5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a6eac3-1abf-41a1-8237-3abe08408c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:20:51.468843Z",
     "iopub.status.busy": "2024-12-29T09:20:51.467804Z",
     "iopub.status.idle": "2024-12-29T09:20:51.604008Z",
     "shell.execute_reply": "2024-12-29T09:20:51.603061Z",
     "shell.execute_reply.started": "2024-12-29T09:20:51.467804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "      <th>load_1</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>load_2</th>\n",
       "      <th>temp_2</th>\n",
       "      <th>load_3</th>\n",
       "      <th>temp_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01 00:00:00</td>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01 02:00:00</td>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01 03:00:00</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01 04:00:00</td>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26299</th>\n",
       "      <td>2014-12-31 19:00:00</td>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>3536.038818</td>\n",
       "      <td>17.42215</td>\n",
       "      <td>3510.463867</td>\n",
       "      <td>17.211538</td>\n",
       "      <td>3519.478271</td>\n",
       "      <td>17.948671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26300</th>\n",
       "      <td>2014-12-31 20:00:00</td>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "      <td>3176.726807</td>\n",
       "      <td>18.847271</td>\n",
       "      <td>3171.276367</td>\n",
       "      <td>17.548513</td>\n",
       "      <td>3128.720703</td>\n",
       "      <td>18.629642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26301</th>\n",
       "      <td>2014-12-31 21:00:00</td>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>3031.6604</td>\n",
       "      <td>20.686588</td>\n",
       "      <td>3009.648682</td>\n",
       "      <td>18.426052</td>\n",
       "      <td>2926.2146</td>\n",
       "      <td>20.532143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26302</th>\n",
       "      <td>2014-12-31 22:00:00</td>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "      <td>3027.04834</td>\n",
       "      <td>18.566456</td>\n",
       "      <td>2871.080811</td>\n",
       "      <td>20.581285</td>\n",
       "      <td>2861.856934</td>\n",
       "      <td>19.809053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26303</th>\n",
       "      <td>2014-12-31 23:00:00</td>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "      <td>2778.003662</td>\n",
       "      <td>18.84025</td>\n",
       "      <td>2813.012451</td>\n",
       "      <td>17.611696</td>\n",
       "      <td>2860.808838</td>\n",
       "      <td>19.373793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time    load   temp       load_1     temp_1       load_2  \\\n",
       "0     2012-01-01 00:00:00  2698.0  32.00          NaN        NaN          NaN   \n",
       "1     2012-01-01 01:00:00  2558.0  32.67          NaN        NaN          NaN   \n",
       "2     2012-01-01 02:00:00  2444.0  30.00          NaN        NaN          NaN   \n",
       "3     2012-01-01 03:00:00  2402.0  31.00          NaN        NaN          NaN   \n",
       "4     2012-01-01 04:00:00  2403.0  32.00          NaN        NaN          NaN   \n",
       "...                   ...     ...    ...          ...        ...          ...   \n",
       "26299 2014-12-31 19:00:00  4012.0  18.00  3536.038818   17.42215  3510.463867   \n",
       "26300 2014-12-31 20:00:00  3856.0  16.67  3176.726807  18.847271  3171.276367   \n",
       "26301 2014-12-31 21:00:00  3671.0  17.00    3031.6604  20.686588  3009.648682   \n",
       "26302 2014-12-31 22:00:00  3499.0  15.33   3027.04834  18.566456  2871.080811   \n",
       "26303 2014-12-31 23:00:00  3345.0  15.33  2778.003662   18.84025  2813.012451   \n",
       "\n",
       "          temp_2       load_3     temp_3  \n",
       "0            NaN          NaN        NaN  \n",
       "1            NaN          NaN        NaN  \n",
       "2            NaN          NaN        NaN  \n",
       "3            NaN          NaN        NaN  \n",
       "4            NaN          NaN        NaN  \n",
       "...          ...          ...        ...  \n",
       "26299  17.211538  3519.478271  17.948671  \n",
       "26300  17.548513  3128.720703  18.629642  \n",
       "26301  18.426052    2926.2146  20.532143  \n",
       "26302  20.581285  2861.856934  19.809053  \n",
       "26303  17.611696  2860.808838  19.373793  \n",
       "\n",
       "[26304 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2fda34e-735a-41c2-a411-0cbd6f2b0a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:20:53.920510Z",
     "iopub.status.busy": "2024-12-29T09:20:53.918883Z",
     "iopub.status.idle": "2024-12-29T09:20:53.948486Z",
     "shell.execute_reply": "2024-12-29T09:20:53.947483Z",
     "shell.execute_reply.started": "2024-12-29T09:20:53.920510Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取最后一个预测结果\n",
    "def last_prediction(prediction, pred_len, time_col, target):\n",
    "    pre_target = [i+'_'+str(pred_len) for i in target]\n",
    "    prediction_target = prediction[pre_target]\n",
    "    time = prediction[[time_col]]\n",
    "    # 向下平移数据\n",
    "    prediction_shift = prediction_target.shift(pred_len)\n",
    "    prediction_shift.columns = target\n",
    "    # 对齐时间\n",
    "    last_prediction = pd.concat([time, prediction_shift], axis=1)\n",
    "    \n",
    "    return last_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441fc511-d434-4b1d-8a73-7426255563e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:20:54.681211Z",
     "iopub.status.busy": "2024-12-29T09:20:54.679746Z",
     "iopub.status.idle": "2024-12-29T09:20:54.716076Z",
     "shell.execute_reply": "2024-12-29T09:20:54.714924Z",
     "shell.execute_reply.started": "2024-12-29T09:20:54.681211Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取最后一个预测结果\n",
    "params6 = {\n",
    "    \"prediction\": y_pred,\n",
    "    \"pred_len\": 3,\n",
    "    \"time_col\": 'time',\n",
    "    \"target\": ['load', 'temp']\n",
    "}\n",
    "y_pred = last_prediction(**params6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ddb1e72-249d-48b1-bf94-da5ecebad9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:20:57.143292Z",
     "iopub.status.busy": "2024-12-29T09:20:57.141783Z",
     "iopub.status.idle": "2024-12-29T09:20:57.185208Z",
     "shell.execute_reply": "2024-12-29T09:20:57.183825Z",
     "shell.execute_reply.started": "2024-12-29T09:20:57.143292Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算评估指标\n",
    "def score(x1: pd.DataFrame,\n",
    "          x2: pd.DataFrame,\n",
    "          time_col: Union[str, None] = None,\n",
    "          eval_metrics: str = 'rmse') -> float:\n",
    "    \"\"\"\n",
    "    计算评估指标\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    x1 : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据\n",
    "    x2 : {DataFrame} of shape (n_samples, n_features)\n",
    "        预测数据\n",
    "    time_col : {str}\n",
    "        时间标签，如果为None，默认数据中不含时间特征\n",
    "    eval_metrics : {str}\n",
    "        评估指标值，可选'r2'和'rmse'\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    eval_value : {float}\n",
    "        评估值\n",
    "    \"\"\"\n",
    "    # 规范化数据\n",
    "    x1 = x1.reset_index(drop=True)\n",
    "    x2 = x2.reset_index(drop=True)\n",
    "\n",
    "    # 选取时间列\n",
    "    if time_col != None:\n",
    "        no_time_cols = [i for i in x1.columns if i != time_col]\n",
    "        x1[time_col] = pd.to_datetime(x1[time_col])\n",
    "        x1_no_time = x1.loc[:, no_time_cols].values.astype('float32')\n",
    "        x2[time_col] = pd.to_datetime(x2[time_col])\n",
    "        x2_no_time = x2.loc[:, no_time_cols].values.astype('float32')\n",
    "    else:\n",
    "        x1_no_time = x1.values.astype('float32')\n",
    "        x2_no_time = x2.values.astype('float32')\n",
    "\n",
    "    # 缺失值删除\n",
    "    x1_not_nan_index = np.where(~np.isnan(x1_no_time))[0]\n",
    "    x2_not_nan_index = np.where(~np.isnan(x2_no_time))[0]\n",
    "    not_nan_index = list(set(x1_not_nan_index) & set(x2_not_nan_index))\n",
    "    x1_not_nan = x1_no_time[not_nan_index]\n",
    "    x2_not_nan = x2_no_time[not_nan_index]\n",
    "\n",
    "    # 计算评估指标\n",
    "    if eval_metrics == 'r2':\n",
    "        eval_value = r2_score(x1_not_nan, x2_not_nan)\n",
    "    elif eval_metrics == 'rmse':\n",
    "        eval_value = np.sqrt(mean_squared_error(x1_not_nan, x2_not_nan))\n",
    "\n",
    "    return round(eval_value, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5afe178-b149-4103-a8fc-8604f4c4d973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T09:20:58.096611Z",
     "iopub.status.busy": "2024-12-29T09:20:58.094553Z",
     "iopub.status.idle": "2024-12-29T09:20:58.217938Z",
     "shell.execute_reply": "2024-12-29T09:20:58.216591Z",
     "shell.execute_reply.started": "2024-12-29T09:20:58.096611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134.205"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估指标\n",
    "params7 = {\n",
    "    \"x1\": ts_data,\n",
    "    \"x2\": y_pred,\n",
    "    \"time_col\": 'time',\n",
    "    \"eval_metrics\": 'rmse'\n",
    "}\n",
    "score(**params7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb5a16-9b16-4c1a-83da-8f44a946cbe8",
   "metadata": {},
   "source": [
    "## 静态量化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c70c8-d862-4b86-8daf-0209a9ad2c22",
   "metadata": {},
   "source": [
    "静态量化需要校准数据来捕获模型的激活范围。它适用于卷积神经网络（如 ResNet），并且在推理时对性能的提升效果较好。\n",
    "静态量化适合 CNN 等架构。  \n",
    "步骤：  \n",
    "1、准备模型：  \n",
    "- 模型必须定义为可量化。\n",
    "- 在模型中插入量化/反量化模块。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "443230d4-8db2-4baa-81af-e46899c59d1d",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "\n",
    "class QuantizableModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.model(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "# 包装预训练模型\n",
    "quant_model = QuantizableModel(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef488a-2285-4968-99c3-803fe77064dd",
   "metadata": {},
   "source": [
    "2、模型校准和量化："
   ]
  },
  {
   "cell_type": "raw",
   "id": "0addc9d5-c5bc-4fd9-a9bc-5d70cdb910f6",
   "metadata": {},
   "source": [
    "from torch.quantization import prepare, convert\n",
    "\n",
    "# 准备模型\n",
    "quant_model.eval()\n",
    "quant_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "prepare(quant_model, inplace=True)\n",
    "\n",
    "# 使用校准数据运行模型\n",
    "for data, label in calibration_data_loader:\n",
    "    quant_model(data)\n",
    "\n",
    "# 转换为量化模型\n",
    "convert(quant_model, inplace=True)\n",
    "\n",
    "# 保存量化模型\n",
    "torch.save(quant_model, \"static_quantized_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28949532-24f1-4dd4-ac39-44e66a50a35a",
   "metadata": {},
   "source": [
    "## 量化感知训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2596f04-8583-4596-a8fa-889a2f933610",
   "metadata": {},
   "source": [
    "QAT 模拟了训练期间的量化行为，使模型在训练结束后对量化误差更加鲁棒，适合对精度要求较高的场景。\n",
    "\n",
    "步骤：  \n",
    "1、准备模型：\n",
    "\n",
    "- 和静态量化类似，包装模型以支持量化。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "585f8a6a-6881-4d94-acbf-ef55c10bba6e",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "\n",
    "class QuantizableModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.model(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "# 包装预训练模型\n",
    "quant_model = QuantizableModel(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d161dbf-eeb4-4903-98bc-ffa569bc0c5a",
   "metadata": {},
   "source": [
    "2、配置量化感知训练："
   ]
  },
  {
   "cell_type": "raw",
   "id": "cee439eb-875b-4179-8dd2-8ece3ce5340a",
   "metadata": {},
   "source": [
    "from torch.quantization import prepare_qat\n",
    "\n",
    "# 配置 QAT 模型\n",
    "quant_model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "prepare_qat(quant_model, inplace=True)\n",
    "\n",
    "# 训练模型\n",
    "optimizer = torch.optim.SGD(quant_model.parameters(), lr=0.01)\n",
    "for epoch in range(num_epochs):\n",
    "    for data, label in training_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = quant_model(data)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 转换为量化模型\n",
    "convert(quant_model.eval(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc00caff-842c-42cd-803b-e97b8356ef55",
   "metadata": {},
   "source": [
    "## 量化方法对比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b39996c-af60-4cf0-b504-1e1dd2c2db9a",
   "metadata": {},
   "source": [
    "量化方法\t|模型精度损失\t|模型大小\t|推理速度提升\n",
    "---|---|---|---|\n",
    "动态量化\t|最小\t|中等\t|较高\n",
    "静态量化\t|中等\t|较小\t|较高\n",
    "量化感知训练\t|最小\t|较小\t|较高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb754a-244d-415f-a200-f76c83ea18b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
