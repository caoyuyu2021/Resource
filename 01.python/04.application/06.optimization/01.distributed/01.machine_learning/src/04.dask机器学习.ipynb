{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915e8bde",
   "metadata": {},
   "source": [
    "本章将聚焦于 Dask 机器学习，主要介绍 Dask-ML 等库的使用。Dask-ML 基于 Dask 的分布式计算能力，面向机器学习应用，可以无缝对接 scikit-learn、XGBoost 等机器学习库。相比之下，Dask-ML 更适合传统机器学习的训练和推理，比如回归、决策树等等，深度学习相关的训练和推理更多基于 PyTorch 或 TensorFlow 等框架。\n",
    "\n",
    "总结起来，Dask 和 Dask-ML 适合的场景有以下几类：\n",
    "\n",
    "原始数据无法放到单机内存中，需要进行分布式数据预处理和特征工程；\n",
    "\n",
    "训练数据和模型可放到单机内存中，超参数调优需要多机并行；\n",
    "\n",
    "训练数据无法放到单机内存中，需要进行分布式训练。\n",
    "\n",
    "一方面，Dask 社区将主要精力投入在 Dask DataFrame 上，对 Dask-ML 和分布式训练的优化并不多；另一方面，深度学习已经冲击传统机器学习算法，Dask 设计之初并不是面向深度学习的。读者阅读本章，了解 Dask 机器学习能力后，可以根据自身需求选择适合自己的框架。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05151674",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7962531",
   "metadata": {},
   "source": [
    "数据科学工作的重点是理解数据和处理数据，Dask 可以将很多单机的任务横向扩展到集群上，并且可以和 Python 社区数据可视化等库结合，完成探索性数据分析。\n",
    "\n",
    "分布式数据预处理部分更多依赖 Dask DataFrame 和 Dask Array 的能力，这里不再赘述。\n",
    "\n",
    "特征工程部分，Dask-ML 实现了很多 sklearn.preprocessing 的 API，比如 MinMaxScaler。对 Dask 而言，稍有不同的是其独热编码，本书写作时，Dask 使用 DummyEncoder 对类别特征进行独热编码，DummyEncoder 是 scikit-learn OneHotEncoder 的 Dask 替代。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd9189",
   "metadata": {},
   "source": [
    "# 超参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5238f",
   "metadata": {},
   "source": [
    "我们可以使用 Dask 进行超参数调优，主要有两种方式：\n",
    "\n",
    "- 基于 scikit-learn 的 joblib 后端，将多个超参数调优任务分布到 Dask 集群\n",
    "\n",
    "- 使用 Dask-ML 提供的超参数调优 API\n",
    "\n",
    "这两种方式都是针对训练数据量可放到单机内存中的场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3006a817",
   "metadata": {},
   "source": [
    "## scikit-learn joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa8302",
   "metadata": {},
   "source": [
    "单机的 scikit-learn 已经提供了丰富易用的模型训练和超参数调优接口，它默认使用 joblib 在单机多核之间并行。像随机搜索和网格搜索等超参数调优任务容易并行，任务之间没有依赖关系，很容易并行起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc80a11f",
   "metadata": {},
   "source": [
    "### 案例：飞机延误预测（scikit-learn）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb77c46",
   "metadata": {},
   "source": [
    "下面展示一个基于 scikit-learn 的机器学习分类案例，我们使用 scikit-learn 提供的网格搜索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81ab4cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T02:49:00.717210Z",
     "start_time": "2024-08-08T02:49:00.712214Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_path = os.path.join(\"../../../../data/20.others/nyc_flights/\", \"nyc-flights\", \"1991.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af9e8f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T02:49:02.210199Z",
     "start_time": "2024-08-08T02:49:01.792513Z"
    }
   },
   "outputs": [],
   "source": [
    "input_cols = [\n",
    "    \"Year\",\n",
    "    \"Month\",\n",
    "    \"DayofMonth\",\n",
    "    \"DayOfWeek\",\n",
    "    \"CRSDepTime\",\n",
    "    \"CRSArrTime\",\n",
    "    \"UniqueCarrier\",\n",
    "    \"FlightNum\",\n",
    "    \"ActualElapsedTime\",\n",
    "    \"Origin\",\n",
    "    \"Dest\",\n",
    "    \"Distance\",\n",
    "    \"Diverted\",\n",
    "    \"ArrDelay\",\n",
    "]\n",
    "\n",
    "df = pd.read_csv(file_path, usecols=input_cols)\n",
    "df = df.dropna()\n",
    "\n",
    "# 预测是否延误\n",
    "df[\"ArrDelayBinary\"] = 1.0 * (df[\"ArrDelay\"] > 10)\n",
    "\n",
    "df = df[df.columns.difference([\"ArrDelay\"])]\n",
    "\n",
    "# 将 Dest/Origin/UniqueCarrier 等字段转化为 category 类型\n",
    "for col in df.select_dtypes([\"object\"]).columns:\n",
    "    df[col] = df[col].astype(\"category\").cat.codes.astype(np.int32)\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05f989af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T02:49:20.607672Z",
     "start_time": "2024-08-08T02:49:16.327014Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV as SkGridSearchCV\n",
    "from sklearn.model_selection import train_test_split as sk_train_test_split\n",
    "\n",
    "_y_label = \"ArrDelayBinary\"\n",
    "X_train, X_test, y_train, y_test = sk_train_test_split(\n",
    "    df.loc[:, df.columns != _y_label], \n",
    "    df[_y_label], \n",
    "    test_size=0.25,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "model = SGDClassifier(penalty='elasticnet', max_iter=1_000, warm_start=True, loss='log_loss')\n",
    "params = {'alpha': np.logspace(-4, 1, num=81)}\n",
    "\n",
    "sk_grid_search = SkGridSearchCV(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc4119",
   "metadata": {},
   "source": [
    "在进行超参数搜索时，只需要添加 `with joblib.parallel_backend('dask'):`，将网格搜索计算任务扩展到 Dask 集群。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188f1de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T02:51:24.668227Z",
     "start_time": "2024-08-08T02:51:19.414815Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a5b1eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:04:11.166218Z",
     "start_time": "2024-08-08T02:59:05.415591Z"
    }
   },
   "outputs": [],
   "source": [
    "with joblib.parallel_backend('dask'):\n",
    "    sk_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51c3bed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:04:24.614988Z",
     "start_time": "2024-08-08T03:04:24.533292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8082122790726955"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8043d4",
   "metadata": {},
   "source": [
    "## Dask-ML API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f0c8de",
   "metadata": {},
   "source": [
    "### 案例：飞机延误预测（Dask-ML）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3fc382",
   "metadata": {},
   "source": [
    "Dask-ML 自己也实现了一些超参数调优的 API，除了提供和 scikit-learn 对标的 GridSearchCV、RandomizedSearchCV 等算法外，还提供了连续减半算法、Hyperband 算法等，比如 SuccessiveHalvingSearchCV、HyperbandSearchCV。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63800a3",
   "metadata": {},
   "source": [
    "下面展示一个基于 Dask-ML 的 Hyperband 超参数调优案例。\n",
    "\n",
    "Dask-ML 的超参数调优算法要求输入为 Dask DataFrame 或 Dask Array 等可被切分的数据，而非 pandas DataFrame，因此数据预处理部分需要改为 Dask。\n",
    "\n",
    "值得注意的是，Dask-ML 提供的 SuccessiveHalvingSearchCV 和 HyperbandSearchCV 等算法要求模型必须支持 partial_fit() 和 score()。partial_fit() 是 scikit-learn 中迭代式算法（比如梯度下降法）的一次迭代过程。连续减半算法和 Hyperband 算法先分配一些算力额度，不是完成试验的所有迭代，而只做一定次数的迭代（对 partial_fit() 调用有限次数），评估性能（在验证集上调用 score() 方法），淘汰性能较差的试验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88a59845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:06:05.404317Z",
     "start_time": "2024-08-08T03:06:04.662784Z"
    }
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "input_cols = [\n",
    "    \"Year\",\n",
    "    \"Month\",\n",
    "    \"DayofMonth\",\n",
    "    \"DayOfWeek\",\n",
    "    \"CRSDepTime\",\n",
    "    \"CRSArrTime\",\n",
    "    \"UniqueCarrier\",\n",
    "    \"FlightNum\",\n",
    "    \"ActualElapsedTime\",\n",
    "    \"Origin\",\n",
    "    \"Dest\",\n",
    "    \"Distance\",\n",
    "    \"Diverted\",\n",
    "    \"ArrDelay\",\n",
    "]\n",
    "\n",
    "ddf = dd.read_csv(file_path, usecols=input_cols,)\n",
    "\n",
    "# 预测是否延误\n",
    "ddf[\"ArrDelayBinary\"] = 1.0 * (ddf[\"ArrDelay\"] > 10)\n",
    "\n",
    "ddf = ddf[ddf.columns.difference([\"ArrDelay\"])]\n",
    "ddf = ddf.dropna()\n",
    "ddf = ddf.repartition(npartitions=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0272653",
   "metadata": {},
   "source": [
    "另外，Dask 处理类型变量时与 pandas/scikit-learn 也稍有不同，我们需要：\n",
    "\n",
    "- 将该特征转换为 category 类型，比如，使用 Dask DataFrame 的 categorize() 方法，或 Dask-ML 的 Categorizer 预处理器。\n",
    "\n",
    "- 进行独热编码：Dask-ML 中的 DummyEncoder 对类别特征进行独热编码，是 scikit-learn OneHotEncoder 的 Dask 替代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b13a8ff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:10:37.964021Z",
     "start_time": "2024-08-08T03:10:34.340927Z"
    }
   },
   "outputs": [],
   "source": [
    "from dask_ml.preprocessing import DummyEncoder\n",
    "\n",
    "dummy = DummyEncoder()\n",
    "ddf = ddf.categorize(columns=[\"Dest\", \"Origin\", \"UniqueCarrier\"])\n",
    "dummified_ddf = dummy.fit_transform(ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c660a4a",
   "metadata": {},
   "source": [
    "并使用 Dask-ML 的 train_test_split 方法切分训练集和测试集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ce599b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:11:05.487271Z",
     "start_time": "2024-08-08T03:11:05.464272Z"
    }
   },
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split as dsk_train_test_split\n",
    "\n",
    "_y_label = \"ArrDelayBinary\"\n",
    "X_train, X_test, y_train, y_test = dsk_train_test_split(\n",
    "    dummified_ddf.loc[:, dummified_ddf.columns != _y_label], \n",
    "    dummified_ddf[_y_label], \n",
    "    test_size=0.25,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0713453",
   "metadata": {},
   "source": [
    "定义模型和搜索空间的方式与 scikit-learn 类似，然后调用 Dask-ML 的 HyperbandSearchCV 进行超参数调优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7669894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:14:59.586193Z",
     "start_time": "2024-08-08T03:11:52.694910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 30 is smaller than n_iter=81. Running 30 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 30 is smaller than n_iter=34. Running 30 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HyperbandSearchCV(estimator=SGDClassifier(loss=&#x27;log_loss&#x27;, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          warm_start=True),\n",
       "                  max_iter=243,\n",
       "                  parameters={&#x27;alpha&#x27;: array([1.00000000e-04, 1.48735211e-04, 2.21221629e-04, 3.29034456e-04,\n",
       "       4.89390092e-04, 7.27895384e-04, 1.08263673e-03, 1.61026203e-03,\n",
       "       2.39502662e-03, 3.56224789e-03, 5.29831691e-03, 7.88046282e-03,\n",
       "       1.17210230e-02, 1.74332882e-02, 2.59294380e-02, 3.85662042e-02,\n",
       "       5.73615251e-02, 8.53167852e-02, 1.26896100e-01, 1.88739182e-01,\n",
       "       2.80721620e-01, 4.17531894e-01, 6.21016942e-01, 9.23670857e-01,\n",
       "       1.37382380e+00, 2.04335972e+00, 3.03919538e+00, 4.52035366e+00,\n",
       "       6.72335754e+00, 1.00000000e+01])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HyperbandSearchCV</label><div class=\"sk-toggleable__content\"><pre>HyperbandSearchCV(estimator=SGDClassifier(loss=&#x27;log_loss&#x27;, penalty=&#x27;elasticnet&#x27;,\n",
       "                                          warm_start=True),\n",
       "                  max_iter=243,\n",
       "                  parameters={&#x27;alpha&#x27;: array([1.00000000e-04, 1.48735211e-04, 2.21221629e-04, 3.29034456e-04,\n",
       "       4.89390092e-04, 7.27895384e-04, 1.08263673e-03, 1.61026203e-03,\n",
       "       2.39502662e-03, 3.56224789e-03, 5.29831691e-03, 7.88046282e-03,\n",
       "       1.17210230e-02, 1.74332882e-02, 2.59294380e-02, 3.85662042e-02,\n",
       "       5.73615251e-02, 8.53167852e-02, 1.26896100e-01, 1.88739182e-01,\n",
       "       2.80721620e-01, 4.17531894e-01, 6.21016942e-01, 9.23670857e-01,\n",
       "       1.37382380e+00, 2.04335972e+00, 3.03919538e+00, 4.52035366e+00,\n",
       "       6.72335754e+00, 1.00000000e+01])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;, penalty=&#x27;elasticnet&#x27;, warm_start=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;, penalty=&#x27;elasticnet&#x27;, warm_start=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HyperbandSearchCV(estimator=SGDClassifier(loss='log_loss', penalty='elasticnet',\n",
       "                                          warm_start=True),\n",
       "                  max_iter=243,\n",
       "                  parameters={'alpha': array([1.00000000e-04, 1.48735211e-04, 2.21221629e-04, 3.29034456e-04,\n",
       "       4.89390092e-04, 7.27895384e-04, 1.08263673e-03, 1.61026203e-03,\n",
       "       2.39502662e-03, 3.56224789e-03, 5.29831691e-03, 7.88046282e-03,\n",
       "       1.17210230e-02, 1.74332882e-02, 2.59294380e-02, 3.85662042e-02,\n",
       "       5.73615251e-02, 8.53167852e-02, 1.26896100e-01, 1.88739182e-01,\n",
       "       2.80721620e-01, 4.17531894e-01, 6.21016942e-01, 9.23670857e-01,\n",
       "       1.37382380e+00, 2.04335972e+00, 3.03919538e+00, 4.52035366e+00,\n",
       "       6.72335754e+00, 1.00000000e+01])})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.model_selection import HyperbandSearchCV\n",
    "\n",
    "# client = Client(LocalCluster())\n",
    "model = SGDClassifier(penalty='elasticnet', max_iter=1_000, warm_start=True, loss='log_loss')\n",
    "params = {'alpha': np.logspace(-4, 1, num=30)}\n",
    "\n",
    "dsk_hyperband = HyperbandSearchCV(model, params, max_iter=243)\n",
    "dsk_hyperband.fit(X_train, y_train, classes=[0.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "252ecd74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:15:27.923629Z",
     "start_time": "2024-08-08T03:15:23.305218Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SGDClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8248179783780376"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsk_hyperband.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8f72b",
   "metadata": {},
   "source": [
    "# 分布式机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15d94",
   "metadata": {},
   "source": [
    "如果训练数据量很大，Dask-ML 提供了分布式机器学习功能，可以在集群上对大数据进行训练。目前，Dask 提供了两类分布式机器学习 API：\n",
    "\n",
    "- scikit-learn 式：与 scikit-learn 的调用方式类似\n",
    "\n",
    "- XGBoost 和 LightGBM 决策树式：与 XGBoost 和 LightGBM 的调用方式类似"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009ebebd",
   "metadata": {},
   "source": [
    "## scikit-learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93695a52",
   "metadata": {},
   "source": [
    "基于 Dask Array、Dask DataFrame 和 Dask Delayed 提供的分布式计算能力，参考 scikit-learn，Dask-ML 对机器学习算法做了分布式的实现，比如 dask_ml.linear_model 中的线性回归 LinearRegression、逻辑回归 LogisticRegression，dask_ml.cluster 中的 KMeans。Dask-ML 尽量保持这些机器学习算法的使用方法与 scikit-learn 一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94ec16f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:16:27.963535Z",
     "start_time": "2024-08-08T03:16:24.325589Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import dask_ml.datasets\n",
    "import sklearn.linear_model\n",
    "import dask_ml.linear_model\n",
    "from dask_ml.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0c02347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:17:06.106031Z",
     "start_time": "2024-08-08T03:17:05.840186Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\dask\\base.py:1366: UserWarning: Running on a single-machine scheduler when a distributed client is active might lead to unexpected results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 3.81 MiB </td>\n",
       "                        <td> 39.06 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10000, 50) </td>\n",
       "                        <td> (100, 50) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 100 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"25\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"18\" x2=\"25\" y2=\"18\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"25\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"25\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"43\" x2=\"25\" y2=\"43\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"25\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"25\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"62\" x2=\"25\" y2=\"62\" />\n",
       "  <line x1=\"0\" y1=\"68\" x2=\"25\" y2=\"68\" />\n",
       "  <line x1=\"0\" y1=\"75\" x2=\"25\" y2=\"75\" />\n",
       "  <line x1=\"0\" y1=\"81\" x2=\"25\" y2=\"81\" />\n",
       "  <line x1=\"0\" y1=\"87\" x2=\"25\" y2=\"87\" />\n",
       "  <line x1=\"0\" y1=\"93\" x2=\"25\" y2=\"93\" />\n",
       "  <line x1=\"0\" y1=\"100\" x2=\"25\" y2=\"100\" />\n",
       "  <line x1=\"0\" y1=\"106\" x2=\"25\" y2=\"106\" />\n",
       "  <line x1=\"0\" y1=\"112\" x2=\"25\" y2=\"112\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.41261651458249,0.0 25.41261651458249,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >50</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">10000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<normal, shape=(10000, 50), dtype=float64, chunksize=(100, 50), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = dask_ml.datasets.make_classification(n_samples=10000, \n",
    "        n_features=50, \n",
    "        random_state=42,\n",
    "        chunks=10000 // 100\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817dc97f",
   "metadata": {},
   "source": [
    "调用 fit() 方法（与 scikit-learn 类似）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c44132bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:18:04.333793Z",
     "start_time": "2024-08-08T03:17:40.644981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\dask\\config.py:693: UserWarning: Configuration key \"fuse_ave_width\" has been deprecated. Please use \"optimization.fuse.ave-width\" instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = dask_ml.linear_model.LogisticRegression(solver=\"lbfgs\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf62308",
   "metadata": {},
   "source": [
    "训练好的模型可以用来预测（predict()），也可以计算准确度（score()）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "008e35e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:18:19.691223Z",
     "start_time": "2024-08-08T03:18:19.543687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False,  True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = lr.predict(X_test)\n",
    "y_predicted[:5].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18ea7a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T03:18:30.313878Z",
     "start_time": "2024-08-08T03:18:28.276608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.705"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b7cbee",
   "metadata": {},
   "source": [
    "如果在单机的 scikit-learn 上使用同样大小的数据训练模型，会因为内存不足而报错。\n",
    "\n",
    "尽管 Dask-ML 这种分布式训练的 API 与 scikit-learn 极其相似，scikit-learn 只能使用单核，Dask-ML 可以使用多核甚至集群，但并不意味着所有场景下都选择 Dask-ML，因为有些时候 Dask-ML 并非性能或性价比最优的选择。这一点与 Dask DataFrame 和 pandas 关系一样，如果数据量能放进单机内存，原生的 pandas 、NumPy 和 scikit-learn 的性能和兼容性总是最优的。\n",
    "\n",
    "下面的代码对不同规模的训练数据进行了性能分析，在单机多核且数据量较小的场景，Dask-ML 的性能并不比 scikit-learn 更快。原因有很多，包括：\n",
    "\n",
    "很多机器学习算法是迭代式的，scikit-learn 中，迭代式算法使用 Python 原生 for 循环来实现；Dask-ML 参考了这种 for 循环，但对于 Dask 的 Task Graph 来说，for 循环会使得 Task Graph 很臃肿，执行效率并不是很高。\n",
    "\n",
    "分布式实现需要在不同进程间分发和收集数据，相比单机单进程，额外增加了很多数据同步和通信开销。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48c0de",
   "metadata": {},
   "source": [
    "训练数据量和模型性能之间的关系可以通过学习曲线（Learning Curves）来可视化，随着训练数据量增加，像朴素贝叶斯等算法的性能提升十分有限。如果一些机器学习算法无法进行分布式训练或分布式训练成本很高，可以考虑对训练数据采样，数据大小能够放进单机内存，使用 scikit-learn 这种单机框架训练。\n",
    "\n",
    "综上，如果有一个超出单机内存的训练数据，要根据问题特点、所使用的算法和成本等多方面因素来决定使用何种方式处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4b960",
   "metadata": {},
   "source": [
    "## XGBoost 和 LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b244ed",
   "metadata": {},
   "source": [
    "XGBoost 和 LightGBM 是两种决策树模型的实现，他们本身就对分布式训练友好，且集成了 Dask 的分布式能力。下面以 XGBoost 为例，介绍 XGBoost 如何基于 Dask 实现分布式训练，LightGBM 与之类似。\n",
    "\n",
    "在 XGBoost 中，训练一个模型既可以使用 train() 方法，也可以使用 scikit-learn 式的 fit() 方法。这两种方式都支持 Dask 分布式训练。\n",
    "\n",
    "下面的代码对单机的 XGBoost 和 Dask 分布式训练两种方式进行了性能对比。如果使用 Dask，用户需要将 xgboost.DMatrix 修改为 xgboost.dask.DaskDMatrix，xgboost.dask.DaskDMatrix 可以将分布式的 Dask Array 或 Dask DataFrame 转化为 XGBoost 所需要的数据格式；用户还需要将 xgboost.train() 修改为 `xgboost.dask.train()`；并传入 Dask 集群客户端 client。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536fd74",
   "metadata": {},
   "source": [
    "如果是 XGBoost 的 scikit-learn 式 API，需要将 xgboost.XGBClassifier 修改为 `xgboost.dask.DaskXGBClassifier` 或者 xgboost.XGBRegressor 修改为 `xgboost.dask.DaskXGBRegressor`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0279d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195.48px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
