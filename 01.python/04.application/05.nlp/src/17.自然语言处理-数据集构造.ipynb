{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e84b7df",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ab1d0-5009-4b0d-baed-1558b34aff81",
   "metadata": {},
   "source": [
    "## 任务：分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f722dd34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T06:14:01.324970Z",
     "start_time": "2024-11-30T06:13:58.874698Z"
    },
    "execution": {
     "iopub.execute_input": "2024-12-01T08:36:07.453509Z",
     "iopub.status.busy": "2024-12-01T08:36:07.453509Z",
     "iopub.status.idle": "2024-12-01T08:36:07.473512Z",
     "shell.execute_reply": "2024-12-01T08:36:07.472511Z",
     "shell.execute_reply.started": "2024-12-01T08:36:07.453509Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from datetime import timedelta\n",
    "from numpy import ndarray\n",
    "from typing import Union, List, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # 打印进度条\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from pandas.tseries import offsets\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "import codecs\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "046ae436-89eb-48fa-a114-9120818f82fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T08:22:23.274466Z",
     "iopub.status.busy": "2024-12-01T08:22:23.273464Z",
     "iopub.status.idle": "2024-12-01T08:22:23.295638Z",
     "shell.execute_reply": "2024-12-01T08:22:23.294242Z",
     "shell.execute_reply.started": "2024-12-01T08:22:23.274466Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator(data_list, train_ratio, valid_ratio, tokenizer, batch_size, max_length: int = 128):\n",
    "    \"\"\"\n",
    "    读取数据，并对数据进行划分，生成加载器\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_list : {list[DataFrame]}\n",
    "        输入数据，包含数据和标签\n",
    "    train_ratio : {float}\n",
    "        用于训练的数据集占比:将数据按照一定比例进行切分，取值范围为(0,1)\n",
    "    valid_ratio : {float}\n",
    "        用于验证的数据集占比:将数据按照一定比例进行切分，取值范围为(0,1)\n",
    "    tokenizer : {}\n",
    "        分词器\n",
    "    batch_size : {int} \n",
    "        输入数据的批次大小，正整数\n",
    "    max_length : {int} \n",
    "        最大文本截取长度，正整数\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data_loader : {torch.utils.data.dataloader.DataLoader}\n",
    "        数据加载器\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    texts = data_list[0]  # 特征\n",
    "    labels = data_list[1]  # 目标\n",
    "    \n",
    "    # 划分数据\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=train_ratio, random_state=42)\n",
    "\n",
    "    # 定义数据集的Dataset类\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, texts, labels, tokenizer, max_length=max_length):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "    \n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "    \n",
    "        def __getitem__(self, idx):\n",
    "            text = self.texts[idx]\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            # 对文本进行token化，并转换为输入id和attention mask\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "                'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "\n",
    "    # 创建Dataset和DataLoader\n",
    "    train_dataset = CustomDataset(train_texts, train_labels, tokenizer, max_length=max_length)\n",
    "    val_dataset = CustomDataset(val_texts, val_labels, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset, train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70a9e399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T12:02:15.298104Z",
     "start_time": "2024-11-30T12:02:15.234117Z"
    },
    "execution": {
     "iopub.execute_input": "2024-12-01T08:22:25.195524Z",
     "iopub.status.busy": "2024-12-01T08:22:25.195524Z",
     "iopub.status.idle": "2024-12-01T08:22:25.279955Z",
     "shell.execute_reply": "2024-12-01T08:22:25.278113Z",
     "shell.execute_reply.started": "2024-12-01T08:22:25.195524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>0</td>\n",
       "      <td>尼斯酒店的几大特点：噪音大、环境差、配置低、服务效率低。如：1、隔壁歌厅的声音闹至午夜3点许...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>0</td>\n",
       "      <td>盐城来了很多次，第一次住盐阜宾馆，我的确很失望整个墙壁黑咕隆咚的，好像被烟熏过一样家具非常的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7763</th>\n",
       "      <td>0</td>\n",
       "      <td>看照片觉得还挺不错的，又是4星级的，但入住以后除了后悔没有别的，房间挺大但空空的，早餐是有但...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7764</th>\n",
       "      <td>0</td>\n",
       "      <td>我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7765</th>\n",
       "      <td>0</td>\n",
       "      <td>说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7766 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             review\n",
       "0         1  距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...\n",
       "1         1                       商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!\n",
       "2         1         早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。\n",
       "3         1  宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...\n",
       "4         1               CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风\n",
       "...     ...                                                ...\n",
       "7761      0  尼斯酒店的几大特点：噪音大、环境差、配置低、服务效率低。如：1、隔壁歌厅的声音闹至午夜3点许...\n",
       "7762      0  盐城来了很多次，第一次住盐阜宾馆，我的确很失望整个墙壁黑咕隆咚的，好像被烟熏过一样家具非常的...\n",
       "7763      0  看照片觉得还挺不错的，又是4星级的，但入住以后除了后悔没有别的，房间挺大但空空的，早餐是有但...\n",
       "7764      0  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...\n",
       "7765      0  说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...\n",
       "\n",
       "[7766 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载语料，酒店评论\n",
    "data = pd.read_csv('../../../../../data/03.nlp/ChineseNlpCorpus/datasets/ChnSentiCorp_htl_all/ChnSentiCorp_htl_all.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f111f4c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T08:22:38.837806Z",
     "iopub.status.busy": "2024-12-01T08:22:38.836633Z",
     "iopub.status.idle": "2024-12-01T08:22:39.666365Z",
     "shell.execute_reply": "2024-12-01T08:22:39.665073Z",
     "shell.execute_reply.started": "2024-12-01T08:22:38.837806Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"data_list\": [data['review'].values, data['label'].values],\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"valid_ratio\": 0.1,\n",
    "    \"tokenizer\": BertTokenizer.from_pretrained('bert-base-chinese'),\n",
    "    \"batch_size\": 3,\n",
    "    \"max_length\": 128,\n",
    "}\n",
    "\n",
    "# 函数传参\n",
    "train_dataset, val_dataset, train_loader, valid_loader = generator(**params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8a9b9d5-b9e1-4237-9de0-cb5aed965411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T08:22:46.881964Z",
     "iopub.status.busy": "2024-12-01T08:22:46.881964Z",
     "iopub.status.idle": "2024-12-01T08:22:46.891048Z",
     "shell.execute_reply": "2024-12-01T08:22:46.890055Z",
     "shell.execute_reply.started": "2024-12-01T08:22:46.881964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 6983, 2421, 1762, 7188, 6662, 3178, 8024, 3241,  677, 4125,  102,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_dataset[0]  # 获取第一个样本\n",
    "input_ids = sample['input_ids']  # 提取 input_ids\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31da990a-608c-451c-b2b5-dd7d5e5a52fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T08:22:53.608947Z",
     "iopub.status.busy": "2024-12-01T08:22:53.607839Z",
     "iopub.status.idle": "2024-12-01T08:22:53.628469Z",
     "shell.execute_reply": "2024-12-01T08:22:53.627468Z",
     "shell.execute_reply.started": "2024-12-01T08:22:53.608947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cbb491-f932-4992-a0ff-59e1eb24c86b",
   "metadata": {},
   "source": [
    "## 任务：命名实体识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f468637c-906b-4a5a-ad90-a3cbc7ae4691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T09:14:29.503898Z",
     "iopub.status.busy": "2024-12-01T09:14:29.503898Z",
     "iopub.status.idle": "2024-12-01T09:14:29.514246Z",
     "shell.execute_reply": "2024-12-01T09:14:29.513185Z",
     "shell.execute_reply.started": "2024-12-01T09:14:29.503898Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_iob2(file_path):\n",
    "    '''加载 IOB2 格式的数据'''\n",
    "    token_seqs = []\n",
    "    label_seqs = []\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    with codecs.open(file_path, encoding='utf-8') as f:\n",
    "        for index, line in enumerate(f):\n",
    "            items = line.strip().split()\n",
    "            if len(items) == 2:\n",
    "                token, label = items\n",
    "                tokens.append(token)\n",
    "                labels.append(label)\n",
    "            elif len(items) == 0:\n",
    "                if tokens:\n",
    "                    token_seqs.append(tokens)\n",
    "                    label_seqs.append(labels)\n",
    "                    tokens = []\n",
    "                    labels = []\n",
    "            else:\n",
    "                print(f'格式错误。行号：{index} 内容：{line.strip()}')\n",
    "                continue\n",
    "                \n",
    "    if tokens:  # 文件末尾处理\n",
    "        token_seqs.append(tokens)\n",
    "        label_seqs.append(labels)\n",
    "        \n",
    "    return token_seqs, label_seqs\n",
    "\n",
    "\n",
    "def show_iob2(token_seqs, label_seqs, num=5, shuffle=True):\n",
    "    '''显示 IOB2 格式数据'''\n",
    "    length = len(token_seqs)\n",
    "    indexes = random.sample(range(length), min(num, length)) if shuffle else range(min(num, length))\n",
    "    \n",
    "    for i in indexes:\n",
    "        tokens, labels = token_seqs[i], label_seqs[i]\n",
    "        print(' '.join(f'{token}/{label}' for token, label in zip(tokens, labels)))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "66684736-8ae3-49f4-927b-8c558dfaa6f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:06:46.764853Z",
     "iopub.status.busy": "2024-12-01T10:06:46.764853Z",
     "iopub.status.idle": "2024-12-01T10:06:46.811087Z",
     "shell.execute_reply": "2024-12-01T10:06:46.809101Z",
     "shell.execute_reply.started": "2024-12-01T10:06:46.764853Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator(data_list, train_ratio, valid_ratio, tokenizer, batch_size, label2id, max_length=128):\n",
    "    \"\"\"\n",
    "    读取数据，并对数据进行划分，生成加载器\n",
    "    \"\"\"\n",
    "    texts = data_list[0]  # 特征\n",
    "    labels = data_list[1]  # 标签（每个token的标签）\n",
    "\n",
    "    # 划分训练集和临时验证集+测试集\n",
    "    train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "        texts, labels, test_size=(1 - train_ratio), random_state=42\n",
    "    )\n",
    "\n",
    "    # 划分验证集和测试集\n",
    "    val_size = valid_ratio / (1 - train_ratio)\n",
    "    val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "        temp_texts, temp_labels, test_size=1 - val_size, random_state=42\n",
    "    )\n",
    "\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, texts, labels, tokenizer, max_length, label2id):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "            self.label2id = label2id\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            text = self.texts[idx]\n",
    "            label = self.labels[idx]\n",
    "\n",
    "            # 对文本进行token化\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                is_split_into_words=True,  # 支持拆分后的token输入\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            # 标签编码：将标签映射为数字\n",
    "            label_ids = [self.label2id.get(l, 0) for l in label]  # 使用get避免出现未知标签\n",
    "\n",
    "            # 处理特殊标记：忽略[CLS], [SEP]等特殊token，填充标签时使用-100\n",
    "            input_ids = encoding['input_ids'].squeeze(0)\n",
    "            attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "            # 忽略特殊标记的位置（[CLS]和[SEP]），将其标签设为-100\n",
    "            label_ids = label_ids + [0] * (self.max_length - len(label_ids))  # 填充标签\n",
    "            label_ids = label_ids[:self.max_length]  # 确保长度不超过max_length\n",
    "\n",
    "            # 获取特殊标记的索引：[CLS]的索引为0，[SEP]的索引为102\n",
    "            special_tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
    "            cls_idx = special_tokens.index('[CLS]') if '[CLS]' in special_tokens else -1\n",
    "            sep_idx = special_tokens.index('[SEP]') if '[SEP]' in special_tokens else -1\n",
    "            pad_ids = [idx for idx, token in enumerate(special_tokens) if token == '[PAD]']\n",
    "\n",
    "            # 将特殊标记和PAD的标签设置为-100（忽略这些位置）\n",
    "            if cls_idx != -1:\n",
    "                label_ids[cls_idx] = -100\n",
    "            if sep_idx != -1:\n",
    "                label_ids[sep_idx] = -100\n",
    "            for pad_idx in pad_ids:\n",
    "                label_ids[pad_idx] = -100\n",
    "\n",
    "            return {\n",
    "                'input_ids': input_ids,  # 取消batch维度\n",
    "                'attention_mask': attention_mask,  # 取消batch维度\n",
    "                'labels': torch.tensor(label_ids, dtype=torch.long)  # 标签\n",
    "            }\n",
    "\n",
    "    # 创建Dataset和DataLoader\n",
    "    train_dataset = CustomDataset(train_texts, train_labels, tokenizer, max_length, label2id)\n",
    "    val_dataset = CustomDataset(val_texts, val_labels, tokenizer, max_length, label2id)\n",
    "    test_dataset = CustomDataset(test_texts, test_labels, tokenizer, max_length, label2id)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0a7899fa-42af-4b17-b8e4-82d6c32cde4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:06:47.899863Z",
     "iopub.status.busy": "2024-12-01T10:06:47.899579Z",
     "iopub.status.idle": "2024-12-01T10:06:53.267336Z",
     "shell.execute_reply": "2024-12-01T10:06:53.266374Z",
     "shell.execute_reply.started": "2024-12-01T10:06:47.899863Z"
    }
   },
   "outputs": [],
   "source": [
    "token_seqs, label_seqs = load_iob2('../../../../../data/03.nlp/ChineseNlpCorpus/datasets/dh_msra/dh_msra/dh_msra.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b521e4f4-9383-4b48-8a0c-589144757960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:06:54.995819Z",
     "iopub.status.busy": "2024-12-01T10:06:54.994656Z",
     "iopub.status.idle": "2024-12-01T10:06:55.012659Z",
     "shell.execute_reply": "2024-12-01T10:06:55.011782Z",
     "shell.execute_reply.started": "2024-12-01T10:06:54.995819Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['由',\n",
       " '于',\n",
       " '这',\n",
       " '一',\n",
       " '时',\n",
       " '期',\n",
       " '战',\n",
       " '争',\n",
       " '频',\n",
       " '繁',\n",
       " '，',\n",
       " '条',\n",
       " '件',\n",
       " '艰',\n",
       " '苦',\n",
       " '，',\n",
       " '又',\n",
       " '遭',\n",
       " '国',\n",
       " '民',\n",
       " '党',\n",
       " '毁',\n",
       " '禁',\n",
       " '，',\n",
       " '传',\n",
       " '世',\n",
       " '量',\n",
       " '稀',\n",
       " '少',\n",
       " '，',\n",
       " '购',\n",
       " '藏',\n",
       " '不',\n",
       " '易',\n",
       " '。']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_seqs[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dc95f3d2-0227-4613-87b7-a1bda5e913d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:06:59.425707Z",
     "iopub.status.busy": "2024-12-01T10:06:59.424709Z",
     "iopub.status.idle": "2024-12-01T10:06:59.432314Z",
     "shell.execute_reply": "2024-12-01T10:06:59.432302Z",
     "shell.execute_reply.started": "2024-12-01T10:06:59.424709Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_seqs[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "eea70ac4-e2a2-4169-81a9-f7ec0dbf56a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:07:03.637082Z",
     "iopub.status.busy": "2024-12-01T10:07:03.637082Z",
     "iopub.status.idle": "2024-12-01T10:07:03.643084Z",
     "shell.execute_reply": "2024-12-01T10:07:03.642087Z",
     "shell.execute_reply.started": "2024-12-01T10:07:03.637082Z"
    }
   },
   "outputs": [],
   "source": [
    "# 标签映射，假设标签为字符串，需要映射到整数\n",
    "label2id = {\n",
    "    'O': 0,       # 不是实体的标签\n",
    "    'B-PER': 1,   # 人名\n",
    "    'I-PER': 2,   # 人名的内部\n",
    "    'B-LOC': 3,   # 地点\n",
    "    'I-LOC': 4,   # 地点的内部\n",
    "    'B-ORG': 5,   # 组织\n",
    "    'I-ORG': 6    # 组织的内部\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "711f20c8-1e8c-4d7a-ae9d-91b4f76450cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:07:05.376888Z",
     "iopub.status.busy": "2024-12-01T10:07:05.376275Z",
     "iopub.status.idle": "2024-12-01T10:07:06.381359Z",
     "shell.execute_reply": "2024-12-01T10:07:06.380357Z",
     "shell.execute_reply.started": "2024-12-01T10:07:05.376888Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"data_list\": [token_seqs, label_seqs],\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"valid_ratio\": 0.1,\n",
    "    \"tokenizer\": BertTokenizer.from_pretrained('bert-base-chinese'),\n",
    "    \"batch_size\": 3,\n",
    "    \"max_length\": 128,\n",
    "    \"label2id\": label2id\n",
    "}\n",
    "\n",
    "# 函数传参\n",
    "train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader = generator(**params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "56d9915d-7b91-439f-9af9-0e28c020d448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:07:09.515534Z",
     "iopub.status.busy": "2024-12-01T10:07:09.514531Z",
     "iopub.status.idle": "2024-12-01T10:07:09.539611Z",
     "shell.execute_reply": "2024-12-01T10:07:09.538645Z",
     "shell.execute_reply.started": "2024-12-01T10:07:09.515534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 1343, 2399, 1374, 2458, 4638,  704, 1744, 1066,  772, 1054, 5018,\n",
       "        1282,  758, 3613, 1059, 1744,  807, 6134, 1920,  833, 1469, 1184,  679,\n",
       "         719, 1374, 2458, 4638,  736, 2237, 1059, 1744,  782, 1920,  671, 3613,\n",
       "         833, 6379, 8024, 4802, 2137,  749, 2769,  812, 1744, 2157, 6659,  686,\n",
       "        5279, 1355, 2245, 4638, 2131,  836, 4680, 3403,  511,  102,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_dataset[30]  # 获取第一个样本\n",
    "input_ids = sample['input_ids']  # 提取 input_ids\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8dbeb8ff-cb54-4814-bd00-5f42775e528b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:07:13.203456Z",
     "iopub.status.busy": "2024-12-01T10:07:13.203241Z",
     "iopub.status.idle": "2024-12-01T10:07:13.225140Z",
     "shell.execute_reply": "2024-12-01T10:07:13.224594Z",
     "shell.execute_reply.started": "2024-12-01T10:07:13.203456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100,    0,    0,    0,    0,    5,    6,    6,    6,    6,    6,    6,\n",
       "           6,    6,    6,    6,    6,    6,    6,    6,    0,    0,    0,    0,\n",
       "           0,    0,    0,    5,    6,    6,    6,    6,    6,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "381b2876-ccbe-4b62-91da-d414eb1b72c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T09:15:10.368546Z",
     "iopub.status.busy": "2024-12-01T09:15:10.368546Z",
     "iopub.status.idle": "2024-12-01T09:15:10.386457Z",
     "shell.execute_reply": "2024-12-01T09:15:10.385456Z",
     "shell.execute_reply.started": "2024-12-01T09:15:10.368546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26494291-7581-489f-816b-1967a74ed4d1",
   "metadata": {},
   "source": [
    "## 任务：问答系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "53d0f5d9-e387-489f-b710-0b02b95751e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:00:09.223246Z",
     "iopub.status.busy": "2024-12-01T10:00:09.222183Z",
     "iopub.status.idle": "2024-12-01T10:00:09.518909Z",
     "shell.execute_reply": "2024-12-01T10:00:09.504933Z",
     "shell.execute_reply.started": "2024-12-01T10:00:09.223246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>reply</th>\n",
       "      <th>is_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>最近在安邦长青树中看到什么豁免，这个是什么意思？</td>\n",
       "      <td>NaN</td>\n",
       "      <td>您好，这个是重疾险中给予投保者的一项权利，安*长青树保障责任规定，投保者可以享受多次赔付，豁...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>和老婆利用假期去澳*探亲，但是第一次去不大熟悉，有没有相关保险呢？</td>\n",
       "      <td>NaN</td>\n",
       "      <td>您好，HUTS保险中的乐游全球（探亲版）-慧择旅游保险澳新计划是澳*新西兰探亲专属保障，承保...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUTS中有没有适合帆船比赛的保险，我男朋友这周就要开始了</td>\n",
       "      <td>NaN</td>\n",
       "      <td>您好，水上运动比赛，尤其是带有奖金的比赛一般承保的公司比较少。不过，HUTS保险中的众行天下...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>计划端午节和男朋友自驾去九*山，买保险三天要多少钱？</td>\n",
       "      <td>NaN</td>\n",
       "      <td>您好，端午出行的人比较多，而且自驾存在一定风险，所以有保险意识还是很好的。考虑到价格以及保障...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>计划端午节和男朋友自驾去九*山，买保险三天要多少钱？</td>\n",
       "      <td>NaN</td>\n",
       "      <td>不到10块钱………………</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8357</th>\n",
       "      <td>如何为一家三口买保险？</td>\n",
       "      <td>近段时间一直想给自己的小家买份保险，但是保险公司多，保险品种更多，看得眼花。所以想请各位专家...</td>\n",
       "      <td>你好！每年的保费不要超过年收入的20%</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8358</th>\n",
       "      <td>如何为一家三口买保险？</td>\n",
       "      <td>近段时间一直想给自己的小家买份保险，但是保险公司多，保险品种更多，看得眼花。所以想请各位专家...</td>\n",
       "      <td>可以退保费的意外险下载注册平安app，填邀请码自已投保里面有N个一百万身价</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8359</th>\n",
       "      <td>如何为一家三口买保险？</td>\n",
       "      <td>近段时间一直想给自己的小家买份保险，但是保险公司多，保险品种更多，看得眼花。所以想请各位专家...</td>\n",
       "      <td>你好平安守护星是一款分红型产品也可以做为教育金为主是一款少儿产品如有意向可以私聊我具体了解</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8360</th>\n",
       "      <td>23岁买什么保险好啊？</td>\n",
       "      <td>我今年刚刚23岁，大学毕业刚开始工作，想给自己买份保险，不知道有什么保险好啊？</td>\n",
       "      <td>根据您提供的信息，建议您购买一份综合意外保险。保障普通意外、意外医疗、交通意外、住院津贴等等...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>23岁买什么保险好啊？</td>\n",
       "      <td>我今年刚刚23岁，大学毕业刚开始工作，想给自己买份保险，不知道有什么保险好啊？</td>\n",
       "      <td>我觉得你还是先给你父母买份养老保险吧。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8362 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0              最近在安邦长青树中看到什么豁免，这个是什么意思？   \n",
       "1     和老婆利用假期去澳*探亲，但是第一次去不大熟悉，有没有相关保险呢？   \n",
       "2         HUTS中有没有适合帆船比赛的保险，我男朋友这周就要开始了   \n",
       "3            计划端午节和男朋友自驾去九*山，买保险三天要多少钱？   \n",
       "4            计划端午节和男朋友自驾去九*山，买保险三天要多少钱？   \n",
       "...                                 ...   \n",
       "8357                        如何为一家三口买保险？   \n",
       "8358                        如何为一家三口买保险？   \n",
       "8359                        如何为一家三口买保险？   \n",
       "8360                        23岁买什么保险好啊？   \n",
       "8361                        23岁买什么保险好啊？   \n",
       "\n",
       "                                               question  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "8357  近段时间一直想给自己的小家买份保险，但是保险公司多，保险品种更多，看得眼花。所以想请各位专家...   \n",
       "8358  近段时间一直想给自己的小家买份保险，但是保险公司多，保险品种更多，看得眼花。所以想请各位专家...   \n",
       "8359  近段时间一直想给自己的小家买份保险，但是保险公司多，保险品种更多，看得眼花。所以想请各位专家...   \n",
       "8360            我今年刚刚23岁，大学毕业刚开始工作，想给自己买份保险，不知道有什么保险好啊？   \n",
       "8361            我今年刚刚23岁，大学毕业刚开始工作，想给自己买份保险，不知道有什么保险好啊？   \n",
       "\n",
       "                                                  reply  is_best  \n",
       "0     您好，这个是重疾险中给予投保者的一项权利，安*长青树保障责任规定，投保者可以享受多次赔付，豁...        1  \n",
       "1     您好，HUTS保险中的乐游全球（探亲版）-慧择旅游保险澳新计划是澳*新西兰探亲专属保障，承保...        0  \n",
       "2     您好，水上运动比赛，尤其是带有奖金的比赛一般承保的公司比较少。不过，HUTS保险中的众行天下...        1  \n",
       "3     您好，端午出行的人比较多，而且自驾存在一定风险，所以有保险意识还是很好的。考虑到价格以及保障...        1  \n",
       "4                                          不到10块钱………………        0  \n",
       "...                                                 ...      ...  \n",
       "8357                                你好！每年的保费不要超过年收入的20%        0  \n",
       "8358              可以退保费的意外险下载注册平安app，填邀请码自已投保里面有N个一百万身价        0  \n",
       "8359      你好平安守护星是一款分红型产品也可以做为教育金为主是一款少儿产品如有意向可以私聊我具体了解        0  \n",
       "8360  根据您提供的信息，建议您购买一份综合意外保险。保障普通意外、意外医疗、交通意外、住院津贴等等...        1  \n",
       "8361                                我觉得你还是先给你父母买份养老保险吧。        0  \n",
       "\n",
       "[8362 rows x 4 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../../../../data/03.nlp/ChineseNlpCorpus/datasets/baoxianzhidao/baoxianzhidao_filter.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f14a8-0eb0-4abb-8548-36fc7d4f5a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "227.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
