{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4fa61d-a05c-420c-90d8-1f3dcda12ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:14:46.799353Z",
     "iopub.status.busy": "2024-12-11T02:14:46.798352Z",
     "iopub.status.idle": "2024-12-11T02:15:54.440364Z",
     "shell.execute_reply": "2024-12-11T02:15:54.439364Z",
     "shell.execute_reply.started": "2024-12-11T02:14:46.799353Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from datetime import timedelta\n",
    "from numpy import ndarray\n",
    "from typing import Union, List, Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # 打印进度条\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from pandas.tseries import offsets\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2d67d2-2927-456d-ab0c-813685b3ee7e",
   "metadata": {},
   "source": [
    "# 基础知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58bb126-6084-4889-b905-d72c9f90626e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "001e8ada-048c-445c-b5bf-b2f1d7b22c6b",
   "metadata": {},
   "source": [
    "# 基于Transformer和增量学习的时间序列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79391641-d885-4668-bc3c-5e0cff61a1ff",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4535439-2412-4334-bf03-ab12e2540258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:15:59.182052Z",
     "iopub.status.busy": "2024-12-11T02:15:59.182052Z",
     "iopub.status.idle": "2024-12-11T02:15:59.209224Z",
     "shell.execute_reply": "2024-12-11T02:15:59.207984Z",
     "shell.execute_reply.started": "2024-12-11T02:15:59.182052Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "\n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_1 = re.findall('[0-9]', freq)\n",
    "        re_2 = re.findall('[a-z]', freq)\n",
    "        # 识别数字频率\n",
    "        if len(re_1) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_1))\n",
    "        # 识别频率\n",
    "        fr = re_2[0]\n",
    "        # 生成时间间隔\n",
    "        if fr == 's':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(\n",
    "                                           seconds=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 't':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(\n",
    "                                           minutes=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 'h':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(\n",
    "                                           hours=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 'd':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(\n",
    "                                           days=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col]  # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1e44b5-244e-4f99-9ce4-34470525dbdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:16:00.170150Z",
     "iopub.status.busy": "2024-12-11T02:16:00.169147Z",
     "iopub.status.idle": "2024-12-11T02:16:00.315642Z",
     "shell.execute_reply": "2024-12-11T02:16:00.314635Z",
     "shell.execute_reply.started": "2024-12-11T02:16:00.170150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2698.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2558.0</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2444.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2402.0</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2403.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4012.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3856.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3671.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3499.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3345.0</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load   temp\n",
       "2012-01-01 00:00:00  2698.0  32.00\n",
       "2012-01-01 01:00:00  2558.0  32.67\n",
       "2012-01-01 02:00:00  2444.0  30.00\n",
       "2012-01-01 03:00:00  2402.0  31.00\n",
       "2012-01-01 04:00:00  2403.0  32.00\n",
       "...                     ...    ...\n",
       "2014-12-31 19:00:00  4012.0  18.00\n",
       "2014-12-31 20:00:00  3856.0  16.67\n",
       "2014-12-31 21:00:00  3671.0  17.00\n",
       "2014-12-31 22:00:00  3499.0  15.33\n",
       "2014-12-31 23:00:00  3345.0  15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3145e7-246d-44b8-9f0a-b44049af23cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:16:01.167955Z",
     "iopub.status.busy": "2024-12-11T02:16:01.166828Z",
     "iopub.status.idle": "2024-12-11T02:16:01.194924Z",
     "shell.execute_reply": "2024-12-11T02:16:01.193969Z",
     "shell.execute_reply.started": "2024-12-11T02:16:01.167955Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba9ad9e4-0e0a-40b9-a101-c20c7492811b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:16:02.605468Z",
     "iopub.status.busy": "2024-12-11T02:16:02.605468Z",
     "iopub.status.idle": "2024-12-11T02:16:02.628217Z",
     "shell.execute_reply": "2024-12-11T02:16:02.627127Z",
     "shell.execute_reply.started": "2024-12-11T02:16:02.605468Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "def divider(df, train_ratio, valid_ratio, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    \"\"\"\n",
    "    读取数据，并对数据进行划分\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    df : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据\n",
    "    train_ratio : {float}\n",
    "        用于训练的数据集占比:将数据按照一定比例进行切分，取值范围为(0,1)\n",
    "    valid_ratio : {float}\n",
    "        用于验证的数据集占比:将数据按照一定比例进行切分，取值范围为(0,1)\n",
    "    x_feature_list : {list[str]} \n",
    "        训练特征列，不包含时间列\n",
    "    y_feature_list : {list[str]} \n",
    "        目标特征列，不包含时间列\n",
    "    freq : {str}\n",
    "        用来编码时间特征的频率，可选[s:秒,t:分,h:时,d:天,b:工作日,w:周,m:月]，频率越低，模型可能越精确\n",
    "    scaler_path : {str} \n",
    "        数据归一化模型保存地址\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    x_scaler : {sklearn.preprocessing.MinMaxScaler}\n",
    "        训练特征列归一化器\n",
    "    y_scaler : {sklearn.preprocessing.MinMaxScaler}\n",
    "        目标特征列归一化器\n",
    "    train : {list[DataFrame]}\n",
    "        训练特征数据，目标特征数据，时间特征数据\n",
    "    valid : {list[DataFrame]}\n",
    "        验证特征数据，目标特征数据，时间特征数据\n",
    "    test : {list[DataFrame]}\n",
    "        测试特征数据，目标特征数据，时间特征数据\n",
    "    \"\"\"\n",
    "    # 归一化\n",
    "    x_scaler = MinMaxScaler()  # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list])\n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    # 测试集\n",
    "    train = df.copy().iloc[:int(df.shape[0]*train_ratio), :][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "    ytr = df.copy().iloc[:int(df.shape[0]*train_ratio), :][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "\n",
    "    # 验证集\n",
    "    if train_ratio != 1:\n",
    "        valid = df.copy().iloc[int(df.shape[0]*train_ratio)\n",
    "                        : int(df.shape[0]*(train_ratio+valid_ratio)), :][x_feature_list]\n",
    "        valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "        valid_stamp = valid_stamp.transpose(1, 0)\n",
    "        valid[x_feature_list] = x_scaler.transform(valid)\n",
    "        xva = valid.values.astype('float32')\n",
    "        yva = df.copy().iloc[int(df.shape[0]*train_ratio)\n",
    "                      : int(df.shape[0]*(train_ratio+valid_ratio)), :][y_feature_list]\n",
    "        yva[y_feature_list] = y_scaler.transform(yva)\n",
    "        yva = yva.values.astype('float32')\n",
    "        valid = [xva, yva, valid_stamp]\n",
    "    else:\n",
    "        valid = [np.array(0), np.array(0), np.array(0)]\n",
    "\n",
    "    # 测试集\n",
    "    if train_ratio + valid_ratio != 1:\n",
    "        test = df.copy().iloc[int(\n",
    "            df.shape[0]*(train_ratio+valid_ratio)):, :][x_feature_list]\n",
    "        test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "        test_stamp = test_stamp.transpose(1, 0)\n",
    "        test[x_feature_list] = x_scaler.transform(test)\n",
    "        xte = test.values.astype('float32')\n",
    "        yte = df.copy().iloc[int(\n",
    "            df.shape[0]*(train_ratio+valid_ratio)):, :][y_feature_list]\n",
    "        yte[y_feature_list] = y_scaler.transform(yte)\n",
    "        yte = yte.values.astype('float32')\n",
    "        test = [xte, yte, test_stamp]\n",
    "    else:\n",
    "        test = [np.array(0), np.array(0), np.array(0)]\n",
    "\n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd7f557-d66d-4f97-8a27-3f4b10898e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:16:04.106995Z",
     "iopub.status.busy": "2024-12-11T02:16:04.105962Z",
     "iopub.status.idle": "2024-12-11T02:16:04.200232Z",
     "shell.execute_reply": "2024-12-11T02:16:04.198693Z",
     "shell.execute_reply.started": "2024-12-11T02:16:04.105962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (18412, 2) y_train shape: (18412, 2) stamp_train shape: (18412, 4)\n",
      "x_valid shape: (2631, 2) y_valid shape: (2631, 2) stamp_valid shape: (2631, 4)\n",
      "x_test shape: (5261, 2) y_test shape: (5261, 2) stamp_test shape: (5261, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"train_ratio\": 0.7,\n",
    "    \"valid_ratio\": 0.1,\n",
    "    \"x_feature_list\": ['load', 'temp'],\n",
    "    \"y_feature_list\": ['load', 'temp'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../outputs/scalers/Transformer'\n",
    "}\n",
    "\n",
    "# 函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(\n",
    "    train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(\n",
    "    valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(\n",
    "    test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb08df5-a661-4299-b3b7-0f2d5ed1344d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:16:05.425146Z",
     "iopub.status.busy": "2024-12-11T02:16:05.424148Z",
     "iopub.status.idle": "2024-12-11T02:16:05.444013Z",
     "shell.execute_reply": "2024-12-11T02:16:05.443459Z",
     "shell.execute_reply.started": "2024-12-11T02:16:05.425146Z"
    }
   },
   "outputs": [],
   "source": [
    "# 利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size, sample_freq: int = 1):\n",
    "    \"\"\"\n",
    "    读取数据，并对数据进行划分\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_list : {list[DataFrame]}\n",
    "        输入特征数据，目标特征数据，时间特征数据\n",
    "    seq_len : {int}\n",
    "        输入数据包含过去多少个时间步，正整数\n",
    "    pred_len : {int}\n",
    "        目标应该在未来多少个时间步之后，正整数\n",
    "    label_len : {int} \n",
    "        先验时间步\n",
    "    batch_size : {int} \n",
    "        输入数据的批次大小，正整数\n",
    "    sample_freq : {int} \n",
    "        采样频率，正整数\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    X : {torch.Tensor}\n",
    "        特征数据张量\n",
    "    y : {torch.Tensor}\n",
    "        目标数据张量\n",
    "    X_stamp : {torch.Tensor}\n",
    "        特征时间编码张量\n",
    "    y_stamp : {torch.Tensor}\n",
    "        目标时间编码张量\n",
    "    data_loader : {torch.utils.data.dataloader.DataLoader}\n",
    "        数据加载器，[特征，目标，特征时间编码，目标时间编码]\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0]  # 特征\n",
    "    target = data_list[1]  # 目标\n",
    "    stamp = data_list[2]  # 时间戳，不包含未来的时间\n",
    "\n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "\n",
    "    for index in range(0, len(feature) - seq_len - pred_len + 1, sample_freq):\n",
    "        # 起点\n",
    "        s_begin = index\n",
    "        # 终点(起点 + 回视窗口)\n",
    "        s_end = s_begin + seq_len\n",
    "        # (终点 - 先验序列窗口)\n",
    "        r_begin = s_end - label_len\n",
    "        # (终点 + 预测序列长度)\n",
    "        r_end = r_begin + label_len + pred_len\n",
    "\n",
    "        # 数据维度\n",
    "        feat = feature[s_begin: s_end]\n",
    "        tar = target[r_begin: r_end]\n",
    "        X.append(np.array(feat))\n",
    "        y.append(np.array(tar))\n",
    "\n",
    "        # 时间维度\n",
    "        xs = stamp[s_begin: s_end]\n",
    "        ys = stamp[r_begin: r_end]\n",
    "        X_stamp.append(np.array(xs))\n",
    "        y_stamp.append(np.array(ys))\n",
    "\n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "\n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "\n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(\n",
    "        X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9764a281-8b22-4924-b91c-5ca4c482483c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:16:07.336557Z",
     "iopub.status.busy": "2024-12-11T02:16:07.336557Z",
     "iopub.status.idle": "2024-12-11T02:16:14.207398Z",
     "shell.execute_reply": "2024-12-11T02:16:14.206130Z",
     "shell.execute_reply.started": "2024-12-11T02:16:07.336557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([18350, 60, 2]),y_size: torch.Size([18350, 13, 2]),loader_len: 574\n",
      "X_size: torch.Size([2569, 60, 2]),y_size: torch.Size([2569, 13, 2]),loader_len: 81\n",
      "X_size: torch.Size([5199, 60, 2]),y_size: torch.Size([5199, 13, 2]),loader_len: 163\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 60,\n",
    "    \"pred_len\": 3,\n",
    "    \"label_len\": 10,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(\n",
    "    train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(\n",
    "    valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(\n",
    "    test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(\n",
    "    X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(\n",
    "    X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(\n",
    "    X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c2066d-3481-4e27-b38f-56b233f46c52",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b903ef85-d188-4f10-ac90-4fe7e56a9a8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:16:22.170295Z",
     "iopub.status.busy": "2024-12-11T02:16:22.170295Z",
     "iopub.status.idle": "2024-12-11T02:16:22.252554Z",
     "shell.execute_reply": "2024-12-11T02:16:22.250672Z",
     "shell.execute_reply.started": "2024-12-11T02:16:22.170295Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataEmbedding编码类\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "        \n",
    "        # freq拆分\n",
    "        number = re.findall('[0-9]', freq)\n",
    "        number = 1 if len(number)==0 else int(''.join(number))\n",
    "        string = re.findall('[a-z]', freq)[0]\n",
    "        if string == 'h':\n",
    "            hour_size = int(24 / number)\n",
    "        elif string == 't':\n",
    "            hour_size = 24\n",
    "            minute_size = int(60 / number)\n",
    "        elif string == 's':\n",
    "            hour_size = 24\n",
    "            minute_size = 60\n",
    "            second_size = int(60 / number)\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        if freq == 's':\n",
    "            self.second_embed = Embed(second_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        second_x = self.second_embed(x[:, :, 5]) if hasattr(\n",
    "            self, 'second_embed') else 0.\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x + second_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# Transformer_EncDec类\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "    \n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
    "                 dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask,\n",
    "            tau=tau, delta=None\n",
    "        )[0])\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )[0])\n",
    "\n",
    "        y = x = self.norm2(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm3(x + y)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask, tau=tau, delta=delta)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# 自编码类\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "    \n",
    "    \n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "        \n",
    "        \n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "    \n",
    "    \n",
    "# Transformer模型\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "        embed: time features encoding, options:[timeF, fixed, learned]\n",
    "        freq: 'freq for time features encoding, options:[s:secondly, \n",
    "            t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], \n",
    "            you can also use more detailed freq like 15min or 3h'\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len, pred_len, label_len, output_attention, enc_in, d_model, dropout, factor, n_heads, d_ff, \n",
    "                e_layers, dec_in, d_layers, c_out, embed, freq):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.output_attention = output_attention\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                      output_attention=output_attention), d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu'\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(True, factor, attention_dropout=dropout,\n",
    "                                      output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, factor, attention_dropout=dropout,\n",
    "                                      output_attention=False),\n",
    "                        d_model, n_heads),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation='relu',\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model),\n",
    "            projection=nn.Linear(d_model, c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out, x_mask=None, cross_mask=None)\n",
    "        \n",
    "        output = dec_out[:, -self.pred_len:, :]  # [B, L, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eee27a-2e0f-4d2b-909c-a16dba4fa731",
   "metadata": {},
   "source": [
    "## 模型训练（旧）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469f5482-3dc2-49ad-bb2e-87f15acbfaa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:16:25.324709Z",
     "iopub.status.busy": "2024-12-11T02:16:25.324709Z",
     "iopub.status.idle": "2024-12-11T02:16:25.362750Z",
     "shell.execute_reply": "2024-12-11T02:16:25.361707Z",
     "shell.execute_reply.started": "2024-12-11T02:16:25.324709Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_args, model_args):\n",
    "    # 参数配置\n",
    "    features = train_args['features']  # 模型预测模式\n",
    "    model_name = train_args['model_name']  # 模型名称\n",
    "    train_loader = train_args['train_loader']  # 训练集\n",
    "    valid_loader = train_args['valid_loader']  # 验证集\n",
    "    n_epochs = train_args['n_epochs']  # 训练次数\n",
    "    learning_rate = train_args['learning_rate']  # 学习率\n",
    "    loss = train_args['loss']  # 损失函数\n",
    "    patience = train_args['patience']  # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj']  # 学习率函数\n",
    "    model_path = train_args['model_path']  # 模型保存路径\n",
    "    verbose = train_args['verbose']  # 打印训练过程\n",
    "    plots = train_args['plots']  # 绘制损失图\n",
    "    device = train_args['device']  # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len']  # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "\n",
    "    # 检查可用device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "\n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate / 2 *\n",
    "                         (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "\n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience  # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(\n",
    "                    f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(\n",
    "                    f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "\n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            # 将数据移至 device\n",
    "            batch_x = batch_x.to(device)  # 会用到实际数据\n",
    "            batch_y = batch_y.to(device)  # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            f_dim = -1 if features == 'MS' else 0\n",
    "            outputs = outputs[:, -pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -pred_len:, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            # 每个batch的loss和\n",
    "            total_train_loss += train_loss.item()  # .item()表示只包含一个元素的tensor中提取值\n",
    "\n",
    "        # 每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # 所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # 评估模型\n",
    "        model.eval()\n",
    "        # 关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                # 将数据移至 device\n",
    "                batch_x = batch_x.to(device)  # 会用到实际数据\n",
    "                batch_y = batch_y.to(device)  # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if features == 'MS' else 0\n",
    "                outputs = outputs[:, -pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -pred_len:, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                # 每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "        # 每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "\n",
    "        # 所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # 打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj,\n",
    "                             learning_rate, n_epochs)\n",
    "\n",
    "    # 绘制损失函数图\n",
    "    def plot_loss(train_loss, val_loss):\n",
    "        \"\"\"\n",
    "        绘制训练和验证损失曲线\n",
    "\n",
    "        参数:\n",
    "        - train_loss: 训练损失数组\n",
    "        - val_loss: 验证损失数组\n",
    "        \"\"\"\n",
    "        # 自动生成 epochs（假设train_loss和val_loss长度一致）\n",
    "        epochs = np.arange(len(train_loss))\n",
    "\n",
    "        # 使用 Seaborn 设置白色背景样式\n",
    "        sns.set(style=\"white\")\n",
    "\n",
    "        # 创建图形并优化细节\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # 绘制训练和验证曲线\n",
    "        plt.plot(epochs, train_loss, label='Training', color='#d62728', linewidth=2, marker='o', markersize=6)\n",
    "        plt.plot(epochs, val_loss, label='Validation', color='#1f77b4', linewidth=2, marker='s', markersize=6)\n",
    "\n",
    "        # 添加标题和标签\n",
    "        plt.title('Training and Validation Loss', fontsize=18, fontweight='bold', color='black')\n",
    "        plt.xlabel('Epoch', fontsize=14)\n",
    "        plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "        # 添加图例\n",
    "        plt.legend(fontsize=12, loc='upper right')\n",
    "\n",
    "        # 启用横向网格线\n",
    "        plt.grid(True, axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        # 去掉顶部和右侧的边框，仅显示左侧和底部的边框\n",
    "        plt.gca().spines['top'].set_visible(False)\n",
    "        plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "        # 可选：修改左侧和底部边框的样式\n",
    "        plt.gca().spines['left'].set_linewidth(1.5)\n",
    "        plt.gca().spines['bottom'].set_linewidth(1.5)\n",
    "\n",
    "        plt.gca().spines['left'].set_visible(True)\n",
    "        plt.gca().spines['bottom'].set_visible(True)\n",
    "\n",
    "        plt.gca().tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "        # 调整布局以防止标签重叠\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 展示图形\n",
    "        plt.show()\n",
    "\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c09cd05-e858-4675-90f8-894c36e49f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:16:36.856646Z",
     "iopub.status.busy": "2024-12-11T02:16:36.856646Z",
     "iopub.status.idle": "2024-12-11T02:33:04.500262Z",
     "shell.execute_reply": "2024-12-11T02:33:04.499046Z",
     "shell.execute_reply.started": "2024-12-11T02:16:36.856646Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 0.1382, Validation Loss: 0.0054\n",
      "Validation loss decreased (inf --> 0.005427).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                 | 1/50 [01:05<53:31, 65.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 0.0009990133642141358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                            | 2/50 [03:13<1:21:54, 102.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Training Loss: 0.0056, Validation Loss: 0.0048\n",
      "Validation loss decreased (0.005427 --> 0.004755).  Saving model ...\n",
      "Updating learning rate to 0.000996057350657239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                            | 3/50 [04:26<1:09:35, 88.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Training Loss: 0.0027, Validation Loss: 0.0021\n",
      "Validation loss decreased (0.004755 --> 0.002080).  Saving model ...\n",
      "Updating learning rate to 0.0009911436253643444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                          | 4/50 [05:39<1:03:11, 82.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Training Loss: 0.0018, Validation Loss: 0.0025\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0009842915805643156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████                                                                         | 5/50 [06:55<1:00:18, 80.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Training Loss: 0.0015, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.002080 --> 0.001121).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▉                                                                         | 6/50 [08:08<57:00, 77.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Training Loss: 0.0012, Validation Loss: 0.0020\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0009648882429441257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▌                                                                       | 7/50 [09:17<53:42, 74.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Training Loss: 0.0011, Validation Loss: 0.0013\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 0.0009524135262330098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▎                                                                     | 8/50 [10:29<51:40, 73.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Training Loss: 0.0010, Validation Loss: 0.0009\n",
      "Validation loss decreased (0.001121 --> 0.000917).  Saving model ...\n",
      "Updating learning rate to 0.0009381533400219318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▉                                                                    | 9/50 [11:40<49:50, 72.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Training Loss: 0.0009, Validation Loss: 0.0009\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0009221639627510075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▍                                                                 | 10/50 [12:50<48:09, 72.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Training Loss: 0.0009, Validation Loss: 0.0010\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████                                                                | 11/50 [14:03<47:07, 72.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Training Loss: 0.0009, Validation Loss: 0.0012\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 0.0008852566213878947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▋                                                              | 12/50 [15:14<45:37, 72.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Training Loss: 0.0009, Validation Loss: 0.0015\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 0.0008644843137107057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▋                                                              | 12/50 [16:25<52:01, 82.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Training Loss: 0.0009, Validation Loss: 0.0009\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params3 = {\n",
    "    \"train_args\": {\n",
    "        \"features\": 'M',\n",
    "        \"model_name\": Transformer,\n",
    "        \"train_loader\": train_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 50,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 5,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../outputs/best_models/Transformer_ewc\",\n",
    "        \"device\": 'cuda',\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'seq_len': 60,\n",
    "        'pred_len': 3, \n",
    "        'label_len': 10,\n",
    "        'output_attention': True,\n",
    "        'embed': 'timeF', # 可选'timeF','fixed'和'learned'\n",
    "        'freq': 'h',\n",
    "        'd_model': 512,\n",
    "        'enc_in': 2,\n",
    "        'dec_in': 2,\n",
    "        'dropout': 0.1,\n",
    "        'factor': 3,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 2,\n",
    "        'd_layers': 2,\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9dd40a-bd74-493f-8c75-5310fabdef8e",
   "metadata": {},
   "source": [
    "## 增量学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cadea487-13db-41b3-8223-9314b83d51f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:55:24.095574Z",
     "iopub.status.busy": "2024-12-11T02:55:24.093573Z",
     "iopub.status.idle": "2024-12-11T02:55:24.139623Z",
     "shell.execute_reply": "2024-12-11T02:55:24.138773Z",
     "shell.execute_reply.started": "2024-12-11T02:55:24.095574Z"
    }
   },
   "outputs": [],
   "source": [
    "class EWC():\n",
    "    def __init__(self, ewc_args, model_args):\n",
    "        model_name = ewc_args['model_name']  # 模型名称\n",
    "        old_data_loader = ewc_args['old_data_loader']  # 旧数据集\n",
    "        model_path = ewc_args['model_path']  # 模型保存路径\n",
    "        self.criterion = ewc_args['criterion']  # 损失函数\n",
    "        self.features = ewc_args['features']  \n",
    "        self.device = ewc_args['device']  \n",
    "        self.pred_len = model_args['pred_len']  # 预测长度\n",
    "        self.label_len = model_args['label_len']\n",
    "        \n",
    "        # 加载模型\n",
    "        self.model = model_name(**model_args)\n",
    "        state_dict = torch.load(model_path, map_location=self.device)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # 保存模型在旧任务上的最优参数值 θ*\n",
    "        self.old_params = {name: param.clone().detach() for name, param in self.model.named_parameters()}\n",
    "        \n",
    "        # 计算Fisher信息矩阵，表示参数对旧任务的重要性\n",
    "        self.fisher = self._compute_fisher(old_data_loader)\n",
    "\n",
    "    def _compute_fisher(self, data_loader):\n",
    "        \"\"\"\n",
    "        计算模型在旧任务上的Fisher信息矩阵。\n",
    "        \n",
    "        参数:\n",
    "        - data_loader: 旧任务的数据加载器。\n",
    "        \n",
    "        返回:\n",
    "        - fisher: 每个模型参数的Fisher信息矩阵。\n",
    "        \"\"\"\n",
    "        # 初始化Fisher信息矩阵，结构与模型参数相同\n",
    "        fisher = {name: torch.zeros_like(param) for name, param in self.model.named_parameters()}\n",
    "        \n",
    "        self.model.eval()  # 设置模型为评估模式（不启用dropout等正则化）\n",
    "        \n",
    "        # 遍历旧任务数据集，计算Fisher信息矩阵\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in data_loader:\n",
    "            # 将数据移至 device\n",
    "            batch_x = batch_x.to(self.device)  # 会用到实际数据\n",
    "            batch_y = batch_y.to(self.device)  # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(self.device)\n",
    "            batch_y_mark = batch_y_mark.to(self.device)\n",
    "            # decoder输入\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -self.pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :self.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            f_dim = -1 if self.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -self.pred_len:, f_dim:]\n",
    "            loss = self.criterion(outputs, batch_y)\n",
    "            \n",
    "            # 清空之前的梯度\n",
    "            self.model.zero_grad()\n",
    "            \n",
    "            # 反向传播，计算梯度\n",
    "            loss.backward()\n",
    "            \n",
    "            # 将参数梯度平方累加到Fisher信息矩阵中\n",
    "            for name, param in self.model.named_parameters():\n",
    "                fisher[name] += param.grad.data ** 2\n",
    "\n",
    "        # 返回累积的Fisher信息矩阵\n",
    "        return fisher\n",
    "\n",
    "    def regularization_loss(self, model):\n",
    "        \"\"\"\n",
    "        计算EWC正则化损失。\n",
    "        \n",
    "        参数:\n",
    "        - model: 在新任务上进行微调的模型。\n",
    "        \n",
    "        返回:\n",
    "        - loss: EWC正则化损失值。\n",
    "        \"\"\"\n",
    "        loss = 0  # 初始化正则化损失\n",
    "        \n",
    "        # 遍历模型的每个参数\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:  # 确保参数是可训练的\n",
    "                # 计算EWC损失：\n",
    "                # Fisher信息矩阵 * (当前参数值 - 旧任务参数值)的平方\n",
    "                loss += torch.sum(self.fisher[name] * (param - self.old_params[name])**2)\n",
    "        \n",
    "        # 返回总的正则化损失\n",
    "        return loss\n",
    "\n",
    "    # 自定义对象表示形式\n",
    "    def __repr__(self):\n",
    "        return (f\"<EWC Object | Tracked Params: {len(self.old_params)} | \"\n",
    "                f\"Fisher Matrix Keys: {list(self.fisher.keys())[:5]}...>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c2bf43c-cae8-446d-89a5-fb7a00abfcac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:55:25.145520Z",
     "iopub.status.busy": "2024-12-11T02:55:25.144522Z",
     "iopub.status.idle": "2024-12-11T02:56:19.359975Z",
     "shell.execute_reply": "2024-12-11T02:56:19.358972Z",
     "shell.execute_reply.started": "2024-12-11T02:55:25.144754Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构造参数字典\n",
    "params4 = {\n",
    "    \"ewc_args\": {\n",
    "        \"model_name\": Transformer,\n",
    "        \"model_path\": \"../outputs/best_models/Transformer_ewc/checkpoint.pth\",\n",
    "        \"features\": 'M',\n",
    "        \"device\": 'cuda',\n",
    "        \"old_data_loader\": train_loader,\n",
    "        \"criterion\": nn.MSELoss(),\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'seq_len': 60,\n",
    "        'pred_len': 3, \n",
    "        'label_len': 10,\n",
    "        'output_attention': True,\n",
    "        'embed': 'timeF', \n",
    "        'freq': 'h',\n",
    "        'd_model': 512,\n",
    "        'enc_in': 2,\n",
    "        'dec_in': 2,\n",
    "        'dropout': 0.1,\n",
    "        'factor': 3,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 2,\n",
    "        'd_layers': 2,\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "ewc = EWC(**params4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec1d8701-f013-491f-b7ea-8c2cdaeb3c95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:56:33.043179Z",
     "iopub.status.busy": "2024-12-11T02:56:33.043179Z",
     "iopub.status.idle": "2024-12-11T02:56:33.058367Z",
     "shell.execute_reply": "2024-12-11T02:56:33.057364Z",
     "shell.execute_reply.started": "2024-12-11T02:56:33.043179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EWC Object | Tracked Params: 94 | Fisher Matrix Keys: ['enc_embedding.value_embedding.tokenConv.weight', 'enc_embedding.temporal_embedding.embed.weight', 'encoder.attn_layers.0.attention.query_projection.weight', 'encoder.attn_layers.0.attention.query_projection.bias', 'encoder.attn_layers.0.attention.key_projection.weight']...>\n"
     ]
    }
   ],
   "source": [
    "print(ewc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb64f4df-5034-4113-9c4f-e03fbb53bd01",
   "metadata": {},
   "source": [
    "## 模型训练（新）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abeb8a85-62d7-4653-a307-cafd648b0a6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:56:46.800762Z",
     "iopub.status.busy": "2024-12-11T02:56:46.799766Z",
     "iopub.status.idle": "2024-12-11T02:56:46.863025Z",
     "shell.execute_reply": "2024-12-11T02:56:46.862105Z",
     "shell.execute_reply.started": "2024-12-11T02:56:46.800762Z"
    }
   },
   "outputs": [],
   "source": [
    "def re_train(train_args, model_args):\n",
    "    # 参数配置\n",
    "    features = train_args['features']  # 模型预测模式\n",
    "    model_name = train_args['model_name']  # 模型名称\n",
    "    train_loader = train_args['train_loader']  # 训练集\n",
    "    valid_loader = train_args['valid_loader']  # 验证集\n",
    "    n_epochs = train_args['n_epochs']  # 训练次数\n",
    "    learning_rate = train_args['learning_rate']  # 学习率\n",
    "    loss = train_args['loss']  # 损失函数\n",
    "    patience = train_args['patience']  # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj']  # 学习率函数\n",
    "    model_path = train_args['model_path']  # 模型保存路径\n",
    "    verbose = train_args['verbose']  # 打印训练过程\n",
    "    plots = train_args['plots']  # 绘制损失图\n",
    "    device = train_args['device']  # 训练设备，可选'cuda'和'cpu'\n",
    "    ewc = train_args['ewc']  # fisher信息阵\n",
    "    lambda_reg = train_args['lambda_reg']\n",
    "    pred_len = model_args['pred_len']  # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "\n",
    "    # 检查可用device\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "\n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate / 2 *\n",
    "                         (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "\n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience  # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(\n",
    "                    f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(\n",
    "                    f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "\n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            # 将数据移至 device\n",
    "            batch_x = batch_x.to(device)  # 会用到实际数据\n",
    "            batch_y = batch_y.to(device)  # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            f_dim = -1 if features == 'MS' else 0\n",
    "            outputs = outputs[:, -pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -pred_len:, f_dim:]\n",
    "            train_task_loss = criterion(outputs, batch_y)\n",
    "            train_reg_loss = ewc.regularization_loss(model)\n",
    "            train_loss = train_task_loss + lambda_reg * train_reg_loss\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            # 每个batch的loss和\n",
    "            total_train_loss += train_loss.item()  # .item()表示只包含一个元素的tensor中提取值\n",
    "\n",
    "        # 每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # 所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # 评估模型\n",
    "        model.eval()\n",
    "        # 关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                # 将数据移至 device\n",
    "                batch_x = batch_x.to(device)  # 会用到实际数据\n",
    "                batch_y = batch_y.to(device)  # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if features == 'MS' else 0\n",
    "                outputs = outputs[:, -pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -pred_len:, f_dim:]\n",
    "                val_task_loss = criterion(outputs, batch_y)\n",
    "                val_reg_loss = ewc.regularization_loss(model)\n",
    "                val_loss = val_task_loss + lambda_reg * val_reg_loss\n",
    "                # 每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "        # 每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "\n",
    "        # 所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # 打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj,\n",
    "                             learning_rate, n_epochs)\n",
    "\n",
    "    # 绘制损失函数图\n",
    "    def plot_loss(train_loss, val_loss):\n",
    "        \"\"\"\n",
    "        绘制训练和验证损失曲线\n",
    "\n",
    "        参数:\n",
    "        - train_loss: 训练损失数组\n",
    "        - val_loss: 验证损失数组\n",
    "        \"\"\"\n",
    "        # 自动生成 epochs（假设train_loss和val_loss长度一致）\n",
    "        epochs = np.arange(len(train_loss))\n",
    "\n",
    "        # 使用 Seaborn 设置白色背景样式\n",
    "        sns.set(style=\"white\")\n",
    "\n",
    "        # 创建图形并优化细节\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # 绘制训练和验证曲线\n",
    "        plt.plot(epochs, train_loss, label='Training', color='#d62728', linewidth=2, marker='o', markersize=6)\n",
    "        plt.plot(epochs, val_loss, label='Validation', color='#1f77b4', linewidth=2, marker='s', markersize=6)\n",
    "\n",
    "        # 添加标题和标签\n",
    "        plt.title('Training and Validation Loss', fontsize=18, fontweight='bold', color='black')\n",
    "        plt.xlabel('Epoch', fontsize=14)\n",
    "        plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "        # 添加图例\n",
    "        plt.legend(fontsize=12, loc='upper right')\n",
    "\n",
    "        # 启用横向网格线\n",
    "        plt.grid(True, axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        # 去掉顶部和右侧的边框，仅显示左侧和底部的边框\n",
    "        plt.gca().spines['top'].set_visible(False)\n",
    "        plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "        # 可选：修改左侧和底部边框的样式\n",
    "        plt.gca().spines['left'].set_linewidth(1.5)\n",
    "        plt.gca().spines['bottom'].set_linewidth(1.5)\n",
    "\n",
    "        plt.gca().spines['left'].set_visible(True)\n",
    "        plt.gca().spines['bottom'].set_visible(True)\n",
    "\n",
    "        plt.gca().tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "        # 调整布局以防止标签重叠\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 展示图形\n",
    "        plt.show()\n",
    "\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba150f6-472a-4214-8881-cdbe06d52517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T02:56:53.910005Z",
     "iopub.status.busy": "2024-12-11T02:56:53.910005Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                 | 1/50 [00:26<21:46, 26.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 0.4150, Validation Loss: 0.0524\n",
      "Validation loss decreased (inf --> 0.052382).  Saving model ...\n",
      "Updating learning rate to 0.0009990133642141358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 2/50 [00:54<21:41, 27.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Training Loss: 0.0386, Validation Loss: 0.0227\n",
      "Validation loss decreased (0.052382 --> 0.022672).  Saving model ...\n",
      "Updating learning rate to 0.000996057350657239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                              | 3/50 [01:24<22:35, 28.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Training Loss: 0.0246, Validation Loss: 0.0315\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0009911436253643444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                            | 4/50 [02:02<24:52, 32.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Training Loss: 0.0083, Validation Loss: 0.0154\n",
      "Validation loss decreased (0.022672 --> 0.015365).  Saving model ...\n",
      "Updating learning rate to 0.0009842915805643156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 5/50 [02:35<24:20, 32.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Training Loss: 0.0054, Validation Loss: 0.0100\n",
      "Validation loss decreased (0.015365 --> 0.009956).  Saving model ...\n",
      "Updating learning rate to 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▉                                                                         | 6/50 [03:05<23:15, 31.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Training Loss: 0.0041, Validation Loss: 0.0103\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0009648882429441257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▌                                                                       | 7/50 [03:38<22:54, 31.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Training Loss: 0.0033, Validation Loss: 0.0084\n",
      "Validation loss decreased (0.009956 --> 0.008387).  Saving model ...\n",
      "Updating learning rate to 0.0009524135262330098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▎                                                                     | 8/50 [04:11<22:36, 32.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Training Loss: 0.0026, Validation Loss: 0.0040\n",
      "Validation loss decreased (0.008387 --> 0.003956).  Saving model ...\n",
      "Updating learning rate to 0.0009381533400219318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▉                                                                    | 9/50 [04:43<22:04, 32.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Training Loss: 0.0023, Validation Loss: 0.0120\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0009221639627510075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▍                                                                 | 10/50 [05:17<21:51, 32.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Training Loss: 0.0022, Validation Loss: 0.0057\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 0.0009045084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████                                                                | 11/50 [05:48<21:02, 32.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Training Loss: 0.0018, Validation Loss: 0.0065\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 0.0008852566213878947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▋                                                              | 12/50 [06:23<20:58, 33.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Training Loss: 0.0015, Validation Loss: 0.0037\n",
      "Validation loss decreased (0.003956 --> 0.003745).  Saving model ...\n",
      "Updating learning rate to 0.0008644843137107057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████▎                                                            | 13/50 [06:57<20:37, 33.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Training Loss: 0.0017, Validation Loss: 0.0026\n",
      "Validation loss decreased (0.003745 --> 0.002647).  Saving model ...\n",
      "Updating learning rate to 0.0008422735529643444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▉                                                           | 14/50 [07:34<20:36, 34.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Training Loss: 0.0014, Validation Loss: 0.0033\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0008187119948743449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▌                                                         | 15/50 [08:08<20:05, 34.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Training Loss: 0.0014, Validation Loss: 0.0023\n",
      "Validation loss decreased (0.002647 --> 0.002288).  Saving model ...\n",
      "Updating learning rate to 0.0007938926261462366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████▏                                                       | 16/50 [08:43<19:28, 34.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Training Loss: 0.0011, Validation Loss: 0.0033\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0007679133974894983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▉                                                      | 17/50 [09:17<18:54, 34.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Training Loss: 0.0011, Validation Loss: 0.0020\n",
      "Validation loss decreased (0.002288 --> 0.002038).  Saving model ...\n",
      "Updating learning rate to 0.0007408768370508576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▌                                                    | 18/50 [09:51<18:14, 34.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Training Loss: 0.0010, Validation Loss: 0.0021\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0007128896457825364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▏                                                  | 19/50 [10:22<17:15, 33.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Training Loss: 0.0010, Validation Loss: 0.0041\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 0.0006840622763423391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▊                                                 | 20/50 [10:54<16:26, 32.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Training Loss: 0.0010, Validation Loss: 0.0011\n",
      "Validation loss decreased (0.002038 --> 0.001118).  Saving model ...\n",
      "Updating learning rate to 0.0006545084971874737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▍                                               | 21/50 [11:25<15:40, 32.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Training Loss: 0.0010, Validation Loss: 0.0027\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0006243449435824276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████                                              | 22/50 [11:57<14:57, 32.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Training Loss: 0.0010, Validation Loss: 0.0011\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 0.0005936906572928624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▋                                            | 23/50 [12:32<14:55, 33.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Training Loss: 0.0009, Validation Loss: 0.0029\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 0.0005626666167821521\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params5 = {\n",
    "    \"train_args\": {\n",
    "        \"features\": 'M',\n",
    "        \"model_name\": Transformer,\n",
    "        \"train_loader\": test_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        \"n_epochs\": 50,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"loss\": nn.MSELoss(),\n",
    "        \"patience\": 5,\n",
    "        \"lradj\": 'cosine',\n",
    "        \"model_path\": \"../outputs/best_models/Transformer_ewc_new\",\n",
    "        \"device\": 'cuda',\n",
    "        \"ewc\": ewc,\n",
    "        \"lambda_reg\": 1e-3,\n",
    "        \"verbose\": True,\n",
    "        \"plots\": True,\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'seq_len': 60,\n",
    "        'pred_len': 3, \n",
    "        'label_len': 10,\n",
    "        'output_attention': True,\n",
    "        'embed': 'timeF', # 可选'timeF','fixed'和'learned'\n",
    "        'freq': 'h',\n",
    "        'd_model': 512,\n",
    "        'enc_in': 2,\n",
    "        'dec_in': 2,\n",
    "        'dropout': 0.1,\n",
    "        'factor': 3,\n",
    "        'n_heads': 8,\n",
    "        'd_ff': 128,\n",
    "        'e_layers': 2,\n",
    "        'd_layers': 2,\n",
    "        'c_out': 2\n",
    "    },\n",
    "}\n",
    "model = re_train(**params5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455bca8e-0b88-44ff-b6e4-c53b9ed8da76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
