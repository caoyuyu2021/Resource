{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33424c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T07:39:32.802992Z",
     "start_time": "2024-10-27T07:39:32.793989Z"
    }
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.fft as fft\n",
    "import os\n",
    "from tqdm import tqdm # 打印进度条\n",
    "import math\n",
    "from einops import rearrange, repeat, reduce\n",
    "from scipy.fftpack import next_fast_len\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "from functools import partial, wraps\n",
    "from sympy import Poly, legendre, Symbol, chebyshevt\n",
    "from scipy.special import eval_legendre\n",
    "from scipy import signal\n",
    "from torch.nn.modules.linear import Linear\n",
    "from operator import mul\n",
    "from typing import List\n",
    "from pandas.tseries import offsets\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import pandas as pd\n",
    "import joblib\n",
    "# 两种绘图接口\n",
    "import plotly_express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "334a9b63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:21:16.012251Z",
     "start_time": "2024-10-27T10:21:15.872511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>936</th>\n",
       "      <th>937</th>\n",
       "      <th>938</th>\n",
       "      <th>939</th>\n",
       "      <th>940</th>\n",
       "      <th>941</th>\n",
       "      <th>942</th>\n",
       "      <th>943</th>\n",
       "      <th>944</th>\n",
       "      <th>945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.312502</td>\n",
       "      <td>-0.312502</td>\n",
       "      <td>-0.312502</td>\n",
       "      <td>-0.312502</td>\n",
       "      <td>-0.312502</td>\n",
       "      <td>-0.312502</td>\n",
       "      <td>-0.312502</td>\n",
       "      <td>-0.312502</td>\n",
       "      <td>-0.312502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512194</td>\n",
       "      <td>0.503002</td>\n",
       "      <td>0.492524</td>\n",
       "      <td>0.482045</td>\n",
       "      <td>0.463662</td>\n",
       "      <td>0.445278</td>\n",
       "      <td>0.426895</td>\n",
       "      <td>0.408511</td>\n",
       "      <td>0.390129</td>\n",
       "      <td>0.371746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.629721</td>\n",
       "      <td>1.629721</td>\n",
       "      <td>1.629721</td>\n",
       "      <td>1.629721</td>\n",
       "      <td>1.629721</td>\n",
       "      <td>1.629721</td>\n",
       "      <td>1.629721</td>\n",
       "      <td>1.629721</td>\n",
       "      <td>1.629721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424252</td>\n",
       "      <td>-0.424252</td>\n",
       "      <td>-0.424252</td>\n",
       "      <td>-0.424414</td>\n",
       "      <td>-0.426015</td>\n",
       "      <td>-0.437960</td>\n",
       "      <td>-0.449905</td>\n",
       "      <td>-0.461849</td>\n",
       "      <td>-0.473794</td>\n",
       "      <td>-0.485739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.665410</td>\n",
       "      <td>0.665410</td>\n",
       "      <td>0.665410</td>\n",
       "      <td>0.665410</td>\n",
       "      <td>0.665410</td>\n",
       "      <td>0.665410</td>\n",
       "      <td>0.665410</td>\n",
       "      <td>0.665410</td>\n",
       "      <td>0.665410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.856895</td>\n",
       "      <td>-0.856895</td>\n",
       "      <td>-0.856895</td>\n",
       "      <td>-0.856895</td>\n",
       "      <td>-0.856895</td>\n",
       "      <td>-0.856895</td>\n",
       "      <td>-0.856895</td>\n",
       "      <td>-0.856895</td>\n",
       "      <td>-0.856895</td>\n",
       "      <td>-0.856895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194748</td>\n",
       "      <td>-0.131015</td>\n",
       "      <td>-0.286569</td>\n",
       "      <td>0.051284</td>\n",
       "      <td>0.389136</td>\n",
       "      <td>0.149143</td>\n",
       "      <td>0.245672</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.639840</td>\n",
       "      <td>0.842551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.272493</td>\n",
       "      <td>1.272493</td>\n",
       "      <td>1.272493</td>\n",
       "      <td>1.272493</td>\n",
       "      <td>1.272493</td>\n",
       "      <td>1.272493</td>\n",
       "      <td>1.272493</td>\n",
       "      <td>1.272493</td>\n",
       "      <td>1.272493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.852405</td>\n",
       "      <td>1.819330</td>\n",
       "      <td>1.741195</td>\n",
       "      <td>1.624052</td>\n",
       "      <td>1.506909</td>\n",
       "      <td>1.439170</td>\n",
       "      <td>1.500978</td>\n",
       "      <td>1.618121</td>\n",
       "      <td>1.735263</td>\n",
       "      <td>1.852405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>3</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202822</td>\n",
       "      <td>-0.128241</td>\n",
       "      <td>-0.321706</td>\n",
       "      <td>-0.044231</td>\n",
       "      <td>0.142222</td>\n",
       "      <td>0.328674</td>\n",
       "      <td>0.110026</td>\n",
       "      <td>0.147317</td>\n",
       "      <td>0.184607</td>\n",
       "      <td>0.221897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.232312</td>\n",
       "      <td>-1.232312</td>\n",
       "      <td>-1.232312</td>\n",
       "      <td>-1.232312</td>\n",
       "      <td>-1.232312</td>\n",
       "      <td>-1.232312</td>\n",
       "      <td>-1.232312</td>\n",
       "      <td>-1.232312</td>\n",
       "      <td>-1.232312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221684</td>\n",
       "      <td>0.233878</td>\n",
       "      <td>0.246070</td>\n",
       "      <td>0.258264</td>\n",
       "      <td>0.270456</td>\n",
       "      <td>0.282650</td>\n",
       "      <td>0.294843</td>\n",
       "      <td>0.307036</td>\n",
       "      <td>0.319229</td>\n",
       "      <td>0.331423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>2</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>0.285103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219075</td>\n",
       "      <td>-0.213164</td>\n",
       "      <td>-0.187128</td>\n",
       "      <td>0.176418</td>\n",
       "      <td>0.138347</td>\n",
       "      <td>0.198371</td>\n",
       "      <td>0.446330</td>\n",
       "      <td>0.161218</td>\n",
       "      <td>0.225716</td>\n",
       "      <td>0.270101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>7</td>\n",
       "      <td>1.251416</td>\n",
       "      <td>1.251416</td>\n",
       "      <td>1.251416</td>\n",
       "      <td>1.251416</td>\n",
       "      <td>1.251416</td>\n",
       "      <td>1.251416</td>\n",
       "      <td>1.251416</td>\n",
       "      <td>1.251416</td>\n",
       "      <td>1.251416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155403</td>\n",
       "      <td>-0.158187</td>\n",
       "      <td>-0.185514</td>\n",
       "      <td>-0.291492</td>\n",
       "      <td>-0.401972</td>\n",
       "      <td>-0.499320</td>\n",
       "      <td>-0.553890</td>\n",
       "      <td>-0.544005</td>\n",
       "      <td>-0.500638</td>\n",
       "      <td>-0.427876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.166397</td>\n",
       "      <td>-0.166397</td>\n",
       "      <td>-0.166397</td>\n",
       "      <td>-0.166397</td>\n",
       "      <td>-0.166397</td>\n",
       "      <td>-0.166397</td>\n",
       "      <td>-0.166397</td>\n",
       "      <td>-0.166397</td>\n",
       "      <td>-0.166397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.873007</td>\n",
       "      <td>-0.873007</td>\n",
       "      <td>-0.872369</td>\n",
       "      <td>-0.867265</td>\n",
       "      <td>-0.856664</td>\n",
       "      <td>-0.846063</td>\n",
       "      <td>-0.825577</td>\n",
       "      <td>-0.797916</td>\n",
       "      <td>-0.766113</td>\n",
       "      <td>-0.734310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896 rows × 946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6    \\\n",
       "0      6 -0.312502 -0.312502 -0.312502 -0.312502 -0.312502 -0.312502   \n",
       "1      5  1.629721  1.629721  1.629721  1.629721  1.629721  1.629721   \n",
       "2      5  0.665410  0.665410  0.665410  0.665410  0.665410  0.665410   \n",
       "3      3  0.164887  0.164887  0.164887  0.164887  0.164887  0.164887   \n",
       "4      4  1.272493  1.272493  1.272493  1.272493  1.272493  1.272493   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "891    3  0.126056  0.126056  0.126056  0.126056  0.126056  0.126056   \n",
       "892    1 -1.232312 -1.232312 -1.232312 -1.232312 -1.232312 -1.232312   \n",
       "893    2  0.285103  0.285103  0.285103  0.285103  0.285103  0.285103   \n",
       "894    7  1.251416  1.251416  1.251416  1.251416  1.251416  1.251416   \n",
       "895    5 -0.166397 -0.166397 -0.166397 -0.166397 -0.166397 -0.166397   \n",
       "\n",
       "          7         8         9    ...       936       937       938  \\\n",
       "0   -0.312502 -0.312502 -0.312502  ...  0.512194  0.503002  0.492524   \n",
       "1    1.629721  1.629721  1.629721  ... -0.424252 -0.424252 -0.424252   \n",
       "2    0.665410  0.665410  0.665410  ... -0.856895 -0.856895 -0.856895   \n",
       "3    0.164887  0.164887  0.164887  ... -0.194748 -0.131015 -0.286569   \n",
       "4    1.272493  1.272493  1.272493  ...  1.852405  1.819330  1.741195   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "891  0.126056  0.126056  0.126056  ... -0.202822 -0.128241 -0.321706   \n",
       "892 -1.232312 -1.232312 -1.232312  ...  0.221684  0.233878  0.246070   \n",
       "893  0.285103  0.285103  0.285103  ... -0.219075 -0.213164 -0.187128   \n",
       "894  1.251416  1.251416  1.251416  ... -0.155403 -0.158187 -0.185514   \n",
       "895 -0.166397 -0.166397 -0.166397  ... -0.873007 -0.873007 -0.872369   \n",
       "\n",
       "          939       940       941       942       943       944       945  \n",
       "0    0.482045  0.463662  0.445278  0.426895  0.408511  0.390129  0.371746  \n",
       "1   -0.424414 -0.426015 -0.437960 -0.449905 -0.461849 -0.473794 -0.485739  \n",
       "2   -0.856895 -0.856895 -0.856895 -0.856895 -0.856895 -0.856895 -0.856895  \n",
       "3    0.051284  0.389136  0.149143  0.245672  0.437129  0.639840  0.842551  \n",
       "4    1.624052  1.506909  1.439170  1.500978  1.618121  1.735263  1.852405  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "891 -0.044231  0.142222  0.328674  0.110026  0.147317  0.184607  0.221897  \n",
       "892  0.258264  0.270456  0.282650  0.294843  0.307036  0.319229  0.331423  \n",
       "893  0.176418  0.138347  0.198371  0.446330  0.161218  0.225716  0.270101  \n",
       "894 -0.291492 -0.401972 -0.499320 -0.553890 -0.544005 -0.500638 -0.427876  \n",
       "895 -0.867265 -0.856664 -0.846063 -0.825577 -0.797916 -0.766113 -0.734310  \n",
       "\n",
       "[896 rows x 946 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/UWaveGestureLibraryAll_TRAIN.tsv\"\n",
    "data = pd.read_csv(data_path, sep='\\t', header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b190e00f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:21:17.173326Z",
     "start_time": "2024-10-27T10:21:17.168354Z"
    }
   },
   "outputs": [],
   "source": [
    "data1 = data\n",
    "data2 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "731bd22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:18:11.645969Z",
     "start_time": "2024-10-27T10:18:11.639230Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "854db593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:35:27.148932Z",
     "start_time": "2024-10-27T10:35:27.108467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                              feature1\n",
       " 0    [-0.31250227, -0.31250227, -0.31250227, -0.312...\n",
       " 1    [1.6297212, 1.6297212, 1.6297212, 1.6297212, 1...\n",
       " 2    [0.66540969, 0.66540969, 0.66540969, 0.6654096...\n",
       " 3    [0.16488744, 0.16488744, 0.16488744, 0.1648874...\n",
       " 4    [1.2724935, 1.2724935, 1.2724935, 1.2724935, 1...\n",
       " ..                                                 ...\n",
       " 891  [0.12605618, 0.12605618, 0.12605618, 0.1260561...\n",
       " 892  [-1.2323122, -1.2323122, -1.2323122, -1.232312...\n",
       " 893  [0.28510341, 0.28510341, 0.28510341, 0.2851034...\n",
       " 894  [1.2514163, 1.2514163, 1.2514163, 1.2514163, 1...\n",
       " 895  [-0.16639664, -0.16639664, -0.16639664, -0.166...\n",
       " \n",
       " [896 rows x 1 columns],\n",
       " array([6, 5, 5, 3, 4, 8, 7, 4, 4, 6, 1, 7, 3, 5, 2, 6, 1, 6, 1, 2, 8, 6,\n",
       "        1, 7, 8, 7, 3, 6, 2, 6, 2, 7, 8, 4, 5, 6, 8, 1, 7, 8, 5, 6, 1, 6,\n",
       "        5, 1, 7, 8, 1, 5, 4, 4, 7, 1, 4, 1, 8, 2, 1, 2, 3, 8, 1, 4, 2, 1,\n",
       "        1, 7, 5, 5, 2, 5, 7, 2, 1, 7, 1, 6, 5, 3, 7, 2, 1, 6, 2, 7, 1, 1,\n",
       "        5, 6, 4, 8, 6, 3, 4, 5, 3, 8, 3, 5, 2, 8, 8, 8, 8, 7, 5, 2, 2, 5,\n",
       "        2, 3, 4, 4, 7, 7, 1, 4, 5, 4, 1, 6, 5, 5, 4, 6, 4, 6, 2, 3, 6, 6,\n",
       "        3, 3, 5, 5, 3, 6, 5, 8, 4, 6, 1, 8, 5, 8, 2, 5, 5, 8, 2, 7, 1, 2,\n",
       "        4, 2, 3, 8, 7, 7, 6, 4, 3, 1, 3, 4, 3, 8, 6, 2, 7, 3, 5, 2, 2, 2,\n",
       "        4, 5, 7, 6, 1, 1, 8, 6, 6, 1, 6, 1, 3, 2, 7, 5, 2, 5, 5, 8, 7, 4,\n",
       "        7, 5, 8, 4, 2, 4, 1, 1, 6, 4, 5, 3, 2, 8, 4, 6, 3, 4, 5, 1, 8, 6,\n",
       "        2, 4, 6, 1, 8, 8, 7, 4, 4, 2, 2, 1, 4, 8, 5, 6, 1, 5, 3, 3, 4, 3,\n",
       "        6, 3, 6, 1, 1, 3, 7, 2, 5, 2, 3, 6, 8, 2, 4, 8, 6, 7, 4, 1, 6, 3,\n",
       "        7, 6, 5, 4, 1, 7, 7, 1, 4, 7, 8, 5, 3, 8, 5, 7, 7, 7, 5, 5, 4, 1,\n",
       "        8, 7, 3, 3, 4, 7, 5, 6, 1, 6, 4, 8, 7, 7, 6, 3, 7, 2, 1, 6, 3, 1,\n",
       "        5, 7, 4, 2, 2, 2, 1, 6, 4, 2, 3, 3, 4, 6, 2, 4, 5, 4, 7, 4, 1, 7,\n",
       "        3, 5, 2, 5, 4, 6, 8, 7, 5, 2, 3, 4, 4, 6, 4, 5, 8, 5, 4, 3, 6, 3,\n",
       "        4, 6, 8, 2, 1, 3, 3, 1, 7, 6, 6, 6, 6, 6, 3, 1, 2, 2, 8, 4, 7, 5,\n",
       "        7, 3, 3, 1, 7, 7, 1, 4, 6, 2, 2, 1, 4, 4, 8, 1, 3, 1, 1, 3, 7, 2,\n",
       "        6, 1, 3, 4, 4, 6, 2, 1, 1, 4, 5, 8, 5, 1, 5, 8, 3, 4, 7, 1, 7, 1,\n",
       "        2, 1, 3, 4, 1, 3, 8, 5, 7, 7, 5, 6, 3, 6, 1, 1, 7, 2, 4, 4, 2, 8,\n",
       "        3, 1, 1, 3, 4, 1, 5, 8, 5, 3, 7, 5, 8, 5, 4, 7, 2, 5, 8, 1, 8, 2,\n",
       "        7, 3, 8, 6, 4, 6, 4, 8, 5, 6, 3, 3, 1, 6, 7, 2, 6, 5, 2, 7, 5, 6,\n",
       "        7, 6, 8, 3, 6, 5, 5, 5, 2, 5, 1, 5, 5, 2, 8, 7, 3, 6, 5, 7, 6, 3,\n",
       "        2, 7, 5, 3, 2, 6, 7, 5, 3, 7, 8, 5, 8, 8, 3, 8, 1, 8, 8, 3, 4, 6,\n",
       "        8, 8, 6, 4, 8, 8, 1, 3, 6, 5, 7, 5, 3, 7, 3, 5, 2, 1, 8, 5, 3, 4,\n",
       "        5, 2, 1, 2, 8, 5, 4, 7, 8, 2, 6, 4, 8, 7, 4, 1, 6, 4, 2, 7, 2, 3,\n",
       "        6, 7, 2, 4, 1, 6, 5, 4, 8, 6, 8, 5, 2, 3, 7, 2, 7, 4, 2, 3, 3, 7,\n",
       "        3, 6, 5, 5, 2, 4, 8, 6, 1, 2, 3, 7, 8, 1, 7, 3, 7, 1, 7, 3, 7, 6,\n",
       "        7, 1, 7, 3, 5, 7, 4, 7, 5, 5, 7, 8, 5, 3, 6, 5, 6, 7, 2, 1, 7, 5,\n",
       "        5, 2, 4, 4, 5, 3, 1, 3, 4, 8, 6, 2, 4, 5, 5, 6, 4, 3, 1, 7, 7, 5,\n",
       "        7, 3, 2, 1, 8, 5, 4, 1, 8, 7, 3, 7, 4, 1, 6, 2, 8, 4, 6, 2, 4, 1,\n",
       "        5, 7, 1, 1, 5, 2, 5, 4, 5, 8, 1, 4, 3, 5, 5, 8, 1, 8, 2, 1, 6, 6,\n",
       "        6, 2, 2, 6, 4, 1, 8, 4, 5, 1, 8, 6, 8, 1, 1, 6, 1, 4, 3, 6, 5, 8,\n",
       "        7, 3, 3, 4, 4, 3, 7, 5, 5, 2, 2, 5, 8, 1, 4, 8, 1, 1, 1, 3, 6, 4,\n",
       "        1, 8, 2, 2, 5, 1, 6, 4, 8, 4, 5, 6, 2, 2, 6, 8, 1, 5, 4, 4, 5, 4,\n",
       "        3, 2, 3, 5, 5, 2, 3, 3, 6, 2, 8, 2, 7, 5, 7, 7, 3, 8, 8, 1, 7, 7,\n",
       "        1, 2, 7, 2, 2, 5, 1, 8, 1, 6, 7, 7, 3, 5, 1, 3, 5, 1, 2, 7, 3, 1,\n",
       "        3, 8, 5, 4, 4, 7, 8, 2, 2, 4, 6, 1, 2, 3, 5, 8, 4, 6, 3, 6, 5, 1,\n",
       "        2, 5, 7, 2, 2, 3, 6, 7, 8, 1, 7, 1, 4, 6, 4, 6, 8, 6, 1, 2, 1, 8,\n",
       "        5, 4, 8, 5, 6, 6, 7, 1, 8, 5, 7, 7, 5, 3, 4, 2, 3, 6, 2, 7, 1, 2,\n",
       "        6, 8, 3, 1, 5, 1, 2, 3, 4, 6, 5, 3, 1, 2, 7, 5], dtype=int64))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_all([data1], ['feature1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7389e58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T09:47:38.473708Z",
     "start_time": "2024-10-27T09:47:38.435579Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = data1.iloc[:, 1:]\n",
    "# row.tolist()将这一行的所有列值提取并转换为一个普通的 Python 列表\n",
    "df1 = pd.DataFrame(df1.apply(lambda row: row.tolist(), axis=1),columns=['feature1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a542f73f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T09:47:40.077418Z",
     "start_time": "2024-10-27T09:47:40.027513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.31250227, -0.31250227, -0.31250227, -0.312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.6297212, 1.6297212, 1.6297212, 1.6297212, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.66540969, 0.66540969, 0.66540969, 0.6654096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.16488744, 0.16488744, 0.16488744, 0.1648874...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.2724935, 1.2724935, 1.2724935, 1.2724935, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>[0.12605618, 0.12605618, 0.12605618, 0.1260561...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>[-1.2323122, -1.2323122, -1.2323122, -1.232312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>[0.28510341, 0.28510341, 0.28510341, 0.2851034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>[1.2514163, 1.2514163, 1.2514163, 1.2514163, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>[-0.16639664, -0.16639664, -0.16639664, -0.166...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature2\n",
       "0    [-0.31250227, -0.31250227, -0.31250227, -0.312...\n",
       "1    [1.6297212, 1.6297212, 1.6297212, 1.6297212, 1...\n",
       "2    [0.66540969, 0.66540969, 0.66540969, 0.6654096...\n",
       "3    [0.16488744, 0.16488744, 0.16488744, 0.1648874...\n",
       "4    [1.2724935, 1.2724935, 1.2724935, 1.2724935, 1...\n",
       "..                                                 ...\n",
       "891  [0.12605618, 0.12605618, 0.12605618, 0.1260561...\n",
       "892  [-1.2323122, -1.2323122, -1.2323122, -1.232312...\n",
       "893  [0.28510341, 0.28510341, 0.28510341, 0.2851034...\n",
       "894  [1.2514163, 1.2514163, 1.2514163, 1.2514163, 1...\n",
       "895  [-0.16639664, -0.16639664, -0.16639664, -0.166...\n",
       "\n",
       "[896 rows x 1 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = data2.iloc[:, 1:]\n",
    "# row.tolist()将这一行的所有列值提取并转换为一个普通的 Python 列表\n",
    "df2 = pd.DataFrame(df2.apply(lambda row: row.tolist(), axis=1),columns=['feature2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ba893b30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T09:48:21.719997Z",
     "start_time": "2024-10-27T09:48:21.713924Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c702ec71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T09:48:23.606237Z",
     "start_time": "2024-10-27T09:48:23.598846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 5, 3, 4, 8, 7, 4, 4, 6, 1, 7, 3, 5, 2, 6, 1, 6, 1, 2, 8, 6,\n",
       "       1, 7, 8, 7, 3, 6, 2, 6, 2, 7, 8, 4, 5, 6, 8, 1, 7, 8, 5, 6, 1, 6,\n",
       "       5, 1, 7, 8, 1, 5, 4, 4, 7, 1, 4, 1, 8, 2, 1, 2, 3, 8, 1, 4, 2, 1,\n",
       "       1, 7, 5, 5, 2, 5, 7, 2, 1, 7, 1, 6, 5, 3, 7, 2, 1, 6, 2, 7, 1, 1,\n",
       "       5, 6, 4, 8, 6, 3, 4, 5, 3, 8, 3, 5, 2, 8, 8, 8, 8, 7, 5, 2, 2, 5,\n",
       "       2, 3, 4, 4, 7, 7, 1, 4, 5, 4, 1, 6, 5, 5, 4, 6, 4, 6, 2, 3, 6, 6,\n",
       "       3, 3, 5, 5, 3, 6, 5, 8, 4, 6, 1, 8, 5, 8, 2, 5, 5, 8, 2, 7, 1, 2,\n",
       "       4, 2, 3, 8, 7, 7, 6, 4, 3, 1, 3, 4, 3, 8, 6, 2, 7, 3, 5, 2, 2, 2,\n",
       "       4, 5, 7, 6, 1, 1, 8, 6, 6, 1, 6, 1, 3, 2, 7, 5, 2, 5, 5, 8, 7, 4,\n",
       "       7, 5, 8, 4, 2, 4, 1, 1, 6, 4, 5, 3, 2, 8, 4, 6, 3, 4, 5, 1, 8, 6,\n",
       "       2, 4, 6, 1, 8, 8, 7, 4, 4, 2, 2, 1, 4, 8, 5, 6, 1, 5, 3, 3, 4, 3,\n",
       "       6, 3, 6, 1, 1, 3, 7, 2, 5, 2, 3, 6, 8, 2, 4, 8, 6, 7, 4, 1, 6, 3,\n",
       "       7, 6, 5, 4, 1, 7, 7, 1, 4, 7, 8, 5, 3, 8, 5, 7, 7, 7, 5, 5, 4, 1,\n",
       "       8, 7, 3, 3, 4, 7, 5, 6, 1, 6, 4, 8, 7, 7, 6, 3, 7, 2, 1, 6, 3, 1,\n",
       "       5, 7, 4, 2, 2, 2, 1, 6, 4, 2, 3, 3, 4, 6, 2, 4, 5, 4, 7, 4, 1, 7,\n",
       "       3, 5, 2, 5, 4, 6, 8, 7, 5, 2, 3, 4, 4, 6, 4, 5, 8, 5, 4, 3, 6, 3,\n",
       "       4, 6, 8, 2, 1, 3, 3, 1, 7, 6, 6, 6, 6, 6, 3, 1, 2, 2, 8, 4, 7, 5,\n",
       "       7, 3, 3, 1, 7, 7, 1, 4, 6, 2, 2, 1, 4, 4, 8, 1, 3, 1, 1, 3, 7, 2,\n",
       "       6, 1, 3, 4, 4, 6, 2, 1, 1, 4, 5, 8, 5, 1, 5, 8, 3, 4, 7, 1, 7, 1,\n",
       "       2, 1, 3, 4, 1, 3, 8, 5, 7, 7, 5, 6, 3, 6, 1, 1, 7, 2, 4, 4, 2, 8,\n",
       "       3, 1, 1, 3, 4, 1, 5, 8, 5, 3, 7, 5, 8, 5, 4, 7, 2, 5, 8, 1, 8, 2,\n",
       "       7, 3, 8, 6, 4, 6, 4, 8, 5, 6, 3, 3, 1, 6, 7, 2, 6, 5, 2, 7, 5, 6,\n",
       "       7, 6, 8, 3, 6, 5, 5, 5, 2, 5, 1, 5, 5, 2, 8, 7, 3, 6, 5, 7, 6, 3,\n",
       "       2, 7, 5, 3, 2, 6, 7, 5, 3, 7, 8, 5, 8, 8, 3, 8, 1, 8, 8, 3, 4, 6,\n",
       "       8, 8, 6, 4, 8, 8, 1, 3, 6, 5, 7, 5, 3, 7, 3, 5, 2, 1, 8, 5, 3, 4,\n",
       "       5, 2, 1, 2, 8, 5, 4, 7, 8, 2, 6, 4, 8, 7, 4, 1, 6, 4, 2, 7, 2, 3,\n",
       "       6, 7, 2, 4, 1, 6, 5, 4, 8, 6, 8, 5, 2, 3, 7, 2, 7, 4, 2, 3, 3, 7,\n",
       "       3, 6, 5, 5, 2, 4, 8, 6, 1, 2, 3, 7, 8, 1, 7, 3, 7, 1, 7, 3, 7, 6,\n",
       "       7, 1, 7, 3, 5, 7, 4, 7, 5, 5, 7, 8, 5, 3, 6, 5, 6, 7, 2, 1, 7, 5,\n",
       "       5, 2, 4, 4, 5, 3, 1, 3, 4, 8, 6, 2, 4, 5, 5, 6, 4, 3, 1, 7, 7, 5,\n",
       "       7, 3, 2, 1, 8, 5, 4, 1, 8, 7, 3, 7, 4, 1, 6, 2, 8, 4, 6, 2, 4, 1,\n",
       "       5, 7, 1, 1, 5, 2, 5, 4, 5, 8, 1, 4, 3, 5, 5, 8, 1, 8, 2, 1, 6, 6,\n",
       "       6, 2, 2, 6, 4, 1, 8, 4, 5, 1, 8, 6, 8, 1, 1, 6, 1, 4, 3, 6, 5, 8,\n",
       "       7, 3, 3, 4, 4, 3, 7, 5, 5, 2, 2, 5, 8, 1, 4, 8, 1, 1, 1, 3, 6, 4,\n",
       "       1, 8, 2, 2, 5, 1, 6, 4, 8, 4, 5, 6, 2, 2, 6, 8, 1, 5, 4, 4, 5, 4,\n",
       "       3, 2, 3, 5, 5, 2, 3, 3, 6, 2, 8, 2, 7, 5, 7, 7, 3, 8, 8, 1, 7, 7,\n",
       "       1, 2, 7, 2, 2, 5, 1, 8, 1, 6, 7, 7, 3, 5, 1, 3, 5, 1, 2, 7, 3, 1,\n",
       "       3, 8, 5, 4, 4, 7, 8, 2, 2, 4, 6, 1, 2, 3, 5, 8, 4, 6, 3, 6, 5, 1,\n",
       "       2, 5, 7, 2, 2, 3, 6, 7, 8, 1, 7, 1, 4, 6, 4, 6, 8, 6, 1, 2, 1, 8,\n",
       "       5, 4, 8, 5, 6, 6, 7, 1, 8, 5, 7, 7, 5, 3, 4, 2, 3, 6, 2, 7, 1, 2,\n",
       "       6, 8, 3, 1, 5, 1, 2, 3, 4, 6, 5, 3, 1, 2, 7, 5], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data.iloc[:, 0].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f52209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106e232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a2409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b398f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a557d589",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T09:48:28.310493Z",
     "start_time": "2024-10-27T09:48:28.303603Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5098586e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T09:48:29.620388Z",
     "start_time": "2024-10-27T09:48:29.616023Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c6c2da55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:35:35.560905Z",
     "start_time": "2024-10-27T10:35:35.543387Z"
    }
   },
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, data, columns):\n",
    "        df, labels = self.load_all(data, columns)\n",
    "        self.all_df, self.labels_df = self.load_single(df, labels)\n",
    "        self.all_IDs = self.all_df.index.unique()  # all sample IDs (integer indices 0 ... num_samples-1)\n",
    "\n",
    "        # use all features\n",
    "        self.feature_names = self.all_df.columns\n",
    "        self.feature_df = self.all_df\n",
    "\n",
    "        # pre_process\n",
    "#         normalizer = Normalizer()\n",
    "#         self.feature_df = normalizer.normalize(self.feature_df)\n",
    "#         print(len(self.all_IDs))\n",
    "    # 加载多个数据集\n",
    "    def load_all(self, data: List[pd.DataFrame], columns: List[str]):\n",
    "        # 特征数据合并\n",
    "        for i in range(len(data)):\n",
    "            if i == 0:\n",
    "                df = data[i].iloc[:, 1:]\n",
    "                # row.tolist()将这一行的所有列值提取并转换为一个普通的 Python 列表\n",
    "                df = pd.DataFrame(df.apply(lambda row: row.tolist(), axis=1),\n",
    "                                  columns=[columns[i]])\n",
    "            else:\n",
    "                df2 = data[i].iloc[:, 1:]\n",
    "                df2 = pd.DataFrame(df2.apply(lambda row: row.tolist(), axis=1),\n",
    "                                   columns=[columns[i]])\n",
    "                df = pd.concat([df, df2], axis=1)\n",
    "\n",
    "        # 标签数据\n",
    "        labels = data[0].iloc[:, 0].values\n",
    "\n",
    "        return df, labels\n",
    "\n",
    "    # 加载单个数据集\n",
    "    def load_single(self, df, labels):\n",
    "        labels = pd.Series(labels, dtype=\"category\")\n",
    "        self.class_names = labels.cat.categories\n",
    "        labels_df = pd.DataFrame(labels.cat.codes,\n",
    "                                 dtype=np.int8)  # int8-32 gives an error when using nn.CrossEntropyLoss\n",
    "\n",
    "        lengths = df.applymap(\n",
    "            lambda x: len(x)).values  # (num_samples, num_dimensions) array containing the length of each series\n",
    "\n",
    "        horiz_diffs = np.abs(lengths - np.expand_dims(lengths[:, 0], -1))\n",
    "\n",
    "        if np.sum(horiz_diffs) > 0:  # if any row (sample) has varying length across dimensions\n",
    "            df = df.applymap(self.subsample)\n",
    "\n",
    "        lengths = df.applymap(lambda x: len(x)).values\n",
    "        vert_diffs = np.abs(lengths - np.expand_dims(lengths[0, :], 0))\n",
    "        if np.sum(vert_diffs) > 0:  # if any column (dimension) has varying length across samples\n",
    "            self.max_seq_len = int(np.max(lengths[:, 0]))\n",
    "        else:\n",
    "            self.max_seq_len = lengths[0, 0]\n",
    "\n",
    "        # First create a (seq_len, feat_dim) dataframe for each sample, indexed by a single integer (\"ID\" of the sample)\n",
    "        # Then concatenate into a (num_samples * seq_len, feat_dim) dataframe, with multiple rows corresponding to the\n",
    "        # sample index (i.e. the same scheme as all datasets in this project)\n",
    "\n",
    "        df = pd.concat((pd.DataFrame({col: df.loc[row, col] for col in df.columns}).reset_index(drop=True).set_index(\n",
    "            pd.Series(lengths[row, 0] * [row])) for row in range(df.shape[0])), axis=0)\n",
    "\n",
    "        # Replace NaN values\n",
    "        grp = df.groupby(by=df.index)\n",
    "        df = grp.transform(self.interpolate_missing)\n",
    "\n",
    "        return df, labels_df\n",
    "    \n",
    "    # 通过采样保持序列长度一致\n",
    "    def subsample(self, y, limit=256, factor=2):\n",
    "        \"\"\"\n",
    "        If a given Series is longer than `limit`, returns subsampled sequence by the specified integer factor\n",
    "        \"\"\"\n",
    "        if len(y) > limit:\n",
    "            return y[::factor].reset_index(drop=True)\n",
    "        return y\n",
    "    \n",
    "    # 线性插值填充缺失值\n",
    "    def interpolate_missing(self, y):\n",
    "        \"\"\"\n",
    "        Replaces NaN values in pd.Series `y` using linear interpolation\n",
    "        \"\"\"\n",
    "        if y.isna().any():\n",
    "            y = y.interpolate(method='linear', limit_direction='both')\n",
    "        return y\n",
    "\n",
    "#     def instance_norm(self, case):\n",
    "#         if self.root_path.count('EthanolConcentration') > 0:  # special process for numerical stability\n",
    "#             mean = case.mean(0, keepdim=True)\n",
    "#             case = case - mean\n",
    "#             stdev = torch.sqrt(torch.var(case, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "#             case /= stdev\n",
    "#             return case\n",
    "#         else:\n",
    "#             return case\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        batch_x = self.feature_df.loc[self.all_IDs[ind]].values\n",
    "#         print(batch_x.shape)\n",
    "        labels = self.labels_df.loc[self.all_IDs[ind]].values\n",
    "#         if self.flag == \"TRAIN\" and self.args.augmentation_ratio > 0:\n",
    "    #         # 数据增强，仅限训练阶段\n",
    "    #         num_samples = len(self.all_IDs)\n",
    "    #         num_columns = self.feature_df.shape[1]\n",
    "    #         seq_len = int(self.feature_df.shape[0] / num_samples)\n",
    "    #         batch_x = batch_x.reshape((1, seq_len, num_columns))\n",
    "    #         batch_x, labels, augmentation_tags = run_augmentation_single(batch_x, labels, self.args)\n",
    "\n",
    "        batch_x = batch_x.reshape((1 * seq_len, num_columns))\n",
    "\n",
    "        return torch.from_numpy(batch_x), \\\n",
    "               torch.from_numpy(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1b4fbd29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:35:37.429270Z",
     "start_time": "2024-10-27T10:35:36.471217Z"
    }
   },
   "outputs": [],
   "source": [
    "data_set = TensorDataset([data1, data2], ['feature1', 'feature2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6d5e7f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:35:37.749372Z",
     "start_time": "2024-10-27T10:35:37.741220Z"
    }
   },
   "outputs": [],
   "source": [
    "def padding_mask(lengths, max_len=None):\n",
    "    \"\"\"\n",
    "    Used to mask padded positions: creates a (batch_size, max_len) boolean mask from a tensor of sequence lengths,\n",
    "    where 1 means keep element at this position (time step)\n",
    "    \"\"\"\n",
    "    batch_size = lengths.numel()\n",
    "    max_len = max_len or lengths.max()  # trick works because of overloading of 'or' operator for non-boolean types\n",
    "    return (torch.arange(0, max_len, device=lengths.device)\n",
    "            .type_as(lengths)\n",
    "            .repeat(batch_size, 1)\n",
    "            .lt(lengths.unsqueeze(1)))\n",
    "\n",
    "def collate_fn(data, max_len=None):\n",
    "    \"\"\"Build mini-batch tensors from a list of (X, mask) tuples. Mask input. Create\n",
    "    Args:\n",
    "        data: len(batch_size) list of tuples (X, y).\n",
    "            - X: torch tensor of shape (seq_length, feat_dim); variable seq_length.\n",
    "            - y: torch tensor of shape (num_labels,) : class indices or numerical targets\n",
    "                (for classification or regression, respectively). num_labels > 1 for multi-task models\n",
    "        max_len: global fixed sequence length. Used for architectures requiring fixed length input,\n",
    "            where the batch length cannot vary dynamically. Longer sequences are clipped, shorter are padded with 0s\n",
    "    Returns:\n",
    "        X: (batch_size, padded_length, feat_dim) torch tensor of masked features (input)\n",
    "        targets: (batch_size, padded_length, feat_dim) torch tensor of unmasked features (output)\n",
    "        target_masks: (batch_size, padded_length, feat_dim) boolean torch tensor\n",
    "            0 indicates masked values to be predicted, 1 indicates unaffected/\"active\" feature values\n",
    "        padding_masks: (batch_size, padded_length) boolean tensor, 1 means keep vector at this position, 0 means padding\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(data)\n",
    "    features, labels = zip(*data)\n",
    "\n",
    "    print(features)\n",
    "    # Stack and pad features and masks (convert 2D to 3D tensors, i.e. add batch dimension)\n",
    "    lengths = [X.shape[0] for X in features]  # original sequence length for each time series\n",
    "    if max_len is None:\n",
    "        max_len = max(lengths)\n",
    "\n",
    "    X = torch.zeros(batch_size, max_len, features[0].shape[-1])  # (batch_size, padded_length, feat_dim)\n",
    "    for i in range(batch_size):\n",
    "        end = min(lengths[i], max_len)\n",
    "        X[i, :end, :] = features[i][:end, :]\n",
    "\n",
    "    targets = torch.stack(labels, dim=0)  # (batch_size, num_labels)\n",
    "\n",
    "#     print(torch.tensor(lengths, dtype=torch.int16).max())\n",
    "    padding_masks = padding_mask(torch.tensor(lengths, dtype=torch.int16),\n",
    "                                 max_len=max_len)  # (batch_size, padded_length) boolean tensor, \"1\" means keep\n",
    "\n",
    "    return X, targets, padding_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "68953ff8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:35:38.972374Z",
     "start_time": "2024-10-27T10:35:38.968004Z"
    }
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=16,\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "            collate_fn=lambda x: collate_fn(x, max_len=data_set.max_seq_len)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a1a5549c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:35:41.276188Z",
     "start_time": "2024-10-27T10:35:41.187584Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y, mask \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch_x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch_y\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[129], line 110\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[1;34m(self, ind)\u001b[0m\n\u001b[0;32m    101\u001b[0m         labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_IDs[ind]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m#         if self.flag == \"TRAIN\" and self.args.augmentation_ratio > 0:\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m#         # 数据增强，仅限训练阶段\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m#         num_samples = len(self.all_IDs)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m#         batch_x = batch_x.reshape((1, seq_len, num_columns))\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m#         batch_x, labels, augmentation_tags = run_augmentation_single(batch_x, labels, self.args)\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m         batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m seq_len, num_columns))\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(batch_x), \\\n\u001b[0;32m    113\u001b[0m                torch\u001b[38;5;241m.\u001b[39mfrom_numpy(labels)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seq_len' is not defined"
     ]
    }
   ],
   "source": [
    "for batch_x, batch_y, mask in data_loader:\n",
    "    print(batch_x.shape)\n",
    "    print(batch_y.shape)\n",
    "    print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcafac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
