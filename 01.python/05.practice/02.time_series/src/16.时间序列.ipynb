{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d59574",
   "metadata": {},
   "source": [
    "# 基于时间序列的填补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c112019c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:00:54.104245Z",
     "start_time": "2024-10-29T09:00:54.096865Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.fft as fft\n",
    "import os\n",
    "from tqdm import tqdm # 打印进度条\n",
    "import math\n",
    "from einops import rearrange, repeat, reduce\n",
    "from scipy.fftpack import next_fast_len\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "from functools import partial, wraps\n",
    "from sympy import Poly, legendre, Symbol, chebyshevt\n",
    "from scipy.special import eval_legendre\n",
    "from scipy import signal\n",
    "from torch.nn.modules.linear import Linear\n",
    "from operator import mul\n",
    "from typing import List\n",
    "from pandas.tseries import offsets\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import joblib\n",
    "# 两种绘图接口\n",
    "import plotly_express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f015623",
   "metadata": {},
   "source": [
    "## 基础知识"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e2b0d",
   "metadata": {},
   "source": [
    "缺失值填补(Imputation)是一项旨在预测时间序列中某些缺失值的任务，因此在某种程度上类似于预测。用于实现Imputation的模型架构与长时预测相同。然而，其区别在于，**模型在训练过程中会对输入数据中的部分信息进行掩码处理，随后利用模型预测输入数据中被掩码的值。并基于均方误差（MSEloss）损失计算掩码部分的差值**。这一阶段不需要训练标签的参与。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81dd54b",
   "metadata": {},
   "source": [
    "## TimesNet填补"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a662f91",
   "metadata": {},
   "source": [
    "### 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70071d89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T08:43:03.873835Z",
     "start_time": "2024-10-29T08:43:03.862397Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    读取数据，并对输入数据时间列进行处理\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        输入数据地址，如果为空，读取已有数据\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，如果需读取本地数据，将该值置空，否则传入已有数据\n",
    "    time_col : {str}\n",
    "        输入数据的时间列，如果没有时间列，生成时间戳范围，或者生成固定频率的时间戳数据\n",
    "    datetime : {str} \n",
    "        时间列开始时间，如果time_col为空，需填入此项，格式为%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        时间序列频率，单位为秒\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        经过时间序列处理后的数据\n",
    "    \"\"\"\n",
    "    # 读取原始数据\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # 时间列处理\n",
    "    if time_col == None:\n",
    "        # 筛选输入频率\n",
    "        re_1 = re.findall('[0-9]', freq)\n",
    "        re_2 = re.findall('[a-z]', freq)\n",
    "        # 识别数字频率\n",
    "        if len(re_1) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_1))\n",
    "        # 识别频率\n",
    "        fr = re_2[0]\n",
    "        # 生成时间间隔\n",
    "        if fr == 's':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 't':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(minutes=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 'h':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(hours=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 'd':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(days=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # 去除时间列\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a92ec68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T08:47:04.318835Z",
     "start_time": "2024-10-29T08:47:04.218860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HUFL</th>\n",
       "      <th>HULL</th>\n",
       "      <th>MUFL</th>\n",
       "      <th>MULL</th>\n",
       "      <th>LUFL</th>\n",
       "      <th>LULL</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01 00:00:00</th>\n",
       "      <td>5.827</td>\n",
       "      <td>2.009</td>\n",
       "      <td>1.599</td>\n",
       "      <td>0.462</td>\n",
       "      <td>4.203</td>\n",
       "      <td>1.340</td>\n",
       "      <td>30.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 01:00:00</th>\n",
       "      <td>5.693</td>\n",
       "      <td>2.076</td>\n",
       "      <td>1.492</td>\n",
       "      <td>0.426</td>\n",
       "      <td>4.142</td>\n",
       "      <td>1.371</td>\n",
       "      <td>27.787001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 02:00:00</th>\n",
       "      <td>5.157</td>\n",
       "      <td>1.741</td>\n",
       "      <td>1.279</td>\n",
       "      <td>0.355</td>\n",
       "      <td>3.777</td>\n",
       "      <td>1.218</td>\n",
       "      <td>27.787001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 03:00:00</th>\n",
       "      <td>5.090</td>\n",
       "      <td>1.942</td>\n",
       "      <td>1.279</td>\n",
       "      <td>0.391</td>\n",
       "      <td>3.807</td>\n",
       "      <td>1.279</td>\n",
       "      <td>25.044001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01 04:00:00</th>\n",
       "      <td>5.358</td>\n",
       "      <td>1.942</td>\n",
       "      <td>1.492</td>\n",
       "      <td>0.462</td>\n",
       "      <td>3.868</td>\n",
       "      <td>1.279</td>\n",
       "      <td>21.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26 15:00:00</th>\n",
       "      <td>-1.674</td>\n",
       "      <td>3.550</td>\n",
       "      <td>-5.615</td>\n",
       "      <td>2.132</td>\n",
       "      <td>3.472</td>\n",
       "      <td>1.523</td>\n",
       "      <td>10.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26 16:00:00</th>\n",
       "      <td>-5.492</td>\n",
       "      <td>4.287</td>\n",
       "      <td>-9.132</td>\n",
       "      <td>2.274</td>\n",
       "      <td>3.533</td>\n",
       "      <td>1.675</td>\n",
       "      <td>11.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26 17:00:00</th>\n",
       "      <td>2.813</td>\n",
       "      <td>3.818</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>2.097</td>\n",
       "      <td>3.716</td>\n",
       "      <td>1.523</td>\n",
       "      <td>10.271000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26 18:00:00</th>\n",
       "      <td>9.243</td>\n",
       "      <td>3.818</td>\n",
       "      <td>5.472</td>\n",
       "      <td>2.097</td>\n",
       "      <td>3.655</td>\n",
       "      <td>1.432</td>\n",
       "      <td>9.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26 19:00:00</th>\n",
       "      <td>10.114</td>\n",
       "      <td>3.550</td>\n",
       "      <td>6.183</td>\n",
       "      <td>1.564</td>\n",
       "      <td>3.716</td>\n",
       "      <td>1.462</td>\n",
       "      <td>9.567000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17420 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
       "2016-07-01 00:00:00   5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
       "2016-07-01 01:00:00   5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
       "2016-07-01 02:00:00   5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
       "2016-07-01 03:00:00   5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
       "2016-07-01 04:00:00   5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n",
       "...                     ...    ...    ...    ...    ...    ...        ...\n",
       "2018-06-26 15:00:00  -1.674  3.550 -5.615  2.132  3.472  1.523  10.904000\n",
       "2018-06-26 16:00:00  -5.492  4.287 -9.132  2.274  3.533  1.675  11.044000\n",
       "2018-06-26 17:00:00   2.813  3.818 -0.817  2.097  3.716  1.523  10.271000\n",
       "2018-06-26 18:00:00   9.243  3.818  5.472  2.097  3.655  1.432   9.778000\n",
       "2018-06-26 19:00:00  10.114  3.550  6.183  1.564  3.716  1.462   9.567000\n",
       "\n",
       "[17420 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/ETTh1.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='date')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c212aabc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T08:47:05.209018Z",
     "start_time": "2024-10-29T08:47:05.204017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecbb4a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T08:47:06.125814Z",
     "start_time": "2024-10-29T08:47:06.112880Z"
    }
   },
   "outputs": [],
   "source": [
    "# 时间格式编码\n",
    "def time_features_from_frequency_str(freq_str: str):\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    class TimeFeature:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "    class SecondOfMinute(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class MinuteOfHour(TimeFeature):\n",
    "        \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "    class HourOfDay(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfWeek(TimeFeature):\n",
    "        \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfMonth(TimeFeature):\n",
    "        \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "    class DayOfYear(TimeFeature):\n",
    "        \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "    class MonthOfYear(TimeFeature):\n",
    "        \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "    class WeekOfYear(TimeFeature):\n",
    "        \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "        def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "            return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "    \n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "    \n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "776e9f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T08:47:07.837429Z",
     "start_time": "2024-10-29T08:47:07.823111Z"
    }
   },
   "outputs": [],
   "source": [
    "# 包含时间维度的数据集划分\n",
    "def divider(df, train_ratio, valid_ratio, x_feature_list, y_feature_list, freq, scaler_path):\n",
    "    \"\"\"\n",
    "    读取数据，并对数据进行划分\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    df : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据\n",
    "    train_ratio : {float}\n",
    "        用于训练的数据集占比:将数据按照一定比例进行切分，取值范围为(0,1)\n",
    "    valid_ratio : {float}\n",
    "        用于验证的数据集占比:将数据按照一定比例进行切分，取值范围为(0,1)\n",
    "    x_feature_list : {list[str]} \n",
    "        训练特征列，不包含时间列\n",
    "    y_feature_list : {list[str]} \n",
    "        目标特征列，不包含时间列\n",
    "    freq : {str}\n",
    "        用来编码时间特征的频率，可选[s:秒,t:分,h:时,d:天,b:工作日,w:周,m:月]，频率越低，模型可能越精确\n",
    "    scaler_path : {str} \n",
    "        数据归一化模型保存地址\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    x_scaler : {sklearn.preprocessing.MinMaxScaler}\n",
    "        训练特征列归一化器\n",
    "    y_scaler : {sklearn.preprocessing.MinMaxScaler}\n",
    "        目标特征列归一化器\n",
    "    train : {list[DataFrame]}\n",
    "        训练特征数据，目标特征数据，时间特征数据\n",
    "    valid : {list[DataFrame]}\n",
    "        验证特征数据，目标特征数据，时间特征数据\n",
    "    test : {list[DataFrame]}\n",
    "        测试特征数据，目标特征数据，时间特征数据\n",
    "    \"\"\"\n",
    "    #归一化\n",
    "    x_scaler = MinMaxScaler() # 保证数据同分布\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # 设置保存归一化参数路径\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # 保存归一化参数\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #测试集\n",
    "    train = df.copy().iloc[:int(df.shape[0]*train_ratio), :][x_feature_list]\n",
    "    train_stamp = time_features(pd.to_datetime(train.index), freq=freq)\n",
    "    train_stamp = train_stamp.transpose(1, 0)\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "    ytr = df.copy().iloc[:int(df.shape[0]*train_ratio), :][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "    train = [xtr, ytr, train_stamp]\n",
    "\n",
    "    #验证集\n",
    "    valid = df.copy().iloc[int(df.shape[0]*train_ratio): int(df.shape[0]*(train_ratio+valid_ratio)), :][x_feature_list]\n",
    "    valid_stamp = time_features(pd.to_datetime(valid.index), freq=freq)\n",
    "    valid_stamp = valid_stamp.transpose(1, 0)\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "    yva = df.copy().iloc[int(df.shape[0]*train_ratio): int(df.shape[0]*(train_ratio+valid_ratio)), :][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "    valid = [xva, yva, valid_stamp]\n",
    "\n",
    "    #测试集\n",
    "    if train_ratio + valid_ratio != 1:\n",
    "        test = df.copy().iloc[int(df.shape[0]*(train_ratio+valid_ratio)):, :][x_feature_list]\n",
    "        test_stamp = time_features(pd.to_datetime(test.index), freq=freq)\n",
    "        test_stamp = test_stamp.transpose(1, 0)\n",
    "        test[x_feature_list] = x_scaler.transform(test)\n",
    "        xte = test.values.astype('float32')\n",
    "        yte = df.copy().iloc[int(df.shape[0]*(train_ratio+valid_ratio)):, :][y_feature_list]\n",
    "        yte[y_feature_list] = y_scaler.transform(yte)\n",
    "        yte = yte.values.astype('float32')\n",
    "        test = [xte, yte, test_stamp]\n",
    "    else:\n",
    "        test = [np.array(0), np.array(0), np.array(0)]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bfa0949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T08:47:30.249001Z",
     "start_time": "2024-10-29T08:47:30.187987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (12194, 7) y_train shape: (12194, 7) stamp_train shape: (12194, 4)\n",
      "x_valid shape: (1741, 7) y_valid shape: (1741, 7) stamp_valid shape: (1741, 4)\n",
      "x_test shape: (3485, 7) y_test shape: (3485, 7) stamp_test shape: (3485, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params1 = {\n",
    "    \"df\": ts_data,\n",
    "    \"train_ratio\": 0.7,\n",
    "    \"valid_ratio\": 0.1,\n",
    "    \"x_feature_list\": ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'],\n",
    "    \"y_feature_list\": ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'],\n",
    "    \"freq\": 'h',\n",
    "    \"scaler_path\": '../outputs/scalers/TimesNet_IN'\n",
    "}\n",
    "\n",
    "#函数传参\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params1)\n",
    "print(\"x_train shape: {0} y_train shape: {1} stamp_train shape: {2}\".format(train_data[0].shape, train_data[1].shape, train_data[2].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1} stamp_valid shape: {2}\".format(valid_data[0].shape, valid_data[1].shape, valid_data[2].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1} stamp_test shape: {2}\".format(test_data[0].shape, test_data[1].shape, test_data[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8747a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:01:00.165281Z",
     "start_time": "2024-10-29T09:01:00.157594Z"
    }
   },
   "outputs": [],
   "source": [
    "# 利用前seq_len个数据，预测下pred_len个数据\n",
    "def generator(data_list, seq_len, pred_len, label_len, batch_size, sample_freq: int = 1):\n",
    "    \"\"\"\n",
    "    读取数据，并对数据进行划分\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data_list : {list[DataFrame]}\n",
    "        输入特征数据，目标特征数据，时间特征数据\n",
    "    seq_len : {int}\n",
    "        输入数据包含过去多少个时间步，正整数\n",
    "    pred_len : {int}\n",
    "        目标应该在未来多少个时间步之后，正整数\n",
    "    label_len : {int} \n",
    "        先验时间步\n",
    "    batch_size : {int} \n",
    "        输入数据的批次大小，正整数\n",
    "    sample_freq : {int} \n",
    "        采样频率，正整数\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    X : {torch.Tensor}\n",
    "        特征数据张量\n",
    "    y : {torch.Tensor}\n",
    "        目标数据张量\n",
    "    X_stamp : {torch.Tensor}\n",
    "        特征时间编码张量\n",
    "    y_stamp : {torch.Tensor}\n",
    "        目标时间编码张量\n",
    "    data_loader : {torch.utils.data.dataloader.DataLoader}\n",
    "        数据加载器，[特征，目标，特征时间编码，目标时间编码]\n",
    "    \"\"\"\n",
    "    # 获取数据\n",
    "    feature = data_list[0] # 特征\n",
    "    target = data_list[1] # 目标\n",
    "    stamp = data_list[2] # 时间戳\n",
    "    \n",
    "    # 循环生成数据\n",
    "    X, y = [], []\n",
    "    X_stamp, y_stamp = [], []\n",
    "    seq_len = seq_len - 1 # 包含当前时间点\n",
    "    for i in range(seq_len, len(feature) - pred_len, sample_freq):\n",
    "        # 数据维度\n",
    "        feat = feature[i - seq_len:i + 1]\n",
    "        tar = target[i + 1:i + 1 + pred_len]\n",
    "        X.append(np.array(feat))\n",
    "        y.append(np.array(tar))\n",
    "        \n",
    "        # 时间维度\n",
    "        xs = stamp[i - seq_len:i + 1]\n",
    "        ys = stamp[i + 1 - label_len:i + 1 + pred_len]\n",
    "        X_stamp.append(np.array(xs))\n",
    "        y_stamp.append(np.array(ys))\n",
    "        \n",
    "    # 转为张量，数据维度\n",
    "    X = torch.as_tensor(X).float()\n",
    "    y = torch.as_tensor(y).float()\n",
    "    \n",
    "    # 转为张量，时间维度\n",
    "    X_stamp = torch.as_tensor(X_stamp).float()\n",
    "    y_stamp = torch.as_tensor(y_stamp).float()\n",
    "    \n",
    "    # 创建dataloader，[特征，目标，特征时间编码，目标时间编码]\n",
    "    data_loader = DataLoader(TensorDataset(X, y, X_stamp, y_stamp), shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return X, y, X_stamp, y_stamp, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "942402cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:01:10.196518Z",
     "start_time": "2024-10-29T09:01:02.450024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_size: torch.Size([12099, 96, 7]),y_size: torch.Size([12099, 0]),loader_len: 379\n",
      "X_size: torch.Size([1646, 96, 7]),y_size: torch.Size([1646, 0]),loader_len: 52\n",
      "X_size: torch.Size([3390, 96, 7]),y_size: torch.Size([3390, 0]),loader_len: 106\n"
     ]
    }
   ],
   "source": [
    "# 构造参数字典\n",
    "params2 = {\n",
    "    \"seq_len\": 96,\n",
    "    \"pred_len\": 0,\n",
    "    \"label_len\": 0,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "X_train, y_train, X_train_stamp, y_train_stamp, train_loader = generator(train_data, **params2)\n",
    "X_valid, y_valid, X_valid_stamp, y_valid_stamp, valid_loader = generator(valid_data, **params2)\n",
    "X_test, y_test, X_test_stamp, y_test_stamp, test_loader = generator(test_data, **params2)\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_train.shape, y_train.shape, len(train_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_valid.shape, y_valid.shape, len(valid_loader)))\n",
    "print(\"X_size: {0},y_size: {1},loader_len: {2}\".format(X_test.shape, y_test.shape, len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34616e01",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5b96db2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:32:00.466293Z",
     "start_time": "2024-10-29T09:32:00.412720Z"
    }
   },
   "outputs": [],
   "source": [
    "# 位置编码，是对于每一条序列位置的编码，和具体的值无关\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        # 注意：d_model需要是偶数\n",
    "        # 0::2：从0开始，以步长为2进行取值，取到的都是偶数位置\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # 1::2：从1开始，以步长为2进行取值，取到的都是奇数位置\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # 作用是该组参数不会更新，但是保存模型时，该组参数又作为模型参数被保存\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "    \n",
    "# 使用conv1d的目的是要对序列中的每一个时间点上的数据（也就是token）来做编码\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "    \n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "# 是对于时间戳的编码（协变量），和序列本身的位置、数值无关\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "        \n",
    "        # freq拆分\n",
    "        number = re.findall('[0-9]', freq)\n",
    "        number = 1 if len(number)==0 else int(''.join(number))\n",
    "        string = re.findall('[a-z]', freq)[0]\n",
    "        if string == 'h':\n",
    "            hour_size = int(24 / number)\n",
    "        elif string == 't':\n",
    "            hour_size = 24\n",
    "            minute_size = int(60 / number)\n",
    "        elif string == 's':\n",
    "            hour_size = 24\n",
    "            minute_size = 60\n",
    "            second_size = int(60 / number)\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        if freq == 's':\n",
    "            self.second_embed = Embed(second_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        second_x = self.second_embed(x[:, :, 5]) if hasattr(\n",
    "            self, 'second_embed') else 0.\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x + second_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "# 将不同的卷积层通过并联的方式结合在一起，经过不同卷积层处理的结果矩阵在深度这个维度拼接起来，形成一个更深的矩阵\n",
    "class Inception_Block_V1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_kernels=6, init_weight=True):\n",
    "        super(Inception_Block_V1, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_kernels = num_kernels # 卷积核尺寸\n",
    "        kernels = []\n",
    "        for i in range(self.num_kernels):\n",
    "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=2 * i + 1, padding=i))\n",
    "        self.kernels = nn.ModuleList(kernels)\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res_list = []\n",
    "        for i in range(self.num_kernels):\n",
    "            res_list.append(self.kernels[i](x))\n",
    "        res = torch.stack(res_list, dim=-1).mean(-1)\n",
    "        return res\n",
    "    \n",
    "# 快速傅里叶变换，返回周期长度和频率\n",
    "def FFT_for_Period(x, k=2):\n",
    "    # [B, T, C]\n",
    "    xf = torch.fft.rfft(x, dim=1)\n",
    "    # find period by amplitudes\n",
    "    frequency_list = abs(xf).mean(0).mean(-1)\n",
    "    frequency_list[0] = 0\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "    period = x.shape[1] // top_list\n",
    "    return period, abs(xf).mean(-1)[:, top_list]\n",
    "\n",
    "\n",
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, top_k, d_model, d_ff, num_kernels):\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.k = top_k # 强度最大的K个频率，不宜过大，容易出现0的情况\n",
    "        # parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(d_model, d_ff, num_kernels=num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(d_ff, d_model, num_kernels=num_kernels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "            # reshape\n",
    "            out = out.reshape(B, length // period, period, C).permute(0, 3, 1, 2).contiguous()\n",
    "            # 2D conv: from 1d Variation to 2d Variation\n",
    "            out = self.conv(out)\n",
    "            # reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, C)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "        res = torch.stack(res, dim=-1)\n",
    "        # 自适应融合\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(1).unsqueeze(1).repeat(1, T, C, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "        # 残差连接\n",
    "        res = res + x\n",
    "        return res\n",
    "    \n",
    "# TimesNet模型\n",
    "class TimesNet(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, label_len, top_k, d_model, d_ff, \n",
    "                 num_kernels, e_layers, enc_in, dropout, c_out, embed, freq):\n",
    "        super(TimesNet, self).__init__()\n",
    "        self.seq_len = seq_len # 输入序列长度\n",
    "        self.pred_len = pred_len # 输出序列长度\n",
    "        self.model = nn.ModuleList([TimesBlock(self.seq_len, self.pred_len, top_k, d_model, d_ff, num_kernels) \n",
    "                                    for _ in range(e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(enc_in, # 编码器维度\n",
    "                                           d_model, # 隐藏层维度\n",
    "                                           embed, # 时间特征编码，[timeF, fixed, learned]\n",
    "                                           freq, # 时间特征编码频率，[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly]\n",
    "                                           dropout)\n",
    "        self.layer = e_layers # TimesBlock层数\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.predict_linear = nn.Linear(self.seq_len, self.pred_len + self.seq_len)\n",
    "        self.projection = nn.Linear(d_model, c_out, bias=True) # 输出序列维度\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask):\n",
    "        # Normalization from Non-stationary Transformer\n",
    "        means = torch.sum(x_enc, dim=1) / torch.sum(mask == 1, dim=1)\n",
    "        means = means.unsqueeze(1).detach()\n",
    "        x_enc = x_enc - means\n",
    "        x_enc = x_enc.masked_fill(mask == 0, 0)\n",
    "        stdev = torch.sqrt(torch.sum(x_enc * x_enc, dim=1) /\n",
    "                           torch.sum(mask == 1, dim=1) + 1e-5)\n",
    "        stdev = stdev.unsqueeze(1).detach()\n",
    "        x_enc /= stdev\n",
    "\n",
    "        # embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "        # TimesNet\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "        # porject back\n",
    "        dec_out = self.projection(enc_out)\n",
    "\n",
    "        # De-Normalization from Non-stationary Transformer\n",
    "        dec_out = dec_out * \\\n",
    "                  (stdev[:, 0, :].unsqueeze(1).repeat(\n",
    "                      1, self.pred_len + self.seq_len, 1))\n",
    "        output = dec_out + \\\n",
    "                  (means[:, 0, :].unsqueeze(1).repeat(\n",
    "                      1, self.pred_len + self.seq_len, 1))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885562e7",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3174c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(task_args, train_args, model_args):\n",
    "    # 参数配置\n",
    "    columns = task_args['columns'] # 模型全部特征\n",
    "    target = task_args['target'] # 模型预测特征\n",
    "    features = task_args['features'] # 模型预测模式\n",
    "    model_name = train_args['model_name'] # 模型名称\n",
    "    train_loader = train_args['train_loader'] # 训练集\n",
    "    valid_loader = train_args['valid_loader'] # 验证集\n",
    "    n_epochs = train_args['n_epochs'] # 训练次数\n",
    "    learning_rate = train_args['learning_rate'] # 学习率\n",
    "    loss = train_args['loss'] # 损失函数\n",
    "    patience = train_args['patience'] # 最大早停次数阈值，超过就会早停\n",
    "    lradj = train_args['lradj'] # 学习率函数\n",
    "    model_path = train_args['model_path'] # 模型保存路径\n",
    "    verbose = train_args['verbose'] # 打印训练过程\n",
    "    plots = train_args['plots'] # 绘制损失图\n",
    "    device = train_args['device'] # 训练设备，可选'cuda'和'cpu'\n",
    "    pred_len = model_args['pred_len'] # 预测长度\n",
    "    label_len = model_args['label_len']\n",
    "    \n",
    "    #检查是否可用GPU\n",
    "    device = torch.device(device)\n",
    "    \n",
    "    # 创建模型和优化器\n",
    "    model = model_name(**model_args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss\n",
    "    \n",
    "    # 调整学习率\n",
    "    def adjust_learning_rate(optimizer, epoch, lradj, learning_rate, train_epochs):\n",
    "        # lr = learning_rate * (0.2 ** (epoch // 2))\n",
    "        if lradj == 'type1':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif lradj == 'type2':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif lradj == \"cosine\":\n",
    "            lr_adjust = {epoch: learning_rate /2 * (1 + math.cos(epoch / train_epochs * math.pi))}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            # 参数组(param_groups)是用来指定不同的参数组以便对它们进行不同的优化设置，比如'lr'\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "    \n",
    "    # 设置早停\n",
    "    class EarlyStopping():\n",
    "        def __init__(self, patience=7, verbose=False, delta=0):\n",
    "            self.patience = patience # 连续超限次数，如果满足条件，则早停\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_score = None\n",
    "            self.early_stop = False\n",
    "            self.val_loss_min = np.Inf\n",
    "            self.delta = delta\n",
    "\n",
    "        def __call__(self, val_loss, model, path):\n",
    "            score = -val_loss\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model, path)\n",
    "                self.counter = 0\n",
    "\n",
    "        def save_checkpoint(self, val_loss, model, path):\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "            self.val_loss_min = val_loss\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
    "    \n",
    "    # 训练任务\n",
    "    def forecasting_task(columns, target, features):\n",
    "        \"\"\"\n",
    "        features: [M, S, MS]; \n",
    "            M:multivariate predict multivariate, \n",
    "            S:univariate predict univariate, \n",
    "            MS:multivariate predict univariate'\n",
    "        \"\"\"\n",
    "        # 字典索引生成\n",
    "        col_dict = {}\n",
    "        for i,j in enumerate(columns):\n",
    "            col_dict[j] = i\n",
    "\n",
    "        if features == 'MS':\n",
    "            target = target[0]\n",
    "            if target in columns:\n",
    "                f_dim = col_dict[target]\n",
    "            else:\n",
    "                f_dim = 0\n",
    "        elif features == 'S':\n",
    "            f_dim = 0\n",
    "        else:\n",
    "            f_dim = 0\n",
    "        return f_dim\n",
    "    f_dim = forecasting_task(columns, target, features)\n",
    "    \n",
    "    # 设置保存模型路径\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # 模型训练和验证\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "            #将数据移至 GPU\n",
    "            batch_x = batch_x.to(device) # 会用到实际数据\n",
    "            batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # decoder输入 \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            if features == 'MS':\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                if outputs.shape[-1] == 1:\n",
    "                    f_dim = 0\n",
    "                outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "            else:\n",
    "                dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs[:, :, f_dim:]\n",
    "            train_loss = criterion(outputs, batch_y)\n",
    "            # 反向传播计算得到每个参数的梯度值\n",
    "            train_loss.backward()\n",
    "            # 通过梯度下降执行一步参数更新\n",
    "            optimizer.step()\n",
    "            #每个batch的loss和\n",
    "            total_train_loss += train_loss.item() # .item()表示只包含一个元素的tensor中提取值\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        #评估模型\n",
    "        model.eval()\n",
    "        #关闭自动求导功能，只使用训练好的模型进行预测或评估，不需要进行梯度计算和参数更新\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for batch_x, batch_y, batch_x_mark, batch_y_mark in valid_loader:\n",
    "                #将数据移至 GPU\n",
    "                batch_x = batch_x.to(device) # 会用到实际数据\n",
    "                batch_y = batch_y.to(device) # 只用来获取维度，不会用到实际数据，防止泄露信息\n",
    "                batch_x_mark = batch_x_mark.to(device)\n",
    "                batch_y_mark = batch_y_mark.to(device)\n",
    "                # decoder输入\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                if features == 'MS':\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim: f_dim+1], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    if outputs.shape[-1] == 1:\n",
    "                        f_dim = 0\n",
    "                    outputs = outputs[:, :, f_dim: f_dim+1] \n",
    "                else:\n",
    "                    dec_inp = torch.cat([batch_x[:, -label_len:, f_dim:], dec_inp], dim=1).float().to(device)\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, :, f_dim:]\n",
    "                val_loss = criterion(outputs, batch_y)\n",
    "                #每个batch的loss和\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        #每个epoch的损失平均\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        \n",
    "        #所有epoch的loss\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        #打印训练过程\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            \n",
    "        # 设置早停\n",
    "        early_stopping(avg_val_loss, model, model_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "            \n",
    "        # 调整学习率\n",
    "        adjust_learning_rate(optimizer, epoch+1, lradj, learning_rate, n_epochs)\n",
    "\n",
    "    #绘制损失函数图\n",
    "    def plot_loss(train_losses, val_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.style.use('seaborn-v0_8-paper') #绘制背景色\n",
    "        plt.grid(axis = 'y',linewidth=0.35) #绘制网格\n",
    "        plt.plot(val_losses, linestyle='-',color = '#11b3b6')\n",
    "        plt.plot(train_losses, linestyle='-',color = '#f14643')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Progress\")\n",
    "        plt.legend([\"Validation\", \"Training\"])\n",
    "        plt.show()\n",
    "    if plots:\n",
    "        plot_loss(train_losses, val_losses)\n",
    "            \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
