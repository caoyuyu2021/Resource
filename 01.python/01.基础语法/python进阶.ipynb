{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d14c58d",
   "metadata": {},
   "source": [
    "# 文件操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ddf2ef",
   "metadata": {},
   "source": [
    "## 实时向csv文件写入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb6755",
   "metadata": {},
   "source": [
    "- 最常用的一种方法，利用pandas包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6ad5acd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:50:01.933418Z",
     "start_time": "2022-11-09T09:50:01.908098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a_name  b_name\n",
      "0       1       4\n",
      "1       2       5\n",
      "2       3       6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#任意的多组列表\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]    \n",
    "\n",
    "#字典中的key值即为csv中列名\n",
    "dataframe = pd.DataFrame({'a_name':a,'b_name':b})\n",
    "\n",
    "#将DataFrame存储为csv,index表示是否显示行名，default=True，\"a\"表示导入的数据不会将test3.csv文件中的原始数据覆盖\n",
    "dataframe.to_csv(\"test.csv\", mode='a', index=False,sep=',')\n",
    "\n",
    "#同样pandas也提供简单的读csv方法，会得到一个DataFrame类型的data\n",
    "data = pd.read_csv('test.csv')\n",
    "print(data)\n",
    "\n",
    "os.remove(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df4f46",
   "metadata": {},
   "source": [
    "- 另一种方法用csv包，一行一行写入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c4287bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:50:07.162881Z",
     "start_time": "2022-11-09T09:50:07.155905Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"test3.csv\",\"a\",newline='') as csvfile: \n",
    "    writer = csv.writer(csvfile, delimiter=' ')\n",
    "    writer.writerow([\"index\",\"a_name\",\"b_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bec01c",
   "metadata": {},
   "source": [
    "上述代码参数解释：\n",
    "\n",
    "​ test3.csv表示要创建一个test3.csv的文件，注意:如果当前目录下没有这个文件，则会自动生成test3.csv文件，如果当前目录下已经有了test3.csv的文件，那么在新建结束后，会将原始的test3.csv文件覆盖。\n",
    "\n",
    "​ \"a\"表示导入的数据不会将test3.csv文件中的原始数据覆盖，即：在后面继续添加，如果需要覆盖，则将\"a\"改成\"w\"即可。\n",
    "\n",
    "​ newline=’ ’ 表示不会以空行作为每一行的分割线，注意:这一行代码必须添加上，否则csv文件中的每一行数据的前面会出现空行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "392466ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:50:12.072975Z",
     "start_time": "2022-11-09T09:50:12.060019Z"
    }
   },
   "outputs": [],
   "source": [
    "list1=[0,0,0]\n",
    "list2=[1,1,1]\n",
    "\n",
    "data_array=[[5,5,5],[1,2,3]]\n",
    "with open(\"test3.csv\",\"a\",newline='') as csvfile: \n",
    "    writer = csv.writer(csvfile)\n",
    "    # 多行写入用writerows\n",
    "    writer.writerows(data_array)\n",
    "\n",
    "    # 单行逐个写入用 writerow\n",
    "#     writer.writerow(list1)\n",
    "#     writer.writerow(list2)\n",
    "    \n",
    "    # 执行添加数据操作之后，要写close关闭，否则下次无法再次插入新的数据\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ed94f",
   "metadata": {},
   "source": [
    "​ 实时写入数据时，有可能是逐个写入，也可能是一次性写入多个数据。多行写入用writerows，\n",
    "\n",
    "单行逐个写入用 writerow，根据需求调整。close()这行代码一定要加上，否则下次无法再次插入新的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18ffdff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:50:13.705495Z",
     "start_time": "2022-11-09T09:50:13.691583Z"
    }
   },
   "outputs": [],
   "source": [
    "list1=[0,0,0]\n",
    "list2=[1,1,1]\n",
    "\n",
    "data_array=[[5,5,5],[1,2,3]]\n",
    "with open(\"test3.csv\",\"a\",newline='') as csvfile: \n",
    "    writer = csv.writer(csvfile)\n",
    "    # 写入多行用writerows\n",
    "#     writer.writerows(data_array)\n",
    "\n",
    "#     写入单行用 writerow\n",
    "    writer.writerow(list1)\n",
    "    writer.writerow(list2)\n",
    "    \n",
    "    # 执行添加数据操作之后，要写close关闭，否则下次无法再次插入新的数据\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3be145aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:50:14.966967Z",
     "start_time": "2022-11-09T09:50:14.946940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index a_name b_name']\n",
      "['5', '5', '5']\n",
      "['1', '2', '3']\n",
      "['0', '0', '0']\n",
      "['1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"test3.csv\",\"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    #这里不需要readlines\n",
    "    for line in reader:\n",
    "        print(line)\n",
    "        \n",
    "os.remove(\"test3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e091bc6",
   "metadata": {},
   "source": [
    "## 实时向txt文件写入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cde4cf",
   "metadata": {},
   "source": [
    "实时向txt文件写入内容的过程，与创建csv文件，实时向文件写入内容大致相同，只需要添加一个换行符就行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3afcdf38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:50:17.845896Z",
     "start_time": "2022-11-09T09:50:17.827912Z"
    }
   },
   "outputs": [],
   "source": [
    "with open ('testing.txt','a') as f:\n",
    "    f.write('%s       %s      %s'%('姓名','国籍','金额'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cac5853",
   "metadata": {},
   "source": [
    "再次向txt文件中写入数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9ef5cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:50:18.880756Z",
     "start_time": "2022-11-09T09:50:18.866786Z"
    }
   },
   "outputs": [],
   "source": [
    "with open ('testing.txt','a') as f:   \n",
    "    f.write('\\n')     #换行\n",
    "    f.write('%s       %s      %d' %('张三','中国',2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13f78997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T09:50:19.461754Z",
     "start_time": "2022-11-09T09:50:19.451784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['姓名       国籍      金额']\n",
      "['张三       中国      2000']\n"
     ]
    }
   ],
   "source": [
    "with open(\"testing.txt\",\"r\") as testfile:\n",
    "    reader = csv.reader(testfile)\n",
    "    #这里不需要readlines\n",
    "    for line in reader:\n",
    "        print(line)\n",
    "        \n",
    "os.remove(\"testing.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655aaaa0",
   "metadata": {},
   "source": [
    "## 使用pickle读写数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c75c313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T06:54:50.715670Z",
     "start_time": "2023-07-06T06:54:50.396369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4\n",
       "0   0   1   2   3   4\n",
       "1   5   6   7   8   9\n",
       "2  10  11  12  13  14\n",
       "3  15  16  17  18  19"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.arange(20).reshape(4,5))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead4fdab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T06:56:10.452049Z",
     "start_time": "2023-07-06T06:56:10.439092Z"
    }
   },
   "outputs": [],
   "source": [
    "#使用DataFrame的to_pickle属性就可以生成pickle文件对数据进行永久储存\n",
    "df.to_pickle('D:\\\\Jupyter notebook\\\\data\\\\python\\\\foo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485253c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T06:57:38.115885Z",
     "start_time": "2023-07-06T06:57:38.101932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4\n",
       "0   0   1   2   3   4\n",
       "1   5   6   7   8   9\n",
       "2  10  11  12  13  14\n",
       "3  15  16  17  18  19"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('D:\\\\Jupyter notebook\\\\data\\\\python\\\\foo.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe862895",
   "metadata": {},
   "source": [
    "# 类型提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d98ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc737e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944a2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b6321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763a46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6061f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c8071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb526a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68feaa47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2fba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460fdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9be5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aeef94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08772f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142a771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0704a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b76ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7569e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538272d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bda4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6d14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0b33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b35fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10bb14c4",
   "metadata": {},
   "source": [
    "# 标准代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce192975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:50:36.144364Z",
     "start_time": "2024-03-26T09:50:33.414230Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from numpy import ndarray\n",
    "from typing import Union, List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# 归一化和反归一化函数\n",
    "def __minmax(data: DataFrame,\n",
    "             feature_max: Series,\n",
    "             feature_min: Series,\n",
    "             inverse: bool = False) -> DataFrame:\n",
    "    \"\"\"\n",
    "    对输入数据进行归一化或反归一化\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，可以是历史数据，实时数据或者状态矩阵等\n",
    "    feature_max : {Series} of shape (n_features, )\n",
    "        输入数据每个特征的最大值\n",
    "    feature_min : {Series} of shape (n_features, )\n",
    "        输入数据每个特征的最小值\n",
    "    inverse : {bool}\n",
    "        是否反归一化，如果为True，则为反归一化；反之为归一化\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输出归一化或反归一化后的数据\n",
    "    \"\"\"\n",
    "    if inverse:\n",
    "        # 反归一化\n",
    "        max_min_diff = feature_max - feature_min\n",
    "        data_min_diff = data * max_min_diff\n",
    "        data = data_min_diff + feature_min\n",
    "    else:\n",
    "        # 正归一化\n",
    "        max_min_diff = feature_max - feature_min\n",
    "        data_min_diff = data - feature_min\n",
    "        data = data_min_diff / max_min_diff\n",
    "    return data\n",
    "\n",
    "\n",
    "# 初始化状态矩阵\n",
    "def __init_state_matrix(data: DataFrame, n_columns: Union[int, None],\n",
    "                        time_tag: Union[str, None]) -> DataFrame:\n",
    "    \"\"\"\n",
    "    初始化状态矩阵参数并生成状态矩阵\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，可以是历史数据\n",
    "    time_tag : {str}\n",
    "        时间标签，如果为None，默认数据中不含时间特征\n",
    "    n_columns : {int}\n",
    "        状态矩阵数据样本数\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    D : {DataFrame} of shape (n_samples, n_features)\n",
    "        输出数据，状态矩阵\n",
    "    \"\"\"\n",
    "    # 规范化数据\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # 选取时间列\n",
    "    if time_tag != None:\n",
    "        no_time_tags = [i for i in data.columns if i != time_tag]\n",
    "        data[time_tag] = pd.to_datetime(data[time_tag])\n",
    "        data_no_time = data.loc[:, no_time_tags].astype('float32')\n",
    "    else:\n",
    "        data_no_time = data.astype('float32')\n",
    "\n",
    "    # 求最大最小值\n",
    "    feature_max = data_no_time.max()\n",
    "    feature_min = data_no_time.min()\n",
    "\n",
    "    # 数据归一化\n",
    "    filter_data = __minmax(data_no_time, feature_max, feature_min)\n",
    "\n",
    "    # 把每个测点的最大最小值中位数所在状态的数据均选入状态矩阵\n",
    "    m = filter_data.shape[1]  # 数据列数\n",
    "    index_list = []\n",
    "    for i in range(m):\n",
    "        index_max = filter_data.iloc[:, i].argmax()\n",
    "        index_list.append(index_max)\n",
    "        index_min = filter_data.iloc[:, i].argmin()\n",
    "        index_list.append(index_min)\n",
    "        index_median = np.argsort(\n",
    "            filter_data.iloc[:,\n",
    "                             i].values)[len(filter_data.iloc[:, i].values) //\n",
    "                                        2]\n",
    "        index_list.append(index_median)\n",
    "\n",
    "    D1 = set(index_list)\n",
    "    n = filter_data.shape[0]  # 数据行数\n",
    "    D_full = set(range(n))\n",
    "    D_comp = D_full - D1  # 补集\n",
    "\n",
    "    # 剩余按照L2范数大小递减\n",
    "    row_key = list(D_comp)\n",
    "    row_value = []\n",
    "    filter_data_comp = filter_data.iloc[row_key, :]\n",
    "    for j in row_key:\n",
    "        norm = np.linalg.norm(filter_data_comp.loc[j, :])\n",
    "        row_value.append(norm)\n",
    "    row = pd.DataFrame(zip(row_key, row_value)).sort_values(\n",
    "        by=1, ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # 以t为因子进行抽取\n",
    "    n_columns = n_columns\n",
    "    k = (n_columns - len(D1))\n",
    "    t = np.floor(len(D_comp) / (n_columns - len(D1)))  # 每t个抽取一次\n",
    "    D2 = []\n",
    "    i = 1\n",
    "    for j in row.index:\n",
    "        if j % t == 0 and i <= k:\n",
    "            D2.append(int(row.loc[j, :][0]))\n",
    "            i += 1\n",
    "    D2 = set(D2)\n",
    "\n",
    "    # 状态矩阵的行为特征数，列为样本数\n",
    "    D_no_time = filter_data.iloc[list(D1\n",
    "                                      | D2), :].reset_index(drop=True).values\n",
    "    D_no_time = pd.DataFrame(D_no_time, columns=data_no_time.columns)\n",
    "\n",
    "    # 反归一化\n",
    "    D_no_time = __minmax(D_no_time, feature_max, feature_min, inverse=True)\n",
    "\n",
    "    # 拼接时间列\n",
    "    if time_tag != None:\n",
    "        data_time = data.iloc[list(D1 | D2), :].loc[:, time_tag].reset_index(\n",
    "            drop=True)\n",
    "        D = pd.concat([data_time, D_no_time], axis=1)\n",
    "    else:\n",
    "        data_no_time = data\n",
    "        D = D_no_time\n",
    "    return D\n",
    "\n",
    "\n",
    "def __distance(x1: ndarray, x2: ndarray, dist_metric: str) -> ndarray:\n",
    "    \"\"\"\n",
    "    计算数据间的“距离”\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    x1 : {array-like}\n",
    "        输入数据，矩阵或向量\n",
    "    x2 : {array-like}\n",
    "        输入数据，矩阵或向量\n",
    "    dist_metric : {str}\n",
    "        距离类型，默认为'union'，可选'gaussian','euclidean','union'\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    dist_mat : {array-like}\n",
    "        输出数据，距离矩阵或向量\n",
    "    \"\"\"\n",
    "    # 选择距离度量方式\n",
    "    if dist_metric == 'gaussian':\n",
    "        m, n = x1.shape[0], x2.shape[0]  #获取行数\n",
    "        dist_matrix = np.zeros((m, n), dtype=float)  #全零矩阵\n",
    "        # 数据间的距离\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                dist_matrix[i][j] = np.sum((x1[i] - x2[j])**2)  #向量差的平方和\n",
    "        # 参数初始化，表示数据的紧密程度\n",
    "        gamma = 0.5\n",
    "        dist_mat = np.exp(-gamma * dist_matrix)  #计算结果矩阵\n",
    "\n",
    "    elif dist_metric == 'union':\n",
    "        m, n = x1.shape[0], x2.shape[0]  #获取行数\n",
    "        dist_matrix = np.zeros((m, n), dtype=float)  #全零矩阵\n",
    "        # 数据间的距离\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                dist_matrix[i][j] = np.sum((x1[i] - x2[j])**2)  #向量差的平方和\n",
    "        # 参数初始化，表示数据的紧密程度\n",
    "        gamma1 = 0.5\n",
    "        # 高斯核\n",
    "        dist_matrix1 = np.exp(-gamma1 * dist_matrix)\n",
    "        # 欧氏距离\n",
    "        dist_matrix2 = cdist(x1, x2, 'euclidean')\n",
    "        # 联合“距离”\n",
    "        dist_matrix3 = dist_matrix1 - dist_matrix2\n",
    "        gamma2 = 0.5\n",
    "        # 高斯核\n",
    "        dist_mat = np.exp(-gamma2 * dist_matrix3)\n",
    "\n",
    "    elif dist_metric == 'euclidean':\n",
    "        dist_mat = cdist(x1, x2, dist_metric)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Please enter the correct parameters!')\n",
    "    return dist_mat\n",
    "\n",
    "\n",
    "# 权重向量\n",
    "def __weight(D: ndarray, x_in: ndarray, dist_metric: str) -> ndarray:\n",
    "    \"\"\"\n",
    "    计算数据间的权重向量\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    D : {array-like} of shape (n_features, n_samples)\n",
    "        输入数据，可以是状态矩阵\n",
    "    x_in : {array-like} of shape (n_features, n_samples)\n",
    "        输入数据，待预测数据\n",
    "    dist_metric : {str}\n",
    "        距离类型，默认为'union'，可选'gaussian','euclidean','union'\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    w : {array-like}\n",
    "        输出数据，权重向量\n",
    "    \"\"\"\n",
    "    # 计算距离\n",
    "    G = __distance(D.T, D.T, dist_metric)\n",
    "    G_inv = np.linalg.inv(G)\n",
    "\n",
    "    # 相似性度量\n",
    "    a = __distance(D.T, x_in, dist_metric)\n",
    "\n",
    "    # 计算权重向量\n",
    "    w0 = np.dot(G_inv, a)\n",
    "    w = w0 / np.sum(w0, axis=0)\n",
    "    return w\n",
    "\n",
    "\n",
    "# VSG函数\n",
    "def __vsg(D: ndarray, x_in: ndarray, ms: Union[int, None],\n",
    "          dist_metric: str) -> ndarray:\n",
    "    \"\"\"\n",
    "    返回不含缺失值的特征列索引\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    D : {array-like} of shape (n_features, n_samples)\n",
    "        输入数据，可以是状态矩阵\n",
    "    x_in : {array-like} of shape (n_features, n_samples)\n",
    "        输入数据，矩阵或向量\n",
    "    ms : {int}\n",
    "        权重前ms个\n",
    "    dist_metric : {str}\n",
    "        距离类型，默认为'union'，可选'gaussian','euclidean','union'\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    x_index : {array-like}\n",
    "        不包含缺失值的特征列索引\n",
    "    \"\"\"\n",
    "    x_out = []\n",
    "    for j in range(x_in.shape[0]):\n",
    "        # 判断缺失值\n",
    "        x_nan_len = np.isnan(x_in[j]).sum()\n",
    "        if x_nan_len / len(x_in[j]) <= 0.2:\n",
    "            # 判断异常值\n",
    "            x_in_out = [i if i <= 1 and i >= 0 else np.nan for i in x_in[j]]\n",
    "            x__in = np.array(x_in_out).reshape((1, -1))\n",
    "\n",
    "            # 预测值中包含缺失值的索引\n",
    "            nan_index = np.where(np.isnan(x__in[0]))[0]\n",
    "            not_nan_index = list(set(range(x__in.shape[1])) - set(nan_index))\n",
    "\n",
    "            # 去除缺失值\n",
    "            x__in_ = x__in[:, not_nan_index]\n",
    "            D_ = D[not_nan_index, :]\n",
    "\n",
    "            # 计算权重向量\n",
    "            w = __weight(D_, x__in_, dist_metric)\n",
    "\n",
    "            # VBM算法：选择权重最大的ms个索引\n",
    "            if ms != None:\n",
    "                w_index = np.argsort(-w.T)[0][:ms]\n",
    "                # 动态状态矩阵\n",
    "                D__ = D_[:, w_index]\n",
    "                # 计算权重向量\n",
    "                w_ms = __weight(D__, x__in_, dist_metric)\n",
    "                # 计算输出向量\n",
    "                D_ms = D[:, w_index]\n",
    "                x_out_ = np.dot(D_ms, w_ms).T\n",
    "            else:\n",
    "                # 计算输出向量\n",
    "                x_out_ = np.dot(D, w).T\n",
    "            x_out_ = x_out_.reshape((-1, ))\n",
    "            x_out.append(x_out_)\n",
    "        else:\n",
    "            x_out.append(x_in[j])\n",
    "\n",
    "    x_out = np.array(x_out)\n",
    "    return x_out\n",
    "\n",
    "\n",
    "# 填补状态矩阵中与缺失值相似的值\n",
    "def __fillna(D: ndarray, x_in: ndarray, ms: Union[int, None],\n",
    "             dist_metric: str) -> ndarray:\n",
    "    \"\"\"\n",
    "    缺失值填充\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    D : {array-like} of shape (n_features, n_samples)\n",
    "        输入数据，可以是状态矩阵\n",
    "    x_in : {array-like} of shape (n_features, n_samples)\n",
    "        输入数据，待预测数据\n",
    "    ms : {int}\n",
    "        权重前ms个\n",
    "    dist_metric : {str}\n",
    "        距离类型，默认为'union'，可选'gaussian','euclidean','union'\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    full_x : {array-like}\n",
    "        输出数据，填充后的待预测数据\n",
    "    \"\"\"\n",
    "    full_x = []\n",
    "    # 异常的点置空并填充\n",
    "    for j in range(x_in.shape[0]):\n",
    "        x_in_out = [i if i <= 1 and i >= 0 else np.nan for i in x_in[j]]\n",
    "        x__in = np.array(x_in_out).reshape((1, -1))\n",
    "\n",
    "        # 预测值中包含缺失值的索引\n",
    "        nan_index = np.where(np.isnan(x__in[0]))[0]\n",
    "        not_nan_index = list(set(range(x__in.shape[1])) - set(nan_index))\n",
    "\n",
    "        # 去除缺失值\n",
    "        x__in_ = x__in[:, not_nan_index]\n",
    "        D_ = D[not_nan_index, :].T\n",
    "\n",
    "        # 与状态矩阵差值最小的索引，也就是最相似的数据\n",
    "        diff_index = np.argmin(np.sum(np.abs(x__in_ - D_), axis=1))\n",
    "\n",
    "        # 填补缺失值\n",
    "        fillna = D.T[diff_index, :][nan_index]\n",
    "        x__in[0][nan_index] = fillna\n",
    "        x__in = x__in.reshape((-1, ))\n",
    "\n",
    "        # 输出整个数组\n",
    "        full_x.append(x__in)\n",
    "    full_x = np.array(full_x)\n",
    "\n",
    "    # 计算权重向量\n",
    "    w = __weight(D, full_x, dist_metric)\n",
    "\n",
    "    # VBM算法：选择权重最大的ms个索引\n",
    "    if ms != None:\n",
    "        w_index = np.argsort(-w.T)[0][:ms]\n",
    "        # 动态状态矩阵\n",
    "        D_ms = D[:, w_index]\n",
    "        # 计算权重向量\n",
    "        w_ms = __weight(D_ms, full_x, dist_metric)\n",
    "        # 计算输出向量\n",
    "        x_out_ = np.dot(D_ms, w_ms).T\n",
    "    else:\n",
    "        # 计算输出向量\n",
    "        x_out_ = np.dot(D, w).T\n",
    "    return x_out_\n",
    "\n",
    "\n",
    "# 自学习\n",
    "def state_matrix(data: DataFrame,\n",
    "                 time_tag: Union[str, None] = None,\n",
    "                 n_columns: Union[int, None] = None,\n",
    "                 k: Union[int, None] = None,\n",
    "                 n_trials: Union[int, None] = None,\n",
    "                 bayes_opt: bool = False) -> DataFrame:\n",
    "    \"\"\"\n",
    "    利用贝叶斯模型生成最佳状态矩阵\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，训练数据\n",
    "    time_tag : {str}\n",
    "        时间标签，如果为None，默认数据中不含时间特征\n",
    "    n_columns : {int}\n",
    "        状态矩阵样本数，在不使用贝叶斯优化的情况下可自行设置，默认为400\n",
    "    k : {int}\n",
    "        K折交叉验证，在使用贝叶斯优化时填写，默认为5\n",
    "    n_trials : {int}\n",
    "        迭代次数，在使用贝叶斯优化时填写，默认为50\n",
    "    bayes_opt : {bool}\n",
    "        是否采用贝叶斯优化生成状态矩阵，如果为True，使用贝叶斯；反之，不使用\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    D : {DataFrame} of shape (n_samples, n_features)\n",
    "        输出数据，最终状态矩阵\n",
    "    ms : {int}\n",
    "        权重最大的ms个索引\n",
    "    \"\"\"\n",
    "    # 输入数据判断类型\n",
    "    if not isinstance(data, DataFrame):\n",
    "        raise TypeError('data should be of DataFrame type!')\n",
    "    if time_tag != None:\n",
    "        if not isinstance(time_tag, str):\n",
    "            raise TypeError('time_tag should be of str type!')\n",
    "    if n_columns != None:\n",
    "        if not isinstance(n_columns, int):\n",
    "            raise TypeError('n_columns should be of int type!')\n",
    "    if k != None:\n",
    "        if not isinstance(k, int):\n",
    "            raise TypeError('k should be of int type!')\n",
    "    if n_trials != None:\n",
    "        if not isinstance(n_trials, int):\n",
    "            raise TypeError('n_trials should be of int type!')\n",
    "    if not isinstance(bayes_opt, bool):\n",
    "        raise TypeError('bayes_opt should be of bool type!')\n",
    "\n",
    "    # 规范化数据\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # 缺失值处理，如果历史数据存在缺失值，直接结束，不生成状态矩阵\n",
    "    if data.isna().values.sum() > 0:\n",
    "        raise ValueError('The data should not contain missing values!')\n",
    "\n",
    "    # 贝叶斯优化\n",
    "    if bayes_opt:\n",
    "        # 划分训练集和验证集\n",
    "        samples = data.shape[0]\n",
    "        features = data.shape[1]\n",
    "\n",
    "        # K折交叉验证\n",
    "        if k == None:\n",
    "            k = 5\n",
    "        best_values = []\n",
    "        best_n_columns = []\n",
    "        best_mss = []\n",
    "        for i in range(k):\n",
    "            start = np.random.randint(0, int(samples * 0.875))\n",
    "            end = start + int(samples * 0.125)\n",
    "            train, valid = pd.concat(\n",
    "                [data.iloc[:start, :], data.iloc[end:, :]],\n",
    "                axis=0).reset_index(drop=True), data.iloc[start:end, :]\n",
    "\n",
    "            # optuna优化\n",
    "            def optuna_objective(trial):\n",
    "                # 定义参数空间\n",
    "                n_columns = trial.suggest_int(\"n_columns_params\",\n",
    "                                              features * 3 * 2,\n",
    "                                              features * 3 * 10,\n",
    "                                              1)  # 整数型，(参数名称，下界，上界，步长)\n",
    "                ms = trial.suggest_int(\"ms_params\", features * 3 * 2,\n",
    "                                       n_columns, 1)\n",
    "                D = __init_state_matrix(train, n_columns, time_tag=time_tag)\n",
    "                X_out = estimate(D, valid, time_tag=time_tag, ms=ms)\n",
    "                ivbm_eva = eval(valid, X_out, time_tag=time_tag)\n",
    "                return ivbm_eva\n",
    "\n",
    "            algo = optuna.samplers.TPESampler(n_startup_trials=10,\n",
    "                                              n_ei_candidates=24)\n",
    "            # 实例化优化器\n",
    "            study = optuna.create_study(sampler=algo, direction=\"minimize\")\n",
    "            # 开始优化，n_trials为允许的最大迭代次数\n",
    "            if n_trials == None:\n",
    "                n_trials = 50\n",
    "            study.optimize(optuna_objective,\n",
    "                           n_trials=n_trials,\n",
    "                           show_progress_bar=True)\n",
    "\n",
    "            # 是否选择参数优化\n",
    "            best_value = study.best_trial.value  # 获取最优值\n",
    "            best_param = study.best_trial.params  # 获取最优值对应的参数列表\n",
    "            best_n_column = best_param['n_columns_params']\n",
    "            best_ms = best_param['ms_params']\n",
    "\n",
    "            # 结果拼接\n",
    "            best_values.append(best_value)\n",
    "            best_n_columns.append(best_n_column)\n",
    "            best_mss.append(best_ms)\n",
    "        # 选择RMSE最小的值对应的样本数\n",
    "        best_index = np.where(\n",
    "            np.array(best_values) == np.array(best_values).min())[0][0]\n",
    "        best_n_column = best_n_columns[best_index]\n",
    "        best_ms = best_mss[best_index]\n",
    "    else:\n",
    "        if n_columns == None:\n",
    "            n_columns = 400\n",
    "        best_n_column = n_columns\n",
    "        best_ms = None\n",
    "\n",
    "    best_D = __init_state_matrix(data, best_n_column, time_tag=time_tag)\n",
    "\n",
    "    return best_D, best_ms\n",
    "\n",
    "\n",
    "# 估计\n",
    "def estimate(D: DataFrame,\n",
    "             x_in: DataFrame,\n",
    "             time_tag: Union[str, None] = None,\n",
    "             in_tags: Union[List[str], None] = None,\n",
    "             ms: Union[int, None] = None,\n",
    "             vsg: bool = False,\n",
    "             dist_metric: str = 'union') -> DataFrame:\n",
    "    \"\"\"\n",
    "    待预测数据进行预测\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    D : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，状态矩阵\n",
    "    x_in : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据，测试数据\n",
    "    time_tag : {str}\n",
    "        时间标签，如果为None，默认数据中不含时间特征\n",
    "    in_tags : {list}\n",
    "        独立标签索引，如果为None，默认选择全部特征\n",
    "    ms : {int}\n",
    "        权重最大的ms个索引，如果为None，默认使用全部权重向量，权重越大，拟合效果越好，容易过拟合\n",
    "    vsg : {bool}\n",
    "        是否使用VSG方法处理缺失值，默认不使用，使用空值填充，vsg精度稍高但运行时间长\n",
    "    dist_metric : {str}\n",
    "        距离类型，默认为'union'，可选'gaussian','euclidean','union'\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    x_out : {DataFrame} of shape (n_samples, n_features)\n",
    "        输出向量\n",
    "    \"\"\"\n",
    "    # 输入数据判断类型\n",
    "    if not isinstance(D, DataFrame):\n",
    "        raise TypeError('D should be of DataFrame type!')\n",
    "    if not isinstance(x_in, DataFrame):\n",
    "        raise TypeError('x_in should be of DataFrame type!')\n",
    "    if time_tag != None:\n",
    "        if not isinstance(time_tag, str):\n",
    "            raise TypeError('time_tag should be of str type!')\n",
    "    if in_tags != None:\n",
    "        if not isinstance(in_tags, list):\n",
    "            raise TypeError('in_tags should be of list type!')\n",
    "    if ms != None:\n",
    "        if not isinstance(ms, int):\n",
    "            raise TypeError('ms should be of int type!')\n",
    "    if not isinstance(vsg, bool):\n",
    "        raise TypeError('vsg should be of bool type!')\n",
    "\n",
    "    # 规范化数据\n",
    "    D = D.reset_index(drop=True)\n",
    "    x_in = x_in.reset_index(drop=True)\n",
    "\n",
    "    # 选取时间列\n",
    "    if time_tag != None:\n",
    "        no_time_tags = [i for i in D.columns if i != time_tag]\n",
    "        D[time_tag] = pd.to_datetime(D[time_tag])\n",
    "        D_no_time = D.loc[:, no_time_tags].astype('float32')\n",
    "        x_in[time_tag] = pd.to_datetime(x_in[time_tag])\n",
    "        x_in_no_time = x_in.loc[:, no_time_tags].astype('float32')\n",
    "    else:\n",
    "        D_no_time = D.astype('float32')\n",
    "        x_in_no_time = x_in.astype('float32')\n",
    "\n",
    "    # 自关联模型，选择独立标签\n",
    "    if in_tags != None:\n",
    "        x_independent = x_in_no_time.loc[:, in_tags]\n",
    "        D_independent = D_no_time.loc[:, in_tags]\n",
    "        columns = in_tags\n",
    "    else:\n",
    "        x_independent = x_in_no_time\n",
    "        D_independent = D_no_time\n",
    "        columns = D_no_time.columns\n",
    "\n",
    "    # 缺失值处理，缺失值大于20%的，将原输入作为输出\n",
    "    if vsg == False:\n",
    "        for i in range(x_independent.shape[0]):\n",
    "            ratio = x_independent.iloc[\n",
    "                i, :].isna().sum() / x_independent.shape[1]\n",
    "            if ratio >= 0.2 or vsg == True:\n",
    "                vsg = True\n",
    "            else:\n",
    "                vsg = vsg\n",
    "\n",
    "    # 状态矩阵归一化，最大最小值\n",
    "    feature_max = D_independent.max()\n",
    "    feature_min = D_independent.min()\n",
    "    D_minmax = __minmax(D_independent, feature_max, feature_min)\n",
    "    D_minmax = D_minmax.values.T\n",
    "\n",
    "    # 待预测数据归一化\n",
    "    x_minmax = __minmax(x_independent, feature_max, feature_min)\n",
    "    if len(x_independent.shape) == 1:\n",
    "        x_minmax = x_minmax.values.reshape((1, -1))\n",
    "    else:\n",
    "        x_minmax = x_minmax.values\n",
    "\n",
    "    # 异常值处理方式：置空并空值填充或者VSG\n",
    "    if vsg:\n",
    "        x_out_minmax = __vsg(D_minmax, x_minmax, ms, dist_metric)\n",
    "    else:\n",
    "        x_out_minmax = __fillna(D_minmax, x_minmax, ms, dist_metric)\n",
    "\n",
    "    x_out_minmax = pd.DataFrame(x_out_minmax, columns=columns)\n",
    "\n",
    "    # 反归一化\n",
    "    x_out = __minmax(x_out_minmax, feature_max, feature_min, inverse=True)\n",
    "\n",
    "    # 拼接时间列\n",
    "    if time_tag != None:\n",
    "        x_out_time = x_in.loc[:, time_tag]\n",
    "        x_out = pd.concat([x_out_time, x_out], axis=1)\n",
    "    else:\n",
    "        x_out = x_out\n",
    "\n",
    "    return x_out\n",
    "\n",
    "\n",
    "# 计算评估指标\n",
    "def eval(x_in: DataFrame,\n",
    "         x_out: DataFrame,\n",
    "         time_tag: Union[str, None] = None,\n",
    "         eval_metrics: str = 'rmse') -> float:\n",
    "    \"\"\"\n",
    "    计算评估指标\n",
    "\n",
    "    参数说明\n",
    "    ----------\n",
    "    x_in : {DataFrame} of shape (n_samples, n_features)\n",
    "        输入数据\n",
    "    x_out : {DataFrame} of shape (n_samples, n_features)\n",
    "        预测数据\n",
    "    time_tag : {str}\n",
    "        时间标签，如果为None，默认数据中不含时间特征\n",
    "    eval_metrics : {str}\n",
    "        评估指标值，可选'r2'和'rmse'\n",
    "\n",
    "    返回值\n",
    "    -------\n",
    "    eval_value : {float}\n",
    "        评估值\n",
    "    \"\"\"\n",
    "    # 输入数据判断类型\n",
    "    if not isinstance(x_in, DataFrame):\n",
    "        raise TypeError('x_in should be of DataFrame type!')\n",
    "    if not isinstance(x_out, DataFrame):\n",
    "        raise TypeError('x_out should be of DataFrame type!')\n",
    "    if time_tag != None:\n",
    "        if not isinstance(time_tag, str):\n",
    "            raise TypeError('time_tag should be of str type!')\n",
    "    if eval_metrics not in ['r2', 'rmse']:\n",
    "        raise ValueError('eval_metrics should be one of \"r2\" or \"rmse\"!')\n",
    "\n",
    "    # 规范化数据\n",
    "    x_in = x_in.reset_index(drop=True)\n",
    "    x_out = x_out.reset_index(drop=True)\n",
    "\n",
    "    # 选取时间列\n",
    "    if time_tag != None:\n",
    "        no_time_tags = [i for i in x_in.columns if i != time_tag]\n",
    "        x_in[time_tag] = pd.to_datetime(x_in[time_tag])\n",
    "        x_in_no_time = x_in.loc[:, no_time_tags].astype('float32')\n",
    "        x_out[time_tag] = pd.to_datetime(x_out[time_tag])\n",
    "        x_out_no_time = x_out.loc[:, no_time_tags].astype('float32')\n",
    "    else:\n",
    "        x_in_no_time = x_in.astype('float32')\n",
    "        x_out_no_time = x_out.astype('float32')\n",
    "\n",
    "    # 缺失值索引\n",
    "    nan_index = set(np.where(np.isnan(x_in_no_time.values))[0])\n",
    "    no_nan_index = list(set(range(x_in_no_time.shape[0])) - nan_index)\n",
    "\n",
    "    # 删除缺失值\n",
    "    x_in_no_nan = x_in_no_time.iloc[no_nan_index, :]\n",
    "    x_out_no_nan = x_out_no_time.iloc[no_nan_index, :]\n",
    "\n",
    "    #     # 计算偏差值\n",
    "    #     RES = x_in_no_nan - x_out_no_nan\n",
    "\n",
    "    # 计算评估指标\n",
    "    if eval_metrics == 'r2':\n",
    "        eval_value = r2_score(x_in_no_nan.values.T, x_out_no_nan.values.T)\n",
    "    elif eval_metrics == 'rmse':\n",
    "        eval_value = np.sqrt(\n",
    "            mean_squared_error(x_in_no_nan.values.T, x_out_no_nan.values.T))\n",
    "\n",
    "    return eval_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdad82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
